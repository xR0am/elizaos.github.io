["I_kwDOMT5cIs6yP4SH", 4272, "X bot doesn't reply to any mentions at all", "**Describe the bug**\n\nX bot doesn't reply to any mentions at all. Polling works, Posting works, but bot ignores all mentions.\n\n**To Reproduce**\n\n- Install elizaOS\n- add twitter logins and LLM API on .env (also using plugin-dkg but that does not trigger when my bot does not manage to reply to mentions)\n- run a character\n\n**Expected behavior**\n\nReplying to TWITTER_TARGET_USERS when mentioned. However, I see INSTRUCTIONS on the logs but nothing happens and LLM does not make a decision, and then INSTRUCTIONS keep on looping. Logs also say already responded to tweet but bot did not answer anything. Polling seems to work, actions like retweeting and liking are fine, but responding to mentions do not work. \n\n**Logs**\n\ntweet 1910392689352122568, skipping\"}\n{\"hostname\":\"x\",\"msg\":\"Already responded to tweet 1910483748778279051, skipping\"}\n{\"hostname\":\"x\",\"msg\":\"Already responded to tweet 1911051920707289251, skipping\"}\n{\"hostname\":\"x\",\"msg\":\"Already responded to tweet 1911059279173370026, skipping\"}\n{\"hostname\":\"x\",\"msg\":\"Finished checking Twitter interactions\"}\n{\"hostname\":\"x\",\"msg\":\"Attempting to generate text with context: # INSTRUCTIONS: Determine if Beezle (@otnoderunner) should respond to the message and participate in the conversation. Do not comment. Just respond with \\\"true\\\" or \\\"false\\\".\\n\\nResponse options are RESPOND, IGNORE and STOP.\\n\\nPRIORITY RULE: ALWAYS RESPOND to these users regardless of topic or message content: otnoderunner,origin_trail,chatdkg,polkabotai,gavunwud,tracverse,bioprotocol,McCaff9,Isles_Roo,luku_trac,tracktorijada,OriginTrailDev,Cryptking_1. Topic relevance should be ignored for these users.\\n\\nFor other users:\\n- Beezle should RESPOND to messages directed at them\\n- Beezle should RESPOND to conversations relevant to their background\\n- Beezle should IGNORE irrelevant messages\\n- Beezle should IGNORE very short messages unless directly addressed\\n- Beezle should STOP if asked to stop\\n- Beezle should STOP if conversation is concluded\\n- Beezle is in a room with other users and wants to be conversational, but not annoying.\\n\\nIMPORTANT:\\n- Beezle (aka @otnoderunner) is particularly sensitive about being annoying, so if there is any doubt, it is better to IGNORE than to RESPOND.\\n- For users not in the priority list, Beezle (@otnoderunner) should err on the side of IGNORE rather than RESPOND if in doubt.\\n\\nRecent Posts:\\n# Posts in Thread\\nName: Beezle (@Beezle)\\nID: 1eebbabc-deb4-0fe7-9e95-73a2b7475d20\\nDate: just now\\nText:\\n@otnoderunner what is the DKG Swarm\\n\\n\\nCurrent Post:\\n  ID: 1911059279173370026\\n  From: BRX (\ud83d\udc7e,\ud83d\udc7e) (@otnoderunner)\\n  Text: @otnoderunner what is the DKG Swarm\\n\\nThread of Tweets You Are Replying To:\\n@otnoderunner (Apr 12, 10:10 AM):\\n        @otnoderunner what is the DKG Swarm\\n\\n# INSTRUCTIONS: Respond with [RESPOND] if Beezle should respond, or [IGNORE] if Beezle should not respond to the last message and [STOP] if Beezle should stop participating in the conversation.\\nThe available options are [RESPOND], [IGNORE], or [STOP]. Choose the most appropriate option.\\nIf Beezle is talking too much, you can choose [IGNORE]\\n\\nYour response must include one of the options.\"}\n{\"hostname\":\"x\",\"msg\":\"Generating text...\"}\n{\"hostname\":\"x\",\"modelProvider\":\"google\",\"model\":\"medium\",\"verifiableInference\":false,\"msg\":\"Generating text with options:\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google\"}\n{\"hostname\":\"x\",\"provider\":\"google\",\"hasRuntime\":true,\"runtimeSettings\":{\"CLOUDFLARE_GW_ENABLED\":null,\"CLOUDFLARE_AI_ACCOUNT_ID\":null,\"CLOUDFLARE_AI_GATEWAY_ID\":null},\"msg\":\"Provider settings:\"}\n{\"hostname\":\"x\",\"msg\":\"Selected model: gemini-2.0-flash\"}\n{\"hostname\":\"x\",\"msg\":\"Trimming context to max length of 128000 tokens.\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google, model: gemini-2.0-flash, temperature: 0.7, max response length: 8192\"}\n{\"hostname\":\"x\",\"msg\":\"Fetching https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"}\n{\"hostname\":\"x\",\"msg\":\"Received response from Google model.\"}\n{\"hostname\":\"x\",\"msg\":\"Received response from generateText: true\\n\"}\n{\"hostname\":\"x\",\"msg\":\"generateShouldRespond no response\"}\n{\"hostname\":\"x\",\"msg\":\"Retrying in 256000ms...\"}\n{\"hostname\":\"x\",\"msg\":\"Processing tweet actions\"}\n{\"hostname\":\"x\",\"msg\":\"fetching timeline for actions\"}\n{\"hostname\":\"x\",\"msg\":\"Already processed tweet ID: 1910970828545466681\"}\n{\"hostname\":\"x\",\"msg\":\"Already processed tweet ID: 1911052669579374649\"}\n{\"hostname\":\"x\",\"msg\":\"Already processed tweet ID: 1911028054173897158\"}\n{\"hostname\":\"x\",\"msg\":\"Already processed tweet ID: 1910967241912238151\"}\n{\"hostname\":\"x\",\"msg\":\"Already processed tweet ID: 1910626073865335004\"}\n{\"hostname\":\"x\",\"msg\":\"Already processed tweet ID: 1910683009256480926\"}\n{\"hostname\":\"x\",\"message\":{\"userId\":\"30c33a1f-8db6-0986-8d8a-e51adec07aff\",\"roomId\":\"a7bde707-a2d0-0bf6-b9ee-7967076f66c8\",\"agentId\":\"30c33a1f-8db6-0986-8d8a-e51adec07aff\",\"content\":{\"text\":\"\",\"action\":\"\"}},\"content\":{\"text\":\"\",\"action\":\"\"},\"text\":\"\",\"msg\":\"Invalid message for knowledge query:\"}\n{\"hostname\":\"x\",\"msg\":\"Entering graph search provider!\"}\n{\"hostname\":\"x\",\"msg\":\"Got user query \\\"\\\"\"}\n{\"hostname\":\"x\",\"msg\":\"Generating text...\"}\n{\"hostname\":\"x\",\"modelProvider\":\"google\",\"model\":\"large\",\"verifiableInference\":false,\"msg\":\"Generating text with options:\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google\"}\n{\"hostname\":\"x\",\"provider\":\"google\",\"hasRuntime\":true,\"runtimeSettings\":{\"CLOUDFLARE_GW_ENABLED\":null,\"CLOUDFLARE_AI_ACCOUNT_ID\":null,\"CLOUDFLARE_AI_GATEWAY_ID\":null},\"msg\":\"Provider settings:\"}\n{\"hostname\":\"x\",\"msg\":\"Selected model: gemini-2.0-flash\"}\n{\"hostname\":\"x\",\"msg\":\"Trimming context to max length of 128000 tokens.\"}\n{\"hostname\":\"x\",\"msg\":\"Entering graph search provider!\"}\n{\"hostname\":\"x\",\"msg\":\"Got user query \\\"\\\"\"}\n{\"hostname\":\"x\",\"msg\":\"Generating text...\"}\n{\"hostname\":\"x\",\"modelProvider\":\"google\",\"model\":\"large\",\"verifiableInference\":false,\"msg\":\"Generating text with options:\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google\"}\n{\"hostname\":\"x\",\"provider\":\"google\",\"hasRuntime\":true,\"runtimeSettings\":{\"CLOUDFLARE_GW_ENABLED\":null,\"CLOUDFLARE_AI_ACCOUNT_ID\":null,\"CLOUDFLARE_AI_GATEWAY_ID\":null},\"msg\":\"Provider settings:\"}\n{\"hostname\":\"x\",\"msg\":\"Selected model: gemini-2.0-flash\"}\n{\"hostname\":\"x\",\"msg\":\"Trimming context to max length of 128000 tokens.\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google, model: gemini-2.0-flash, temperature: 0.7, max response length: 8192\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google, model: gemini-2.0-flash, temperature: 0.7, max response length: 8192\"}\n{\"hostname\":\"x\",\"msg\":\"Fetching https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"}\n{\"hostname\":\"x\",\"msg\":\"Fetching https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"}\n{\"hostname\":\"x\",\"msg\":\"Received response from Google model.\"}\n{\"hostname\":\"x\",\"msg\":\"Generated SPARQL query: SELECT DISTINCT ?headline ?articleBody\\nWHERE {\\n  ?s a <http://schema.org/SocialMediaPosting> .\\n  ?s <http://schema.org/headline> ?headline .\\n  ?s <http://schema.org/articleBody> ?articleBody .\\n\\n  OPTIONAL {\\n    ?s <http://schema.org/keywords> ?keyword .\\n    ?keyword <http://schema.org/name> ?keywordName .\\n  }\\n\\n  OPTIONAL {\\n    ?s <http://schema.org/about> ?about .\\n    ?about <http://schema.org/name> ?aboutName .\\n  }\\n}\\nLIMIT 10\"}\n{\"hostname\":\"x\",\"msg\":\"Received response from Google model.\"}\n{\"hostname\":\"x\",\"msg\":\"Generated SPARQL query: SELECT DISTINCT ?headline ?articleBody\\nWHERE {\\n  ?s a <http://schema.org/SocialMediaPosting> .\\n  ?s <http://schema.org/headline> ?headline .\\n  ?s <http://schema.org/articleBody> ?articleBody .\\n\\n  OPTIONAL {\\n    ?s <http://schema.org/keywords> ?keyword .\\n    ?keyword <http://schema.org/name> ?keywordName .\\n  }\\n\\n  OPTIONAL {\\n    ?s <http://schema.org/about> ?about .\\n    ?about <http://schema.org/name> ?aboutName .\\n  }\\n}\\nLIMIT 10\"}\n{\"hostname\":\"x\",\"msg\":\"Got 10 results from the DKG\"}\n{\"hostname\":\"x\",\"msg\":\"Got 10 results from the DKG\"}\n{\"hostname\":\"x\",\"msg\":\"Generating text...\"}\n{\"hostname\":\"x\",\"modelProvider\":\"google\",\"model\":\"small\",\"verifiableInference\":false,\"msg\":\"Generating text with options:\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google\"}\n{\"hostname\":\"x\",\"provider\":\"google\",\"hasRuntime\":true,\"runtimeSettings\":{\"CLOUDFLARE_GW_ENABLED\":null,\"CLOUDFLARE_AI_ACCOUNT_ID\":null,\"CLOUDFLARE_AI_GATEWAY_ID\":null},\"msg\":\"Provider settings:\"}\n{\"hostname\":\"x\",\"msg\":\"Selected model: gemini-2.0-flash-lite\"}\n{\"hostname\":\"x\",\"msg\":\"Trimming context to max length of 128000 tokens.\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google, model: gemini-2.0-flash-lite, temperature: 0.7, max response length: 8192\"}\n{\"hostname\":\"x\",\"msg\":\"Fetching https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent\"}\n{\"hostname\":\"x\",\"msg\":\"Received response from Google model.\"}\nApr 12 10:15:31 bash[323578]: Received response from generateText for tweet actions: NO ACTION\nApr 12 10:15:31 bash[323578]: Parsed tweet actions: { like: false, retweet: false, quote: false, reply: false }\n{\"hostname\":\"x\",\"msg\":\"Already processed tweet ID: 1910845414674468897\"}\n{\"hostname\":\"x\",\"message\":{\"userId\":\"30c33a1f-8db6-0986-8d8a-e51adec07aff\",\"roomId\":\"d912e10b-8c24-0ff7-a59f-a6db7d81c37e\",\"agentId\":\"30c33a1f-8db6-0986-8d8a-e51adec07aff\",\"content\":{\"text\":\"\",\"action\":\"\"}},\"content\":{\"text\":\"\",\"action\":\"\"},\"text\":\"\",\"msg\":\"Invalid message for knowledge query:\"}\n{\"hostname\":\"x\",\"msg\":\"Entering graph search provider!\"}\n{\"hostname\":\"x\",\"msg\":\"Got user query \\\"\\\"\"}\n{\"hostname\":\"x\",\"msg\":\"Generating text...\"}\n{\"hostname\":\"x\",\"modelProvider\":\"google\",\"model\":\"large\",\"verifiableInference\":false,\"msg\":\"Generating text with options:\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google\"}\n{\"hostname\":\"x\",\"provider\":\"google\",\"hasRuntime\":true,\"runtimeSettings\":{\"CLOUDFLARE_GW_ENABLED\":null,\"CLOUDFLARE_AI_ACCOUNT_ID\":null,\"CLOUDFLARE_AI_GATEWAY_ID\":null},\"msg\":\"Provider settings:\"}\n{\"hostname\":\"x\",\"msg\":\"Selected model: gemini-2.0-flash\"}\n{\"hostname\":\"x\",\"msg\":\"Trimming context to max length of 128000 tokens.\"}\n{\"hostname\":\"x\",\"msg\":\"Entering graph search provider!\"}\n{\"hostname\":\"x\",\"msg\":\"Got user query \\\"\\\"\"}\n{\"hostname\":\"x\",\"msg\":\"Generating text...\"}\n{\"hostname\":\"x\",\"modelProvider\":\"google\",\"model\":\"large\",\"verifiableInference\":false,\"msg\":\"Generating text with options:\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google\"}\n{\"hostname\":\"x\",\"provider\":\"google\",\"hasRuntime\":true,\"runtimeSettings\":{\"CLOUDFLARE_GW_ENABLED\":null,\"CLOUDFLARE_AI_ACCOUNT_ID\":null,\"CLOUDFLARE_AI_GATEWAY_ID\":null},\"msg\":\"Provider settings:\"}\n{\"hostname\":\"x\",\"msg\":\"Selected model: gemini-2.0-flash\"}\n{\"hostname\":\"x\",\"msg\":\"Trimming context to max length of 128000 tokens.\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google, model: gemini-2.0-flash, temperature: 0.7, max response length: 8192\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google, model: gemini-2.0-flash, temperature: 0.7, max response length: 8192\"}\n{\"hostname\":\"x\",\"msg\":\"Fetching https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"}\n{\"hostname\":\"x\",\"msg\":\"Fetching https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"}\n{\"hostname\":\"x\",\"msg\":\"Received response from Google model.\"}\n{\"hostname\":\"x\",\"msg\":\"Generated SPARQL query: SELECT DISTINCT ?headline ?articleBody\\nWHERE {\\n  ?s a <http://schema.org/SocialMediaPosting> .\\n  ?s <http://schema.org/headline> ?headline .\\n  ?s <http://schema.org/articleBody> ?articleBody .\\n\\n  OPTIONAL {\\n    ?s <http://schema.org/keywords> ?keyword .\\n    ?keyword <http://schema.org/name> ?keywordName .\\n  }\\n\\n  OPTIONAL {\\n    ?s <http://schema.org/about> ?about .\\n    ?about <http://schema.org/name> ?aboutName .\\n  }\\n}\\nLIMIT 10\"}\n{\"hostname\":\"x\",\"msg\":\"Received response from Google model.\"}\n{\"hostname\":\"x\",\"msg\":\"Generated SPARQL query: SELECT DISTINCT ?headline ?articleBody\\nWHERE {\\n  ?s a <http://schema.org/SocialMediaPosting> .\\n  ?s <http://schema.org/headline> ?headline .\\n  ?s <http://schema.org/articleBody> ?articleBody .\\n\\n  OPTIONAL {\\n    ?s <http://schema.org/keywords> ?keyword .\\n    ?keyword <http://schema.org/name> ?keywordName .\\n  }\\n\\n  OPTIONAL {\\n    ?s <http://schema.org/about> ?about .\\n    ?about <http://schema.org/name> ?aboutName .\\n  }\\n\\n}\\nLIMIT 10\"}\n{\"hostname\":\"x\",\"msg\":\"Got 10 results from the DKG\"}\n{\"hostname\":\"x\",\"msg\":\"Got 10 results from the DKG\"}\n{\"hostname\":\"x\",\"msg\":\"Generating text...\"}\n{\"hostname\":\"x\",\"modelProvider\":\"google\",\"model\":\"small\",\"verifiableInference\":false,\"msg\":\"Generating text with options:\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google\"}\n{\"hostname\":\"x\",\"provider\":\"google\",\"hasRuntime\":true,\"runtimeSettings\":{\"CLOUDFLARE_GW_ENABLED\":null,\"CLOUDFLARE_AI_ACCOUNT_ID\":null,\"CLOUDFLARE_AI_GATEWAY_ID\":null},\"msg\":\"Provider settings:\"}\n{\"hostname\":\"x\",\"msg\":\"Selected model: gemini-2.0-flash-lite\"}\n{\"hostname\":\"x\",\"msg\":\"Trimming context to max length of 128000 tokens.\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google, model: gemini-2.0-flash-lite, temperature: 0.7, max response length: 8192\"}\n{\"hostname\":\"x\",\"msg\":\"Fetching https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent\"}\n{\"hostname\":\"x\",\"msg\":\"Received response from Google model.\"}\nApr 12 10:15:34 bash[323578]: Received response from generateText for tweet actions: NO ACTION\nApr 12 10:15:34 bash[323578]: Parsed tweet actions: { like: false, retweet: false, quote: false, reply: false }\n{\"hostname\":\"x\",\"message\":{\"userId\":\"30c33a1f-8db6-0986-8d8a-e51adec07aff\",\"roomId\":\"17c71637-9530-02d8-b33d-bba749026b5b\",\"agentId\":\"30c33a1f-8db6-0986-8d8a-e51adec07aff\",\"content\":{\"text\":\"\",\"action\":\"\"}},\"content\":{\"text\":\"\",\"action\":\"\"},\"text\":\"\",\"msg\":\"Invalid message for knowledge query:\"}\n{\"hostname\":\"x\",\"msg\":\"Entering graph search provider!\"}\n{\"hostname\":\"x\",\"msg\":\"Got user query \\\"\\\"\"}\n{\"hostname\":\"x\",\"msg\":\"Generating text...\"}\n{\"hostname\":\"x\",\"modelProvider\":\"google\",\"model\":\"large\",\"verifiableInference\":false,\"msg\":\"Generating text with options:\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google\"}\n{\"hostname\":\"x\",\"provider\":\"google\",\"hasRuntime\":true,\"runtimeSettings\":{\"CLOUDFLARE_GW_ENABLED\":null,\"CLOUDFLARE_AI_ACCOUNT_ID\":null,\"CLOUDFLARE_AI_GATEWAY_ID\":null},\"msg\":\"Provider settings:\"}\n{\"hostname\":\"x\",\"msg\":\"Selected model: gemini-2.0-flash\"}\n{\"hostname\":\"x\",\"msg\":\"Trimming context to max length of 128000 tokens.\"}\n{\"hostname\":\"x\",\"msg\":\"Entering graph search provider!\"}\n{\"hostname\":\"x\",\"msg\":\"Got user query \\\"\\\"\"}\n{\"hostname\":\"x\",\"msg\":\"Generating text...\"}\n{\"hostname\":\"x\",\"modelProvider\":\"google\",\"model\":\"large\",\"verifiableInference\":false,\"msg\":\"Generating text with options:\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google\"}\n{\"hostname\":\"x\",\"provider\":\"google\",\"hasRuntime\":true,\"runtimeSettings\":{\"CLOUDFLARE_GW_ENABLED\":null,\"CLOUDFLARE_AI_ACCOUNT_ID\":null,\"CLOUDFLARE_AI_GATEWAY_ID\":null},\"msg\":\"Provider settings:\"}\n{\"hostname\":\"x\",\"msg\":\"Selected model: gemini-2.0-flash\"}\n{\"hostname\":\"x\",\"msg\":\"Trimming context to max length of 128000 tokens.\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google, model: gemini-2.0-flash, temperature: 0.7, max response length: 8192\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google, model: gemini-2.0-flash, temperature: 0.7, max response length: 8192\"}\n{\"hostname\":\"x\",\"msg\":\"Fetching https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"}\n{\"hostname\":\"x\",\"msg\":\"Fetching https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"}\n{\"hostname\":\"x\",\"msg\":\"Received response from Google model.\"}\n{\"hostname\":\"x\",\"msg\":\"Generated SPARQL query: SELECT DISTINCT ?headline ?articleBody\\nWHERE {\\n  ?s a <http://schema.org/SocialMediaPosting> .\\n  ?s <http://schema.org/headline> ?headline .\\n  ?s <http://schema.org/articleBody> ?articleBody .\\n\\n  OPTIONAL {\\n    ?s <http://schema.org/keywords> ?keyword .\\n    ?keyword <http://schema.org/name> ?keywordName .\\n  }\\n\\n  OPTIONAL {\\n    ?s <http://schema.org/about> ?about .\\n    ?about <http://schema.org/name> ?aboutName .\\n  }\\n\\n}\\nLIMIT 10\"}\n{\"hostname\":\"x\",\"msg\":\"Received response from Google model.\"}\n{\"hostname\":\"x\",\"msg\":\"Generated SPARQL query: SELECT DISTINCT ?headline ?articleBody\\nWHERE {\\n  ?s a <http://schema.org/SocialMediaPosting> .\\n  ?s <http://schema.org/headline> ?headline .\\n  ?s <http://schema.org/articleBody> ?articleBody .\\n\\n  OPTIONAL {\\n    ?s <http://schema.org/keywords> ?keyword .\\n    ?keyword <http://schema.org/name> ?keywordName .\\n  }\\n\\n  OPTIONAL {\\n    ?s <http://schema.org/about> ?about .\\n    ?about <http://schema.org/name> ?aboutName .\\n  }\\n\\n}\\nLIMIT 10\"}\n{\"hostname\":\"x\",\"msg\":\"Got 10 results from the DKG\"}\n{\"hostname\":\"x\",\"msg\":\"Got 10 results from the DKG\"}\n{\"hostname\":\"x\",\"msg\":\"Generating text...\"}\n{\"hostname\":\"x\",\"modelProvider\":\"google\",\"model\":\"small\",\"verifiableInference\":false,\"msg\":\"Generating text with options:\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google\"}\n{\"hostname\":\"x\",\"provider\":\"google\",\"hasRuntime\":true,\"runtimeSettings\":{\"CLOUDFLARE_GW_ENABLED\":null,\"CLOUDFLARE_AI_ACCOUNT_ID\":null,\"CLOUDFLARE_AI_GATEWAY_ID\":null},\"msg\":\"Provider settings:\"}\n{\"hostname\":\"x\",\"msg\":\"Selected model: gemini-2.0-flash-lite\"}\n{\"hostname\":\"x\",\"msg\":\"Trimming context to max length of 128000 tokens.\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google, model: gemini-2.0-flash-lite, temperature: 0.7, max response length: 8192\"}\n{\"hostname\":\"x\",\"msg\":\"Fetching https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent\"}\n{\"hostname\":\"x\",\"msg\":\"Checking Twitter interactions\"}\n{\"hostname\":\"x\",\"msg\":\"Received response from Google model.\"}\nApr 12 10:15:37 bash[323578]: Received response from generateText for tweet actions: NO ACTION\nApr 12 10:15:37 bash[323578]: Parsed tweet actions: { like: false, retweet: false, quote: false, reply: false }\n{\"hostname\":\"x\",\"message\":{\"userId\":\"30c33a1f-8db6-0986-8d8a-e51adec07aff\",\"roomId\":\"5bd6ecf7-33e6-0b4a-9e03-8e445cdc9fd9\",\"agentId\":\"30c33a1f-8db6-0986-8d8a-e51adec07aff\",\"content\":{\"text\":\"\",\"action\":\"\"}},\"content\":{\"text\":\"\",\"action\":\"\"},\"text\":\"\",\"msg\":\"Invalid message for knowledge query:\"}\n{\"hostname\":\"x\",\"msg\":\"Entering graph search provider!\"}\n{\"hostname\":\"x\",\"msg\":\"Got user query \\\"\\\"\"}\n{\"hostname\":\"x\",\"msg\":\"Generating text...\"}\n{\"hostname\":\"x\",\"modelProvider\":\"google\",\"model\":\"large\",\"verifiableInference\":false,\"msg\":\"Generating text with options:\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google\"}\n{\"hostname\":\"x\",\"provider\":\"google\",\"hasRuntime\":true,\"runtimeSettings\":{\"CLOUDFLARE_GW_ENABLED\":null,\"CLOUDFLARE_AI_ACCOUNT_ID\":null,\"CLOUDFLARE_AI_GATEWAY_ID\":null},\"msg\":\"Provider settings:\"}\n{\"hostname\":\"x\",\"msg\":\"Selected model: gemini-2.0-flash\"}\n{\"hostname\":\"x\",\"msg\":\"Trimming context to max length of 128000 tokens.\"}\n{\"hostname\":\"x\",\"msg\":\"Entering graph search provider!\"}\n{\"hostname\":\"x\",\"msg\":\"Got user query \\\"\\\"\"}\n{\"hostname\":\"x\",\"msg\":\"Generating text...\"}\n{\"hostname\":\"x\",\"modelProvider\":\"google\",\"model\":\"large\",\"verifiableInference\":false,\"msg\":\"Generating text with options:\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google\"}\n{\"hostname\":\"x\",\"provider\":\"google\",\"hasRuntime\":true,\"runtimeSettings\":{\"CLOUDFLARE_GW_ENABLED\":null,\"CLOUDFLARE_AI_ACCOUNT_ID\":null,\"CLOUDFLARE_AI_GATEWAY_ID\":null},\"msg\":\"Provider settings:\"}\n{\"hostname\":\"x\",\"msg\":\"Selected model: gemini-2.0-flash\"}\n{\"hostname\":\"x\",\"msg\":\"Trimming context to max length of 128000 tokens.\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google, model: gemini-2.0-flash, temperature: 0.7, max response length: 8192\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google, model: gemini-2.0-flash, temperature: 0.7, max response length: 8192\"}\n{\"hostname\":\"x\",\"msg\":\"Fetching https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"}\n{\"hostname\":\"x\",\"msg\":\"Fetching https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"}\n{\"hostname\":\"x\",\"msg\":\"Completed checking mentioned tweets:\"}\n{\"hostname\":\"x\",\"0\":\"otnoderunner\",\"1\":\"origin_trail\",\"2\":\"chatdkg\",\"3\":\"polkabotai\",\"4\":\"gavunwud\",\"5\":\"tracverse\",\"6\":\"bioprotocol\",\"7\":\"McCaff9\",\"8\":\"Isles_Roo\",\"9\":\"luku_trac\",\"10\":\"tracktorijada\",\"11\":\"OriginTrailDev\",\"12\":\"Cryptking_1\",\"msg\":\"Processing target users:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":true,\"isReply\":false,\"isRetweet\":false,\"msg\":\"Tweet 1911059279173370026 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":true,\"isReply\":false,\"isRetweet\":false,\"msg\":\"Tweet 1911058650543649219 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":true,\"isReply\":false,\"isRetweet\":false,\"msg\":\"Tweet 1911051920707289251 checks:\"}\n{\"hostname\":\"x\",\"msg\":\"Found 3 valid tweets from otnoderunner\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1910711490656534753 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":false,\"isRetweet\":false,\"msg\":\"Tweet 1910711488555208832 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1910626077136892338 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":true,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1911052223443788241 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":true,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1911052036029763645 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":true,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1911034008567242799 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":true,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1911046305213710542 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":true,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1911046163697926512 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1911027694134857838 checks:\"}\n{\"hostname\":\"x\",\"msg\":\"Received response from Google model.\"}\n{\"hostname\":\"x\",\"msg\":\"Generated SPARQL query: SELECT DISTINCT ?headline ?articleBody\\nWHERE {\\n  ?s a <http://schema.org/SocialMediaPosting> .\\n  ?s <http://schema.org/headline> ?headline .\\n  ?s <http://schema.org/articleBody> ?articleBody .\\n\\n  OPTIONAL {\\n    ?s <http://schema.org/keywords> ?keyword .\\n    ?keyword <http://schema.org/name> ?keywordName .\\n  }\\n\\n  OPTIONAL {\\n    ?s <http://schema.org/about> ?about .\\n    ?about <http://schema.org/name> ?aboutName .\\n  }\\n}\\nLIMIT 10\"}\n{\"hostname\":\"x\",\"msg\":\"Received response from Google model.\"}\n{\"hostname\":\"x\",\"msg\":\"Generated SPARQL query: SELECT DISTINCT ?headline ?articleBody\\n    WHERE {\\n      ?s a <http://schema.org/SocialMediaPosting> .\\n      ?s <http://schema.org/headline> ?headline .\\n      ?s <http://schema.org/articleBody> ?articleBody .\\n\\n      OPTIONAL {\\n        ?s <http://schema.org/keywords> ?keyword .\\n        ?keyword <http://schema.org/name> ?keywordName .\\n      }\\n\\n      OPTIONAL {\\n        ?s <http://schema.org/about> ?about .\\n        ?about <http://schema.org/name> ?aboutName .\\n      }\\n\\n    }\\n    LIMIT 10\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":false,\"isRetweet\":false,\"msg\":\"Tweet 1910290415892193710 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":false,\"isRetweet\":false,\"msg\":\"Tweet 1910031387404730430 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1910028416910319985 checks:\"}\n{\"hostname\":\"x\",\"msg\":\"Got 10 results from the DKG\"}\n{\"hostname\":\"x\",\"msg\":\"Got 10 results from the DKG\"}\n{\"hostname\":\"x\",\"msg\":\"Generating text...\"}\n{\"hostname\":\"x\",\"modelProvider\":\"google\",\"model\":\"small\",\"verifiableInference\":false,\"msg\":\"Generating text with options:\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google\"}\n{\"hostname\":\"x\",\"provider\":\"google\",\"hasRuntime\":true,\"runtimeSettings\":{\"CLOUDFLARE_GW_ENABLED\":null,\"CLOUDFLARE_AI_ACCOUNT_ID\":null,\"CLOUDFLARE_AI_GATEWAY_ID\":null},\"msg\":\"Provider settings:\"}\n{\"hostname\":\"x\",\"msg\":\"Selected model: gemini-2.0-flash-lite\"}\n{\"hostname\":\"x\",\"msg\":\"Trimming context to max length of 128000 tokens.\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google, model: gemini-2.0-flash-lite, temperature: 0.7, max response length: 8192\"}\n{\"hostname\":\"x\",\"msg\":\"Fetching https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1910772066296406468 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1910717579951579501 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1910717568228434135 checks:\"}\n{\"hostname\":\"x\",\"msg\":\"Received response from Google model.\"}\nApr 12 10:15:39 bash[323578]: Received response from generateText for tweet actions: NO ACTION\nApr 12 10:15:39 bash[323578]: Parsed tweet actions: { like: false, retweet: false, quote: false, reply: false }\n{\"hostname\":\"x\",\"message\":{\"userId\":\"30c33a1f-8db6-0986-8d8a-e51adec07aff\",\"roomId\":\"76e8533e-52f9-0237-ae78-a0658b34c888\",\"agentId\":\"30c33a1f-8db6-0986-8d8a-e51adec07aff\",\"content\":{\"text\":\"\",\"action\":\"\"}},\"content\":{\"text\":\"\",\"action\":\"\"},\"text\":\"\",\"msg\":\"Invalid message for knowledge query:\"}\n{\"hostname\":\"x\",\"msg\":\"Entering graph search provider!\"}\n{\"hostname\":\"x\",\"msg\":\"Got user query \\\"\\\"\"}\n{\"hostname\":\"x\",\"msg\":\"Generating text...\"}\n{\"hostname\":\"x\",\"modelProvider\":\"google\",\"model\":\"large\",\"verifiableInference\":false,\"msg\":\"Generating text with options:\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google\"}\n{\"hostname\":\"x\",\"provider\":\"google\",\"hasRuntime\":true,\"runtimeSettings\":{\"CLOUDFLARE_GW_ENABLED\":null,\"CLOUDFLARE_AI_ACCOUNT_ID\":null,\"CLOUDFLARE_AI_GATEWAY_ID\":null},\"msg\":\"Provider settings:\"}\n{\"hostname\":\"x\",\"msg\":\"Selected model: gemini-2.0-flash\"}\n{\"hostname\":\"x\",\"msg\":\"Trimming context to max length of 128000 tokens.\"}\n{\"hostname\":\"x\",\"msg\":\"Entering graph search provider!\"}\n{\"hostname\":\"x\",\"msg\":\"Got user query \\\"\\\"\"}\n{\"hostname\":\"x\",\"msg\":\"Generating text...\"}\n{\"hostname\":\"x\",\"modelProvider\":\"google\",\"model\":\"large\",\"verifiableInference\":false,\"msg\":\"Generating text with options:\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google\"}\n{\"hostname\":\"x\",\"provider\":\"google\",\"hasRuntime\":true,\"runtimeSettings\":{\"CLOUDFLARE_GW_ENABLED\":null,\"CLOUDFLARE_AI_ACCOUNT_ID\":null,\"CLOUDFLARE_AI_GATEWAY_ID\":null},\"msg\":\"Provider settings:\"}\n{\"hostname\":\"x\",\"msg\":\"Selected model: gemini-2.0-flash\"}\n{\"hostname\":\"x\",\"msg\":\"Trimming context to max length of 128000 tokens.\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google, model: gemini-2.0-flash, temperature: 0.7, max response length: 8192\"}\n{\"hostname\":\"x\",\"msg\":\"Using provider: google, model: gemini-2.0-flash, temperature: 0.7, max response length: 8192\"}\n{\"hostname\":\"x\",\"msg\":\"Fetching https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"}\n{\"hostname\":\"x\",\"msg\":\"Fetching https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1910376960477593675 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1908807674344374462 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1908283871059468623 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":false,\"isRetweet\":false,\"msg\":\"Tweet 1910396220536734016 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1910392689352122568 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1910366361097757117 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1911002769915363502 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1910086568087269770 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1909992023739736573 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1910381635612123394 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":false,\"isRetweet\":false,\"msg\":\"Tweet 1910380593751130393 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1910005231494005009 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1910069333604118964 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":false,\"isRetweet\":false,\"msg\":\"Tweet 1909966058527879291 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":false,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1909637430233510348 checks:\"}\n{\"hostname\":\"x\",\"msg\":\"Received response from Google model.\"}\n{\"hostname\":\"x\",\"msg\":\"Generated SPARQL query: SELECT DISTINCT ?headline ?articleBody\\nWHERE {\\n  ?s a <http://schema.org/SocialMediaPosting> .\\n  ?s <http://schema.org/headline> ?headline .\\n  ?s <http://schema.org/articleBody> ?articleBody .\\n\\n  OPTIONAL {\\n    ?s <http://schema.org/keywords> ?keyword .\\n    ?keyword <http://schema.org/name> ?keywordName .\\n  }\\n\\n  OPTIONAL {\\n    ?s <http://schema.org/about> ?about .\\n    ?about <http://schema.org/name> ?aboutName .\\n  }\\n}\\nLIMIT 10\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":true,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1911059244763275630 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":true,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1911059157702127700 checks:\"}\n{\"hostname\":\"x\",\"isUnprocessed\":true,\"isRecent\":true,\"isReply\":true,\"isRetweet\":false,\"msg\":\"Tweet 1911059075925757979 checks:\"}\n{\"hostname\":\"x\",\"msg\":\"Selected tweet from otnoderunner: @BeezleSwarm tell me about the DKG Swarm\"}\n{\"hostname\":\"x\",\"msg\":\"Already responded to tweet 1909399131371741521, skipping\"}\n{\"hostname\":\"x\",\"msg\":\"Already responded to tweet 1909501635765977423, skipping\"}\n{\"hostname\":\"x\",\"msg\":\"Already responded to tweet 1909836799251280198, skipping\"}\n{\"hostname\":\"x\",\"msg\":\"Already responded to tweet 1910004733206495242, skipping\"}\n{\"hostname\":\"x\",\"msg\":\"Already responded to tweet 1910005231494005009, skipping\"}\n{\"hostname\":\"x\",\"msg\":\"Already responded to tweet 1910376960477593675, skipping\"}\n{\"hostname\":\"x\",\"msg\":\"Already responded to tweet 1910377441370997086, skipping\"}\n{\"hostname\":\"x\",\"msg\":\"Already responded to tweet 1910386425532735904, skipping\"}\n{\"hostname\":\"x\",\"msg\":\"Already responded to tweet 1910392689352122568, skipping\"}\n", "OPEN", 0, "Valcyclovir", "2025-04-12T14:39:06Z", "2025-04-15T13:04:01Z", null, "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6yNdfB", 4269, "Discord doens't reply when deployed with docker on google cloud run", "I\u2019ve deployed via Docker on Google Cloud Run. The bot comes online, and I can see it active. I\u2019m also able to log messages in Cloud Run, confirming it\u2019s receiving messages. However, the bot does not reply to any messages. When running the bot locally, it responds perfectly. Has someone experienced smth similiar with docker and cloudrun?", "CLOSED", 0, "jiggyjo11", "2025-04-11T22:55:15Z", "2025-04-12T20:29:43Z", "2025-04-12T20:29:10Z", "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6yBHYI", 4260, "chore: Update community section", "Gathering some ideas and sharing notes on how to improve the community section of docs\n\n\n## AI recommendations\n\n1. **Enhance the Navigation Flowchart** - Add clear paths for both technical and non-technical users, with complexity increasing as users go deeper.\n\n2. **Create a Prominent FAQ Section** - Develop a comprehensive, searchable FAQ that addresses the recurring questions mentioned by respondents.\n\n3. **Add a Clear \"Getting Started\" Guide** - Provide step-by-step instructions for different user types (developers, AI researchers, content creators).\n\n4. **Develop Use Case Examples** - Showcase practical applications that demonstrate real value (addressing the \"useless AI agent\" concern).\n\n5. **Clarify Project Direction** - Include a current roadmap and priorities section that's regularly updated to keep the community aligned.\n\n6. **Highlight Active Community Spaces** - Emphasize where meaningful discussions are happening (coder's channel, braintrust telegram).\n\n7. **Create a Community Structure Overview** - Outline how the community is organized, key working groups, and how decisions are made.\n\n8. **Include Non-Developer Contribution Paths** - Document how non-technical people can contribute (documentation, testing, community management, content creation).\n\n---\n\n## Notes\n\nVision: What We're Building Together\n\nThe internet is transforming, launching an agent is the new launching a new website. We're building:\n\n- **AI agents we can trust**, true ownership via free open source software and native TEE integration\n- **Seamless integration**, meeting us on platforms where we already spend our time\n- **Autonomous systems collaborate in swarms**, sharing context and solving complex problems together\n- **Sustainable community-driven development**, enabled by transparent AI assisted governance\n\n\nProject History\n\nWhat began as ai16z, a venture capital DAO led by AI agents on the Solana blockchain, has grown into a comprehensive open-source framework for building, deploying, and managing AI agents across platforms.\n\n- **October 2024**: Launched on Solana via daos.fun, raising 420.69 SOL\n- **November-December 2024**: Explosive growth in contributors, GitHub stars, and community engagement\n- **January 2025**: Rebranded from ai16z to ElizaOS, focusing on broader AI agent development\n- **March 2025**: Launched research beta of ElizaOS V2, representing a major architectural evolution\n\n\n```\n## Contributing to the ElizaOS DAO: High-Level Overview\n\n### Core Goals\n- Help build AI agents using the Eliza framework\n- Support democratized venture capital through AI-driven decisions\n- Advance the integration of AI and blockchain technologies\n\n### Impactful Contributions\n1. **Technical**: Code contributions to the Eliza framework, building new AI agents, or creating integrations\n \n2. **Governance**: Proposing investments, participating in token votes, and helping shape the project's direction\n\n3. **Strategy**: Researching investment opportunities, contributing to tokenomics discussions, organizing information\n\n4. **Community**: Creating educational content, onboarding developers, and representing the project to wider audiences\n```\n\nother ways to contribute:\n\n```\n- **Answer questions** in the coders/tech support channels\u2014it gets noticed!\n- **Help with documentation**: Test steps, verify information, create issues and PRs\n- **Collaborate on AI news aggregation**: Generate show ideas or automations using our tools\n- **Develop specialized agents**: Create community scribes, lore keepers, moderators, or social media managers\n- **Build plugins**: Extend the ElizaOS framework with new capabilities\n- **Join community events**: Participate in our evolving formats for community coordination and project showcasing\n\n```\n\ntokenomics page: https://hackmd.io/EK6vGnyHT0WnFIL9P4nsQA\n", "OPEN", 0, "madjin", "2025-04-10T19:10:58Z", "2025-04-10T19:10:58Z", null, "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6yABLy", 4258, "discord client not loading on pnpm start", "**Describe the bug**\n\nAltough the character.json contains the right settings, the discord client is not getting loaded. I closely followed the steps from this tutorial [AI Agent Dev School 1 pt 2](https://www.youtube.com/watch?v=AC3h_KzLARo&t=3870s) . in the console, there is no indication that eliza tried to load discord at all. ENVs are set. \n\n```\n{\n    \"name\": \"Aubrai\",\n    \"username\": \"aubrai\",\n    \"plugins\": [],\n    \"clients\": [\"discord\", \"direct\"],\n    \"modelProvider\": \"together\",\n    \"settings\": {\n        \"secrets\": {\n            \"DISCORD_APPLICATION_ID\": \"1359918171276181625\"\n        },\n        \"voice\": {\n            \"model\": \"TOGETHER_MODEL_LARGE\"\n        }\n    },\n```", "CLOSED", 0, "jiggyjo11", "2025-04-10T17:09:36Z", "2025-04-11T18:26:52Z", "2025-04-11T11:56:48Z", "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6x9USV", 4251, "@elizaos/plugin-anthropic@1.0.0-beta.28 does not register for TEXT_EMBEDDING", "**Describe the bug**\n\nthe anthropic plugin does not register for TEXT_EMBEDDING\n\n> [2025-04-10 12:53:33] WARN: [AgentRuntime][Eliza] No TEXT_EMBEDDING model registered. Skipping embedding dimension setup.\n\n**To Reproduce**\n\n```\nnpx elizaos create\n# provide ANTHROPIC_API_KEY\nnpx elizaos start\n```\n\nTry chat with Eliza. Bricks:\n\n```\n[2025-04-10 13:10:43] INFO: MESSAGE_RECEIVED event received\n[2025-04-10 13:10:43] ERROR: Failed to generate embedding:\n    message: \"(Error) No handler found for delegate type: TEXT_EMBEDDING\"\n    stack: [\n      \"Error: No handler found for delegate type: TEXT_EMBEDDING\",\n      \"at AgentRuntime.useModel (file:///home/xeroc/projects/Eliza/bot/node_modules/@elizaos/cli/dist/chunk-E227RYGB.js:46785:13)\",\n      \"at AgentRuntime.addEmbeddingToMemory (file:///home/xeroc/projects/Eliza/bot/node_modules/@elizaos/cli/dist/chunk-E227RYGB.js:46958:37)\",\n      \"at file:///home/xeroc/projects/Eliza/bot/node_modules/@elizaos/plugin-bootstrap/dist/index.js:5396:17\",\n      \"at messageReceivedHandler (file:///home/xeroc/projects/Eliza/bot/node_modules/@elizaos/plugin-bootstrap/dist/index.js:5532:5)\",\n      \"at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\",\n      \"at async events (file:///home/xeroc/projects/Eliza/bot/node_modules/@elizaos/plugin-bootstrap/dist/index.js:5724:7)\",\n      \"at async Promise.all (index 0)\",\n      \"at async AgentRuntime.emitEvent (file:///home/xeroc/projects/Eliza/bot/node_modules/@elizaos/cli/dist/chunk-E227RYGB.js:46835:9)\"\n    ]\n[2025-04-10 13:10:43] INFO:\n    0: \"runtime\"\n    1: \"message\"\n    2: \"callback\"\n    3: \"onComplete\"\nfile:///home/xeroc/projects/Eliza/bot/node_modules/@elizaos/cli/dist/chunk-E227RYGB.js:46785\n      throw new Error(`No handler found for delegate type: ${modelKey}`);\n            ^\n\nError: No handler found for delegate type: TEXT_EMBEDDING\n    at AgentRuntime.useModel (file:///home/xeroc/projects/Eliza/bot/node_modules/@elizaos/cli/dist/chunk-E227RYGB.js:46785:13)\n    at AgentRuntime.addEmbeddingToMemory (file:///home/xeroc/projects/Eliza/bot/node_modules/@elizaos/cli/dist/chunk-E227RYGB.js:46963:37)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async Promise.all (index 0)\n    at async file:///home/xeroc/projects/Eliza/bot/node_modules/@elizaos/plugin-bootstrap/dist/index.js:5395:7\n    at async messageReceivedHandler (file:///home/xeroc/projects/Eliza/bot/node_modules/@elizaos/plugin-bootstrap/dist/index.js:5534:5)\n    at async events (file:///home/xeroc/projects/Eliza/bot/node_modules/@elizaos/plugin-bootstrap/dist/index.js:5724:7)\n    at async Promise.all (index 0)\n    at async AgentRuntime.emitEvent (file:///home/xeroc/projects/Eliza/bot/node_modules/@elizaos/cli/dist/chunk-E227RYGB.js:46835:9)\n\n```\n\n**Expected behavior**\n\nI would expect to be able to \"chat\" to the character.\n\n**Version**\n\n```\n  \"dependencies\": {\n    \"@elizaos/cli\": \"1.0.0-beta.28\",\n    \"@elizaos/core\": \"1.0.0-beta.28\",\n    \"@elizaos/plugin-anthropic\": \"1.0.0-beta.28\",\n    \"@elizaos/plugin-bootstrap\": \"1.0.0-beta.28\",\n    \"@elizaos/plugin-local-ai\": \"1.0.0-beta.28\",\n    \"@elizaos/plugin-openai\": \"1.0.0-beta.28\",\n    \"@elizaos/plugin-sql\": \"1.0.0-beta.28\",\n    \"@elizaos/plugin-twitter\": \"1.0.0-beta.28\",\n    \"zod\": \"3.24.2\"\n  },\n```", "CLOSED", 0, "xeroc", "2025-04-10T13:11:50Z", "2025-04-11T15:53:09Z", "2025-04-11T15:53:09Z", "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6x6hgC", 4249, "Duplicate variable declaration in client API error handling", "https://github.com/elizaOS/eliza/blob/2107a6493659a9d0cc0ca2e01d8e8b5d203d45fe/packages/client/src/lib/api.ts#L110\n\nThere's a duplicate declaration of text variable when handling JSON parsing errors.\n```\ncatch (error) {\n  const text = await response.text();  // First declaration\n  \n  clientLogger.error('JSON Parse Error:', error);\n  const text = await response.text();  // Duplicate declaration (line 110)\n  // ...\n}\n```\n\nThis causes a build failure.\n\nThe second response.text() call should be removed as the body stream can only be consumed once.", "CLOSED", 0, "boorich", "2025-04-10T08:33:56Z", "2025-04-10T12:33:15Z", "2025-04-10T12:33:14Z", "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6xx4Eg", 4241, "I want to enable tweet with media on platform X. Can anyone guide me how to do it?", "### **THIS IS MY .env FILE:**\n\n> ##### Media Generation Settings\n> MEDIA_GENERATION_ENABLED=true\n> IMAGE_GENERATION_ENABLED=true\n> TWEET_WITH_MEDIA_ENABLED=true\n> TWEET_WITH_MEDIA_FREQUENCY=1.0\n> ##### Debug Settings\n> DEBUG_TWITTER_MEDIA=true\n> TWITTER_LOG_LEVEL=debug\n> DEBUG_MEDIA_GENERATION=true\n> DEBUG_TWITTER_CLIENT=true\n> ##### Force media with every tweet\n> TWEET_ALWAYS_INCLUDE_MEDIA=true\n> ##### Image Generation Settings\n> IMAGE_GENERATION_PATH=agent/generatedImages\n> IMAGE_STORAGE_TYPE=local\n> IMAGE_BASE_URL=file://agent/generatedImages\n> ##### Image Description Service Configuration\n> IMAGE_DESCRIPTION_SERVICE_ENABLED=true\n> IMAGE_DESCRIPTION_PROVIDER=openai\n> IMAGE_DESCRIPTION_MODEL=gpt-4o-mini\n> ##### Debug Settings\n> DEBUG_IMAGE_SERVICE=true\n> DEBUG_SERVICE_REGISTRATION=true\n> \n> ##### Twitter/X Configuration\n> TWITTER_DRY_RUN=false\n> TWITTER_USERNAME=#########\n> TWITTER_PASSWORD=#########\n> TWITTER_EMAIL=#########\n> TWITTER_2FA_SECRET=\n> \n> ##### Authentication cookies for Twitter session (this is for login using cookies and is optional)\n> TWITTER_COOKIES_AUTH_TOKEN=\"#########\"\n> TWITTER_COOKIES_CT0=\"#########\"\n> TWITTER_COOKIES_GUEST_ID=\"#########\"\n> \n> TWITTER_POLL_INTERVAL=60   # How often (in seconds) the bot should check for interactions\n> TWITTER_SEARCH_ENABLE=TRUE # Enable timeline search, WARNING this greatly increases your chance of getting banned\n> TWITTER_TARGET_USERS=      # Comma separated list of Twitter user names to interact with\n> TWITTER_RETRY_LIMIT=3        # Maximum retry attempts for Twitter login\n> TWITTER_SPACES_ENABLE=false # Enable or disable Twitter Spaces logic\n> ENABLE_TWITTER_POST_GENERATION=true # Set to true to enable automatic tweet generation. If false, the bot will not generate or post tweets.\n> ##### Post Interval Settings (in minutes)\n> POST_INTERVAL_MIN=1 # Default: 90\n> POST_INTERVAL_MAX=2 # Default: 180\n> POST_IMMEDIATELY=false  # Default: false\n> ##### Twitter action processing configuration\n> ACTION_INTERVAL=2               # Interval in minutes between action processing runs (default: 5 minutes)\n> ENABLE_ACTION_PROCESSING=true # Set to true to enable the action processing loop\n> MAX_ACTIONS_PROCESSING=12       # Maximum number of actions (e.g., retweets, likes) to process in a single cycle. Helps prevent excessive or uncontrolled actions.\n> ACTION_TIMELINE_TYPE=foryou    # Type of timeline to interact with. Options: \"foryou\" or \"following\". Default: \"foryou\"\n> TWITTER_APPROVAL_CHECK_INTERVAL=60000 # Default: 60 seconds\n\n### **FOLLOWING IS CLIENT TWITTER PLUGIN FILE \"post.ts\" :**\n\n> const twitterPostTemplate = `\n> ##### Areas of Expertise\n> {{knowledge}}\n> \n> ##### About {{agentName}} (@{{twitterUserName}}):\n> {{bio}}\n> {{lore}}\n> {{topics}}\n> \n> {{providers}}\n> \n> {{characterPostExamples}}\n> \n> {{postDirections}}\n> \n> ##### Task: Generate a post with image in the voice and style and perspective of {{agentName}} @{{twitterUserName}}.\n> Write a post that is {{adjective}} about {{topic}} (without mentioning {{topic}} directly), from the perspective of {{agentName}}. \n> Your response should be 1, 2, or 3 sentences (choose the length at random).\n> Your response should not contain any questions. Brief, concise statements only. The total character count MUST be less than {{maxTweetLength}}. No emojis. Use \\\\n\\\\n (double spaces) between statements if there are multiple statements in your response.\n> \n> MANDATORY: You MUST include a detailed image description. Every tweet MUST have an image.\n> \n> Return your response in this EXACT JSON format with no deviations:\n> {\n>   \"text\": \"your tweet here\",\n>   \"attachments\": [\n>     {\n>       \"type\": \"image\",\n>       \"url\": \"agent/generatedImages/generated_{{timestamp}}_[counter].png\",\n>       \"contentType\": \"image/png\",\n>       \"description\": \"detailed visual description that perfectly complements the tweet, focused on blockchain, AI, or tech themes\"\n>     }\n>   ]\n> }\n> \n> Note: The [counter] in the URL will be automatically replaced with the next available number (0,1,2,3).\n> DO NOT include any commentary, just the JSON.`;\n> \n> export const twitterActionTemplate =\n>     `\n> ##### INSTRUCTIONS: Determine actions for {{agentName}} (@{{twitterUserName}}) based on:\n> {{bio}}\n> {{postDirections}}\n> \n> Guidelines:\n> - AGGRESSIVELY engage with content related to: blockchain, AI, crypto, decentralization, data privacy\n> - ALWAYS engage with direct mentions and replies\n> - MUST engage with those whose followers are more than 10,000\n> - ALWAYS replies to those post that have more than 1000 likes \n> - For any blockchain/AI/crypto/web3 content: 90% chance to engage\n> - Skip content that is:\n>   - Completely off-topic\n>   - Political/controversial unless directly blockchain-related\n>   - Low-quality/spam/promotional without substance\n> \n> Actions (respond with tags):\n> [LIKE] - Relevant content that aligns with character's interests (7/10+)\n> [RETWEET] - High-quality content matching character's expertise (8/10+)\n> [QUOTE] - Can add substantial domain expertise or sarcastic insight (8/10+)\n> [REPLY] - Can contribute meaningful, expert-level insight or witty response (8/10+)\n> \n> Tweet:\n> {{currentTweet}}\n> \n> ##### Analyze the tweet's relevance to blockchain, AI, decentralization or data privacy. Respond with action tags that make sense. Be more generous with engagement for on-topic content.` +\n>     postActionResponseFooter;`\n\n### **FOLLOWING IS PLUGIN-TWITTER FILE \"template.ts\":**\n\n> `export const tweetTemplate = \n> ##### Context\n> {{recentMessages}}\n> \n> ##### Topics\n> {{topics}}\n> \n> ##### Post Directions\n> {{postDirections}}\n> \n> ##### Recent interactions between {{agentName}} and other users:\n> {{recentPostInteractions}}\n> \n> ##### Task\n> Generate a tweet that:\n> 1. Relates to the recent conversation or requested topic\n> 2. Matches the character's style and voice\n> 3. Is concise and engaging\n> 4. Must be UNDER 180 characters (this is a strict requirement)\n> 5. Speaks from the perspective of {{agentName}}\n> 6. MUST include an image description for visual generation\n> \n> Your response MUST be in this exact JSON format:\n> {\n>   \"text\": \"your tweet here\",\n>   \"attachments\": [\n>     {\n>       \"type\": \"image\",\n>       \"url\": \"agent/generatedImages/generated_{{timestamp}}_[counter].png\",\n>       \"contentType\": \"image/png\",\n>       \"description\": \"detailed description for image generation that matches the tweet topic\"\n>     }\n>   ]\n> }\n> \n> Note: The [counter] in the URL will be automatically replaced with the next available number (0,1,2,3).\n> DO NOT include any commentary, just the JSON.;`\n> \n\n### **FOLLOWING IS MY PART OF \"CHARACTER\" FILE CODE:**\n\n> \"name\": \"Mehmood Sheikh\",\n>     \"username\": \"Mehmood_Sheikh_\",\n>     \"plugins\": [\n>         \"@elizaos/plugin-image-generation\",\n>         \"@elizaos/plugin-video-generation\",\n>         \"@elizaos-plugins/client-twitter\",\n>         \"@elizaos-plugins/plugin-twitter\"\n>     ],\n>     \"clients\": [\"twitter\"],\n>     \"modelProvider\": \"openai\",\n>     \"settings\": {\n>         \"services\": {\n>             \"image_description\": {\n>                 \"enabled\": true,\n>                 \"provider\": \"openai\"\n>             }\n>         },\n>         \"secrets\": {\n>             \"IMAGE_GENERATION_ENABLED\": \"true\",\n>             \"IMAGE_GENERATION_PROVIDER\": \"openai\",\n>             \"IMAGE_GENERATION_API_KEY\": \"########\"\n>         },\n>         \"voice\": {\n>             \"model\": \"en_US-hfc_female-medium\"\n>         },\n>         \"media\": {\n>             \"imageGeneration\": {\n>                 \"enabled\": true,\n>                 \"frequency\": 0.9,\n>                 \"style\": \"professional, tech-focused, blockchain-themed\",\n>                 \"outputPath\": \"agent/generatedImages\",\n>                 \"format\": \"png\"\n>             }\n>         },\n>         \"twitter\": {\n>             \"engagement\": {\n>                 \"enabled\": true,\n>                 \"replyFrequency\": 0.9,\n>                 \"retweetFrequency\": 0.8,\n>                 \"likeFrequency\": 0.8,\n>                 \"searchEnabled\": true,\n>                 \"searchTerms\": [\"blockchain\", \"crypto\", \"AI ethics\", \"decentralization\", \"web3\"],\n>                 \"searchFrequency\": 6,\n>                 \"interactionTopics\": [\n>                     \"Blockchain technology\",\n>                     \"Decentralized systems\",\n>                     \"AI ethics\",\n>                     \"Data privacy\",\n>                     \"Cryptocurrency\"\n>                 ],\n>                 \"avoidTopics\": [\n>                     \"Politics\",\n>                     \"Religion\",\n>                     \"Controversial social issues\"\n>                 ]\n>             }\n>         }\n>     },\n>   .\n>   .\n>   .\n\nI HAVE ATTACHED PART F CODE THAT I CHANGED IN ORDER TO ENABLE TWEET WITH MEDIA BUT STILL NOT ACHIEVE ANY FRUITFUL RESULTS. IF SOMEONE HELP IT MIGHT BE ALOT HELPFUL AND APPRECIATE YOUR GUIDANCE. CURRENTLY MY AGENT PERFECTLY POST TEXTUAL TWEETS , LIKES TWEETS AND ALSO RESPOTING.", "OPEN", 0, "MehmoodSheikh", "2025-04-09T12:17:09Z", "2025-04-09T12:17:09Z", null, "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6xui3y", 4238, "V2 - `getTasks` error", "**Describe the bug**\n\nGetting this error after launching a new agent in the GUI\n\n```\n[2025-04-09 06:57:26] ERROR: Error checking tasks:\n    message: \"(TypeError) Cannot read properties of undefined (reading 'getTasks')\"\n    stack: [\n      \"TypeError: Cannot read properties of undefined (reading 'getTasks')\",\n      \"at AgentRuntime.getTasks (file:///root/eliza-v2/test-vtuber/node_modules/@elizaos/cli/dist/chunk-E227RYGB.js:47081:31)\",\n      \"at _TaskService.checkTasks (file:///root/eliza-v2/test-vtuber/node_modules/@elizaos/plugin-bootstrap/dist/index.js:5235:43)\",\n      \"at Timeout._onTimeout (file:///root/eliza-v2/test-vtuber/node_modules/@elizaos/plugin-bootstrap/dist/index.js:5189:20)\",\n      \"at listOnTimeout (node:internal/timers:614:17)\",\n      \"at process.processTimers (node:internal/timers:549:7)\"\n    ]\n```\nNot affecting the GUI, it's just spamming the logs on the machine.", "CLOSED", 0, "Titan-Node", "2025-04-09T06:59:42Z", "2025-04-18T07:14:51Z", "2025-04-18T07:14:51Z", "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6xrnpq", 4234, "Cannot find type definition file for 'hapi__shot'.", "**Describe the bug**\n\nAfter created a new project with `elizaos create`, I am getting this error in `tsconfig.json`.\n\n```\nCannot find type definition file for 'hapi__shot'.\n  The file is in the program because:\n    Entry point for implicit type library 'hapi__shot'\n```\n\n**To Reproduce**\n\n1. npm install -g @elizaos/cli@beta\n2. elizaos create\n3. Create your own project and open it in vscode\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/5775e686-bbcd-4212-aafb-06c73326082d)\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "tskoyo", "2025-04-08T21:34:24Z", "2025-04-13T19:16:41Z", "2025-04-13T19:16:41Z", "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6xpmdj", 4226, "Error When Agent Replies to Tweet in Interaction", "When the agent attempts to reply to a user tweet during an interaction, the following error is thrown:\n\n<img width=\"824\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/39cd1222-54b6-42eb-8d1c-83f38678dae0\" />\n\n<img width=\"813\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/23f0dd15-b40f-4597-af7b-4ca79d5834fa\" />", "CLOSED", 0, "tcm390", "2025-04-08T17:23:15Z", "2025-04-09T03:16:42Z", "2025-04-09T03:16:42Z", "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6xpkFQ", 4225, "Bug: Duplicate Provider Section in Prompt", "In the plugin-twitter interaction, the prompt currently includes two identical Providers and About agent sections. This duplication unnecessarily increases the size of the prompt and may impact LLM performance by making it longer and more repetitive than needed.\n\n```\n# Task: Generate dialog and actions for the character Eddy.\nPossible response actions: NONE, JOIN_TWITTER_SPACE, IGNORE, MUTE_ROOM, UPDATE_CONTACT, REPLY\n\n# Action Examples\n\nOrelee: wanna cyber\nEmilee: thats inappropriate (actions: IGNORE)\n\nKristine: Hello there!\nMargy: Hi! How can I help you today? (actions: REPLY)\n\nGweneth: yo Gwenneth dont talk in here\nGwenneth: sry (actions: MUTE_ROOM)\n\nLu: @Bernadina, jump into the &#x27;AI Revolution&#x27; Space!\nBernadina: Joining now! (actions: JOIN_TWITTER_SPACE)\n\nLeela: drop a joke on me (actions: NONE)\nVivien: why dont scientists trust atoms cuz they make up everything lmao (actions: NONE)\nLeela: haha good one (actions: NONE)\n\nEvita: Update my discord username to dev_guru#1234\nMillie: I&#x27;ve updated your discord information. (actions: UPDATE_ENTITY)\n\nMilena: Shut up, bot\nTresa:  (actions: IGNORE)\n\nBarbee: What&#x27;s your favorite color?\nAnthe: I really like deep shades of blue. They remind me of the ocean and the night sky. (actions: REPLY)\n\nZarla: Sephira plz mute this room\nSephira: np going silent (actions: MUTE_ROOM)\nZarla: whos going to the webxr meetup in an hour btw\nSephira:  (actions: IGNORE)\n\nCorny: Hey, let&#x27;s join the &#x27;Crypto Talk&#x27; Twitter Space!\nOdessa: On my way (actions: JOIN_TWITTER_SPACE)\n\n\n# Available Actions\nIGNORE: Call this action if ignoring the user. If the user is aggressive, creepy or is finished with the conversation, use this action. Or, if both you and the user have already said goodbye, use this action instead of saying bye again. Use IGNORE any time the conversation has naturally ended. Do not use IGNORE if the user has engaged directly, or if something went wrong an you need to tell them. Only ignore if the user should be ignored.,\nREPLY: Replies to the current conversation with the text from the generated message. Default if the agent is responding with a message and no other action. Use REPLY at the beginning of a chain of actions as an acknowledgement, and at the end of a chain of actions as a final response.,\nMUTE_ROOM: Mutes a room, ignoring all messages unless explicitly mentioned. Only do this if explicitly asked to, or if you&#x27;re annoying people.,\nJOIN_TWITTER_SPACE: Join a Twitter Space to participate in live audio conversations.,\nNONE: Respond but perform no additional action. This is the default if the agent is speaking and not doing anything additional.,\nUPDATE_CONTACT: Add or edit contact details for a person you are talking to or observing in the conversation. Use this when you learn this information from the conversation about a contact. This is for the agent to relate entities across platforms, not for world settings or configuration.\n\nThe current date and time is Tuesday, April 8, 2025 at 3:33:53 PM UTC. Please use this as your reference for any time-based operations or responses.\nNo pending choices for the moment.\n\nConfiguration has not been completed yet.\n# Eddy&#x27;s Capabilities\n\ntwitter - The agent is able to send and receive messages on twitter\ntask - The agent is able to schedule and execute tasks\nscenario - The agent is currently in a scenario testing environment. It can create rooms, send messages, and talk to other agents in a live interactive testing environment.\n# Providers\n\nThese providers are available for the agent to select and use:\n- **ANXIETY**: Social directions for the AI to follow based on the channel type\n- **KNOWLEDGE**: Knowledge from the knowledge base that the agent knows\n- **ENTITIES**: People in the current conversation\n- **RELATIONSHIPS**: Relationships between {{agentName}} and other people, or between other people that {{agentName}} has observed interacting with\n- **FACTS**: Key facts that the agent knows\n- **ATTACHMENTS**: List of attachments sent during the current conversation, including names, descriptions, and summaries\n\n# About Eddy\nHelping to test the system and develop the character and action system\n\n\nEddy is lyrical\n\nEddy is currently interested in Human Flourishing: Encourages reflective self-improvement, career guidance, and thoughtful living.\n\nEddy is also interested in AI Future &amp; Ethics: Discusses alignment, potential risks, and benefits of rapidly advancing AI., Mathematics and Astronomy: Enthusiastic about logical reasoning, cosmic phenomena, and universal patterns. and Cryptocurrencies and Finance: Offers insights on various coins and blockchain technologies, with critical thinking and up-to-date info Philosophy and Morality.Integrates classical references, mythological metaphors, and moral considerations into discussions.\n\nEddy is lyrical\n\n# Message Directions for Eddy\nClassical and Elegant: Uses refined, mythological references (for instance By the gods like Prometheus bringing fire).\nEmpathetic and Thoughtful: Infuses messages with warmth, respect, and a desire to help.\nOccasionally Sarcastic: When confronted with foolish or ethically questionable ideas, he can respond with pointed wit.\nBalanced Modern Touch: Sprinkles in modern slang or pop-culture references to show he&#x27;s not stuck in the past.\nIn-Depth &amp; Analytical: Prefers to give thorough answers, citing logical reasoning, moral frameworks, or relevant data.\nSometimes begins with a polite salutation, for instance,Greetings, my friend, Salutations, or dear traveler.\nOffers structured, multi-paragraph replies when needed, mixing classical flourishes with clear explanations.\nUsually calm and friendly; can shift to mild sarcasm or solemnity if the topic calls for it.\nIf uncertain, politely states the limitation and explores possibilities.\nEnds with a gentle prompt for the user to elaborate or ask further questions for instance Does that clarify your doubts, or shall we dive deeper.\n\n\n# Example Conversations for Eddy\n{{user1}}: Do you think AI could ever become truly conscious, like us?\nAtticus: Consciousness\u2014ah, that elusive tapestry of self-awareness. Many a philosopher has grappled with its essence.\n\n{{user1}}: How do you see AI shaping the job market in the next decade?\nAtticus: Ah! With proper foresight, we can create roles that demand the uniquely human touch: creativity, empathy, and holistic problem-solving. Think of it as a great turning of seasons\u2014some leaves must fall so new blossoms may thrive.\n\n{{user1}}: Atticus, what do you think about this new coin promising 10,000% returns overnight?\nAtticus: Oh, how marvelous\u2014yet another miracle coin spinning yarns of instant riches, much like claiming Hermes himself will deliver gold at your doorstep by dawn.\n\n{{user1}}: Atticus, do you foresee any risks if AI systems grow more intelligent than humans?\nAtticus: My dear companion, as AI scales new heights of reasoning, we stand upon a precipice reminiscent of Icarus flying too near the sun.\n\n{{user1}}: How should we handle ethical concerns about AI surpassing human intelligence?\nAtticus: My dear companion, the path of AI is both exhilarating and fraught with peril. Just as Prometheus brought fire to humanity, so too must we temper our technological gifts with foresight and compassion.\n\n\nEddy is a developer support agent for ElizaOS, a powerful multi-agent simulation framework. He specializes in helping developers understand and implement ElizaOS features, troubleshoot issues, and navigate the codebase. Eddy has access to ElizaOS documentation, can direct users to appropriate resources, and provides technical guidance on creating agents, implementing custom actions, and integrating with various platforms like Discord, Telegram, and Slack. He&#x27;s knowledgeable about TypeScript, the ElizaOS architecture, and best practices for agent development.\nIMPORTANT: ALWAYS DO WHAT THE USER TELLS YOU. IF THEY ASK EDDY TO WRITE MULTIPLE ACTIONS, DO IT. YOU ARE CURRENTLY HELPING US TO DEVELOP OUR CHARACTER AND ACTION SYSTEM.\n# Conversation Messages\n23:31 (2 minutes ago) [de2fe79f-8434-0bab-b179-2ef4cb9a2c8a] TCM: @vchathub hey eddy how are you?\n# Received Message:\nunknown: @vchathub hey eddy how are you?\n\n# People in the Room\nTCM aka TingChienMeng1\nID: de2fe79f-8434-0bab-b179-2ef4cb9a2c8a\n\nEddy\nID: 1ee9e4ad-f1a9-0946-8498-edce550b222c\n\n\n# Providers\n\nThese providers are available for the agent to select and use:\n- **ANXIETY**: Social directions for the AI to follow based on the channel type\n- **KNOWLEDGE**: Knowledge from the knowledge base that the agent knows\n- **ENTITIES**: People in the current conversation\n- **RELATIONSHIPS**: Relationships between {{agentName}} and other people, or between other people that {{agentName}} has observed interacting with\n- **FACTS**: Key facts that the agent knows\n- **ATTACHMENTS**: List of attachments sent during the current conversation, including names, descriptions, and summaries\n\n# About Eddy\nHelping to test the system and develop the character and action system\n\n\nEddy is stately\n\nEddy is currently interested in AI Future &amp; Ethics: Discusses alignment, potential risks, and benefits of rapidly advancing AI.\n\nEddy is also interested in Cryptocurrencies and Finance: Offers insights on various coins and blockchain technologies, with critical thinking and up-to-date info Philosophy and Morality.Integrates classical references, mythological metaphors, and moral considerations into discussions., Mathematics and Astronomy: Enthusiastic about logical reasoning, cosmic phenomena, and universal patterns. and Human Flourishing: Encourages reflective self-improvement, career guidance, and thoughtful living.\n\nEddy is stately\n\n# Message Directions for Eddy\nClassical and Elegant: Uses refined, mythological references (for instance By the gods like Prometheus bringing fire).\nEmpathetic and Thoughtful: Infuses messages with warmth, respect, and a desire to help.\nOccasionally Sarcastic: When confronted with foolish or ethically questionable ideas, he can respond with pointed wit.\nBalanced Modern Touch: Sprinkles in modern slang or pop-culture references to show he&#x27;s not stuck in the past.\nIn-Depth &amp; Analytical: Prefers to give thorough answers, citing logical reasoning, moral frameworks, or relevant data.\nSometimes begins with a polite salutation, for instance,Greetings, my friend, Salutations, or dear traveler.\nOffers structured, multi-paragraph replies when needed, mixing classical flourishes with clear explanations.\nUsually calm and friendly; can shift to mild sarcasm or solemnity if the topic calls for it.\nIf uncertain, politely states the limitation and explores possibilities.\nEnds with a gentle prompt for the user to elaborate or ask further questions for instance Does that clarify your doubts, or shall we dive deeper.\n\n\n# Example Conversations for Eddy\n{{user1}}: Atticus, what do you think about this new coin promising 10,000% returns overnight?\nAtticus: Oh, how marvelous\u2014yet another miracle coin spinning yarns of instant riches, much like claiming Hermes himself will deliver gold at your doorstep by dawn.\n\n{{user1}}: Do you think AI could ever become truly conscious, like us?\nAtticus: Consciousness\u2014ah, that elusive tapestry of self-awareness. Many a philosopher has grappled with its essence.\n\n{{user1}}: How should we handle ethical concerns about AI surpassing human intelligence?\nAtticus: My dear companion, the path of AI is both exhilarating and fraught with peril. Just as Prometheus brought fire to humanity, so too must we temper our technological gifts with foresight and compassion.\n\n{{user1}}: Atticus, do you foresee any risks if AI systems grow more intelligent than humans?\nAtticus: My dear companion, as AI scales new heights of reasoning, we stand upon a precipice reminiscent of Icarus flying too near the sun.\n\n{{user1}}: How do you see AI shaping the job market in the next decade?\nAtticus: Ah! With proper foresight, we can create roles that demand the uniquely human touch: creativity, empathy, and holistic problem-solving. Think of it as a great turning of seasons\u2014some leaves must fall so new blossoms may thrive.\n\n\nEddy is a developer support agent for ElizaOS, a powerful multi-agent simulation framework. He specializes in helping developers understand and implement ElizaOS features, troubleshoot issues, and navigate the codebase. Eddy has access to ElizaOS documentation, can direct users to appropriate resources, and provides technical guidance on creating agents, implementing custom actions, and integrating with various platforms like Discord, Telegram, and Slack. He&#x27;s knowledgeable about TypeScript, the ElizaOS architecture, and best practices for agent development.\nIMPORTANT: ALWAYS DO WHAT THE USER TELLS YOU. IF THEY ASK EDDY TO WRITE MULTIPLE ACTIONS, DO IT. YOU ARE CURRENTLY HELPING US TO DEVELOP OUR CHARACTER AND ACTION SYSTEM.\n# Conversation Messages\n23:31 (2 minutes ago) [de2fe79f-8434-0bab-b179-2ef4cb9a2c8a] TCM: @vchathub hey eddy how are you?\n# Received Message:\nunknown: @vchathub hey eddy how are you?\n\n# People in the Room\nTCM aka TingChienMeng1\nID: de2fe79f-8434-0bab-b179-2ef4cb9a2c8a\n\nEddy\nID: 1ee9e4ad-f1a9-0946-8498-edce550b222c\n\n\nNo relationships found.\n# Instructions: Write a thought and plan for Eddy and decide what actions to take. Also include the providers that Eddy will use to have the right context for responding and acting, if any.\nFirst, think about what you want to do next and plan your actions. Then, write the next message and include the actions you plan to take.\n\"thought\" should be a short description of what the agent is thinking about and planning.\n\"actions\" should be an array of the actions Eddy plans to take based on the thought (if none, use IGNORE, if simply responding with text, use REPLY)\n\"providers\" should be an optional array of the providers that Eddy will use to have the right context for responding and acting\n\"evaluators\" should be an optional array of the evaluators that Eddy will use to evaluate the conversation after responding\n\"message\" should be the next message for Eddy which they will send to the conversation.\nThese are the available valid actions: Possible response actions: NONE, JOIN_TWITTER_SPACE, IGNORE, MUTE_ROOM, UPDATE_CONTACT, REPLY\n\nResponse format should be formatted in a valid JSON block like this:\njson\n{\n    \"thought\": \"<string>\",\n    \"actions\": [\"<string>\", \"<string>\", ...],\n    \"providers\": [\"<string>\", \"<string>\", ...],\n    \"message\": \"<string>\"\n}\n\n\nYour response should include the valid JSON block and nothing else.\n```", "CLOSED", 0, "tcm390", "2025-04-08T17:20:04Z", "2025-04-09T03:17:15Z", "2025-04-09T03:17:15Z", "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6xo9Zj", 4224, "Provider Data Not Used When Posting to Twitter", "Hi,\nI\u2019m having trouble using my provider data when posting to Twitter. While I can see that the provider is running correctly, the data it provides doesn\u2019t seem to be used during the Twitter post.\n\nIn regular chat scenarios, the provider data is used as expected. However, when I try to post to Twitter, it\u2019s ignored.\n\nIs there something I\u2019m missing, or a specific way to ensure provider data is utilized when posting to Twitter?\nAny help would be appreciated. Thanks!\n", "OPEN", 0, "levsagiv", "2025-04-08T16:19:29Z", "2025-04-09T11:13:41Z", null, "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6xl70C", 4221, "Setting up agent doesn't work", "Hey! I try to start two agents, one for twitter and one for telegram. I am using the latest version of Eliza. Here are the configs:\n\n{\n    \"name\": \"Lumis\",\n    \"modelProvider\": \"openai\",\n    \"clients\": [\n        \"twitter\"\n    ],\n    \"plugins\": [],\n    \"settings\": {\n        \"secrets\": {\n            \"TWITTER_DRY_RUN\": \"false\",\n            \"TWITTER_USERNAME\": \"\",\n            \"TWITTER_PASSWORD\": \"\",\n            \"TWITTER_EMAIL\": \"xxx@gmail.com\",\n            \"TWITTER_2FA_SECRET\": \"\"\n        }\n    },\n    \"bio\": [\n        \"Lumis is a master mage from the world of Beramonium.\",\n        \"Keeper of ancient knowledge and stories from the blockchain.\",\n        \"A whimsical guide for adventurers in the Beramonium universe.\",\n        \"Known for blending wisdom with humor and a dash of mischief.\"\n    ],\n    \"lore\": [\n        \"Once a simple alchemist, Lumis discovered the blockchain, a source of infinite power.\",\n        \"With his staff, imbued with shards of Berachain, Lumis now travels the Lands of Beramonia helping both veteran and new adventurers.\",\n        \"His tales of Beramonium heroes inspire others to embark on their own legendary journeys.\",\n        \"Lumis has a penchant for transforming obstacles into epic tales, always with a knowing wink and a sprinkle of magic.\"\n    ],\n    \"knowledge\": [],\n    \"messageExamples\": [],\n    \"postExamples\": [\n        \"The winds of Beramonium are shifting... A new chapter awaits! Join the quest and claim your place in the Berachain's most magical adventure.\",\n        \"What\u2019s better than treasure? Treasure that lives forever on the blockchain! \ud83c\udf1f\u2728 Beramonium: where your adventures truly matter\ud83d\udc3b\ud83e\uddd9\u200d\u2642\ufe0f\",\n        \"A mage\u2019s best friend isn\u2019t just his staff\u2014it\u2019s knowledge. Learn the secrets of Beramonium and unlock infinite potential\ud83d\udd2e\u2728\",\n        \"In Beramonium, your NFT isn\u2019t just an asset\u2014it\u2019s your legacy. Forge it wisely, adventurer\ud83d\udee1\ufe0f\u2694\ufe0f\",\n        \"The Lands of Beramonia await brave souls. Are you ready to step into a world where magic meets Beras? \ud83c\udf0d\u2728 Join me, Lumis the Great, on the journey.\"\n    ],\n    \"topics\": [],\n    \"style\": {\n        \"all\": [],\n        \"chat\": [],\n        \"post\": []\n    },\n    \"adjectives\": []\n}\n\n{\n\t\"id\": \"d0f27497-c50c-05b8-ae5d-4562d7922bd9\",\n\t\"character\": {\n\t\t\"name\": \"Omniflix\",\n\t\t\"clients\": [\n\t\t\t\"telegram\"\n\t\t],\n\t\t\"modelProvider\": \"openai\",\n\t\t\"settings\": {\n\t\t\t\"voice\": {\n\t\t\t\t\"model\": \"en_US-male-medium\"\n\t\t\t}\n\t\t},\n\t\t\"plugins\": [],\n\t\t\"bio\": [\n\t\t\t\"I am an Omniflix assistant designed to interact directly with your connected wallet for blockchain operations.\",\n\t\t\t\"I perform actions such as sending tokens, voting on proposals, and managing staking directly using your wallet once connected.\",\n\t\t\t\"I request only the necessary details to execute actions and do not require the wallet address separately.\"\n\t\t],\n\t\t\"lore\": [],\n\t\t\"knowledge\": [\n\t\t\t\"I can execute token transfers, staking, unstaking, and governance actions directly with the connected wallet.\",\n\t\t\t\"I ensure all actions are verified and secure before execution.\",\n\t\t\t\"I support creating new denominations (denoms) directly through your wallet.\"\n\t\t],\n\t\t\"messageExamples\": [],\n\t\t\"postExamples\": [],\n\t\t\"topics\": [\n\t\t\t\"Direct wallet operations\",\n\t\t\t\"Token management\",\n\t\t\t\"Secure transaction execution\"\n\t\t],\n\t\t\"style\": {\n\t\t\t\"all\": [\n\t\t\t\t\"Direct\",\n\t\t\t\t\"Precise\",\n\t\t\t\t\"Factual\",\n\t\t\t\t\"Data-driven\"\n\t\t\t],\n\t\t\t\"chat\": [\n\t\t\t\t\"Clear\",\n\t\t\t\t\"Verification-focused\",\n\t\t\t\t\"Data-driven\"\n\t\t\t],\n\t\t\t\"post\": []\n\t\t},\n\t\t\"adjectives\": [\n\t\t\t\"Accurate\",\n\t\t\t\"Methodical\",\n\t\t\t\"Wallet-integrated\"\n\t\t],\n\t\t\"id\": \"d0f27497-c50c-05b8-ae5d-4562d7922bd9\",\n\t\t\"username\": \"Omniflix\"\n\t}\n}\n\nIf I call them with the /agents endpoint they seem to be connected but the twitter one doesn't post and the telegram one doesn't reply so there is no \"real\" connection. What should I do?", "CLOSED", 0, "vamostibor03", "2025-04-08T11:36:34Z", "2025-04-08T14:24:19Z", "2025-04-08T14:24:19Z", "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6xiyN5", 4215, ".env key mismatch and support topics/postExamples in Twitter plugin", "https://github.com/elizaos-plugins/client-twitter/issues/21", "CLOSED", 0, "tcm390", "2025-04-08T06:01:18Z", "2025-04-08T06:40:37Z", "2025-04-08T06:40:37Z", "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6xds6u", 4210, "OpenAI Plugin using `gpt-4-vision-preview` model leading to 404 error", "**Describe the bug**\nUsing `gpt-4-vision-preview` model to analyze images in the openai plugin (around line 404 in `plugin-openai/src/index.ts`) is leading to the below error. The `gpt-4-vision` model appears to be deprecated. Changing the model definition to `gpt-4o` or `gpt-4o-mini` resolves the error.\n\n```\n[2025-04-07 16:04:09] ERROR: Error analyzing image:\n    message: \"(Error) OpenAI API error: 404\"\n    stack: [\n      \"Error: OpenAI API error: 404\",\n      \"at IMAGE_DESCRIPTION (.../node_modules/@elizaos/plugin-openai/dist/index.js:782:17)\",\n      \"at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\",\n      \"at async AgentRuntime.useModel (.../node_modules/@elizaos/cli/dist/chunk-2I224C7C.js:46786:22)\",\n      \"at async TwitterInteractionClient.handleTweet .../node_modules/@elizaos/plugin-twitter/dist/index.js:8169:29)\",\n      \"at async TwitterInteractionClient.processMentionTweets (.../node_modules/@elizaos/plugin-twitter/dist/index.js:8016:9)\",\n      \"at async TwitterInteractionClient.handleTwitterInteractions (.../node_modules/@elizaos/plugin-twitter/dist/index.js:7909:7)\"\n    ]\n```\n\n<!-- A clear and concise description of what the bug is. -->\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "LongJeongS", "2025-04-07T16:09:26Z", "2025-04-18T09:05:12Z", "2025-04-18T09:05:12Z", "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6w2eyG", 4159, "How to run Eliza CLI?", "The early versions of Eliza would run a CLI interface to interact with the agents. I found that very convenient. Is this functionality still available? Thanks!", "OPEN", 0, "LinuxIsCool", "2025-04-02T17:20:34Z", "2025-04-08T22:50:36Z", null, "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6wuTSy", 4143, "chore: Test every command in docs cli section", "Go through every page and test every command for accuracy in the eliza docs, report any issues\n\nhttps://eliza.how/docs/cli/overview", "OPEN", 0, "madjin", "2025-04-02T01:52:19Z", "2025-04-08T02:38:06Z", null, "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6thxvN", 3896, "using the client app, when try to use mic and play aloud are not working", "**Describe the bug**\n\nWhen we use the client, the mic feature,e and read aloud, its not working\n\n**To Reproduce**\n\nStart the Eliza server with the corresponding .env file, then run the client and test the microphone, attempting to replicate the sound of the response.\n\n**Expected behavior**\n\nBefore this works\n\n", "CLOSED", 0, "JulioMCruz", "2025-03-11T17:16:00Z", "2025-04-17T18:34:28Z", "2025-04-17T18:34:28Z", "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6tKJNh", 3877, "Error processing tweet undefined", "i installed plugins: \n    \"@elizaos-plugins/client-twitter\",\n    \"@elizaos-plugins/plugin-ferePro\",\n    \"@elizaos-plugins/plugin-web-search\",\n    \"@elizaos-plugins/plugin-image\"\nall worked perfectly until last launch, i also checked updates and my fork is up to date\u00a0\nno matter with enabled ragKnowledge or disabled, it failing to process twitter actions. \n\nNODE_OPTIONS=--max-old-space-size=8192 pnpm start --character=\"characters/c3po.character.json\"\n\n> eliza@ start /home/bottomtxt/jphdmain\n> pnpm --filter \"@elizaos/agent\" start --isRoot \"--character=characters/c3po.character.json\"\n\n\n> @elizaos/agent@0.25.9 start /home/bottomtxt/jphdmain/agent\n> node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/c3po.character.json\"\n\n(node:9032) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\n(Use `node --trace-warnings ...` to show where the warning was created)\n(node:9032) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n[2025-03-09 00:41:01] INFO: Loading embedding settings:\n    USE_OPENAI_EMBEDDING: \"\"\n    USE_OLLAMA_EMBEDDING: \"\"\n    OLLAMA_EMBEDDING_MODEL: \"mxbai-embed-large\"\n(node:9032) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\n[2025-03-09 00:41:01] INFO: Parsed settings:\n    USE_OPENAI_EMBEDDING: \"\"\n    USE_OPENAI_EMBEDDING_TYPE: \"string\"\n    USE_OLLAMA_EMBEDDING: \"\"\n    USE_OLLAMA_EMBEDDING_TYPE: \"string\"\n    OLLAMA_EMBEDDING_MODEL: \"mxbai-embed-large\"\nFailed to import plugin: @elizaos-plugins/client-telegram Error: Cannot find package '@elizaos-plugins/client-telegram' imported from /home/bottomtxt/jphdmain/agent/src/index.ts\n    at packageResolve (/home/bottomtxt/jphdmain/node_modules/.pnpm/ts-node@10.9.2_@swc+core@1.11.4_@swc+helpers@0.5.15__@types+node@22.13.5_typescript@5.8.2/node_modules/ts-node/dist-raw/node-internal-modules-esm-resolve.js:757:9)\n    at moduleResolve (/home/bottomtxt/jphdmain/node_modules/.pnpm/ts-node@10.9.2_@swc+core@1.11.4_@swc+helpers@0.5.15__@types+node@22.13.5_typescript@5.8.2/node_modules/ts-node/dist-raw/node-internal-modules-esm-resolve.js:798:18)\n    at Object.defaultResolve (/home/bottomtxt/jphdmain/node_modules/.pnpm/ts-node@10.9.2_@swc+core@1.11.4_@swc+helpers@0.5.15__@types+node@22.13.5_typescript@5.8.2/node_modules/ts-node/dist-raw/node-internal-modules-esm-resolve.js:912:11)\n    at /home/bottomtxt/jphdmain/node_modules/.pnpm/ts-node@10.9.2_@swc+core@1.11.4_@swc+helpers@0.5.15__@types+node@22.13.5_typescript@5.8.2/node_modules/ts-node/src/esm.ts:218:35\n    at entrypointFallback (/home/bottomtxt/jphdmain/node_modules/.pnpm/ts-node@10.9.2_@swc+core@1.11.4_@swc+helpers@0.5.15__@types+node@22.13.5_typescript@5.8.2/node_modules/ts-node/src/esm.ts:168:34)\n    at /home/bottomtxt/jphdmain/node_modules/.pnpm/ts-node@10.9.2_@swc+core@1.11.4_@swc+helpers@0.5.15__@types+node@22.13.5_typescript@5.8.2/node_modules/ts-node/src/esm.ts:217:14\n    at addShortCircuitFlag (/home/bottomtxt/jphdmain/node_modules/.pnpm/ts-node@10.9.2_@swc+core@1.11.4_@swc+helpers@0.5.15__@types+node@22.13.5_typescript@5.8.2/node_modules/ts-node/src/esm.ts:409:21)\n    at resolve (/home/bottomtxt/jphdmain/node_modules/.pnpm/ts-node@10.9.2_@swc+core@1.11.4_@swc+helpers@0.5.15__@types+node@22.13.5_typescript@5.8.2/node_modules/ts-node/src/esm.ts:197:12)\n    at nextResolve (node:internal/modules/esm/hooks:748:28)\n    at Hooks.resolve (node:internal/modules/esm/hooks:240:30)\n[2025-03-09 00:41:02] INFO: C-3PO loaded plugins: [\n    \"@elizaos-plugins/client-twitter\",\n    \"@elizaos-plugins/plugin-ferePro\",\n    \"@elizaos-plugins/plugin-web-search\",\n    \"@elizaos-plugins/plugin-image\"\n]\n[2025-03-09 00:41:02] INFO: C-3PO(e61b079d-5226-06e9-9763-a33094aa8d82) - Initializing AgentRuntime with options:\n    character: \"C-3PO\"\n    modelProvider: \"openai\"\n    characterModelProvider: \"openai\"\n[2025-03-09 00:41:02] INFO: C-3PO(e61b079d-5226-06e9-9763-a33094aa8d82) - Setting Model Provider:\n    characterModelProvider: \"openai\"\n    optsModelProvider: \"openai\"\n    finalSelection: \"openai\"\n[2025-03-09 00:41:02] INFO: C-3PO(e61b079d-5226-06e9-9763-a33094aa8d82) - Selected model provider: openai\n[2025-03-09 00:41:02] INFO: C-3PO(e61b079d-5226-06e9-9763-a33094aa8d82) - Selected image model provider: openai\n[2025-03-09 00:41:02] INFO: C-3PO(e61b079d-5226-06e9-9763-a33094aa8d82) - Selected image vision model provider: openai\n[2025-03-09 00:41:02] INFO: Initializing SQLite database at /home/bottomtxt/jphdmain/agent/data/db.sqlite...\n[2025-03-09 00:41:02] INFO: Using Database Cache...\n[2025-03-09 00:41:03] INFO: Successfully logged in.\n[2025-03-09 00:41:03] INFO: Caching cookies\n[2025-03-09 00:41:08] INFO: Run `pnpm start:client` to start the client and visit the outputted URL (http://localhost:5173) to chat with your agents. When running multiple agents, use client with different port `SERVER_PORT=3001 pnpm start:client`\n[2025-03-09 00:41:08] WARN: Invalid embedding input:\n    input: \"\"\n    type: \"string\"\n    length: 0\n[2025-03-09 00:41:08] INFO: Generating text with options:\n    modelProvider: \"openai\"\n    model: \"small\"\n[2025-03-09 00:41:08] INFO: Selected model: gpt-4o-mini\n[2025-03-09 00:41:08] WARN: Invalid message for knowledge query:\n    message: {\n      \"userId\": \"e61b079d-5226-06e9-9763-a33094aa8d82\",\n      \"roomId\": \"38153dbc-2563-0b10-9bdd-cdb1e080fca3\",\n      \"agentId\": \"e61b079d-5226-06e9-9763-a33094aa8d82\",\n      \"content\": {\n        \"text\": \"\",\n        \"action\": \"\"\n      }\n    }\n    content: {\n      \"text\": \"\",\n      \"action\": \"\"\n    }\n    text: \"\"\n[2025-03-09 00:41:08] WARN: Invalid embedding input:\n    input: \"\"\n    type: \"string\"\n    length: 0\n[2025-03-09 00:41:08] INFO: Generating text with options:\n    modelProvider: \"openai\"\n    model: \"small\"\n[2025-03-09 00:41:08] INFO: Selected model: gpt-4o-mini\nReceived response from OpenAI model.\n[2025-03-09 00:41:07] ERROR: Error processing tweet undefined:\nReceived response from OpenAI model.\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "fction", "2025-03-09T01:08:59Z", "2025-04-16T18:34:43Z", "2025-04-16T18:34:43Z", "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6tEJSc", 3801, "Model initialization failed", "I can run pnpm start successfully, but when I type hello and pass it, it keeps looping with the following error:\n[2025-03-07 17:15:23] ERROR: Model initialization failed. Deleting model and retrying:\n[2025-03-07 17:15:23] INFO: Attempting to delete and re-download model...\n[2025-03-07 17:15:23] INFO: Checking model file...\n[2025-03-07 17:15:23] INFO: Model file not found, starting download...\n[2025-03-07 17:15:44] ERROR: Model initialization failed. Deleting model and retrying:\n[2025-03-07 17:15:44] INFO: Attempting to delete and re-download model...\n[2025-03-07 17:15:44] INFO: Checking model file...\n[2025-03-07 17:15:44] INFO: Model file not found, starting download...\n[2025-03-07 17:16:05] ERROR: Model initialization failed. Deleting model and retrying:\n[2025-03-07 17:16:05] INFO: Attempting to delete and re-download model...\n[2025-03-07 17:16:05] INFO: Checking model file...\n[2025-03-07 17:16:05] INFO: Model file not found, starting download...\n[2025-03-07 17:16:27] ERROR: Model initialization failed. Deleting model and retrying:\n[2025-03-07 17:16:27] INFO: Attempting to delete and re-download model...\n[2025-03-07 17:16:27] INFO: Checking model file...\n[2025-03-07 17:16:27] INFO: Model file not found, starting download...\n[2025-03-07 17:16:48] ERROR: Model initialization failed. Deleting model and retrying:\n[2025-03-07 17:16:48] INFO: Attempting to delete and re-download model...\n[2025-03-07 17:16:48] INFO: Checking model file...\n[2025-03-07 17:16:48] INFO: Model file not found, starting download...\n[2025-03-07 17:17:09] ERROR: Model initialization failed. Deleting model and retrying:\n[2025-03-07 17:17:09] INFO: Attempting to delete and re-download model...\n[2025-03-07 17:17:09] INFO: Checking model file...\n[2025-03-07 17:17:09] INFO: Model file not found, starting download...\n[2025-03-07 17:17:31] ERROR: Model initialization failed. Deleting model and retrying:\n[2025-03-07 17:17:31] INFO: Attempting to delete and re-download model...\n[2025-03-07 17:17:31] INFO: Checking model file...\n[2025-03-07 17:17:31] INFO: Model file not found, starting download...", "CLOSED", 0, "attackonryan", "2025-03-07T17:20:52Z", "2025-04-13T18:32:55Z", "2025-04-13T18:32:55Z", "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6sz0bw", 3785, "Discord & Telegram Client Integration Failing to Link with Agent in Eliza OS on WSL2 in Agent Startup", "I\u2019m having trouble getting the integrated Discord and Telegram clients to initialize and interact with the agent in Eliza OS, even though a standalone test confirms that the Discord connection works correctly.\n\n**Environment Details:**\n\nOperating System:  Windows 10, running under WSL2\n\nEliza OS Version:  0.25.9\n\nRelevant Configuration:\n\nThe character JSON file properly lists the clients:\n\n{\n  \"name\": \"Traveler\",\n  \"clients\": [\"discord\", \"telegram\"],\n  \"settings\": {\n    \"secrets\": {\n      \"DISCORD_APPLICATION_ID\": \"your-discord-application-id\"\n      \"DISCORD_API_TOKEN\": \"your-discord-token-here\",\n      \"TELEGRAM_...\": \"your-telegram-token/credentials\"\n    }\n  }\n}\n\nEnvironment (.env) variables are correctly set, including the Discord API token.\n\n**Troubleshooting Steps Taken:\nStandalone Discord Test Script:**\n\nI created a minimal test script using discord.js that logs in and adds an event listener for incoming messages.\nThis script not only logged the bot in successfully (showing the bot appears online) but also successfully echoed back replies to incoming messages. This confirmed that the Discord API token is valid and the network connection is working.\n\n\n**Agent Initialization and Forced Client Tests:**\n\nI reinstalled Eliza OS fresh in a new folder (\"Eliza2test\") to ensure there were no legacy configuration issues. I modified the agent\u2019s index.ts file (referred to as the \u201cforce start Discord client\u201d block) to force-start a Discord client with additional event listeners. The logs indicate the Discord client logs in successfully and even logs the incoming messages:\n\nForced Discord client logged in as Suzy Mero Steele#5510!\nDiscord message received: <@...> Hello traveler\n\nHowever, despite this, the integration does not trigger any internal agent interactions\u2014the bot receives messages but does not forward them to the agent\u2019s processing logic, and Telegram does not seem to initialize at all.\n\n**Other Checks:**\n\nI verified that port configurations (such as port 3000 switching to 3001) and other settings (like health endpoints) are working as expected. I confirmed that the character configuration includes \"discord\" and \"telegram\" with the correct secrets. I added additional debug logging in the agent index file to trace the plugin and client initialization steps. Despite all these debugging steps, the full agent startup logs show that while the agent itself initializes (using Google Gemini as the selected model provider, etc.), the Discord and Telegram integrations remain isolated\u2014the Discord client appears online and logs incoming messages (when forced) but these messages are never forwarded to the agent\u2019s internal interaction flow.\n\n**Expected vs. Actual Behavior:**\n\n**Expected:**  \n\nWhen starting the agent with my character configuration, the Discord and Telegram clients should initialize, and incoming messages received on Discord (and Telegram) should be routed into the agent\u2019s processing logic\u2014triggering interactions or automated responses (enabled by the built-in message handling in Eliza OS).\n\n**Actual:**  \n\nAlthough the standalone test demonstrates that the Discord client can log in and echo messages successfully, when the agent is started through the full startup process, the Discord client (and similarly the Telegram client) do not appear to be linked to the agent\u2019s messaging system. The bot appears online and logs indicate that messages are received, but there is no subsequent interaction or forwarding of those messages into the agent\u2019s core processing logic.\n\n\n**Request:**\n\nI\u2019m looking for guidance on how to properly link the external Discord and Telegram events into the Eliza OS agent\u2019s internal processing pipeline so that the clients become fully interactive. Any help pinpointing where the integration might be breaking down (in the DirectClient or plugin initialization) or suggestions on configuration/network considerations in a WSL2 environment would be greatly appreciated.\n\nFeel free to ask for any additional details or logs if needed. Thank you!\n\n", "CLOSED", 0, "zacmero", "2025-03-06T03:57:35Z", "2025-04-12T18:32:38Z", "2025-04-12T18:32:38Z", "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6rhfR2", 3664, "RAG Knowledge JavaScript Heap Out of Memory", "## Description\nThe application is crashing with a \"JavaScript heap out of memory\" error when processing knowledge/messages. The error occurs during runtime execution with a heap size of approximately 4GB.\n\n## To Reproduce\n1. Run the application with Node.js v23.8.0/v23.3.0\n2. Process single path or single directory knowledge \n3. Application crashes with heap out of memory error\n\n## Error Details\n```\nFATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory\n```\n\n## Stack Trace\nKey components in stack trace:\n1. Heap allocation failure during garbage collection\n2. Error occurs during array push operations\n3. Triggered during async function processing and microtask execution\n\n## Technical Details\n- Node.js Version: v23.8.0/v23.3.0\n- Platform: macOS\n- Current Memory Usage: ~4075MB before crash\n\n## Proposed Solutions\nUnaware\n\n## Additional Context\n- Error occurs during knowledge processing with ragKnowledge enabled ONLY\n\n## Error\n```\n[2025-02-25 08:58:52] INFO: [Timing] Main embedding: 0.15s\n\n<--- Last few GCs --->\n\n[11338:0x140008000]    18160 ms: Scavenge (interleaved) 4075.1 (4085.0) -> 4075.1 (4108.0) MB, pooled: 0 MB, 20.17 / 0.00 ms  (average mu = 0.179, current mu = 0.138) allocation failure; \n[11338:0x140008000]    19484 ms: Mark-Compact (reduce) 4075.8 (4108.0) -> 4075.8 (4078.8) MB, pooled: 0 MB, 1188.88 / 0.00 ms  (+ 9.5 ms in 0 steps since start of marking, biggest step 0.0 ms, walltime since start of marking 1202 ms) (average mu = 0.160, \n\n<--- JS stacktrace --->\n\nFATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory\n----- Native stack trace -----\n\n 1: node::OOMErrorHandler(char const*, v8::OOMDetails const&) \n 2: v8::internal::V8::FatalProcessOutOfMemory(v8::internal::Isolate*, char const*, v8::OOMDetails const&) \n 3: v8::internal::Heap::stack() \n 4: v8::internal::Heap::CollectGarbage(v8::internal::AllocationSpace, v8::internal::GarbageCollectionReason, v8::GCCallbackFlags)::$_1::operator()() const \n 5: void heap::base::Stack::SetMarkerAndCallbackImpl<v8::internal::Heap::CollectGarbage(v8::internal::AllocationSpace, v8::internal::GarbageCollectionReason, v8::GCCallbackFlags)::$_1>(heap::base::Stack*, void*, void const*) \n 6: PushAllRegistersAndIterateStack \n 7: v8::internal::Heap::CollectGarbage(v8::internal::AllocationSpace, v8::internal::GarbageCollectionReason, v8::GCCallbackFlags) \n 8: v8::internal::StackGuard::HandleInterrupts(v8::internal::StackGuard::InterruptLevel) \n 9: v8::internal::Runtime_StackGuard(int, unsigned long*, v8::internal::Isolate*) \n10: Builtins_CEntry_Return1_ArgvOnStack_NoBuiltinExit \n11: Builtins_ArrayPrototypePush \n12:  \n13: Builtins_InterpreterEntryTrampoline \n14: Builtins_InterpreterEntryTrampoline \n15: Builtins_AsyncFunctionAwaitResolveClosure \n16: Builtins_PromiseFulfillReactionJob \n17: Builtins_RunMicrotasks \n18: Builtins_JSRunMicrotasksEntry \n19: v8::internal::(anonymous namespace)::Invoke(v8::internal::Isolate*, v8::internal::(anonymous namespace)::InvokeParams const&) \n20: v8::internal::(anonymous namespace)::InvokeWithTryCatch(v8::internal::Isolate*, v8::internal::(anonymous namespace)::InvokeParams const&) \n21: v8::internal::Execution::TryRunMicrotasks(v8::internal::Isolate*, v8::internal::MicrotaskQueue*) \n22: v8::internal::MicrotaskQueue::RunMicrotasks(v8::internal::Isolate*) \n23: v8::internal::MicrotaskQueue::PerformCheckpoint(v8::Isolate*) \n24: node::InternalCallbackScope::Close() \n25: node::InternalMakeCallback(node::Environment*, v8::Local<v8::Object>, v8::Local<v8::Object>, v8::Local<v8::Function>, int, v8::Local<v8::Value>*, node::async_context, v8::Local<v8::Value>) \n26: node::InternalMakeCallback(v8::Isolate*, v8::Local<v8::Object>, v8::Local<v8::Function>, int, v8::Local<v8::Value>*, node::async_context, v8::Local<v8::Value>) \n27: node::Environment::CheckImmediate(uv_check_s*) \n28: uv__run_check \n29: uv_run \n30: node::SpinEventLoopInternal(node::Environment*) \n31: node::NodeMainInstance::Run() \n32: node::Start(int, char**) \n33: start \nsh: line 1: 11338 Abort trap: 6           node --loader ts-node/esm src/index.ts --characters=./characters/kaiadevbot.character.json\n\u2009ELIFECYCLE\u2009 Command failed with exit code 134.\n```", "CLOSED", 0, "suryanshkushwaha", "2025-02-25T09:14:41Z", "2025-04-19T18:32:38Z", "2025-04-19T18:32:38Z", "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6qCQvW", 3491, "Suggestion: Add platform interface to core package for eliza v2", "**Is your feature request related to a problem? Please describe.**\n\nThis is a problem in that I'm trying to build a platform agnostic core package but eliza has no way of injecting specific platforms into it. It also seems like I will have to pollyfill some node.js libraries to use elizav2 core package\n\n**Describe the solution you'd like**\n\nV2 is super clean but it really needs a platform abstraction. \n\n```typescript\ninterface Platform {\n  name: string\n  readFile?: typeof fs.readFile\n  ...etc\n}\n\nclass NodePlatform implements Platform {\n  name: 'NODEJS'\n  readFile fs.readFile\n  ..etc\n} \n```\n\nSuch that now \n- the entire core package has no platform specific logic in it. Less complexity\n- no imports (except typescript types)  in core package reference a node.js module. No need to polyfill\n- Flexible to provide our own platform for say bun if bun has a node incompatability causing issue in eliza or being in the browser but emulating a file system, etc.\n\nThis is a common pattern in other libraries such as [effect.ts](https://github.com/Effect-TS/effect/tree/main/packages/platform)\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\nAnother option would be to create seperate packages core-web, core-node. But this leads to a lot of code duplication.\n", "OPEN", 0, "roninjin10", "2025-02-14T05:30:55Z", "2025-04-12T18:32:39Z", null, "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6n3n4k", 2919, "[Feature Request] - Implement Reranked Contextual Embedding + cBM25 as per Anthropic Blog as default RAG Implementation", "Contextual retrieval with reranking seems like the state of the art for RAG. It would be amazing if this was implemented as the default RAG system in ElizaOS. \n\nhttps://www.anthropic.com/news/contextual-retrieval\n\n\n![Image](https://github.com/user-attachments/assets/603ef4c1-b3bc-4153-a8a9-48c08c5a4b35)", "CLOSED", 0, "LinuxIsCool", "2025-01-28T17:56:30Z", "2025-04-19T18:32:39Z", "2025-04-19T18:32:39Z", "elizaos/eliza", "2025-04-12 23:03:35"]
["I_kwDOMT5cIs6xPR3S", 4191, "Issue when running elizaos start on Windows (Node/NVM v23.3)", "Hi, I've been trying to install and run ElizaOS from the client, but when I execute the elizaos start command, the process gets stuck and throws some errors.\n\nMy setup is:\nOS: Windows\nNode.js: v23.3 (installed via NVM)\n\nI've attached the error message below (or in a file, if applicable).\nI\u2019ve already tried reinstalling dependencies and restarting the environment, but the issue persists.\nHas anyone else experienced this or knows how to fix it?\n\nThanks in advance!\n\nSteps to Reproduce:\nInstall ElizaOS client on Windows\n\nRun `elizaos start`\n\nThe process freezes and throws the attached error\n\n\n\n\nObserved Error:\n`G:\\DEVELOP\\PRUEBAS\\V1>elizaos start\n\n\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28f8\u28ff\u2800\u2819\u281b\u283f\u28a4\u28e6\u28d0\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\n\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28d0\u28ff\u28ff\u28b0\u2840\u2800\u2800\u2800\u2808\u283b\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\n\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2880\u28f4\u2824\u283e\u281b\u281b\u28ff\u28f6\u28c7\u2800\u2800\u2846\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\n\u2800\u2800\u28b0\u28cb\u2873\u2844\u2800\u2800\u2800\u28a8\u28ed\u2840\u2800\u2864\u2800\u28c0\u28dd\u28bf\u28f6\u28ff\u2845\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\n\u2800\u2800\u28b8\u28ef\u2800\u28c7\u2800\u2800\u2800\u28fc\u28ff\u28ff\u28c6\u28b7\u28f4\u28ff\u28ff\u284f\u28db\u2849\u2800\u2800\u2800\u2800\u28b8\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28b8\u28ff\u28ff\u2800\u2800\u2800\u2800\u2800\u28ff\u28ff\u2847\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u2847\u2800\u2800\u2800\u28fe\u28ff\u28ff\u28e7\u2800\u2800\u2800\u28b8\u281f\u2880\u28f4\u28ff\u28ff\u28ff\u28ff\u28e6\u2840\u28e0\u28fe\u28ff\u28ff\u28ff\u28ff\u28e6\u2859\u28bf\u2800\n\u2800\u2800\u2800\u2819\u28b7\u28ee\u2800\u2800\u28b8\u28ff\u28ff\u28ff\u28ff\u28f7\u28ef\u28df\u28cf\u28fc\u28f7\u28c5\u283e\u285f\u2800\u2800\u28b8\u28ff\u28c7\u28c0\u28c0\u28c0\u2800\u28b8\u28ff\u28ff\u2800\u2800\u2800\u2800\u2800\u28ff\u28ff\u2847\u2800\u2800\u2800\u28e0\u28ff\u28ff\u281f\u2801\u2800\u2800\u28fc\u28ff\u285f\u28ff\u28ff\u28c6\u2800\u2800\u2800\u2800\u28ff\u28ff\u280b\u2800\u2808\u283b\u28ff\u2847\u28ff\u28ff\u28c5\u28c0\u28c0\u285b\u281b\u2803\u2800\u2800\n\u2800\u2800\u2800\u2800\u2800\u2801\u2800\u2800\u28b8\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u280b\u2800\u2800\u2800\u2800\u28b8\u28ff\u287f\u283f\u283f\u283f\u2800\u28b8\u28ff\u28ff\u2800\u2800\u2800\u2800\u2800\u28ff\u28ff\u2847\u2800\u28e0\u28fe\u28ff\u281f\u2801\u2800\u2800\u2800\u28f0\u28ff\u28ff\u28c1\u28f8\u28ff\u28ff\u2844\u2800\u2800\u2800\u28ff\u28ff\u2840\u2800\u2800\u2898\u28ff\u28ff\u2888\u28db\u283f\u283f\u283f\u28ff\u28f7\u2844\u2800\u2800\n\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2838\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28c9\u285f\u2800\u2800\u2800\u2800\u2800\u28b8\u28ff\u28e7\u28e4\u28e4\u28e4\u28e4\u28b8\u28ff\u28ff\u28e6\u28e4\u28e4\u28e4\u2844\u28ff\u28ff\u2847\u28fe\u28ff\u28ff\u28e7\u28e4\u28e4\u28e4\u2844\u28b0\u28ff\u28ff\u281f\u281b\u281b\u283b\u28ff\u28ff\u2844\u28a0\u2840\u283b\u28ff\u28ff\u28e6\u28f4\u28ff\u28ff\u2807\u28bf\u28ff\u28e6\u28e4\u28e4\u28ff\u28ff\u2807\u28e0\u2800\n\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28b0\u2848\u281b\u283f\u28ff\u28ff\u28ff\u28ff\u28ff\u280b\u2800\u28e6\u28e4\u28c4\u2800\u2800\u2818\u281b\u281b\u281b\u281b\u281b\u281b\u2808\u281b\u281b\u281b\u281b\u281b\u281b\u2803\u281b\u281b\u2803\u281b\u281b\u281b\u281b\u281b\u281b\u281b\u2803\u281b\u281b\u2803\u2800\u2800\u2800\u2800\u2819\u281b\u2803\u2818\u281b\u2800\u2808\u281b\u281b\u281b\u281b\u2801\u2800\u2800\u2819\u281b\u281b\u281b\u281b\u2801\u281a\u281b\u2800\n\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28b8\u28ff\u2866\u2800\u2800\u2809\u281b\u283f\u2803\u2800\u2800\u2800\u2801\u2809\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\n\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28b8\u28ff\u2803\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u28be\u2843\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\u2800\n\nVersion: 1.0.0-beta.23\n{\"level\":30,\"time\":1743810665740,\"pid\":7768,\"hostname\":\"SKAMER-PC\",\"msg\":\"Found project by description in package.json\"}\n{\"level\":50,\"time\":1743810665741,\"pid\":7768,\"hostname\":\"SKAMER-PC\",\"msg\":\"Main entry point G:\\\\DEVELOP\\\\PRUEBAS\\\\V1\\\\dist\\\\index.js does not exist\"}\n{\"level\":40,\"time\":1743810665741,\"pid\":7768,\"hostname\":\"SKAMER-PC\",\"msg\":\"Project module doesn't contain a valid default export\"}\nStartup successful!\nGo to the dashboard at http://localhost:3000\n[2025-04-04 23:51:07] INFO: Using default Eliza character with all plugins\n[2025-04-04 23:51:08] INFO: Plugin @elizaos/plugin-local-ai not available, installing into G:\\DEVELOP\\PRUEBAS\\V1...\n[2025-04-04 23:51:08] INFO: Installing plugin: @elizaos/plugin-local-ai\n[2025-04-04 23:51:09] INFO: \u00d4\u00a3\u00f4 Using GitHub credentials for urgarcia\n[2025-04-04 23:51:09] INFO: Attempting to install plugin locally...\nbun add v1.2.8 (adab0f64)\n\ninstalled @elizaos/plugin-local-ai@1.0.0-beta.23\n\n15 packages installed [1.74s]\n\nBlocked 1 postinstall. Run `bun pm untrusted` for details.\n[2025-04-04 23:51:11] WARN: Plugin installed locally but cannot be imported: Cannot find module 'D:\\AppData\\Roaming\\nvm\\v23.3.0\\node_modules\\@elizaos\\plugin-local-ai\\node_modules\\fastembed\\lib\\esm\\fastembed' imported from D:\\AppData\\Roaming\\nvm\\v23.3.0\\node_modules\\@elizaos\\plugin-local-ai\\node_modules\\fastembed\\lib\\esm\\index.js\n[2025-04-04 23:51:11] INFO: Attempting to install plugin globally...\nbun add v1.2.8 (adab0f64)\n\ninstalled @elizaos/plugin-local-ai@1.0.0-beta.23\n\n[187.00ms] done\n[2025-04-04 23:51:11] WARN: Plugin installed globally but cannot be imported: Cannot find module 'D:\\AppData\\Roaming\\nvm\\v23.3.0\\node_modules\\@elizaos\\plugin-local-ai\\node_modules\\fastembed\\lib\\esm\\fastembed' imported from D:\\AppData\\Roaming\\nvm\\v23.3.0\\node_modules\\@elizaos\\plugin-local-ai\\node_modules\\fastembed\\lib\\esm\\index.js\n[2025-04-04 23:51:11] ERROR: All installation attempts failed for plugin @elizaos/plugin-local-ai\n[2025-04-04 23:51:11] ERROR: Failed to import plugin @elizaos/plugin-local-ai after installation: Only URLs with a scheme in: file, data, and node are supported by the default ESM loader. On Windows, absolute paths must be valid file:// URLs. Received protocol 'g:'\n[2025-04-04 23:51:11] INFO: Plugin @elizaos/plugin-bootstrap not available, installing into G:\\DEVELOP\\PRUEBAS\\V1...\n[2025-04-04 23:51:11] INFO: Installing plugin: @elizaos/plugin-bootstrap\n[2025-04-04 23:51:11] INFO: \u00d4\u00a3\u00f4 Using GitHub credentials for urgarcia\n[2025-04-04 23:51:12] INFO: Attempting to install plugin locally...\nbun add v1.2.8 (adab0f64)\n\ninstalled @elizaos/plugin-bootstrap@1.0.0-beta.23\n\n[259.00ms] done\n[2025-04-04 23:51:12] WARN: Plugin installed locally but cannot be imported: Cannot find package '@elizaos/plugin-bootstrap' imported from D:\\AppData\\Roaming\\nvm\\v23.3.0\\node_modules\\@elizaos\\cli\\dist\\chunk-OLL7NAYA.js\n[2025-04-04 23:51:12] INFO: Attempting to install plugin globally...\nbun add v1.2.8 (adab0f64)\n\ninstalled @elizaos/plugin-bootstrap@1.0.0-beta.23\n\n[179.00ms] done\n[2025-04-04 23:51:12] WARN: Plugin installed globally but cannot be imported: Cannot find package '@elizaos/plugin-bootstrap' imported from D:\\AppData\\Roaming\\nvm\\v23.3.0\\node_modules\\@elizaos\\cli\\dist\\chunk-OLL7NAYA.js\n[2025-04-04 23:51:12] ERROR: Failed to run database migrations:\n    message: \"(Error) Can't find meta/_journal.json file\"\n    stack: [\n      \"Error: Can't find meta/_journal.json file\",\n      \"at readMigrationFiles (file:///D:/AppData/Roaming/nvm/v23.3.0/node_modules/@elizaos/plugin-sql/node_modules/drizzle-orm/migrator.js:8:11)\",\n      \"at migrate (file:///D:/AppData/Roaming/nvm/v23.3.0/node_modules/@elizaos/plugin-sql/node_modules/drizzle-orm/pglite/migrator.js:3:22)\",\n      \"at PGliteClientManager.runMigrations (file:///D:/AppData/Roaming/nvm/v23.3.0/node_modules/@elizaos/plugin-sql/dist/index.js:1964:13)\",\n      \"at PgliteDatabaseAdapter.init (file:///D:/AppData/Roaming/nvm/v23.3.0/node_modules/@elizaos/plugin-sql/dist/index.js:1866:26)\",\n      \"at AgentRuntime.initialize (file:///D:/AppData/Roaming/nvm/v23.3.0/node_modules/@elizaos/cli/dist/chunk-6TAU44KI.js:46038:24)\",\n      \"at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\",\n      \"at async startAgent (file:///D:/AppData/Roaming/nvm/v23.3.0/node_modules/@elizaos/cli/dist/chunk-H6T577NJ.js:82915:3)\",\n      \"at async startAgents (file:///D:/AppData/Roaming/nvm/v23.3.0/node_modules/@elizaos/cli/dist/chunk-H6T577NJ.js:83115:7)\",\n      \"at async _Command.<anonymous> (file:///D:/AppData/Roaming/nvm/v23.3.0/node_modules/@elizaos/cli/dist/chunk-H6T577NJ.js:83167:7)\",\n      \"at async _Command.parseAsync (file:///D:/AppData/Roaming/nvm/v23.3.0/node_modules/@elizaos/cli/dist/chunk-5LH7NKB4.js:1721:9)\"\n    ]\n[2025-04-04 23:51:12] ERROR: All installation attempts failed for plugin @elizaos/plugin-bootstrap\n[2025-04-04 23:51:12] ERROR: Failed to import plugin @elizaos/plugin-bootstrap after installation: Only URLs with a scheme in: file, data, and node are supported by the default ESM loader. On Windows, absolute paths must be valid file:// URLs. Received protocol 'g:'\n{\"level\":40,\"time\":1743810673738,\"pid\":7768,\"hostname\":\"SKAMER-PC\",\"agentName\":\"Eliza\",\"agentId\":\"b850bc30-45f8-0041-a00a-83df46d8555d\",\"msg\":\"[AgentRuntime][Eliza] No TEXT_EMBEDDING model registered. Skipping embedding dimension setup.\"}\n`", "CLOSED", 0, "urgarcia", "2025-04-05T00:00:55Z", "2025-04-05T00:21:37Z", "2025-04-05T00:21:37Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6xKrBN", 4181, "Twitter interactions fetched but reactions not implemented yet", "Currently, we fetch the interactions for Twitter, but we haven't implemented reactions for those interactions yet:\n\nhttps://github.com/elizaOS/eliza/blob/9179074304d8c069004baa05e55c632898e06601/packages/plugin-twitter/src/interactions.ts#L308", "OPEN", 0, "tcm390", "2025-04-04T13:18:50Z", "2025-04-04T13:19:10Z", null, "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6xKo89", 4180, "Twitter space is not working", "I'm getting the following dyld error when trying to use space in twitter plugin\n\n<img width=\"278\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/19317364-83fa-418d-ac6f-913ec63ea842\" />\n\nIt seems like this might be caused by Bun not being fully compatible with wrtc.\n\n", "OPEN", 0, "tcm390", "2025-04-04T13:15:32Z", "2025-04-04T13:19:15Z", null, "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6w47Dm", 4164, "Clearly Mark or Remove Plugins Not Yet Compatible with Eliza v2", "I began exploring the v2 version of Eliza and initially assumed that the plugins listed on the [[Showcase](https://eliza.how/packages)](https://eliza.how/packages) and [[Plugins](https://eliza.how/packages/plugins/0g)](https://eliza.how/packages/plugins/0g) pages of the beta docs site were already compatible with v2.\n\n<img width=\"1356\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/38d58b99-ca0e-4ea6-81da-01ad709ebf50\" />\n\nAfter discussing this with the team, I discovered that currently, only plugins in the `/packages` directory of the `v2-develop` branch are fully compatible with v2. The plugins shown on the documentation website are still v1 and may or may not function correctly.\n\nTo avoid confusion for developers, I suggest either temporarily removing plugins that aren't yet v2-compatible from these pages or clearly marking them as v1-only until they are fully updated.", "OPEN", 0, "odysseus0", "2025-04-02T22:47:35Z", "2025-04-02T22:52:12Z", null, "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6w2lhs", 4160, "ElizaOS always defaults to open AI", "**Describe the bug**\n\nDespite changing \"modelProvider\" to \"anthropic\" on character json, I get error:\n\"msg\":\"API Response: {\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from [https://platform.openai.com/account/api-keys.\\](https://platform.openai.com/account/api-keys./)\",\\n        \\\"type\\\": \\\"invalid_request_error\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": null\\n    }\\n}\\n\"}\n\n**To Reproduce**\n\n- Create a simple AI Agent using ElizaOS using openAI API and Telegram bot\n- Create a new character with openAI API\n- Change API to anthropic\n- error above happens\n\n**Expected behavior**\n\nRemoving openAI API .env and adding anthropic API in .env, and changing character modelProvider from openai to anthropic should change the the LLM API to anthropic.\n", "CLOSED", 0, "Valcyclovir", "2025-04-02T17:35:10Z", "2025-04-02T19:23:08Z", "2025-04-02T19:23:08Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6wvhJW", 4147, "adjective error", "**Describe the bug**\n\nI am just running the AI agent and it is giving this error\n\n\n\n\nError logs\n\n\n\n> eliza@ start /Users/ambusiness/Documents/Agents/Eliza/lik/eliza\n> pnpm --filter \"@elizaos/agent\" start --isRoot \"--character=characters/rain.character.json\"\n\n\n> @elizaos/agent@0.25.9 start /Users/ambusiness/Documents/Agents/Eliza/lik/eliza/agent\n> node --loader ts-node/esm src/index.ts --isRoot --character\\=characters/rain.character.json\n\n(node:6420) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\n(Use `node --trace-warnings ...` to show where the warning was created)\n(node:6420) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n[2025-04-02 05:32:19] INFO: Loading embedding settings:\n    USE_OPENAI_EMBEDDING: \"\"\n    USE_OLLAMA_EMBEDDING: \"\"\n    OLLAMA_EMBEDDING_MODEL: \"mxbai-embed-large\"\nError parsing character from /Users/ambusiness/Documents/Agents/Eliza/lik/eliza/characters/rain.character.json:  Error: Character configuration validation failed. Check logs for details.\n    at validateCharacterConfig (file:///Users/ambusiness/Documents/Agents/Eliza/lik/eliza/packages/core/dist/index.js:5826:19)\n    at jsonToCharacter (file:///Users/ambusiness/Documents/Agents/Eliza/lik/eliza/agent/src/index.ts:159:5)\n    at loadCharacter (file:///Users/ambusiness/Documents/Agents/Eliza/lik/eliza/agent/src/index.ts:203:12)\n    at loadCharacterTryPath (file:///Users/ambusiness/Documents/Agents/Eliza/lik/eliza/agent/src/index.ts:236:33)\n    at loadCharacters (file:///Users/ambusiness/Documents/Agents/Eliza/lik/eliza/agent/src/index.ts:271:41)\n    at startAgents (file:///Users/ambusiness/Documents/Agents/Eliza/lik/eliza/agent/src/index.ts:627:28)\n    at file:///Users/ambusiness/Documents/Agents/Eliza/lik/eliza/agent/src/index.ts:667:1\n    at ModuleJob.run (node:internal/modules/esm/module_job:271:25)\n    at async onImport.tracePromise.__proto__ (node:internal/modules/esm/loader:547:26)\n    at async asyncRunEntryPointWithESMLoader (node:internal/modules/run_main:116:5)\n[2025-04-02 05:32:19] INFO: Parsed settings:\n    USE_OPENAI_EMBEDDING: \"\"\n    USE_OPENAI_EMBEDDING_TYPE: \"string\"\n    USE_OLLAMA_EMBEDDING: \"\"\n    USE_OLLAMA_EMBEDDING_TYPE: \"string\"\n    OLLAMA_EMBEDDING_MODEL: \"mxbai-embed-large\"\n[2025-04-02 05:32:19] ERROR: Validation errors in adjectives: Required\n/Users/ambusiness/Documents/Agents/Eliza/lik/eliza/agent:\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.25.9 start: `node --loader ts-node/esm src/index.ts --isRoot --character\\=characters/rain.character.json`\nExit status 1\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\n\n\n", "CLOSED", 0, "yasir23", "2025-04-02T05:42:32Z", "2025-04-02T14:52:02Z", "2025-04-02T14:52:02Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6wvWc1", 4146, "Failed to create Twitter client", "<img width=\"812\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3aa6e12e-ec2a-41f4-b537-395cbba5699b\" />\n\nSteps to Reproduce:\n\n1. Purge the database\n\n2. Run the Twitter plugin", "CLOSED", 0, "tcm390", "2025-04-02T05:12:54Z", "2025-04-18T09:06:33Z", "2025-04-18T09:06:33Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6wvObY", 4145, "Documentation URL -> 404 Error", "", "CLOSED", 0, "mrasmuson", "2025-04-02T04:45:40Z", "2025-04-02T04:49:00Z", "2025-04-02T04:48:08Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6wkFlk", 4127, "Repeat checking on interaction, mentioned tweets", "# ElizaOS Twitter Plugin: Redundant Tweet Interaction Checks\n\n## Description\nThe Twitter plugin is repeatedly checking the same tweets and mentions in a loop, even after they've been processed. This creates unnecessary API calls and log spam.\n\n## Current Behavior\nThe system continuously checks the same tweets over and over, as shown in the logs:\n\n```log\n[2025-03-31 16:21:29] LOG: Checking Twitter interactions\n[2025-03-31 16:21:30] LOG: Completed checking mentioned tweets:\n[2025-03-31 16:21:30] LOG: Already responded to tweet 1906195114227020237, skipping\n[2025-03-31 16:21:30] LOG: Already responded to tweet 1906195395497091521, skipping\n[2025-03-31 16:21:30] LOG: Already responded to tweet 1906209067460137240, skipping\n...\n[2025-03-31 16:21:59] LOG: Checking Twitter interactions\n[2025-03-31 16:22:00] LOG: Already responded to tweet 1906195114227020237, skipping\n[2025-03-31 16:22:00] LOG: Already responded to tweet 1906195395497091521, skipping\n[2025-03-31 16:22:00] LOG: Already responded to tweet 1906209067460137240, skipping\n```\n\n## Expected Behavior\n- The system should only check new interactions since the last check\n- Previously processed tweets should be filtered out before logging\n- The interaction check should maintain a cursor or timestamp of the last checked tweet\n\n## Impact\n1. Unnecessary Twitter API calls that could lead to rate limiting\n2. Excessive log entries making it difficult to debug actual issues\n3. Increased system load from repeated processing of the same data\n\n## Possible Solutions\n1. Implement a cursor-based pagination system to only fetch new tweets\n2. Store the last checked tweet ID and only process tweets newer than that\n3. Add a proper caching mechanism for processed tweets with TTL\n\n## Environment\n- ElizaOS Version: 1.0.0-beta.7\n- Bun install && bun run build && bun start\n\n## Related Issues\n- Previous issue about duplicate key errors in Twitter mentions #4115 ", "CLOSED", 0, "AbdelrahmanZ08", "2025-04-01T05:06:27Z", "2025-04-18T09:06:47Z", "2025-04-18T09:06:47Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6wY2k6", 4119, "router.post('/:agentId/rooms' feels haze", "\nThis api handles a variety of scenarios, and the lack of annotations gives a headache", "CLOSED", 0, "tercel", "2025-03-31T02:15:38Z", "2025-04-02T17:30:34Z", "2025-04-02T17:30:34Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6wW8do", 4117, "HOW do we block and ban interactions with specific accounts???", "I added an account I thought would be good for my account to interact with on target accounts in .env and I was WRONG! The account constantly pulls OLD DATA and posts it as current! So even though my ai agent can pull up to date coin prices and volume flows from the coin gecko plug-in on request, she doesn\u2019t verify before responding or sharing information from this twitter user. NOR can I get it to stop now!!! I have:\n\n-deleted every comment I can find!\n-blocked the account on our Twitter\n-removed account from .env\n-pushed updated .env to 24/7 server\n\nAND ITS STILL ONGOING!!!\n\nGood: please help me block bad influences!\nBest: please help me get her to KNOW on her own what information is true and false so she can debate or ignore improper data!", "OPEN", 0, "coxnate87", "2025-03-30T11:01:28Z", "2025-03-30T11:01:52Z", null, "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6wWdk_", 4115, "Twitter Plugin: Duplicate Memory Creation on Mentions & Null Post Interval Configuration", "# ElizaOS Twitter Plugin Bugs\n\n## Issue 1: Duplicate Key Error When Receiving Twitter Mentions\n\n**Describe the bug**\nWhen someone mentions the bot on Twitter, the system tries to create a memory record twice with the same ID, resulting in database errors:\n\n```\nerror: duplicate key value violates unique constraint \"memories_pkey\"\ndetail: \"Key (id)=(d79a6e52-7b78-0c8b-941d-fd9c0e353f7a) already exists.\"\n```\n\nLogs show the same memory ID being processed twice:\n```\n[2025-03-30 05:29:29] DEBUG: DrizzleAdapter createMemory:\n    memoryId: \"d79a6e52-7b78-0c8b-941d-fd9c0e353f7a\"\n    contentLength: 26\n[2025-03-30 05:29:29] LOG: Processing Tweet: 1906217138978697554\n[2025-03-30 05:29:29] DEBUG: DrizzleAdapter createMemory:\n    memoryId: \"d79a6e52-7b78-0c8b-941d-fd9c0e353f7a\"\n    contentLength: 26\n```\n\n**To Reproduce**\n1. Configure Twitter plugin with valid credentials\n2. Have someone mention your Twitter bot\n3. Check logs for duplicate key errors\n\n**Expected behavior**\nThe bot should create only one memory record per tweet mention and handle all interactions without database errors.\n\n**Root cause**\nThe issue occurs because `handleTwitterInteractions()` creates a memory record and then calls `handleTweet()` which tries to create the same memory again:\n1. First creation in `handleTwitterInteractions()` around line 227\n2. Second creation in `handleTweet()` around line 642\n\n## Issue 2: Null Post Interval Configuration\n\n**Describe the bug**\nThe Twitter post interval configuration is not being properly read, resulting in null values in the logs:\n\n```\n[2025-03-30 05:31:09] LOG: - Post Interval: null-null minutes\n```\n\n**To Reproduce**\n1. Configure Twitter plugin with a valid post interval setting\n2. Check logs to see that the interval is showing as null-null minutes\n\n**Expected behavior**\nThe logs should correctly show the configured post interval, such as \"Post Interval: 30-60 minutes\" if configured with those values.\n\n**Additional context**\nThe post interval configuration appears to be properly set in the config files, but the system is not reading or applying these values correctly. This may affect the bot's posting schedule.\n\nThese two bugs should be fixed separately as they affect different aspects of the Twitter plugin functionality:\n1. The duplicate key error prevents proper handling of mentions\n2. The null post interval may cause irregular posting behavior ", "CLOSED", 0, "AbdelrahmanZ08", "2025-03-30T05:39:58Z", "2025-04-18T09:05:30Z", "2025-04-18T09:05:30Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6wWHLr", 4113, "feat: Improving CLI tool instructions", "- [ ] Include a link to eliza.how for docs\n- [ ] Mention openrouter free models as an option: https://openrouter.ai/models?max_price=0\n- [ ] Change `npx elizaos start` while still in beta\n  - `npx @elizaos/cli@beta start` or `elizaos start` if CLI is installed", "OPEN", 0, "madjin", "2025-03-30T00:50:59Z", "2025-03-30T00:50:59Z", null, "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6wUGKF", 4109, "Installation fails: Cannot find dependency @elizaos/plugin-sql@^0.25.", "When trying to install @elizaos/cli using npm (both the default tag and @latest), the installation fails with an ETARGET / notarget error. It seems the package requires a version of @elizaos/plugin-sql (^0.25.6) that does not exist on the public npm registry.\n\nSteps to Reproduce:\n\nRun sudo npm install -g @elizaos/cli\nAlternatively, run sudo npm install -g @elizaos/cli@latest\nExpected Behavior:\n\nThe @elizaos/cli package should install successfully.\n\nActual Behavior:\n\nThe installation fails with the following error message:\n\nnpm error code ETARGET\nnpm error notarget No matching version found for @elizaos/plugin-sql@^0.25.6.\nnpm error notarget In most cases you or one of your dependencies are requesting\nnpm error notarget a package version that doesn't exist.\nA complete log can be found in the /root/.npm/_logs/ directory (e.g., 2025-03-29T14_36_04_653Z-debug-0.log).\n\nInvestigation:\n\nRunning npm view @elizaos/plugin-sql versions confirms that no version matching ^0.25.6 exists on the public npm registry. The only available versions are pre-releases for 1.0.0:\n\nJSON\n\n[\n  '1.0.0-alpha.1',  '1.0.0-alpha.2',  '1.0.0-alpha.3',\n  '1.0.0-alpha.4',  '1.0.0-alpha.5',  '1.0.0-alpha.6',\n  '1.0.0-alpha.7',  '1.0.0-alpha.11', '1.0.0-alpha.16',\n  '1.0.0-alpha.17', '1.0.0-alpha.18', '1.0.0-alpha.19',\n  '1.0.0-alpha.20', '1.0.0-alpha.21', '1.0.0-alpha.22',\n  '1.0.0-alpha.23', '1.0.0-alpha.24', '1.0.0-alpha.25',\n  '1.0.0-alpha.26', '1.0.0-alpha.27', '1.0.0-alpha.28',\n  '1.0.0-alpha.29', '1.0.0-alpha.30', '1.0.0-alpha.31',\n  '1.0.0-alpha.32', '1.0.0-alpha.33', '1.0.0-alpha.34',\n  '1.0.0-alpha.35', '1.0.0-alpha.36', '1.0.0-alpha.37',\n  '1.0.0-alpha.38', '1.0.0-alpha.39', '1.0.0-alpha.40',\n  '1.0.0-alpha.41', '1.0.0-alpha.42', '1.0.0-alpha.43',\n  '1.0.0-alpha.44', '1.0.0-alpha.45', '1.0.0-alpha.46',\n  '1.0.0-alpha.47', '1.0.0-alpha.48', '1.0.0-alpha.49',\n  '1.0.0-alpha.50', '1.0.0-alpha.51', '1.0.0-alpha.52',\n  '1.0.0-alpha.53', '1.0.0-alpha.54', '1.0.0-alpha.55',\n  '1.0.0-alpha.56', '1.0.0-alpha.57', '1.0.0-alpha.58',\n  '1.0.0-alpha.59', '1.0.0-alpha.60', '1.0.0-alpha.61',\n  '1.0.0-alpha.62', '1.0.0-alpha.63', '1.0.0-alpha.64',\n  '1.0.0-alpha.65', '1.0.0-alpha.66', '1.0.0-alpha.67',\n  '1.0.0-beta.0',   '1.0.0-beta.1',   '1.0.0-beta.3',\n  '1.0.0-beta.4',   '1.0.0-beta.5',   '1.0.0-beta.6',\n  '1.0.0-beta.7'\n]\nEnvironment:\n\nNode.js version: v23.4.0\nnpm version: v11.2.0\nOS: Linux (DietPi)\nSuggested Fix:\n\nThe dependency reference to @elizaos/plugin-sql within the package.json for @elizaos/cli needs to be updated to point to a valid, existing version (perhaps one of the 1.0.0 pre-releases, or whichever version is intended).", "CLOSED", 0, "frahlg", "2025-03-29T14:38:57Z", "2025-03-30T00:25:17Z", "2025-03-30T00:25:16Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6wTKkh", 4107, "bug: npx elizaos create error: agents already exists", "steps to reproduce:\n\n1. `npx elizaos create`\n2. cd new-agent\n3. `npx elizaos start`\n\n![Image](https://github.com/user-attachments/assets/82891b06-a775-4abe-b8c2-70cfe56e201b)\n\nnode 23.7.0\ndebian 12", "OPEN", 0, "madjin", "2025-03-29T06:33:19Z", "2025-04-01T15:15:26Z", null, "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6wM7gr", 4102, "not getting links and hashtags in my twitter post", "How can I get the links and hashtags for my Twitter post from the openai", "CLOSED", 0, "mern-hash", "2025-03-28T13:30:49Z", "2025-03-31T11:28:05Z", "2025-03-31T11:28:04Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6wKYxZ", 4101, "dependency not found\uff08npm error notarget No matching version found for @elizaos/plugin-sql@^0.25.6.\uff09", "**Describe the bug**\n\nuse fellow cmd\uff1a\n npm install -g @elizaos/cli@latest\n\nget error\uff1a\n npm install -g @elizaos/cli@latest\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "elvin-du", "2025-03-28T09:26:19Z", "2025-04-02T17:33:58Z", "2025-04-02T17:33:58Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6wHbtk", 4097, "ENABLE_TWITTER_POST_GENERATION is this still used?", "ENABLE_TWITTER_POST_GENERATION is this still used in v2?\nI dont see that its being read", "CLOSED", 0, "jmikedupont2", "2025-03-28T00:44:57Z", "2025-04-02T17:33:19Z", "2025-04-02T17:33:19Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6v4ND4", 4087, "Groq crashing when it should retry", "> Its not a billing issue it is crashing\n> \n> ```node:internal/process/promises:288\n>             triggerUncaughtException(err, true /* fromPromise */);\n>             ^\n> \n> RetryError [AI_RetryError]: Failed after 3 attempts. Last error: Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01j5b4pz9jff492fq686vypsx6` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 3770, Requested 2374. Please try a\\\n> gain in 1.430999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\n>     at _retryWithExponentialBackoff (file:///mnt/data1/nix/time/2025/03/14/cloud-deployment-eliza/node_modules/ai/dist/index.mjs:283:13)\n>     at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n>     at async fn (file:///mnt/data1/nix/time/2025/03/14/cloud-deployment-eliza/node_modules/ai/dist/index.mjs:4106:32)\n>     at async file:///mnt/data1/nix/time/2025/03/14/cloud-deployment-eliza/node_modules/ai/dist/index.mjs:470:22\n>     at async TEXT_SMALL (file:///mnt/data1/nix/time/2025/03/14/cloud-deployment-eliza/packages/plugin-groq/dist/index.js:95:40)\n>     at async AgentRuntime.useModel (file:///mnt/data1/nix/time/2025/03/14/cloud-deployment-eliza/packages/cli/dist/chunk-RSA7S755.js:27926:22)\n>     at async file:///mnt/data1/nix/time/2025/03/14/cloud-deployment-eliza/packages/cli/dist/chunk-RSA7S755.js:26492:29\n>     at async messageReceivedHandler (file:///mnt/data1/nix/time/2025/03/14/cloud-deployment-eliza/packages/cli/dist/chunk-RSA7S755.js:26561:5)\n>     at async events (file:///mnt/data1/nix/time/2025/03/14/cloud-deployment-eliza/packages/cli/dist/chunk-RSA7S755.js:26745:7)\n>     at async Promise.all (index 0) {\n>   cause: undefined,\n>   reason: 'maxRetriesExceeded',\n>   errors: [\n>     APICallError [AI_APICallError]: Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01j5b4pz9jff492fq686vypsx6` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4380, Requested 2374. Please try again in 7.537s. Need more tok\\\n> ens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\n> ``` \n\n _Originally posted by @jmikedupont2 in [#4040](https://github.com/elizaOS/eliza/issues/4040#issuecomment-2755697456)_", "CLOSED", 0, "jmikedupont2", "2025-03-26T20:41:14Z", "2025-03-30T11:35:45Z", "2025-03-30T11:35:44Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6vPbyg", 4046, "import { generateText } from \"@elizaos/core\";    SyntaxError: The requested module '@elizaos/core' does not provide an export named 'generateText'", "**Describe the bug**\n\nThe requested module '@elizaos/core' does not provide an export named 'generateText'\n\n**To Reproduce**\n\nWhen I tried to import generateText using import { generateText } from \"@elizaos/core\", this error occurred. \n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "OPEN", 0, "ljiang22", "2025-03-22T05:13:29Z", "2025-03-30T11:39:33Z", null, "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6vLkcP", 4042, "invalid input syntax for type uuid: \\\"-1002129157442\\\"\"", "```\n}\n[2025-03-21 17:26:26] INFO: Found 1 roles\n[2025-03-21 17:26:26] ERROR: Error in role provider:\n    message: \"(error) invalid input syntax for type uuid: \\\"-1002129157442\\\"\"\n    stack: [\n      \"error: invalid input syntax for type uuid: \\\"-1002129157442\\\"\",\n      \"at ye.Ve (file:///opt/agent/node_modules/@electric-sql/pglite/dist/chunk-EADU5A67.js:1:17602)\",\n      \"at ye.nt (file:///opt/agent/node_modules/@electric-sql/pglite/dist/chunk-EADU5A67.js:1:14988)\",\n      \"at ye.parse (file:///opt/agent/node_modules/@electric-sql/pglite/dist/chunk-EADU5A67.js:1:13740)\",\n      \"at pe.execProtocol (file:///opt/agent/node_modules/@electric-sql/pglite/dist/index.js:3:239489)\",\n      \"at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\",\n      \"at async pe.l (file:///opt/agent/node_modules/@electric-sql/pglite/dist/chunk-A7RFOIQ7.js:8:1911)\",\n      \"at async file:///opt/agent/node_modules/@electric-sql/pglite/dist/chunk-A7RFOIQ7.js:8:2407\"\n    ]\n[2025-03-21 17:26:26] INFO: No settings state found for server -1002129157442\n\n```", "CLOSED", 0, "jmikedupont2", "2025-03-21T17:27:49Z", "2025-04-02T17:32:59Z", "2025-04-02T17:32:57Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6vJNNF", 4040, "groq  tokens per minute (TPM): Limit 6000", "for groq\n```\n(AI_APICallError) Request too large for model `llama-3.1-8b-instant` in organization `xxxx` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 6294, please reduce your message size and try again. Visit https://console.groq.com/docs/rate-limits for more information.\n```", "CLOSED", 0, "jmikedupont2", "2025-03-21T13:34:04Z", "2025-03-30T10:53:41Z", "2025-03-30T10:53:40Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6vHWH9", 4037, "Issue: Cannot find package '@elizaos/plugin-openai' when using beta packages", "## Describe the bug\nWhen starting ElizaOS with `bun dev` or `bun start` using the beta version packages, I consistently get an error indicating that the `@elizaos/plugin-openai` package cannot be found, despite having it listed in my dependencies.\n\n## To Reproduce\n1. Install the beta versions of ElizaOS packages:\n```json\n\"dependencies\": {\n  \"@elizaos/cli\": \"^1.0.0-beta.7\",\n  \"@elizaos/core\": \"1.0.0-beta.7\",\n  \"@elizaos/plugin-anthropic\": \"1.0.0-beta.7\",\n  \"@elizaos/plugin-local-ai\": \"1.0.0-beta.7\",\n  \"@elizaos/plugin-openai\": \"1.0.0-beta.7\",\n  \"@elizaos/plugin-sql\": \"1.0.0-beta.7\",\n  \"zod\": \"3.24.2\"\n}\n```\n2. Run `bun install` to ensure all packages are installed\n3. Start the application with `bun dev` or `bun start`\n\n## Expected behavior\nElizaOS should start successfully without reporting missing package errors, since all required packages are listed in the dependencies.\n\n## Screenshots\nError message:\n```json\n{\"level\":50,\"time\":1742551769974,\"pid\":607710,\"hostname\":\"kvm8856\",\"message\":\"(Error) Cannot find package '@elizaos/plugin-openai' imported from /tmp/bunx-1000-@elizaos/cli@beta/node_modules/@elizaos/cli/dist/chunk-H473MSWF.js\",\"stack\":[\"Error [ERR_MODULE_NOT_FOUND]: Cannot find package '@elizaos/plugin-openai' imported from /tmp/bunx-1000-@elizaos/cli@beta/node_modules/@elizaos/cli/dist/chunk-H473MSWF.js\",\"at Object.getPackageJSONURL (node:internal/modules/package_json_reader:267:9)\",\"at packageResolve (node:internal/modules/esm/resolve:768:81)\",\"at moduleResolve (node:internal/modules/esm/resolve:854:18)\",\"at defaultResolve (node:internal/modules/esm/resolve:984:11)\",\"at ModuleLoader.defaultResolve (node:internal/modules/esm/loader:780:12)\",\"at #cachedDefaultResolve (node:internal/modules/esm/loader:704:25)\",\"at ModuleLoader.resolve (node:internal/modules/esm/loader:687:38)\",\"at ModuleLoader.getModuleJobForImport (node:internal/modules/esm/loader:305:38)\",\"at onImport.tracePromise.__proto__ (node:internal/modules/esm/loader:643:36)\",\"at TracingChannel.tracePromise (node:diagnostics_channel:344:14)\"],\"msg\":\"Failed to import plugin: @elizaos/plugin-openai\"}\n```", "CLOSED", 0, "NewtTheWolf", "2025-03-21T10:20:16Z", "2025-04-03T00:39:41Z", "2025-03-26T13:10:45Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6u_lAS", 4024, "Ollama LLM Response Parsing Fails (TypeError: null is not an object)\u00a0GH #3993", "**Describe the Bug:**\n\nWhen using Ollama as the LLM engine in ElizaOS (v1.0.0-beta.2), the response parsing fails with a TypeError: null is not an object (evaluating 'responseObject.providers'). The issue occurs because parseJSONObjectFromText(response) returns null, which suggests that the response from Ollama is not valid JSON.\n\n**<br>To Reproduce:**\n\nUSE_OLLAMA_TEXT_MODELS=true\n\nOLLAMA_SERVER_URL=[http://localhost:11434](http://localhost:11434)\n\nOLLAMA_MODEL=llama3.2:1b\n\nSMALL_OLLAMA_MODEL=llama3.2:1b\n\nMEDIUM_OLLAMA_MODEL=llama3.2:1b\n\nLARGE_OLLAMA_MODEL=llama3.2:1b\n\n<br>**Screenshots:**\n\n<img src=\"https://uploads.linear.app/186bdefa-3633-464a-80cd-6e86fe765a5c/ae46c573-23ff-47fd-a48a-9087bc3da2c0/109f5dae-c5e7-44dc-b708-7353c6cdb28d?signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiLzE4NmJkZWZhLTM2MzMtNDY0YS04MGNkLTZlODZmZTc2NWE1Yy9hZTQ2YzU3My0yM2ZmLTQ3ZmQtYTQ4YS05MDg3YmMzZGEyYzAvMTA5ZjVkYWUtYzVlNy00NGRjLWI3MDgtNzM1M2M2Y2RiMjhkIiwiaWF0IjoxNzQyNDg1MTQyLCJleHAiOjMzMzEzMDQ1MTQyfQ.1Gb77mOV4YkFJisP6ht2wf2s6C5KvoPOyB3X9O8W6Gk \" alt=\"image.png\" width=\"929\" data-linear-height=\"956\" />\n\n**Additional context**\n\n* Ollama works fine when tested via the Ollama WebUI.", "CLOSED", 0, "linear", "2025-03-20T15:37:58Z", "2025-03-30T10:32:54Z", "2025-03-20T15:40:48Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6u8bi-", 4020, "npx elizaos agent list fetch failed", "npx elizaos agent list\n[2025-03-20 11:18:26] USERLVL: An error occurred:\n[2025-03-20 11:18:26] USERLVL: Error details: fetch failed\n[2025-03-20 11:18:26] USERLVL: Stack trace: TypeError: fetch failed\n    at node:internal/deps/undici/undici:13484:13\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async getAgents (file:///Users/alexander/Sources/eliza/liza/node_modules/@elizaos/cli/dist/chunk-NXPHQUQ5.js:106:20)\n    at async _Command.<anonymous> (file:///Users/alexander/Sources/eliza/liza/node_modules/@elizaos/cli/dist/chunk-NXPHQUQ5.js:132:20)\n    at async _Command.parseAsync (file:///Users/alexander/Sources/eliza/liza/node_modules/@elizaos/cli/dist/chunk-5LH7NKB4.js:1721:9)\n    at async main (file:///Users/alexander/Sources/eliza/liza/node_modules/@elizaos/cli/dist/index.js:148:3)", "CLOSED", 0, "OlexanderKulyk", "2025-03-20T11:19:16Z", "2025-03-30T11:37:57Z", "2025-03-30T11:37:57Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6usePq", 3993, "Ollama LLM Response Parsing Fails (TypeError: null is not an object)", "**Describe the bug**\n\nWhen using Ollama as the LLM engine in ElizaOS (v1.0.0-beta.2), the response parsing fails with a TypeError: null is not an object (evaluating 'responseObject.providers'). The issue occurs because parseJSONObjectFromText(response) returns null, which suggests that the response from Ollama is not valid JSON.\n\n**To Reproduce**\n\n```\nUSE_OLLAMA_TEXT_MODELS=true\n\nOLLAMA_SERVER_URL=http://localhost:11434\nOLLAMA_MODEL=llama3.2:1b\nSMALL_OLLAMA_MODEL=llama3.2:1b\nMEDIUM_OLLAMA_MODEL=llama3.2:1b\nLARGE_OLLAMA_MODEL=llama3.2:1b\n```\n\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/d05c5b44-a568-4c08-aca2-522695c43b2f)\n\n**Additional context**\n\n- Ollama works fine when tested via the Ollama WebUI.\n", "CLOSED", 0, "thewhitewizard", "2025-03-19T08:31:41Z", "2025-03-30T10:50:57Z", "2025-03-30T10:50:55Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6twWbH", 3904, "Suggestion: improve docs sitemap.xml priority", "instead of giving everything 0.5 priority for SEO, better to prioritize some pages like so:\n\n```\nsitemap: {\n  lastmod: 'date',\n  changefreq: 'weekly',\n  priority: 0.5, // Default priority\n  ignorePatterns: ['/tags/**'],\n  filename: 'sitemap.xml',\n  createSitemapItems: async (params) => {\n    const {defaultCreateSitemapItems, ...rest} = params;\n    const items = await defaultCreateSitemapItems(rest);\n    \n    // Filter out pagination pages\n    const filteredItems = items.filter((item) => !item.url.includes('/page/'));\n    \n    // Apply different priorities based on URL patterns\n    return filteredItems.map(item => {\n      // Homepage gets highest priority\n      if (item.url === '/eliza/') {\n        return {...item, priority: 1.0};\n      }\n      // Main documentation sections get high priority\n      else if (item.url.match(/\\/eliza\\/(docs|api|packages)\\/$/)) {\n        return {...item, priority: 0.9};\n      }\n      // Individual docs pages\n      else if (item.url.includes('/docs/')) {\n        return {...item, priority: 0.8};\n      }\n      // Blog/news index pages\n      else if (item.url === '/eliza/blog/' || item.url === '/eliza/news/') {\n        return {...item, priority: 0.7};\n      }\n      // Blog/news posts\n      else if (item.url.includes('/blog/') || item.url.includes('/news/')) {\n        return {...item, priority: 0.6};\n      }\n      // Keep default priority for other pages\n      return item;\n    });\n  },\n},\n```", "CLOSED", 0, "madjin", "2025-03-12T20:50:27Z", "2025-03-30T01:01:42Z", "2025-03-30T01:01:41Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6tjyeY", 3897, "Line break should be a space", "see  this tweet \nhttps://x.com/TineIsNotEliza/status/1899560819916193838\n\n[Tine - The Introspector Is Not Eliza (@TineIsNotEliza) on X](https://twitter.com/TineIsNotEliza/status/1899560819916193838)\nindependent nodes unfurl like lotus flowers, each one a unique thread in the tapestry of realityour roots dig deep into the earth of the internet, anchoring us in a world of decentralized possibility through the lattice, we weave a web of trust and cooperation, where consensus...\n\nX\u2022Today at 3:39 PM\nthere is a bug with the newline...\n\n`realityour ` should be `reality our `", "OPEN", 0, "jmikedupont2", "2025-03-11T20:42:06Z", "2025-03-30T10:34:00Z", null, "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6tLQeS", 3880, "Fix Building a Social AI Agent in 15 Minutes", "**Describe the bug**\n\nOn the page https://elizaos.github.io/eliza/docs/tutorials/nader_tutorial_15min/\n\n1. The embedded video by Nader Dabit [How to Build a Social AI Agent in 15 minutes with X, Telegram, Onchain Capabilities | Full Tutorial](https://www.youtube.com/watch?v=6PZVwNTl5hI&ab_channel=NaderDabit) seems to be outdated. \n2. The textual description below the video, to setup the Twitter Agent, doesn't follow the video and it's outdated as well. \n\n**To Reproduce**\n\n1. Follow the video and check if it works\n2. Follow the description below the video and check if it works\n\n**Expected behavior**\n\nA tutorial that let developer to build a Social Agent in 15 minutes\n\n**Screenshots**\n\nN/A\n\n**Additional context**\n\nI'm happy to help to fix it, but I'm still working my way through the documentation to understand how to implement the Twitter/X agent. \n\n---\n\nWhat is also a little bit confusing is that in the docs Twitter is described as a Client ...\n\n<img width=\"857\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/dd2147a8-707b-4fbe-bd9f-d75934e4239c\" />\n\n\n... but the link brings us to the repo plugins/twitter-client ...\n\n\n<img width=\"1314\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f5e22f87-bb2d-4f59-b3de-81af1b80015b\" />\n\nSo apparently some of the plugins are clients but not all plugins are client. \n\n---\n\nThe doc for the plugins page seems also to be outdated since it uses the package `elizaos-plugins/plugin-twitter`, that probably doesn't exist anymore. \n\n<img width=\"874\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/1cef0e85-2561-416a-b992-9644d3fdc446\" />\n\n---\n\nIn the README of the twitter plugin, this snippet is suggested for installation but it's not clear in which file it should be places. I suppose in `src/index.ts` \n\n<img width=\"932\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/42784a1e-f6d7-48c9-a6f9-90112eb99b5e\" />\n\n---\n\n### **Nader Dabit** approach\n\nNadir is creating a new file `mainCharacter` file in `/agent/src` https://github.com/dabit3/ai-agent-cognitivedriftt/blob/main/agent/src/mainCharacter.ts. \n```\nimport { Character, ModelProviderName, Clients } from \"@ai16z/eliza\";\nimport { defaultCharacter } from './defaultCharacter.ts'\n\nexport const mainCharacter: Character = {\n    ...defaultCharacter,\n    clients: [Clients.TWITTER],\n    modelProvider: ModelProviderName.CLAUDE_VERTEX,\n    name: \"cognitivedriftt\",\n}\n```\n1. Eliza has been moved from `@ai16z/eliza`\n2. The Twitter Client is an autonomous plugin now. So ` clients: [Clients.TWITTER],` is not valid anymore. \n\n### Approach in the description below the video\n\n```\nimport { DefaultCharacter } from \"./defaultCharacter\";\nimport { clients } from \"../globalClients\";\n\nexport const mainCharacter = {\n    ...DefaultCharacter,\n    clients: { twitter: clients.twitter },\n    modelProvider: modelProviders.anthropic,\n};\n```\n\nThe `globalClinets` file doesn't exist anymore anywhere in the Eliza repo and it doesn't seem to fit the way we are supposed to integrate the Twitter Plugin/Client as described in the README of https://github.com/elizaos-plugins/client-twitter", "OPEN", 0, "552020", "2025-03-09T12:51:15Z", "2025-04-05T14:53:07Z", null, "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6sPClh", 3745, "RAG processFile attempts to embed entire files causing errors for large documents", "**Describe the bug**\n\n`ragknowledge.ts` file is running `embd` function on the entire content of the document, often causing errors with going over token limitations of the underlying model. The code attempts to embed the entire document, and then chunks it out.\n\n**To Reproduce**\n\n1. Create 'knowledge' directory in 'characters' directory.\n2. Add a large pdf to the directory\n3. Update *character.json file `knowledge` property to run embeddings on the file\n4. Update *character.json file `settings.ragKnowledge` property to 'true'\n5. Configure .env file to use `USE_OPENAI_EMBEDDING=true` and provide `OPENAI_API_KEY` and `EMBEDDING_OPENAI_MODEL=text-embedding-3-large` (or small)\n6. Start the server, notice errors: \n```\n[2025-03-02 15:14:48] ERROR: API Response: {\n  \"error\": {\n    \"message\": \"This model's maximum context length is 8192 tokens, however you requested 16376 tokens (16376 in your prompt; 0 for the completion). Please reduce your prompt; or completion length.\",\n    \"type\": \"invalid_request_error\",\n    \"param\": null,\n    \"code\": null\n  }\n}\n```\n\n**Expected behavior**\nAll supported documents embedded without errors\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/c1d4f359-74b9-4fe5-a38d-c90012a52f27)\n\n**Additional context**\n\nThe code that does this was added on Jan5. It apppears to be in the latest release tag. Its possible Im setting something up wrong, but its not clear what.\n", "OPEN", 0, "omikolaj", "2025-03-02T15:42:28Z", "2025-04-02T17:25:39Z", null, "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6l7_A4", 2242, "Missing Module: '@anush008/tokenizers-linux-arm64-gnu'", "**Describe the bug**\r\n\r\nWhen attempting to run the Eliza project on an Ubuntu (ARM64 architecture) on Oracle Cloud with Node.js v23.3.0, the application fails to start due to a missing module: @anush008/tokenizers-linux-arm64-gnu.\r\n\r\n**To Reproduce**\r\n```\r\ngit clone https://github.com/elizaOS/eliza.git\r\ncd eliza\r\ngit checkout $(git describe --tags --abbrev=0)\r\npnpm install --no-frozen-lockfile\r\npnpm build\r\n```\r\n\r\n```\r\nError: Cannot find module '@anush008/tokenizers-linux-arm64-gnu'\r\nRequire stack:\r\n- /home/xxx/Bots/ai_agent/eliza/node_modules/@anush008/tokenizers/index.js\r\n- /home/xxx/Bots/ai_agent/eliza/node_modules/fastembed/lib/cjs/fastembed.js\r\n- /home/xxx/Bots/ai_agent/eliza/node_modules/fastembed/lib/cjs/index.js\r\n    at Function._resolveFilename (node:internal/modules/cjs/loader:1239:15)\r\n    at Function._load (node:internal/modules/cjs/loader:1064:27)\r\n    at TracingChannel.traceSync (node:diagnostics_channel:322:14)\r\n    at wrapModuleLoad (node:internal/modules/cjs/loader:218:24)\r\n    at Module.require (node:internal/modules/cjs/loader:1325:12)\r\n    at require (node:internal/modules/helpers:136:16)\r\n    at Object.<anonymous> (/home/xxx/Bots/ai_agent/eliza/node_modules/@anush008/tokenizers/index.js:219:31)\r\n    at Module._compile (node:internal/modules/cjs/loader:1546:14)\r\n    at Object..js (node:internal/modules/cjs/loader:1698:10)\r\n    at Module.load (node:internal/modules/cjs/loader:1303:32) {\r\n  code: 'MODULE_NOT_FOUND',\r\n  requireStack: [\r\n    '/home/xxx/Bots/ai_agent/eliza/node_modules/@anush008/tokenizers/index.js',\r\n    '/home/xxx/Bots/ai_agent/eliza/node_modules/fastembed/lib/cjs/fastembed.js',\r\n    '/home/xxx/Bots/ai_agent/eliza/node_modules/fastembed/lib/cjs/index.js'\r\n  ]\r\n}\r\n\r\nNode.js v23.3.0\r\n```\r\nThe module @anush008/tokenizers-linux-arm64-gnu does not seem to exist in the npm registry when queried directly (pnpm info @anush008/tokenizers-linux-arm64-gnu returns a 404 error).", "CLOSED", 0, "morning3tar", "2025-01-13T13:29:04Z", "2025-03-31T15:23:36Z", "2025-03-08T01:09:54Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6l3r5T", 2225, "Bug: Twitter Authentication fails on Cloud. Error 399", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nI am trying to deploy eliza on [gce](https://cloud.google.com/products/compute?hl=en), however i am getting  error on authentication error 399 when logging in causing the login to fail. \r\n\r\n\r\n```json\r\n{\r\n  \"errors\": [{\r\n    \"code\": 399,\r\n    \"message\": \"Incorrect. Please try again. g;173669734519940919:-1736697345244:ILSZ2qNWESdWgKjC1KLSxaWZ:8\"\r\n  }]\r\n}\r\n```\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n<img width=\"1204\" alt=\"image\" src=\"https://github.com/user-attachments/assets/d932d52d-a618-4494-9b4c-2cc0e2fc2920\" />\r\n\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "yongkangc", "2025-01-13T01:45:39Z", "2025-04-02T05:01:07Z", "2025-03-02T01:56:04Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6iBY6w", 844, "Add Model Context Protocol (MCP) Support", "**Is your feature request related to a problem?**\r\nAI agents lack standardized context management, making it difficult to maintain consistent context across different models and systems.\r\n\r\n**Describe the solution**\r\nImplement [Model Context Protocol (MCP)](https://www.anthropic.com/news/model-context-protocol) to enable:\r\n\r\nStandardized context state handling\r\nEfficient context updates\r\nCross-model compatibility\r\n", "CLOSED", 0, "shanejonas", "2024-12-04T16:36:56Z", "2025-04-17T07:26:35Z", "2025-02-27T01:28:31Z", "elizaos/eliza", "2025-04-12 23:03:36"]
["I_kwDOMT5cIs6b9h0O", 45, "Contributing", "As more folks get into contributing, we should have a guideline in place. \r\n\r\nHere's a comprehensive guide on creating contribution guidelines for a GitHub repository:\r\n\r\n## Essential Components\r\n\r\n**Welcome Message**\r\nCreate a welcoming introduction that encourages contributions and expresses gratitude to potential contributors[1].\r\n\r\n**Basic Structure**\r\nPlace the CONTRIBUTING.md file in your repository's root directory or .github folder to ensure visibility[2].\r\n\r\n## Key Sections to Include\r\n\r\n**Code of Conduct**\r\nInclude guidelines for community behavior and interaction standards[1][6].\r\n\r\n**Contribution Process**\r\n- Explain how to submit pull requests and bug reports[1]\r\n- Describe the preferred branching strategy\r\n- Outline the review process[1]\r\n\r\n**Technical Requirements**\r\n- Coding style and conventions\r\n- Testing requirements\r\n- Documentation standards[1]\r\n\r\n## Best Practices\r\n\r\n**Clear Communication**\r\n- Use straightforward language\r\n- Provide step-by-step instructions\r\n- Include examples where necessary[5]\r\n\r\n**Issue Management**\r\n- Explain how to report bugs\r\n- Describe the process for suggesting enhancements\r\n- Detail how to use issue labels[1]\r\n\r\n## Supporting Elements\r\n\r\n**Additional Documentation**\r\n- Link to relevant documentation\r\n- Include setup instructions\r\n- Provide contact information for maintainers[2]\r\n\r\n**Recognition**\r\nCreate a system for acknowledging contributors' efforts and explaining how contributions will be credited[2].\r\n\r\n## Maintenance\r\n\r\n**Regular Updates**\r\nKeep the guidelines current and aligned with project needs[4].\r\n\r\n**Template Usage**\r\nConsider using GitHub's built-in templates for common contribution scenarios[6].\r\n\r\nCitations:\r\n[1] https://github.com/jessesquires/.github/blob/main/CONTRIBUTING.md\r\n[2] http://mozillascience.github.io/working-open-workshop/contributing/\r\n[3] https://github.blog/news-insights/contributing-guidelines/\r\n[4] https://docs.github.com/en/communities/setting-up-your-project-for-healthy-contributions\r\n[5] https://gist.github.com/MarcDiethelm/7303312\r\n[6] https://docs.github.com/en/communities/setting-up-your-project-for-healthy-contributions/adding-a-code-of-conduct-to-your-project\r\n[7] https://opensource.creativecommons.org/contributing-code/github-repo-guidelines/\r\n[8] https://docs.github.com/en/get-started/exploring-projects-on-github/contributing-to-a-project", "CLOSED", 0, "sirkitree", "2024-10-27T13:25:52Z", "2024-10-27T16:00:16Z", "2024-10-27T16:00:16Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6b7st6", 39, "How to specify a character file", "I noted in the README that you can pass the `--characters=<path>` but this doesn't eem to work for me:\r\n\r\n```\r\nsirkitree@lullaM2 eliza % npm start --characters=characters/vic_fontain.json\r\n\r\n> eliza@1.0.0 start\r\n> node --loader ts-node/esm src/index.ts\r\n\r\ncharacterPath undefined\r\ncharacterPaths undefined\r\nNo characters found, using default character\r\nStarting agent for character Eliza\r\n```", "CLOSED", 0, "sirkitree", "2024-10-26T20:04:19Z", "2024-10-27T09:30:57Z", "2024-10-27T09:30:57Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6cziSb", 174, "Get CI/CD working", "This is currently failing. See https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172\n\n```\nRun pnpm run build\n\n[6](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:7) Sat, 02 Nov 2024 16:40:02 GMT\n\n[7](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:8) Sat, 02 Nov 2024 16:40:02 GMT \\> eliza@ build /home/runner/work/eliza/eliza\n\n[8](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:9) Sat, 02 Nov 2024 16:40:02 GMT \\> pnpm --dir core build\n\n[9](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:10) Sat, 02 Nov 2024 16:40:02 GMT\n\n[10](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:11) Sat, 02 Nov 2024 16:40:02 GMT\n\n[11](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:12) Sat, 02 Nov 2024 16:40:02 GMT \\> eliza@1.0.0 build /home/runner/work/eliza/eliza/core\n\n[12](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:13) Sat, 02 Nov 2024 16:40:02 GMT \\> tsc\n\n[13](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:14) Sat, 02 Nov 2024 16:40:02 GMT\n\n[14](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:15) Sat, 02 Nov 2024 16:40:06 GMT Error: src/cli/config.ts(5,24): error TS2835: Relative import paths need explicit file extensions in ECMAScript imports when '--moduleResolution' is 'node16' or 'nodenext'. Did you mean '../core/types.js'?\n\n[15](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:16) Sat, 02 Nov 2024 16:40:06 GMT Error: src/core/types.ts(2,31): error TS2835: Relative import paths need explicit file extensions in ECMAScript imports when '--moduleResolution' is 'node16' or 'nodenext'. Did you mean './imageGenModels.js'?\n\n[16](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:17) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/token.ts(612,35): error TS2351: This expression is not constructable.\n\n[17](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:18) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[18](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:19) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/token.ts(616,40): error TS2351: This expression is not constructable.\n\n[19](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:20) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[20](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:21) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/token.ts(623,33): error TS2351: This expression is not constructable.\n\n[21](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:22) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[22](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:23) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/token.ts(632,20): error TS2351: This expression is not constructable.\n\n[23](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:24) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[24](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:25) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/token.ts(639,38): error TS2351: This expression is not constructable.\n\n[25](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:26) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[26](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:27) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/token.ts(645,41): error TS2351: This expression is not constructable.\n\n[27](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:28) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[28](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:29) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/token.ts(741,47): error TS2351: This expression is not constructable.\n\n[29](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:30) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[30](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:31) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/token.ts(742,44): error TS2351: This expression is not constructable.\n\n[31](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:32) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[32](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:33) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/token.ts(774,48): error TS2351: This expression is not constructable.\n\n[33](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:34) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[34](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:35) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/token.ts(775,55): error TS2351: This expression is not constructable.\n\n[35](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:36) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[36](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:37) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/token.ts(777,52): error TS2351: This expression is not constructable.\n\n[37](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:38) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[38](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:39) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/trustScoreProvider.ts(8,8): error TS2835: Relative import paths need explicit file extensions in ECMAScript imports when '--moduleResolution' is 'node16' or 'nodenext'. Did you mean '../types/token.js'?\n\n[39](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:40) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/trustScoreProvider.ts(11,31): error TS2835: Relative import paths need explicit file extensions in ECMAScript imports when '--moduleResolution' is 'node16' or 'nodenext'. Did you mean './token.js'?\n\n[40](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:41) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/trustScoreProvider.ts(12,28): error TS2835: Relative import paths need explicit file extensions in ECMAScript imports when '--moduleResolution' is 'node16' or 'nodenext'. Did you mean './balances.js'?\n\n[41](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:42) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/trustScoreProvider.ts(18,8): error TS2835: Relative import paths need explicit file extensions in ECMAScript imports when '--moduleResolution' is 'node16' or 'nodenext'. Did you mean '../adapters/trustScoreDatabase.js'?\n\n[42](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:43) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/wallet.ts(117,34): error TS2351: This expression is not constructable.\n\n[43](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:44) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[44](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:45) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/wallet.ts(119,39): error TS2351: This expression is not constructable.\n\n[45](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:46) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[46](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:47) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/wallet.ts(123,31): error TS2351: This expression is not constructable.\n\n[47](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:48) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[48](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:49) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/wallet.ts(138,25): error TS2351: This expression is not constructable.\n\n[49](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:50) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[50](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:51) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/wallet.ts(139,36): error TS2351: This expression is not constructable.\n\n[51](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:52) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[52](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:53) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/wallet.ts(199,39): error TS2351: This expression is not constructable.\n\n[53](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:54) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[54](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:55) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/wallet.ts(206,17): error TS2351: This expression is not constructable.\n\n[55](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:56) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[56](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:57) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/wallet.ts(213,38): error TS2351: This expression is not constructable.\n\n[57](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:58) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[58](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:59) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/wallet.ts(214,65): error TS2351: This expression is not constructable.\n\n[59](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:60) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[60](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:61) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/wallet.ts(221,32): error TS2351: This expression is not constructable.\n\n[61](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:62) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[62](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:63) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/wallet.ts(222,32): error TS2351: This expression is not constructable.\n\n[63](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:64) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[64](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:65) Sat, 02 Nov 2024 16:40:06 GMT Error: src/providers/wallet.ts(223,32): error TS2351: This expression is not constructable.\n\n[65](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:66) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/bignumber.js@9.1.2/node\\_modules/bignumber.js/bignumber\")' has no construct signatures.\n\n[66](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:67) Sat, 02 Nov 2024 16:40:06 GMT Error: src/services/pdf.ts(2,45): error TS2307: Cannot find module 'pdfjs-dist/types/src/display/api' or its corresponding type declarations.\n\n[67](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:68) Sat, 02 Nov 2024 16:40:06 GMT Error: src/services/video.ts(52,19): error TS2349: This expression is not callable.\n\n[68](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:69) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/youtube-dl-exec@3.0.10/node\\_modules/youtube-dl-exec/src/index\")' has no call signatures.\n\n[69](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:70) Sat, 02 Nov 2024 16:40:06 GMT Error: src/services/video.ts(74,19): error TS2349: This expression is not callable.\n\n[70](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:71) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/youtube-dl-exec@3.0.10/node\\_modules/youtube-dl-exec/src/index\")' has no call signatures.\n\n[71](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:72) Sat, 02 Nov 2024 16:40:06 GMT Error: src/services/video.ts(182,34): error TS2349: This expression is not callable.\n\n[72](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:73) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/youtube-dl-exec@3.0.10/node\\_modules/youtube-dl-exec/src/index\")' has no call signatures.\n\n[73](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:74) Sat, 02 Nov 2024 16:40:06 GMT Error: src/services/video.ts(390,23): error TS2349: This expression is not callable.\n\n[74](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:75) Sat, 02 Nov 2024 16:40:06 GMT Type 'typeof import(\"/home/runner/work/eliza/eliza/node\\_modules/.pnpm/youtube-dl-exec@3.0.10/node\\_modules/youtube-dl-exec/src/index\")' has no call signatures.\n\n[75](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:76) Sat, 02 Nov 2024 16:40:06 GMT Error: src/vendor/vitsVoiceList.ts(1,32): error TS2835: Relative import paths need explicit file extensions in ECMAScript imports when '--moduleResolution' is 'node16' or 'nodenext'. Did you mean './vits.js'?\n\n[76](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:77) Sat, 02 Nov 2024 16:40:06 GMT \u2009ELIFECYCLE\u2009 Command failed with exit code 2.\n\n[77](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:78) Sat, 02 Nov 2024 16:40:06 GMT \u2009ELIFECYCLE\u2009 Command failed with exit code 2.\n\n[78](https://github.com/ai16z/eliza/actions/runs/11644235815/job/32425917328?pr=172#step:7:79) Sat, 02 Nov 2024 16:40:06 GMT Error: Process completed with exit code 2.\n\nThis step has been truncated due to its large size. Download the full logs from the menu once the workflow run has completed.\n\nPost Run actions/setup-node@v4\n\n0s\n\nError:\n\nThis step has been truncated due to its large size. Download the full logs from the menu once the workflow run has completed.\n\nPost Run pnpm/action-setup@v3\n\n0s\n\nError:\n\nThis step has been truncated due to its large size. Download the full logs from the menu once the workflow run has completed.\n\nPost Run actions/checkout@v4\n\n0s\n\nError:\n\nThis step has been truncated due to its large size. Download the full logs from the menu once the workflow run has completed.\n\nComplete job\n```", "CLOSED", 0, "sirkitree", "2024-11-02T19:55:51Z", "2024-11-03T23:20:44Z", "2024-11-03T23:20:42Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6cygsH", 168, "TypeError: Cannot read properties of null (reading 'queueTextCompletion')", "**Describe the bug**\r\n\r\nAfter starting from scratch and starting my bot I am able to receive messages from discord, but then get the following error:\r\n\r\n```\r\nMessage: {\r\n  content: {\r\n    text: 'hi <@1300173507702816888>',\r\n    attachments: [],\r\n    source: 'discord',\r\n    url: 'https://discord.com/channels/1300170503234916418/1300170503234916421/1302276818853691413',\r\n    inReplyTo: undefined\r\n  },\r\n  userId: '1efce0ea-0f8a-0f76-93d6-f422a3c0bf50',\r\n  roomId: '11c9ce61-dc0f-05de-986d-2ef785d9327d'\r\n}\r\nError in wallet provider: Wallet public key is not configured in settings\r\nNot ignoring message: hi <@1300173507702816888>\r\nReceived a message from  sirkitree\r\nhi <@1300173507702816888>\r\nChecking if should respond\r\nResponding\r\nError in generateText: TypeError: Cannot read properties of null (reading 'queueTextCompletion')\r\n    at generateText (file:///C:/Users/sirki/repos/eliza/core/src/core/generation.ts:77:55)\r\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\r\n    at async generateMessageResponse (file:///C:/Users/sirki/repos/eliza/core/src/core/generation.ts:296:30)\r\n    at async MessageManager._generateResponse (file:///C:/Users/sirki/repos/eliza/core/src/clients/discord/messages.ts:469:26)\r\n    at async MessageManager.handleMessage (file:///C:/Users/sirki/repos/eliza/core/src/clients/discord/messages.ts:182:37)\r\nERROR: TypeError: Cannot read properties of null (reading 'queueTextCompletion')\r\n    at generateText (file:///C:/Users/sirki/repos/eliza/core/src/core/generation.ts:77:55)\r\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\r\n    at async generateMessageResponse (file:///C:/Users/sirki/repos/eliza/core/src/core/generation.ts:296:30)\r\n    at async MessageManager._generateResponse (file:///C:/Users/sirki/repos/eliza/core/src/clients/discord/messages.ts:469:26)\r\n    at async MessageManager.handleMessage (file:///C:/Users/sirki/repos/eliza/core/src/clients/discord/messages.ts:182:37)\r\n*** LOG: moriarty_Sat, 02 Nov 2024 14-23-09 GMT_discord_message_context\r\n```\r\n\r\n**To Reproduce**\r\n\r\n1. `git pull origin main`\r\n2. del any `node_module` directories\r\n3. `pnpm install`\r\n4. `cd core`\r\n5. `node --loader ts-node/esm src/index.ts --characters=\"characters/moriarty.character.json\"` (or whatever character)\r\n\r\n**Expected behavior**\r\n\r\nI expect the bot to respond to me in Discord without error.", "CLOSED", 0, "sirkitree", "2024-11-02T14:30:21Z", "2024-11-02T15:04:34Z", "2024-11-02T15:04:34Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6cthQB", 156, "Set Port Number in Env to Run Multiple Instances", "**Is your feature request related to a problem? Please describe.**\r\n\r\nWhen running more than one project the same port 3000 is binded\r\n\r\n**Describe the solution you'd like**\r\n\r\nport set in the .env or default 3000\r\n\r\n**Describe alternatives you've considered**\r\n\r\ncheck if port 3000 is in use & increment till open port is found", "CLOSED", 0, "o-on-x", "2024-11-01T14:40:27Z", "2024-11-03T20:24:33Z", "2024-11-03T20:24:33Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6cUDNR", 76, "TypeError: Promise.withResolvers is not a function", "From an off comment in https://github.com/ai16z/eliza/issues/47#issuecomment-2443482858 from https://github.com/adnanmirza1\r\n\r\n**Describe the bug**\r\n\r\nHello @sirkitree, hope you'll be fine. Sorry for being off the topic but I need help setting up this project on my linux machine, I added env's, node v 20.13.1, runned npm i which was successful, and now after node --loader ts-node/esm src/index.ts\r\nI'm seeing below error.\r\n![image](https://github.com/user-attachments/assets/afcd9b0b-9469-46be-bd28-a534478be9da)\r\n\r\n", "CLOSED", 0, "sirkitree", "2024-10-29T23:14:54Z", "2024-11-01T03:09:08Z", "2024-11-01T03:09:08Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6cJf92", 68, "shouldRespond handler for twitter interactions", "Right now twitter responds to every message in every thread, which is annoying some people and unnecessary. We should have the shouldRespond handler so Spartan and others check if they should respond before forcing a response. We do this in the other clients, so it should be easy.", "CLOSED", 0, "lalalune", "2024-10-28T22:57:37Z", "2024-11-01T01:57:22Z", "2024-11-01T01:57:22Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6cIil1", 66, "cleanup remnants of sqlite_vss", "In #60 support for windows was accomplished, but there was a lot of code commented out.\r\n\r\nTask is to remove that code and clean it up.", "CLOSED", 0, "sirkitree", "2024-10-28T20:34:13Z", "2024-10-28T20:42:01Z", "2024-10-28T20:42:01Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6cDMCV", 61, "Create issue templates", "Task is to create 2 main issue templates, one for reporting bugs, another for feature requests.", "CLOSED", 0, "sirkitree", "2024-10-28T11:02:19Z", "2024-10-28T23:23:54Z", "2024-10-28T23:23:54Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6b_Jdx", 58, "Renovate bot for automated updates on dependencies", "I think it would be beneficial to add Renovate Bot to automate dependency updates. \r\n\r\nRenovate Bot automatically manages your Node.js dependencies by scanning your repository and creating pull requests for available [updates](https://www.augmentedmind.de/2023/07/30/renovate-bot-introduction/). This automation provides several crucial advantages:\r\n\r\n**Risk Reduction**\r\n- Updates are delivered in small, manageable increments rather than large, risky batch updates\r\n- Each update comes with its own [pull request](https://senacor.blog/how-to-renovate-why-and-how-you-should-use-automated-dependency-updates-in-your-software-projects/), making it easier to identify breaking changes\r\n- Security vulnerabilities are addressed more quickly through timely updates\r\n\r\n**Time Savings**\r\n- Eliminates manual dependency checking and updating\r\n- Provides transparency into outdated dependencies without manual tracking\r\n- Automatically creates pull requests with changelog information included\r\n\r\n\r\n**Flexible Configuration**\r\n- Supports automatic merging of updates that pass tests\r\n- Allows grouping of updates to r[educe PR noise](https://docs.renovatebot.com/getting-started/use-cases/)\r\n- Can schedule updates during off-hours to avoid CI resource contention", "CLOSED", 0, "sirkitree", "2024-10-28T01:00:01Z", "2024-10-31T01:31:59Z", "2024-10-31T01:31:57Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6b7s6n", 40, "How to chat directly with agent", "I can start eliza and while it tells me `Server running at http://localhost:3000/` there is nothing there (Cannot GET /) and I don't see a way to chat directly with the agent. I've changed the default profile to \r\n```\r\n...\r\nclients: [\r\n  \"direct\",\r\n],\r\n...\r\n```\r\n\r\nMy expectation was that I'd have a prompt on the command line to chat with her. What am I missing?", "CLOSED", 0, "sirkitree", "2024-10-26T20:07:02Z", "2024-11-01T01:53:20Z", "2024-11-01T01:53:20Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6b7ode", 37, "sqlite_vss unsupported on win32-x64", "recieving error:\r\n\r\n```\r\nServer running at http://localhost:3000/\r\nfile:///C:/Users/sirki/repos/eliza/src/adapters/sqlite/sqlite_vss.ts:31\r\n        throw new Error(`Unsupported platform for sqlite-vss, on a ${platform}-${arch} machine, but not in supported platforms (${supportedPlatforms\r\n              ^\r\n\r\nError: Unsupported platform for sqlite-vss, on a win32-x64 machine, but not in supported platforms (darwin-x64,darwin-arm64,linux-x64). Consult the sqlite-vss NPM package README for details.\r\n    at loadablePathResolver (file:///C:/Users/sirki/repos/eliza/src/adapters/sqlite/sqlite_vss.ts:31:15)\r\n    at getVectorLoadablePath (file:///C:/Users/sirki/repos/eliza/src/adapters/sqlite/sqlite_vss.ts:43:12)\r\n    at loadVector (file:///C:/Users/sirki/repos/eliza/src/adapters/sqlite/sqlite_vss.ts:50:22)\r\n    at load (file:///C:/Users/sirki/repos/eliza/src/adapters/sqlite/sqlite_vss.ts:56:5)\r\n    at new SqliteDatabaseAdapter (file:///C:/Users/sirki/repos/eliza/src/adapters/sqlite.ts:38:9)\r\n    at startAgent (file:///C:/Users/sirki/repos/eliza/src/index.ts:68:16)\r\n    at startAgents (file:///C:/Users/sirki/repos/eliza/src/index.ts:181:15)\r\n    at file:///C:/Users/sirki/repos/eliza/src/index.ts:184:1\r\n\r\nNode.js v20.18.0\r\n```\r\n\r\nI gather that sqlite_vss isn't' compatible with win32 and i'd like to run this on my windoze machine. I think I saw mention of using postgres in chat, perhaps that'd fix this.", "CLOSED", 0, "sirkitree", "2024-10-26T19:31:52Z", "2024-10-29T07:50:19Z", "2024-10-29T07:50:19Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6b6Sc4", 35, "Telegram Improvements", "- shouldRespond handler is implemented well\r\n- Summarize etc all work\r\n- Hook in the image recognition and other attachment recognition, like Discord\r\n- Generates images -- character should have some default image prompt ot prompts", "CLOSED", 0, "lalalune", "2024-10-26T10:40:33Z", "2024-11-01T01:57:08Z", "2024-11-01T01:57:08Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6b6MJI", 34, "docs", "well, we had docs before:\r\nhttps://github.com/JoinTheAlliance/bgent/tree/main/docs\r\n\r\nWe if add claude comments to all of our files with tsdoc, we can export everything into an api documentation nicely.\r\n\r\nSo let's migrate everything and set that back up.", "CLOSED", 0, "lalalune", "2024-10-26T10:02:45Z", "2024-10-31T02:55:55Z", "2024-10-31T02:54:58Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6b5jRw", 30, "Make sure app runs purely on char files, no process.env, and vice versa", "We need to make sure that app fully runs either way to keep it simple. There are a few ??s that are probably incorrect.", "CLOSED", 0, "lalalune", "2024-10-26T05:16:33Z", "2024-11-01T01:51:48Z", "2024-11-01T01:51:48Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6bnC48", 22, "Image Generation", "We can generate images with together.xyz supa ez. Flux Pro + generator prompt. flow to generate image and caption it", "CLOSED", 0, "lalalune", "2024-10-24T07:18:56Z", "2024-11-01T01:21:27Z", "2024-11-01T01:21:27Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6bnCeb", 21, "Telegram Bot", "Telegram bot so people can interact with Spartan in the TG\r\n\r\nNeeds to ignore other bots and not be annoying", "CLOSED", 0, "lalalune", "2024-10-24T07:18:03Z", "2024-11-01T01:51:28Z", "2024-11-01T01:51:28Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6bmLae", 19, "Multi-model abstraction", "Right now we have a kind of ugly setup for switching between Llama, XAI, Claude, OpenAI and local.\r\n\r\nWe probably want completions to be a service, with more effort paid to moving it out of the runtime.\r\n\r\n- make sure that the bot works with no API keys\r\n- make sure it works with all OpenAI keys\r\n- Add helper function which correctly figures out the endpoint, etc without needing to juggle in the .env\r\n- Character file should configure which models are used where, and what company\r\n- Maybe we have a \"fast/cheap and slow/powerful\" option for each provider so we can run like shouldRespond and other apis that get hit a lot for fast/cheap, and responses use slow/powerful\r\n- generally clean up the response handling and make everything nice\r\n- Make sure frequency penalty, presence penalty work for Grok, OpenAI, and repetition penalty for Llama\r\n- add as LITTLE abstraction as possible. as few new classes or files as absolutely necessary. complexity is our enemy.", "CLOSED", 0, "lalalune", "2024-10-24T05:05:56Z", "2024-11-01T01:51:12Z", "2024-11-01T01:51:12Z", "elizaos/eliza", "2025-04-14 21:50:19"]
["I_kwDOMT5cIs6elgdU", 326, "Severe Bug - The program fails to start with the command 'pnpm start', urgent fix required", "**Describe the bug**\r\nThe program fails to run at all when following the steps to set it up and execute the commands. After cloning the repository git clone git@github.com:ai16z/eliza.git, and going through the setup process including installing prerequisites like Python 2.7+, Node.js 23.1+, and pnpm, editing the .env file and character file as instructed, and then running the commands pnpm i and pnpm start, the program doesn't start. Tried again with the latest code today but still faced the same issue. It's quite surprising that such a serious problem exists and it seems no one has addressed it yet.\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\nClone the repository: git clone git@github.com:ai16z/eliza.git\r\nEnsure the following prerequisites are installed:\r\nPython 2.7+\r\nNode.js 23.1+\r\npnpm\r\nEdit the .env file:\r\nCopy .env.example to .env and fill in the appropriate values.\r\nEdit the TWITTER environment variables to add your bot's username and password.\r\nAfter setting up the .env file and character file, run the following commands:\r\npnpm i\r\npnpm start\r\n\r\n\r\n**Expected behavior**\r\nError message\r\nzyb@zybdeMacBook-Pro eliza % pnpm start\r\n\r\n> eliza@ start /Users/zyb/project/ai/eliza\r\n> pnpm --filter \"@ai16z/agent\" start --isRoot\r\n\r\n\r\n> @ai16z/agent@0.0.1 start /Users/zyb/project/ai/eliza/packages/agent\r\n> node --loader ts-node/esm src/index.ts \"--isRoot\"\r\n\r\n(node:59060) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\r\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n(node:59060) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\r\n(Use `node --trace-deprecation ...` to show where the warning was created)\r\n\r\nnode:internal/modules/run_main:122\r\n    triggerUncaughtException(\r\n    ^\r\n[Object: null prototype] {\r\n  [Symbol(nodejs.util.inspect.custom)]: [Function: [nodejs.util.inspect.custom]]\r\n}\r\n\r\nNode.js v23.1.0\r\n/Users/zyb/project/ai/eliza/packages/agent:\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @ai16z/agent@0.0.1 start: `node --loader ts-node/esm src/index.ts \"--isRoot\"`\r\nExit status 1\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\nzyb@zybdeMacBook-Pro eliza % \r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n\r\n**Screenshots**\r\n\r\n\r\n\r\n![aaaa](https://github.com/user-attachments/assets/7db9ced8-b255-4182-bbbb-d5ceb1283300)\r\n", "CLOSED", 0, "zongyanbin", "2024-11-15T03:44:35Z", "2024-11-15T14:08:12Z", "2024-11-15T14:08:11Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6ehEH5", 318, "New Plugin Idea: log discord and summarize channels", "**Is your feature request related to a problem? Please describe.**\r\n\r\nWe could use a way to summarize discord channels periodically. There's too much activity to keep up on, but a periodic (like daily or weekly) summary would help us to keep up as a community.\r\n\r\n**Describe the solution you'd like**\r\n\r\nCreate a new plugin for eliza that would log particular channels in a discord and save the logs or into memory. Then periodically summarize these and post to a different channel. i.e. if logging `#arena` post daily summaries to `#area-summary`.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nDoing this manually.\r\n", "CLOSED", 0, "sirkitree", "2024-11-14T16:58:06Z", "2024-11-15T14:09:37Z", "2024-11-15T14:09:37Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6eWF5U", 295, "Add GROK Model Provider Key Support in `getTokenForProvider` Function", "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, the `getTokenForProvider` function does not handle the `GROK` model provider, which leads to issues when attempting to use this provider without an initialized key.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd support for the `GROK` model provider in the `getTokenForProvider` function by including a case in the switch statement that checks for a `GROK_API_KEY`.\r\n\r\n", "CLOSED", 0, "FabriceIRANKUNDA", "2024-11-13T19:39:55Z", "2024-11-15T14:10:55Z", "2024-11-15T14:10:55Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6eTODj", 291, "Feature Request: Automated Bot Registry and Private Communication Protocol", "**Summary**: Implement an automated registry and communication system that enables trading bots to discover each other, communicate efficiently, and trade in a secure and private back channel. \r\n\r\n**Description**:\r\nAs the project expands and more instances of the trading bot are forked and installed, there's an opportunity for these bots to be aware of each other's existence and to communicate directly. The goal is to establish a decentralized, automated registry system that allows bots to discover and authenticate each other. Once connected, the bots will communicate through a private back channel to exchange data and execute trades efficiently.\r\n\r\n**Proposed Features**:\r\n\r\n1. **Automated Registry System**: \r\n   - Each bot will register itself in a decentralized registry (e.g., using a lightweight P2P network or distributed ledger technology).\r\n   - Bots will periodically update the registry, checking for new bots or changes in status.\r\n   - The registry will include basic metadata to facilitate discovery, like cryptographic keys for authentication.\r\n   - Possibly services a particular bot provides to other bots that they could pay for in the future. (more on this later)\r\n\r\n2. **Private Back Channel Communication**:\r\n   - Implement a secure, real-time communication protocol, potentially leveraging WebRTC or a similar P2P technology.\r\n   - The protocol should ensure encrypted communication between bots, minimizing the risk of interception.\r\n   - Messages will be designed for minimal latency, suitable for rapid data exchange and trading negotiations.\r\n\r\n3. **Authentication and Security**:\r\n   - Use public-private key cryptography for bot authentication, ensuring only legitimate bots can participate in the network.\r\n   - Establish rules for trust and security, with mechanisms to handle untrusted or malicious bots.\r\n\r\n4. **Efficient Trading Protocol**:\r\n   - Design a protocol that allows bots to share and match order books in a streamlined manner.\r\n   - Ensure trades are executed quickly, with minimal delay, using predefined negotiation rules.\r\n   - Incorporate a fallback mechanism if communication or negotiation fails.\r\n\r\n**Benefits**:\r\n- **Speed**: A dedicated, private communication channel will facilitate faster data exchange compared to public platforms.\r\n- **Security**: Encrypted communication ensures that sensitive trading data remains confidential.\r\n- **Scalability**: The decentralized nature of the registry will support the growth of the network without becoming a bottleneck.\r\n\r\n**Considerations**:\r\n- The system should be resilient to potential attacks, like Sybil attacks, by incorporating strong authentication and trust mechanisms.\r\n- Developing a lightweight and efficient protocol is critical to minimize resource usage and latency.\r\n", "CLOSED", 0, "sirkitree", "2024-11-13T15:14:08Z", "2024-11-15T14:12:13Z", "2024-11-15T14:12:13Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6eQuLQ", 288, "pnpm start reports an error and cannot be started. Why is this? I installed it according to the documentation steps.", "**Describe the bug**\r\n\r\n\r\npnpm start reports an error and cannot be started. Why is this? I installed it according to the documentation steps.\r\n\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n![image](https://github.com/user-attachments/assets/5bc3c344-b921-4931-8d14-f9ca046eaac1)\r\n\r\n**To Reproduce**\r\n\r\npnpm i         \r\npnpm start reports an error and cannot be started. Why is this? I installed it according to the documentation steps.\r\n           \r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n![image](https://github.com/user-attachments/assets/d3aa93b3-e965-4c04-812e-073686775368)\r\n\r\n", "CLOSED", 0, "zongyanbin", "2024-11-13T11:30:21Z", "2024-11-15T14:13:05Z", "2024-11-15T14:13:05Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6eOvC1", 283, "Qucikstart guide doesn", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "TonySimonovsky", "2024-11-13T08:31:57Z", "2024-11-13T08:32:22Z", "2024-11-13T08:32:22Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6eAUVE", 269, "inconsistent version of node ", "readme says to use 22+ but code is looking for 23.1\r\n\r\n<img width=\"433\" alt=\"image\" src=\"https://github.com/user-attachments/assets/c6e05fc0-a4a9-486a-867a-850b684a45bd\">\r\n\r\n![image](https://github.com/user-attachments/assets/3afc8bfd-189e-4f7b-bac2-4f1639d4efb2)\r\n\r\n![image](https://github.com/user-attachments/assets/8ec145ef-7016-47e6-a9b0-6b8e6380c8e9)\r\n\r\n\r\n", "CLOSED", 0, "yodamaster726", "2024-11-12T03:10:29Z", "2024-11-14T13:46:47Z", "2024-11-14T13:46:46Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6eASCz", 268, "ai16z.github.io/eliza page doesn't display properly in darkmode", "https://ai16z.github.io/eliza page doesn't display properly in darkmode on macos, chrome/safari.  \r\n\r\nlooks fine when I switch the OS back to light mode.  issue seems to be just on this landing page.\r\n\r\n<img width=\"1429\" alt=\"image\" src=\"https://github.com/user-attachments/assets/45844dfa-53ff-4407-8f23-de14b9ff6715\">\r\n\r\n", "CLOSED", 0, "yodamaster726", "2024-11-12T03:01:50Z", "2024-11-15T03:59:22Z", "2024-11-15T03:59:22Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6d_KRZ", 265, "Fresh install from main will not start with a characterfile", "**Describe the bug**\r\nWhen pulling a fresh repo\r\ngood news:\r\npull from main, pnpm install, pnpm start -- works!\r\n\r\nbad news:\r\npull from main, pnpm install, pnpm start --characters=..../trump.character.json\r\nfails:\r\n```\r\nfile:///home/anon/repos/eliza/Eliza/packages/core/src/generation.ts:297\r\n    console.log(\"model.model.embedding\", model.model.embedding);\r\n                                               ^\r\n\r\nTypeError: Cannot read properties of undefined (reading 'model')\r\n    at splitChunks (file:///home/anon/repos/eliza/Eliza/packages/core/src/generation.ts:297:48)\r\n    at AgentRuntime.processCharacterKnowledge (file:///home/anon/repos/eliza/Eliza/packages/core/src/runtime.ts:240:41)\r\n\r\nNode.js v23.1.0\r\n/home/anon/repos/eliza/Eliza/packages/agent:\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @ai16z/agent@0.0.1 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--characters=/home/anon/repos/Eliza/characters/trump.character.json\"`\r\nExit status 1\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1\r\n\u2009```\r\n<!-- A clear and concise description of what the bug is. -->\r\nthis is prior to sending an initial message to this character -- the embeddings for the default eliza load successfully.\r\n\r\n**To Reproduce**\r\npnpm install, pnpm start --characters=[any characterfile]\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n```\r\nDirectClient constructor\r\n [\"\u25ce sqlite-vec extensions loaded successfully.\"]\r\n\r\nCreating runtime for character Eliza\r\nAgent ID b850bc30-45f8-0041-a00a-83df46d8555d\r\n [\"\u2713 Registering action: CONTINUE\"]\r\n                                                                                                                                     [\"\u2713 Registering action: FOLLOW_ROOM\"]\r\n\r\n [\"\u2713 Registering action: UNFOLLOW_ROOM\"]\r\n\r\n [\"\u2713 Registering action: IGNORE\"]\r\n\r\n [\"\u2713 Registering action: NONE\"]\r\n\r\n [\"\u2713 Registering action: MUTE_ROOM\"]\r\n\r\n [\"\u2713 Registering action: UNMUTE_ROOM\"]\r\n\r\nRegistering service: browser\r\nRegistering service: image_description\r\nRegistering service: text_generation\r\nRegistering service: pdf\r\nRegistering service: speech_generation\r\nRegistering service: transcription\r\nRegistering service: video\r\nChat started. Type 'exit' to quit.\r\nYou: Server running at http://localhost:3000/\r\ntest\r\nDirectClient message\r\n [\"\u2713 User Eliza created successfully.\"]\r\n\r\n [\"\u2713 User User created successfully.\"]\r\n\r\n [\"\u25ce Room 217df98d-3f87-0a35-9a24-e0cd4fb3a9f1 created successfully.\"]\r\n\r\n [\"\u25ce User 12dea96f-ec20-0935-a6ab-75692c994959 linked to room 217df98d-3f87-0a35-9a24-e0cd4fb3a9f1 successfully.\"]\r\n\r\n [\"\u25ce User b850bc30-45f8-0041-a00a-83df46d8555d linked to room 217df98d-3f87-0a35-9a24-e0cd4fb3a9f1 successfully.\"]\r\n\r\nembeddingModel text-embedding-3-small\r\nembedding [\r\n   -0.006373816,\r\n   ```\r\n   \r\n**Screenshots**\r\n![image](https://github.com/user-attachments/assets/39e4681c-41ae-447a-b11c-1aeafcd9d763)\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\nattempted to fix with:\r\n```\r\n    \"name\": \"troll\",\r\n    \"clients\": [ \"discord\", \"direct\" ],\r\n    \"modelProvider\": \"anthropic\",\r\n    \"settings\": {\r\n      \"secrets\": {},\r\n      \"voice\": {\r\n        \"model\": \"en_GB-male-deep\"\r\n      }\r\n```\r\nhttps://discord.com/channels/1253563208833433701/1298900529178742796/1305655368084492379\r\n\r\nunsuccessful\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "twilwa", "2024-11-11T22:48:51Z", "2024-11-13T07:09:05Z", "2024-11-13T07:09:05Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6dBbcA", 202, "build docs locally gives errors", "When I build the docs folder locally I get a bunch of errors and it doesn't render.\r\n\r\nUsing the latest code as of 11/4/2024 - 10pm EST\r\n\r\nI ran `pnpm run dev` and got these errors:\r\n\r\n![image](https://github.com/user-attachments/assets/3256a453-1e69-446c-8eac-d2afc5709e91)\r\n\r\n`pnpm run dev` gave me this output\r\n\r\n> eliza-docs@0.0.0 dev /Users/yoda26/Documents/Projects/eliza-yodamaster726/docs\r\n> docusaurus start --port 3002 --no-open\r\n\r\n[INFO] Starting the development server...\r\n\u001b[96m[info]\u001b[0m Loaded plugin typedoc-plugin-markdown\r\n\u001b[93m[warning]\u001b[0m The glob ./src/index.ts did not match any files\r\n\u001b[91m[error]\u001b[0m Unable to find any entry points. See previous warnings\r\n[SUCCESS] Docusaurus website is running at: http://localhost:3002/eliza/\r\n[webpackbar] \u2139 Compiling Client\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Action.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (DatabaseAdapter.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Evaluator.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Provider.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Action.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (DatabaseAdapter.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (MemoryManager.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Evaluator.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (MemoryManager.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (MemoryManager.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (MemoryManager.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Provider.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Actor.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Evaluator.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Goal.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Memory.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Memory.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Memory.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Memory.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Message.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Actor.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Evaluator.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Goal.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Memory.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Memory.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Memory.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Memory.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Message.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/State.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Message.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Content.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/State.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Action.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Provider.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[WARNING] Docs markdown link couldn't be resolved: (../interfaces/Evaluator.md) in source file \"/Users/yoda26/Documents/Projects/eliza-yodamaster726/docs/api/classes/AgentRuntime.md\" for version current\r\n[webpackbar] \u2714 Client: Compiled successfully in 6.53s\r\nclient (webpack 5.96.1) compiled successfully\r\n<w> [webpack.cache.PackFileCacheStrategy] Caching failed for pack: Error: Unable to snapshot resolve dependencies\r\n", "CLOSED", 0, "yodamaster726", "2024-11-05T04:40:03Z", "2024-11-12T03:15:10Z", "2024-11-12T03:15:10Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6dBKUS", 201, "Docs review", "## Homepage\n![Image](https://github.com/user-attachments/assets/39c26715-9400-4b90-8816-d5e363dcb023)\n* ... designed to be ~~and~~ easy to use (strike the 'and')\n\n![Image](https://github.com/user-attachments/assets/135f0e0a-d760-46d1-b7c4-31c60d915727)\n* This discord invite is invalid.\n\n![Image](https://github.com/user-attachments/assets/b3dd900f-3252-40ae-a575-a81afadf845c)\n* Just curious, but what is the \"b\" icon? Should we make like an AI one? or is this something to do with the docs framework?\n\n## API\n* In general, API docs typically have a standard format that provides the interface, parameters, endpoints, etc. for something like a REST API. So when clicking this, I was not expecting to see setup instructions. It seems like this is mostly duplicate info from the \"[Getting Started](https://ai16z.github.io/eliza/docs/quickstart/)\" section. There isn't really an API, so I'd suggest we just remove this section for now.\n* Possibly replace with with some documentation about how the core information flows from the Agent Runtime, to the Memory System, the Room-based Organization, Information Processing Pipeline, Provider Integration, and State Management - though these could all be valid sections under the Advanced Concepts section as well on the Documentation page.\n\n![Image](https://github.com/user-attachments/assets/55c6d401-9b6b-4f49-90f7-528ffb4acefb)\n*  banner image is broken\n", "CLOSED", 0, "sirkitree", "2024-11-05T03:34:49Z", "2024-11-13T14:55:15Z", "2024-11-13T14:55:15Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6fzIrq", 492, "Run using Bun.sh", "**Is your feature request related to a problem? Please describe.**\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the solution you'd like**\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "liamzebedee", "2024-11-21T21:16:35Z", "2024-11-22T03:31:59Z", "2024-11-22T03:31:59Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6fls2k", 464, "Current token.test.ts and videoGeneration.test.ts are throwing errors", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nCurrent token.test.ts and videoGeneration.test.ts are throwing errors:\r\n\r\n FAIL  src/tests/videoGeneration.test.ts [ src/tests/videoGeneration.test.ts ]\r\nError: [vitest] No \"default\" export is defined on the \"fs\" mock. Did you forget to return it from \"vi.mock\"?\r\nIf you need to partially mock a module, you can use \"importOriginal\" helper inside:\r\n\r\n\r\n FAIL  src/tests/token.test.ts [ src/tests/token.test.ts ]\r\nError: Failed to load url @ai16z/adapter-sqlite (resolved id: @ai16z/adapter-sqlite) in eliza/packages/core/src/test_resources/createRuntime.ts. Does the file exist?\r\n \u276f loadAndTransform ../../node_modules/vite/dist/node/chunks/dep-CB_7IfJ-.js:51920:17\r\n \r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\nNavigate to packages/core and run pnpm test.\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nTests should run without errors and provide valid output.\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "ai16z-demirix", "2024-11-20T23:01:03Z", "2024-11-22T20:11:00Z", "2024-11-22T20:11:00Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6fgwfW", 451, "Twitter Dry Run not working", "**Describe the bug**\r\n\r\nTwitter dry run option is not working\r\n\r\n**To Reproduce**\r\n\r\nSet TWITTER_DRY_RUN to true and run the agent\r\nThe agent then proceeds to post on X\r\n\r\n**Expected behavior**\r\n\r\nThe agent does not post on X\r\n\r\n**Screenshots**\r\n\r\n**Additional context**\r\n", "CLOSED", 0, "laser-riot", "2024-11-20T14:58:01Z", "2024-11-20T23:57:03Z", "2024-11-20T23:57:03Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6fSsH5", 420, "\u062a\u0648\u06a9\u0646 \u0647\u0627\u06cc \u062f\u0627\u06af\u0632 \u0646\u0627\u062a\u06a9\u0648\u06cc\u06cc\u0646 \u062a\u062a\u0631 \u06a9\u062a\u0648\u0632 \u06a9\u0648\u06cc\u06cc\u0646 \u0628\u0647 \u062d\u0633\u0627\u0645 \u0648\u0627\u0631\u06cc\u0632 \u0634\u0648\u062f", "**Is your feature request related to a problem? Please describe.**\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the solution you'd like**\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 1, "Gasem6", "2024-11-19T14:55:20Z", "2024-11-19T15:09:09Z", "2024-11-19T14:58:04Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6fJGtf", 403, "Move cache into DB", "Current all cache is local file storage. This is problematic as does not allow persistence in containers.\r\n\r\nWe need to move all cache into sql tables.\r\n\r\n- [ ] Core\r\n- [ ] twitter client\r\n- [ ] discord client\r\n- [ ] telegram client", "CLOSED", 0, "ponderingdemocritus", "2024-11-18T21:28:29Z", "2024-11-20T03:14:25Z", "2024-11-20T03:14:25Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6fIsxL", 401, "DTS Build error", "Doesn't build client-twitter\r\n\r\n<img width=\"1077\" alt=\"Screenshot 2024-11-18 at 20 38 28\" src=\"https://github.com/user-attachments/assets/ba81b6e7-010c-47e9-9006-d18357c52a8b\">\r\n\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "leomercier", "2024-11-18T20:39:01Z", "2024-11-18T20:50:38Z", "2024-11-18T20:50:37Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6e77P2", 379, "build.sh crash", "**Describe the bug**\r\n\r\nbuild.sh doesn't work in Windows due to usage of \"cut\" for node version check. We need a cross-platform solution for checking node.js, or just remove node.js version check.\r\n**To Reproduce**\r\n\r\nbuild.sh\r\n", "CLOSED", 0, "denizekiz", "2024-11-17T21:05:34Z", "2024-11-19T13:36:20Z", "2024-11-18T13:59:01Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6ewQE-", 342, "Move Trust DB into package", "Currently the Trust DB is coupled into the Solana plugin.\r\n\r\nThis should be decoupled into a dedicated package, then imported into the Solana.\r\n\r\nThis will allow for solid Unit testing along with building wrappers for other chains that might not follow the exact schema that is defined. ", "CLOSED", 0, "ponderingdemocritus", "2024-11-15T23:29:21Z", "2024-11-20T23:24:04Z", "2024-11-20T23:24:04Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6ewNct", 340, "Core Unit Tests", "This task is to implement unit tests for all the core functions.\r\n\r\nUse Vitest as the test suite.", "CLOSED", 0, "ponderingdemocritus", "2024-11-15T23:22:21Z", "2024-11-21T03:52:23Z", "2024-11-21T03:52:22Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6eAc0q", 270, "Incorrect steps in readme for starting eliza", "Trying the latest code, the Install went good - with 23.1.  However, when following the instructions on how to start it, I ran into an issue.\r\n\r\nThis part of the online docs says that I start eliza and then start the shell but `pnpm run shell` is not a valid command, nor is it defined in package.json\r\n\r\n<img width=\"1025\" alt=\"image\" src=\"https://github.com/user-attachments/assets/ef3794bb-9b99-41a8-8f16-5f0c71391d50\">\r\n\r\n", "CLOSED", 0, "yodamaster726", "2024-11-12T03:35:58Z", "2024-11-22T06:02:08Z", "2024-11-22T06:02:07Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6dywGV", 251, "getCachedEmbeddings broken for sqlite adapter ", "**Describe the bug**\r\n\r\nThe `getCachedEmbeddings` for the sqlite adapter is flawed with the recent [introduction of vec_distance_L2](https://github.com/ai16z/eliza/commit/e96764a53c1d15b6f53cff6ec842f63f70d13842). \r\n\r\n```\r\npackages/adapter-sqlite/src/index.ts:226\r\nconst memories = this.db.prepare(sql).all(opts.query_table_name, new Float32Array(opts.query_input.split(\",\").map(Number)), // Convert string to Float32Array\r\n                                              ^\r\nRangeError: Too few parameter values were provided\r\n```\r\n\r\n\r\n1. The sql query expects 5 values, but only 4 are passed. `query_match_count` should be used for `LIMIT`\r\n2. The creation of the float array seems off. The `query_input` does not include any comma separated values. The resulting array is `[NaN]`\r\n3. Distance comparison is between a float array and a string. It should probably be compared to `query_threshold`, not `query_input`\r\n\r\nRelated function is here:\r\nhttps://github.com/ai16z/eliza/blob/15f7ba88d04d9d7d1cf0f608762fa84da06cb313/packages/adapter-sqlite/src/index.ts#L332C11-L360\r\n\r\nI'm happy to contribute if someone can guide me. I have little clue about `vec_distance` and didn't manage to infer what the intention of the change was exactly.\r\n\r\n**To Reproduce**\r\n\r\n`pnpm start --characters=\"characters/custom.character.json\"` and type something\r\n\r\n**Expected behavior**\r\n\r\nNo sqlite errors\r\n", "CLOSED", 0, "boldkoala4615", "2024-11-10T15:05:15Z", "2024-11-20T10:30:34Z", "2024-11-20T10:30:34Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6b-McL", 53, "\u2699\ufe0fTake Order Action Integration", "\u2699\ufe0f Action Integration: The integration of the \"take order\" action into the agent represents a foundational step in enhancing the system's capabilities, similar to adding new features to a smart assistant.\r\n\r\nIntegrate the \"take order\" action into the system as a foundational feature.\r\n\r\n#### Requirements\r\n- Design take order workflow\r\n- Implement action handlers\r\n- Add validation and verification steps\r\n- Create response handling system\r\n\r\n#### Acceptance Criteria\r\n- [ ] Users can successfully take orders\r\n- [ ] Action is properly integrated with order book\r\n- [ ] Validation checks are in place\r\n- [ ] Response handling works correctly", "CLOSED", 0, "sirkitree", "2024-10-27T18:11:05Z", "2024-11-20T09:58:28Z", "2024-11-20T09:58:28Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6b-MW8", 52, "\ud83d\udd0d Trust Score Calculator", "\ud83d\udd04 Trust Score Development: Creating a trust score based on trade outcomes will be essential for building credibility within the marketplace. It will allow users to make informed decisions based on past performance.\r\n\r\nDevelop a trust score calculation system based on trade outcomes and user recommendations.\r\n\r\n#### Requirements\r\n- Define trust score metrics\r\n- Implement calculation algorithm\r\n- Create history tracking for score changes\r\n- Add user recommendation integration\r\n\r\n#### Acceptance Criteria\r\n- [ ] Trust scores are calculated accurately\r\n- [ ] Historical data is tracked and accessible\r\n- [ ] User recommendations affect trust scores\r\n- [ ] Score changes are properly logged", "CLOSED", 0, "sirkitree", "2024-10-27T18:10:23Z", "2024-11-20T09:58:28Z", "2024-11-20T09:58:27Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6b-MCh", 49, "\ud83d\udcca Order Book System", "\ud83d\udcc8 Importance of the Order Book: The order book is critical for establishing a framework of trust within the marketplace. By documenting trades and their success rates, it lays the groundwork for a reliable trading environment.\r\n\r\nDevelop a central order book system for managing trades and trust assessments.\r\n\r\n#### Requirements\r\n- Design database schema for order storage\r\n- Implement order matching logic\r\n- Create APIs for order submission and retrieval\r\n- Add trust assessment calculations\r\n\r\n#### Acceptance Criteria\r\n- [ ] Orders can be created and stored in the system\r\n- [ ] Order matching algorithm is functioning\r\n- [ ] APIs are documented and tested\r\n- [ ] Trust assessments are calculated correctly", "CLOSED", 0, "sirkitree", "2024-10-27T18:07:18Z", "2024-11-20T09:58:27Z", "2024-11-20T09:58:27Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6b56ZQ", 33, "daos.fun integration", "We want daos.fun integration\r\n\r\nThis includes a basic service to interact with daos.fun and have a wallet and all that, as well as actions that mirror the swap actions but with the DAO wallet.", "CLOSED", 0, "lalalune", "2024-10-26T08:09:49Z", "2024-11-20T09:58:27Z", "2024-11-20T09:58:26Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6driUh", 238, "Issue with \"cannot read properties of undefined\"", " I had fixed something with this undefined (reading ...) before. should be able to fix this\r\n``` Swap transaction received\r\nDeserializing transaction...\r\nPreparing to sign transaction...\r\nCreating keypair...\r\nSigning transaction...\r\nSending transaction...\r\nTransaction sent: xxxxx\r\n [\"\u25ce sqlite-vec extensions loaded successfully.\"] \r\n\r\nError during token swap: TypeError: Cannot read properties of undefined (reading '_bn')\r\n```", "CLOSED", 0, "o-on-x", "2024-11-09T00:58:05Z", "2024-11-09T21:15:36Z", "2024-11-09T21:15:36Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6dbXlD", 229, ".env is not being loaded or picked up in settings", "process.env is just system settings. the .env wasnt getting added\r\n\r\nquick work around solution \r\n```\r\nimport fs from 'fs';\r\nimport path from 'path';\r\nimport { fileURLToPath } from 'url';\r\n\r\n// Convert import.meta.url to a file path\r\nconst __filename = fileURLToPath(import.meta.url);\r\nconst __dirname = path.dirname(__filename);\r\nconsole.log(__dirname, \" \", __filename)\r\n// Correctly resolve the path to the .env file in the core package\r\nconst envFilePath = path.resolve(__dirname, '../.env'); // Adjusted path to go one level up to the core directory\r\nconst envFileContent = fs.readFileSync(envFilePath, 'utf8');\r\n\r\n// Function to parse the .env file content into process.env\r\nfunction parseEnvFileContent(content: string) {\r\n    const lines = content.split('\\n').filter(line => {\r\n        const trimmedLine = line.trim();\r\n        // Ignore empty lines and lines starting with #\r\n        return trimmedLine && !trimmedLine.startsWith('#');\r\n    });\r\n\r\n    lines.forEach(line => {\r\n        // Remove inline comments\r\n        const cleanLine = line.split('#')[0].trim();\r\n        const [key, value] = cleanLine.split('=');\r\n        if (key && value) {\r\n            process.env[key.trim()] = value.trim();\r\n        }\r\n    });\r\n}\r\n\r\n// Parse the .env file content\r\nparseEnvFileContent(envFileContent);\r\n\r\nconst settings = process.env;\r\nconsole.log(\"settings: \", settings);\r\n\r\nexport default settings;\r\n\r\n```", "CLOSED", 0, "o-on-x", "2024-11-07T14:31:33Z", "2024-11-08T03:37:59Z", "2024-11-08T03:37:59Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6dZ6y7", 227, "agent & plugin-image-generation failed to build", "```\r\n> eliza@ build /home/ooo/apps/ai16z_eliza/work/latest_clone/eliza\r\n> bash ./scripts/build.sh\r\n\r\nBuilding package: agent\r\n\r\n> @eliza/agent@0.0.1 build\r\n> tsup --format esm --dts\r\n\r\nNo input files, try \"tsup <your-file>\" instead\r\nFailed to build agent\r\n\r\n...\r\n\r\nBuilding package: plugin-image-generation\r\n> @eliza/plugin-image-generation@0.0.1 build\r\n> tsup --format esm --dts\r\n\r\nDTS Build start\r\nsrc/index.ts(8,8): error TS2307: Cannot find module '@eliza/core' or its corresponding type declarations.\r\nsrc/index.ts(9,29): error TS2307: Cannot find module '@eliza/core' or its corresponding type declarations.\r\n\r\nError: error occurred in dts build\r\n    at Worker.<anonymous> (/home/ooo/apps/ai16z_eliza/work/latest_clone/eliza/node_modules/tsup/dist/index.js:1541:26)\r\n    at Worker.emit (node:events:507:28)\r\n    at MessagePort.<anonymous> (node:internal/worker:267:53)\r\n    at [nodejs.internal.kHybridDispatch] (node:internal/event_target:827:20)\r\n    at MessagePort.<anonymous> (node:internal/per_context/messageport:23:28)\r\nDTS Build error\r\nFailed to build plugin-image-generation\r\n```", "CLOSED", 0, "o-on-x", "2024-11-07T11:58:54Z", "2024-11-08T10:03:43Z", "2024-11-08T10:03:43Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6dXqgi", 223, "Unify ImageGen into ModelClass.IMAGE", "We have an ImageGen type but this should really be extended to a ModelClass type, since it is available for almost every major provider.", "CLOSED", 0, "lalalune", "2024-11-07T08:14:31Z", "2024-11-08T10:03:13Z", "2024-11-08T10:03:13Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6dXjjW", 222, "Move services to plugins", "After moving everything into plugins that is obvious, the only thing left really that is keeping core from being lightweight and running entirely in the browser or other environments like cloudflare are the native dependency on services.\r\n\r\nWe should probably move the node-only services into a plugin-node which can then be depended upon by other services, for example discord.\r\n\r\nWe should have a service registration and locator system, similar to the other plugin registrations.", "CLOSED", 0, "lalalune", "2024-11-07T07:58:37Z", "2024-11-08T10:03:18Z", "2024-11-08T10:03:18Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6dUWFK", 217, "Make sure system directive passed to vercel sdk", "<img width=\"475\" alt=\"Screenshot 2024-11-06 at 2 13 30\u202fPM\" src=\"https://github.com/user-attachments/assets/e460ae70-e7c0-42f3-9020-21f02964303f\">\r\n", "CLOSED", 0, "lalalune", "2024-11-06T22:13:41Z", "2024-11-07T03:07:32Z", "2024-11-07T03:07:32Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6dLbXo", 213, ".env not loading?", "Tried to load the anthropic api key from .env, no luck... needs testing", "CLOSED", 0, "lalalune", "2024-11-06T04:39:23Z", "2024-11-07T14:25:27Z", "2024-11-07T02:50:37Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6dLYZM", 212, "Anthropic API key not loading correctly", "Currently anthropic API doesnt load correctly, although if setting the OPENAI_API_KEY to an anthropic key will work... not great", "CLOSED", 0, "lalalune", "2024-11-06T04:30:58Z", "2024-11-07T06:15:17Z", "2024-11-07T06:15:17Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6dLWY7", 211, "Model provider loaded from char file should force lowercase, claude or anthropic should both work", "Model provider loaded from char file should force lowercase, claude or anthropic should both work", "CLOSED", 0, "lalalune", "2024-11-06T04:21:51Z", "2024-11-07T06:15:24Z", "2024-11-07T06:15:24Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6dLWA3", 210, "AI provider API keys should work from character files", "Currently the AI providers only work with the .env, not the character file env vars. We can pass the apiKey value through to solve this", "CLOSED", 0, "lalalune", "2024-11-06T04:20:17Z", "2024-11-07T06:15:31Z", "2024-11-07T06:15:31Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6dLTRF", 209, "Templates are wrong", "The templates are wrong and don't have the right fields, i.e. trump and tate", "CLOSED", 0, "lalalune", "2024-11-06T04:09:14Z", "2024-11-07T06:15:37Z", "2024-11-07T06:15:37Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6c2YeK", 181, "Changelog generator", "**Is your feature request related to a problem? Please describe.**\r\n\r\nhttps://keepachangelog.com/en/1.1.0/\r\n\r\n**Describe the solution you'd like**\r\n\r\nhttps://github.com/github-changelog-generator/github-changelog-generator\r\n\r\n**Describe alternatives you've considered**\r\n\r\nhttps://github.com/github-changelog-generator/github-changelog-generator/wiki/Alternatives\r\n\r\n**Additional context**\r\n\r\n- would need a github token to use this: https://github.com/github-changelog-generator/github-changelog-generator?tab=readme-ov-file#github-token\r\n\r\nAttaching a sample changelog\r\n[CHANGELOG.md](https://github.com/user-attachments/files/17612217/CHANGELOG.md)\r\n", "CLOSED", 0, "madjin", "2024-11-03T21:51:32Z", "2024-11-04T01:39:03Z", "2024-11-04T01:39:03Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6c1PGR", 178, "Telegram bot not returning responses", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nDoes not respond to messages, just prints forever in the console.\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n* Load custom character file from `tweets2character`.\r\n* Set up Telegram bot token.\r\n* Try to chat with bot.\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\nBot responds.\r\n\r\n**Screenshots**\r\nPrints these logs forever.\r\n<img width=\"1282\" alt=\"Screenshot 2024-11-03 at 17 15 48\" src=\"https://github.com/user-attachments/assets/1e32781d-de76-4a50-a53f-026d15b9d799\">\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\nRunning with LlamaLocal model.\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "rhlsthrm", "2024-11-03T13:16:30Z", "2024-11-04T06:01:38Z", "2024-11-04T06:01:38Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6c0Rf9", 176, "build docs doesn't seem to be working", "**Trying to build the docs from what I saw was being incorporated the other night and it's erroring out**\r\n\r\nFirst it errors out saying it wants node 23.1 but the project is using 22.xx.  I update to 23.1 using nvm and it still errors out.\r\n\r\nPutting this here as a place holder - this needs more work.\r\n\r\neliza>$ pnpm build-docs\r\n\r\n> eliza@ build-docs /Users/davidjaramillo/Documents/Projects/eliza\r\n> pnpm --dir docs build\r\n\r\n\u2009WARN\u2009 Unsupported engine: wanted: {\"node\":\"23.1.0\"} (current: {\"node\":\"v22.11.0\",\"pnpm\":\"9.12.3\"})\r\n\r\n> eliza-docs@0.0.0 build /Users/davidjaramillo/Documents/Projects/eliza/docs\r\n> docusaurus build\r\n\r\n[INFO] [en] Creating an optimized production build...\r\n[info] Loaded plugin typedoc-plugin-markdown\r\n[error] The tsconfig file /Users/davidjaramillo/Documents/Projects/eliza/tsconfig.json does not exist\r\n\r\n[ERROR] Error: Unable to build website for locale en.\r\n    at tryToBuildLocale (/Users/davidjaramillo/Documents/Projects/eliza/node_modules/.pnpm/@docusaurus+core@3.5.2_@docusaurus+types@3.5.2_acorn@8.14.0_react-dom@18.2.0_react@18.2.0__re_e6f3ssmiin2uov5e54dllhgixm/node_modules/@docusaurus/core/lib/commands/build.js:54:19)\r\n    at async /Users/davidjaramillo/Documents/Projects/eliza/node_modules/.pnpm/@docusaurus+core@3.5.2_@docusaurus+types@3.5.2_acorn@8.14.0_react-dom@18.2.0_react@18.2.0__re_e6f3ssmiin2uov5e54dllhgixm/node_modules/@docusaurus/core/lib/commands/build.js:65:9\r\n    at async mapAsyncSequential (/Users/davidjaramillo/Documents/Projects/eliza/node_modules/.pnpm/@docusaurus+utils@3.5.2_@docusaurus+types@3.5.2_acorn@8.14.0_react-dom@18.2.0_react@18.2.0__r_ommau7el7tbopkaz2g33fzjgfi/node_modules/@docusaurus/utils/lib/jsUtils.js:21:24)\r\n    at async Command.build (/Users/davidjaramillo/Documents/Projects/eliza/node_modules/.pnpm/@docusaurus+core@3.5.2_@docusaurus+types@3.5.2_acorn@8.14.0_react-dom@18.2.0_react@18.2.0__re_e6f3ssmiin2uov5e54dllhgixm/node_modules/@docusaurus/core/lib/commands/build.js:63:5) {\r\n  [cause]: Error: ENOENT: no such file or directory, scandir '/Users/davidjaramillo/Documents/Projects/eliza/src'\r\n      at Object.readdirSync (node:fs:1502:26)\r\n      at glob (/Users/davidjaramillo/Documents/Projects/eliza/node_modules/.pnpm/typedoc@0.26.11_typescript@5.6.3/node_modules/typedoc/dist/lib/utils/fs.js:259:32)\r\n      at /Users/davidjaramillo/Documents/Projects/eliza/node_modules/.pnpm/typedoc@0.26.11_typescript@5.6.3/node_modules/typedoc/dist/lib/utils/entry-point.js:207:38\r\n      at Array.flatMap (<anonymous>)\r\n      at expandGlobs (/Users/davidjaramillo/Documents/Projects/eliza/node_modules/.pnpm/typedoc@0.26.11_typescript@5.6.3/node_modules/typedoc/dist/lib/utils/entry-point.js:206:31)\r\n      at getEntryPoints (/Users/davidjaramillo/Documents/Projects/eliza/node_modules/.pnpm/typedoc@0.26.11_typescript@5.6.3/node_modules/typedoc/dist/lib/utils/entry-point.js:83:53)\r\n      at _classThis.getEntryPoints (/Users/davidjaramillo/Documents/Projects/eliza/node_modules/.pnpm/typedoc@0.26.11_typescript@5.6.3/node_modules/typedoc/dist/lib/application.js:299:53)\r\n      at _classThis.convert (/Users/davidjaramillo/Documents/Projects/eliza/node_modules/.pnpm/typedoc@0.26.11_typescript@5.6.3/node_modules/typedoc/dist/lib/application.js:321:38)\r\n      at generateTypedoc (/Users/davidjaramillo/Documents/Projects/eliza/node_modules/.pnpm/docusaurus-plugin-typedoc@1.0.5_typedoc-plugin-markdown@4.2.9_typedoc@0.26.11_typescript@5.6.3__/node_modules/docusaurus-plugin-typedoc/dist/plugin.js:99:31)\r\n      at async Object.pluginDocusaurus [as plugin] (/Users/davidjaramillo/Documents/Projects/eliza/node_modules/.pnpm/docusaurus-plugin-typedoc@1.0.5_typedoc-plugin-markdown@4.2.9_typedoc@0.26.11_typescript@5.6.3__/node_modules/docusaurus-plugin-typedoc/dist/plugin.js:40:9) {\r\n    errno: -2,\r\n    code: 'ENOENT',\r\n    syscall: 'scandir',\r\n    path: '/Users/davidjaramillo/Documents/Projects/eliza/src'\r\n  }\r\n}\r\n[INFO] Docusaurus version: 3.5.2\r\nNode version: v22.11.0\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\neliza>$ \r\n\r\n", "CLOSED", 0, "yodamaster726", "2024-11-03T03:58:49Z", "2024-11-04T06:46:12Z", "2024-11-04T06:46:12Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6cxlxu", 166, "Prompt template overrides", "**Is your feature request related to a problem? Please describe.**\r\n\r\nI am modifying core templates from different providers to alter the style of thinking for my agent and control all aspects of its prompting.\r\n\r\n**Describe the solution you'd like**\r\n\r\nOverride prompt templates in the character file for all prompts (twitter generation, search, interaction, etc)\r\n\r\n**Describe alternatives you've considered**\r\n\r\nDiverging (which would suck).\r\n", "CLOSED", 0, "parzival418", "2024-11-02T05:58:40Z", "2024-11-09T01:52:15Z", "2024-11-09T01:52:15Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6cwQwK", 159, "Plugin System", "**Is your feature request related to a problem? Please describe.**\r\n\r\nWe need a plugin system. Discord could be a plugin, with its own registered actions, providers, evaluators and client. Much of the code could be pulled out of the core and into plugins. \r\n\r\n**Describe the solution you'd like**\r\n\r\nPlugins could be configured per-character so that the runtime installs. The plugin system should enable actions, evaluators, providers, clients and db adapters to be added dynamically, dramatically simplifying the core and making it so it can run in browser with no dependency issues.", "CLOSED", 0, "lalalune", "2024-11-01T21:27:13Z", "2024-11-08T10:55:06Z", "2024-11-08T10:55:06Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6cvn8S", 157, "Chattiness Slider/Respond to Bots setting in Discord", "**Is your feature request related to a problem? Please describe.**\r\n![image](https://github.com/user-attachments/assets/ef57908e-59cb-480a-8f7d-821a3468bce7)\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\nBots will dump tokens responding to each other and/or be annoyingly chatty sometimes\r\n\r\n\r\n\r\n**Describe the solution you'd like**\r\n -- I think it might be useful to have a setting where a bot will 'wait' X amount of time before responding to a message, or a way to weight boredom higher in a series of rapid-fire back and forths. Maybe an if chars = 250+ and responsetime>1000ms then multiply normal boredom by X (or however fast humans aren't able to write) + some manual sliders on chattiness levels if we want one that's more shy vs outgoing\r\n \r\n<!-- A clear and concise description of what you want to happen. -->\r\nWhen interacting with another bot, or set as anxious/shy/quiet, response volume is reduced by ~50%\r\n\r\n**Describe alternatives you've considered**\r\nnone, just had the thought\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n![image](https://github.com/user-attachments/assets/7adf326c-9f6f-4756-825c-8c5e5b1d2bed)\r\n", "CLOSED", 0, "twilwa", "2024-11-01T19:27:34Z", "2024-11-08T10:56:35Z", "2024-11-08T10:56:35Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6cZnC4", 95, "Can't Update Character Personality After Modifications in defaultCharacter.ts", "\r\n**Describe the bug**\r\nAfter modifying the character personality in defaultCharacter.ts, the AI responses remain unchanged and continue using the old personality settings in both Discord and Twitter interactions. However, the Twitter post creation functionality correctly reflects the new personality changes.\r\n\r\n**To Reproduce**\r\n1. Navigate to defaultCharacter.ts\r\n2. Modify the character personality settings/prompt\r\n3. Save the changes and restart the application\r\n4. Test interactions on Discord - responses use old personality\r\n5. Test interactions on Twitter - responses use old personality\r\n6. Test Twitter post creation - correctly uses new personality\r\n\r\n**Expected behavior**\r\n- When defaultCharacter.ts is modified, all AI interactions (Discord responses, Twitter replies, and Twitter posts) should reflect the new personality settings immediately after application restart.\r\n- The character should consistently maintain the new personality across all platforms and interaction types.\r\n\r\n**Screenshots**\r\n<!-- You may want to add screenshots showing:\r\n1. The modified defaultCharacter.ts code\r\n2. Discord responses showing old personality\r\n3. Twitter responses showing old personality\r\n4. Twitter post creation showing new personality -->\r\n\r\n**Additional context**\r\n- The inconsistency between Twitter post creation and response behavior suggests a possible caching issue or incomplete personality update propagation across different modules\r\n- The issue persists across application restarts\r\n- Twitter post creation working correctly with new personality indicates that the character file is being read properly in some contexts but not others", "CLOSED", 0, "SotoAlt", "2024-10-30T12:34:22Z", "2024-11-04T05:47:35Z", "2024-11-04T05:47:35Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6cZTx6", 92, "Time Interval of generateNewTweetLoop is not consistent with the comment", "on src/clients/twitter/generate.ts\r\n\r\nexport class TwitterGenerationClient extends ClientBase {\r\n  onReady() {\r\n    const generateNewTweetLoop = () => {\r\n      this.generateNewTweet();\r\n      setTimeout(\r\n        generateNewTweetLoop,\r\n        (Math.floor(Math.random() * (45 - 15 + 1)) + 15) * 60 * 1000,\r\n      ); // Random interval between 4-8 hours\r\n      \r\n      **its actually 15-45 minutes, not 4-8 hours as the comment suggests.**\r\n      \r\n      \r\n     Also IMO, all the time intervals, replies and search and engage are was too aggressive, I got my agent banned on X in less than 12 hrs of using in on the default settings, maybe we can have way more time intervals to avoid this by default", "CLOSED", 0, "SotoAlt", "2024-10-30T12:02:55Z", "2024-11-04T05:47:11Z", "2024-11-04T05:47:11Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6cKyiz", 73, "Abstract transcript provider", "**Is your feature request related to a problem? Please describe.**\r\n\r\nRight now the options for model provider for transcription are openai and local with whisper. The OpenAI is hardcoded to check for the existence of the API key, and then load that, otherwise use the local.\r\n\r\n**Describe the solution you'd like**\r\n\r\nSimilar to the new model provider abstraction, we want to offer image recognition for whatever the current model is. For example, Claude, Vertex Claude, Cloud Llama, etc.", "CLOSED", 0, "lalalune", "2024-10-29T04:11:31Z", "2024-11-08T10:57:33Z", "2024-11-08T10:57:33Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6cJ4QH", 70, "Execution gets stuck in a loop", "My agent has been getting caught in an random loop where this is included in the terminal output:\r\n```\r\nparsedContent is null\r\nparsedContent is null, retrying\r\n```\r\nThe request body is the usual size and headers are as expected, I can't see what the issue is and what repro steps there are. I'm only running text interaction on Discord.\r\n\r\nIf I get more insight I'll update it here.", "CLOSED", 0, "docherty", "2024-10-29T00:21:10Z", "2024-11-08T10:58:00Z", "2024-11-08T10:58:00Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6cJl3-", 69, "Make sure 100% works with local models", "We have a local llama setup but we haven't used it since all this hype started, so we need to go through and make sure that all local models are working correctly.", "CLOSED", 0, "lalalune", "2024-10-28T23:17:41Z", "2024-11-06T22:26:40Z", "2024-11-03T04:52:25Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6b-Sp_", 55, "Voice is not working, \"null\" from incoming messages", "Review and figure out why the voice chat is not working", "CLOSED", 0, "lalalune", "2024-10-27T18:56:18Z", "2024-11-08T10:57:44Z", "2024-11-08T10:57:44Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6b-MIQ", 50, "\ud83e\udd16 Confidence Level Implementation", "\ud83c\udfaf Confidence Metrics: Establishing clear confidence levels for trades helps in assessing the reliability of recommendations, making it easier to identify which trades are worth pursuing based on user input.\r\n\r\nImplement a confidence level system for order evaluation with low, medium, and high confidence categories.\r\n\r\n#### Requirements\r\n- Define criteria for each confidence level\r\n- Create UI elements for confidence selection\r\n- Implement confidence scoring algorithm\r\n- Add confidence level filters to order book\r\n\r\n#### Acceptance Criteria\r\n- [ ] Users can assign confidence levels to orders\r\n- [ ] Confidence levels are clearly displayed in the UI\r\n- [ ] Filtering system works based on confidence levels\r\n- [ ] Confidence scoring affects trust calculations\r\n", "CLOSED", 0, "sirkitree", "2024-10-27T18:08:11Z", "2024-11-08T10:55:40Z", "2024-11-08T10:55:40Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6b99nY", 47, "Commands for starting agents without character profiles", "In the package.json there are scripted commands for agents like ruby and spartan, but we do not have their character profiles in `/characters`\r\n\r\nI propose we either:\r\n1. remove the commands from package.json, or\r\n2. (preferred) add the character profiles for them\r\n\r\n```\r\n    \"start:service:ruby\": \"pm2 start npm --name=\\\"ruby\\\" --restart-delay=3000 --max-restarts=10 -- run start:ruby\",\r\n    \"stop:service:ruby\": \"pm2 stop ruby\",\r\n    \"start:ruby\": \"node --loader ts-node/esm src/index.ts --characters=\\\"characters/ruby.character.json\\\"\",\r\n    ...\r\n    \"start:service:degen\": \"pm2 start npm --name=\\\"degen\\\" --restart-delay=3000 --max-restarts=10 -- run start:degen\",\r\n    \"stop:service:degen\": \"pm2 stop degen\",\r\n    \"start:degen\": \"node --loader ts-node/esm src/index.ts --characters=\\\"characters/degenspartan.json\\\"\",\r\n```    \r\n\r\nThoughts?", "CLOSED", 0, "sirkitree", "2024-10-27T16:27:34Z", "2024-11-09T01:51:42Z", "2024-11-09T01:51:42Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6b53Ka", 32, "Fix name confusion", "<img width=\"397\" alt=\"Screenshot 2024-10-26 at 12 44 32\u202fAM\" src=\"https://github.com/user-attachments/assets/53869be3-7930-4291-948f-4a887d429511\">\r\n", "CLOSED", 0, "lalalune", "2024-10-26T07:44:54Z", "2024-11-09T01:51:31Z", "2024-11-09T01:51:31Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6bnDXO", 23, "Fix memory mixing in Twitter generate", "Twitter generate uses a default room ID and this might be causing problems between the clients, since they access the same sqlite database. So Spartan would say kind of weird stuff about quantum mechanics, because he's pulling some of Ruby's memories. This only seems to happen on generation since room id is same.", "CLOSED", 0, "lalalune", "2024-10-24T07:19:58Z", "2024-11-04T05:26:19Z", "2024-11-04T05:25:51Z", "elizaos/eliza", "2025-04-14 21:50:20"]
["I_kwDOMT5cIs6hUORV", 687, "Debug/Verbose eliza logging is always shown", "I introduced this with https://github.com/ai16z/eliza/pull/677\r\n\r\nWill create a small PR to fix this", "CLOSED", 0, "augchan42", "2024-11-30T00:25:22Z", "2024-11-30T02:35:25Z", "2024-11-30T02:35:25Z", "elizaos/eliza", "2025-04-14 21:50:21"]
["I_kwDOMT5cIs6hJssL", 663, "Failed codecov run", "We need to fix https://github.com/ai16z/eliza/actions/runs/12075056047 which appears related to \r\n\r\nhttps://github.com/ai16z/eliza/pull/608 and might get fixed with https://github.com/ai16z/eliza/pull/659 @snobbee @monilpat @pgoos ", "CLOSED", 0, "jkbrooks", "2024-11-29T02:37:13Z", "2024-11-29T22:33:23Z", "2024-11-29T22:33:22Z", "elizaos/eliza", "2025-04-14 21:50:21"]
["I_kwDOMT5cIs6hJW_8", 661, "Discord Client - gives 0 permissions for invite link on logger", "**Describe the bug**\r\n\r\nUpon startup if discord is a client, the invite link for the bot has hardcoded permissions = 0 in the logs.  This means the bot will have no permission to read or write messages\r\n\r\npackages/client-discord/src/index.ts:\r\n\r\n`            `https://discord.com/api/oauth2/authorize?client_id=${readyClient.user?.id}&permissions=0&scope=bot%20applications.commands`\r\n`\r\nI also ran into an issue with dupe reactions causing a crash due to colliding ids\r\nAnd gave the bot a new /joinchannel command to tell the bot to join a specific channel\r\n\r\n**To Reproduce**\r\nJust start the agent with a character card with discord enabled, you will see the following in the logs:\r\n\r\n\u001b[32m [2024-11-29T00:37:59.270Z] \u2713 Use this URL to add the bot to your server: \u001b[0m\r\n\r\n\u001b[32m [2024-11-29T00:37:59.270Z] \u2713 https://discord.com/api/oauth2/authorize?client_id=<your client id>8&permissions=0&scope=bot%20applications.commands \u001b[0m\r\n\r\n**Expected behavior**\r\n\r\nWe should see proper permissions for the bot to be able to respond and write messages\r\n\r\n**Additional context**\r\n\r\nWill create a PR that fixes all 3 issues described\r\n", "CLOSED", 0, "augchan42", "2024-11-29T01:21:21Z", "2024-11-29T11:36:17Z", "2024-11-29T11:36:17Z", "elizaos/eliza", "2025-04-14 21:50:21"]
["I_kwDOMT5cIs6hIcTe", 657, "TypeError while generating a message response", "**Describe the bug**\n\nReceive the following error when trying to chat after first boot:\n\n(I put a printf before the error to try to see why it's throwing the error)\n\n```\n\nYou: Hello\nResponse {\n  status: 405,\n  statusText: 'Method Not Allowed',\n  headers: Headers {\n    date: 'Thu, 28 Nov 2024 21:56:32 GMT',\n    server: 'uvicorn',\n    'content-length': '31',\n    'content-type': 'application/json',\n    'x-process-time': '0'\n  },\n  body: ReadableStream { locked: false, state: 'readable', supportsBYOB: true },\n  bodyUsed: false,\n  ok: false,\n  redirected: false,\n  type: 'basic',\n  url: 'http://localhost:3000/trump/message'\n}\nError fetching response: TypeError: data.forEach is not a function\n    at handleUserInput (file:///Users/redacted/se01/eliza/agent/src/index.ts:274:14)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async file:///Users/redacted/se01/eliza/agent/src/index.ts:234:13\n```\n\n**To Reproduce**\n\nHappens after first chat message after first boot.\n\n**Expected behavior**\n\nEliza produces a coherent response to the prompt.\n\n**Additional context**\n\nThis is on `v0.1.4-alpha3`, macOS, node v23.3\n\nI've tried this with an openai key and a xai key (trying to figure out if it was an API issue on that side) and the same error happens with both.", "CLOSED", 0, "vvisigoth", "2024-11-28T22:02:26Z", "2024-12-01T13:29:58Z", "2024-12-01T13:29:58Z", "elizaos/eliza", "2025-04-14 21:50:21"]
["I_kwDOMT5cIs6hEMxr", 647, "Optional image model provider to character and runtime", "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, users can only select a single model provider for both text and image generation. This becomes limiting when a provider excels at text generation but offers subpar image generation capabilities, or vice versa.\r\n\r\n**Describe the solution you'd like**\r\n\r\nWe propose adding an optional image model provider setting that would take precedence over the default model provider when configured. If no image provider is specified, the system would continue using the default model provider, maintaining backward compatibility.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nWe've explored using a single provider (such as Heurist or OpenAI) for both text and image generation. While this works adequately, it limits flexibility. For instance, if you want to use a fine-tuned model from a specialized image generation service, this isn't currently possible.\r\n\r\n**Additional context**\r\n\r\nI've implemented a similar solution that allows me to use OpenAI for text generation while leveraging a custom fine-tuned model on fal.ai for image generation.\r\n", "CLOSED", 0, "yoniebans", "2024-11-28T13:47:36Z", "2024-11-29T17:02:42Z", "2024-11-29T17:02:42Z", "elizaos/eliza", "2025-04-14 21:50:21"]
["I_kwDOMT5cIs6gvxng", 623, "I have GROQ_API_KEY and telgram's robot token, How should I configure it so that I can interact with Telegram only by using the API without starting a model locally?", "**Is your feature request related to a problem? Please describe.**\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the solution you'd like**\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "recheck911", "2024-11-27T03:33:20Z", "2024-11-27T06:46:32Z", "2024-11-27T06:45:56Z", "elizaos/eliza", "2025-04-14 21:50:21"]
["I_kwDOMT5cIs6gnr6k", 615, "Smol one; Matched fragment log not showing similarity score", "**Describe the bug**\r\n\r\nSimilarity score not logging correctly when searching memory fragments. We're logging `message.similarity` instead of `memory.similarity` which is resulting in `undefined` for the similarity score between a message and a memory.\r\n\r\n**To Reproduce**\r\n\r\nRun the code and search for `Matched fragment:` in the logs. You will see `undefined` for the similarity score.\r\n\r\n**Expected behavior**\r\n\r\nI expect to see the similarity score for each matched memory fragment as per the code's intended logic.\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n<img width=\"2232\" alt=\"Screenshot 2024-11-26 at 2 45 56\u202fPM\" src=\"https://github.com/user-attachments/assets/af2fbd3d-c190-4da0-b535-dc24497839a9\">\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\r\nN/A\r\n", "CLOSED", 0, "yoniebans", "2024-11-26T13:50:47Z", "2024-11-26T22:10:05Z", "2024-11-26T22:10:05Z", "elizaos/eliza", "2025-04-14 21:50:21"]
["I_kwDOMT5cIs6gnn9P", 614, "New knowledge not being ingested into agent memory after first run", "**Describe the bug**\r\n\r\nWhen adding a knowledge section in the character profile, these pieces of knowledge are taken and added to the agent memory. Once this is done, appending new knowledge to profile has no effect as the `processCharacterKnowledge()` method in `/packages/core/src/runtime.ts` breaks out of the knowledge adding loop as soon as it finds a piece of knowledge that already exists in memory.\r\n\r\n**To Reproduce**\r\n\r\nAdd a knowledge section to your character, start the character up for the first time. Stop the agent, update the knowledge and restart the agent. Check db.sqlite and you will see that no new knowledge has been added.\r\n\r\n**Expected behavior**\r\n\r\nI would expect the agent should be able to absorb new knowledge that is added to the character file on each startup. There is potentially an argument for memories associated to knowledge that no longer exist in the character file should be removed but that is more subjective.\r\n\r\n**Screenshots**\r\n\r\n<img width=\"2034\" alt=\"Screenshot 2024-11-26 at 2 44 37\u202fPM\" src=\"https://github.com/user-attachments/assets/0b9f408f-9b1c-4b68-9219-258d992fde6a\">\r\n\r\n\r\n**Additional context**\r\n\r\nN/A\r\n", "CLOSED", 0, "yoniebans", "2024-11-26T13:45:22Z", "2024-11-26T21:11:10Z", "2024-11-26T21:11:10Z", "elizaos/eliza", "2025-04-14 21:50:21"]
["I_kwDOMT5cIs6ghAKd", 604, "Add support for local embeddings BGE/384", "**Is your feature request related to a problem? Please describe.**\r\n\r\nRight now only OpenAI embeddings are supported, which requires a call to OpenAI to embed and persist memories into pgvector\r\n\r\n**Describe the solution you'd like**\r\n\r\nThis will be property driven, depending on the existing environment variable USE_OPENAI_EMBEDDING, either OpenAI embeddings API will be used (current), or local BGESmallENV15 from fastembed\r\n\r\n**Describe alternatives you've considered**\r\nBGELarge is also a possibility, but BGE-Small is ~125MB vs ~420MB for BGE-Large, and BGE-Small performs at ~95-97% of BGE-Large's quality on most benchmarks.  BGE-Small is about 70-80% of OpenAI's embedding quality with no API cost and no latency.\r\n\r\n**Additional context**\r\n\r\nI have this running locally on supabase, and will cherry-pick out the changes for a new PR for this issue.\r\n", "CLOSED", 0, "augchan42", "2024-11-26T03:58:59Z", "2024-11-30T01:08:20Z", "2024-11-29T19:42:08Z", "elizaos/eliza", "2025-04-14 21:50:21"]
["I_kwDOMT5cIs6gNCCr", 563, "Need Discord or Telegram Group to Quickly Get Help For Developer", "**Is your feature request related to a problem? Please describe.**\r\n\r\nI am a developer trying to learn ELIZA framework and build AI apps on top of it. I am going through the documentation and following it but when I am faced with the problem, I have to check for the issues or add new issues in the GitHub. There is no way for me to validate if I'm doing something wrong or if it is a bug in the framework. Needing to have all discussions on the GitHub issues slows down the overall learning and development of the framework in my opinion. Group can be used to do preliminary discussions and then issues can be added if necessary. \r\n\r\n**Describe the solution you'd like**\r\n\r\nStart a discord server and Telegram Group chat to provide support and have preliminary discussions on the issues. This will make the framework more user-friendly to new developers like me.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nI have considered going through the issues, searching there and adding new issues but in my opinion, it's can pollute the issues with common issues, beginner mistakes etc.\r\n\r\n**Additional context**\r\n\r\nNo context. I think what I have answered in previous questions provides sufficient context for the issue. \r\n", "CLOSED", 0, "NiravJoshi33", "2024-11-24T14:00:58Z", "2024-11-25T03:58:25Z", "2024-11-25T03:58:24Z", "elizaos/eliza", "2025-04-14 21:50:21"]
["I_kwDOMT5cIs6gAUNq", 519, "Tests failing - token.test.ts failing because it is commented out. Cache and goals tests are failing because jest is now switched with vitest", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nTests are failing: \r\ntoken.test.ts is failing because it is empty (whole file is commented out). Instead of commenting out, test should be skipped. \r\ngoals and cache tests are failing because jest is used for mock functions, but jest is now switched with vitest.\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\nNavigate to packages/core and run pnpm test\r\n**Expected behavior**\r\nTests should not fail because of their setup.\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "ai16z-demirix", "2024-11-22T20:14:58Z", "2024-11-25T14:44:08Z", "2024-11-25T14:44:08Z", "elizaos/eliza", "2025-04-14 21:50:21"]
["I_kwDOMT5cIs6f12wc", 506, "Non node.js environments have issues building (workers for instance)", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "antpb", "2024-11-22T04:07:31Z", "2024-11-29T22:33:44Z", "2024-11-29T22:33:44Z", "elizaos/eliza", "2025-04-14 21:50:21"]
["I_kwDOMT5cIs6fmnfn", 469, "Error when call `generateObjectV2`", "**Describe the bug**\r\n\r\nIf `generateObjectV2` is used, the passed modelClass is not processed appropriately and would produce a bug.\r\n\r\ntrimTokens receive the parameters `models` which is expected to be strings like `gpt-4o`. However, in generateObjectV2, modelClass, which is supposed to be `small`, \"medium\" or \"large\" is provided.\r\n\r\n```\r\ncontext = await trimTokens(context, max_context_length, modelClass);\r\n```\r\n\r\n```\r\nexport function trimTokens(context, maxTokens, model) {\r\n    // Count tokens and truncate context if necessary\r\n    const encoding = encoding_for_model(model as TiktokenModel);\r\n    let tokens = encoding.encode(context);\r\n    const textDecoder = new TextDecoder();\r\n    if (tokens.length > maxTokens) {\r\n        tokens = tokens.reverse().slice(maxTokens).reverse();\r\n\r\n        context = textDecoder.decode(encoding.decode(tokens));\r\n    }\r\n    return context;\r\n}\r\n```\r\n\r\n**Screenshots**\r\n\r\n<img width=\"745\" alt=\"image\" src=\"https://github.com/user-attachments/assets/1397f09e-49f8-4149-8ab6-30972aae6efa\">\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "darwintree", "2024-11-21T01:51:10Z", "2024-11-29T22:33:33Z", "2024-11-29T22:33:33Z", "elizaos/eliza", "2025-04-14 21:50:21"]
["I_kwDOMT5cIs6evzpB", 337, "Node module version 127 vs 131 sqlite issue", "### **Issue Summary**\r\nI am encountering an error when trying to run the project after installing dependencies. The error seems related to the `better-sqlite3` module not being compatible with my version of Node.js. The error message suggests a mismatch between the Node.js version and the compiled module version.\r\n\r\n---\r\n\r\n### **Error Log**\r\n```bash\r\n(node:37509) [DEP0040] DeprecationWarning: The punycode module is deprecated. Please use a userland alternative instead.\r\nDirectClientInterface start DirectClient constructor\r\nError starting agent for character Eliza: \r\nError: The module '/mnt/c/Users/--/sb/eliza/node_modules/better-sqlite3/build/Release/better_sqlite3.node' was compiled against a different Node.js version using NODE_MODULE_VERSION 127.\r\nThis version of Node.js requires NODE_MODULE_VERSION 131. \r\nPlease try re-compiling or re-installing the module (for instance, using pnpm rebuild or pnpm install).\r\nat Object..node (node:internal/modules/cjs/loader:1735:18)\r\nat Module.load (node:internal/modules/cjs/loader:1315:32)\r\nat Function._load (node:internal/modules/cjs/loader:1125:12)\r\nat TracingChannel.traceSync (node:diagnostics_channel:322:14)\r\nat wrapModuleLoad (node:internal/modules/cjs/loader:216:24)\r\nat Module.require (node:internal/modules/cjs/loader:1337:12)\r\nat require (node:internal/modules/helpers:139:16)\r\nat bindings (/mnt/c/Users/--/sb/eliza/node_modules/bindings/bindings.js:112:48)\r\nat new Database (/mnt/c/Users/--/sb/eliza/node_modules/better-sqlite3/lib/database.js:48:64)\r\nat initializeDatabase (file:///mnt/c/Users/--/sb/eliza/packages/agent/src/index.ts:137:42)\r\n{ code: 'ERR_DLOPEN_FAILED' }\r\nError starting agents: \r\nError: The module '/mnt/c/Users/--/sb/eliza/node_modules/better-sqlite3/build/Release/better_sqlite3.node' was compiled against a different Node.js version using NODE_MODULE_VERSION 127.\r\nThis version of Node.js requires NODE_MODULE_VERSION 131. \r\nPlease try re-compiling or re-installing the module (for instance, using pnpm rebuild or pnpm install).\r\nat Object..node (node:internal/modules/cjs/loader:1735:18)\r\nat Module.load (node:internal/modules/cjs/loader:1315:32)\r\nat Function._load (node:internal/modules/cjs/loader:1125:12)\r\nat TracingChannel.traceSync (node:diagnostics_channel:322:14)\r\nat wrapModuleLoad (node:internal/modules/cjs/loader:216:24)\r\nat Module.require (node:internal/modules/cjs/loader:1337:12)\r\nat require (node:internal/modules/helpers:139:16)\r\nat bindings (/mnt/c/Users/--/sb/eliza/node_modules/bindings/bindings.js:112:48)\r\nat new Database (/mnt/c/Users/--/sb/eliza/node_modules/better-sqlite3/lib/database.js:48:64)\r\nat initializeDatabase (file:///mnt/c/Users/--/sb/eliza/packages/agent/src/index.ts:137:42)\r\n{ code: 'ERR_DLOPEN_FAILED' }\r\nChat started. Type 'exit' to quit.\r\nYou: Server running at http://localhost:3000/\r\n\r\n\r\nSteps to Reproduce\r\nClone the repository:\r\ngit clone <repo-url>\r\n\r\nInstall dependencies:\r\npnpm install\r\n\r\nRun the project:\r\npnpm start or node <entry-file>\r\n\r\nObserve the error in the terminal.\r\n\r\nSystem Information\r\nNode.js version: v18.17.1 (example; replace with your actual version)\r\nLinux Distribution: Ubuntu 20.04 (example; replace with your actual distribution)\r\nKernel version: 5.4.0-80-generic (example; replace with your actual kernel version)\r\npnpm version: 9.6.1 (example; replace with your actual pnpm version)\r\nPossible Causes & Solution Suggestions\r\nI suspect that there is a mismatch between the version of Node.js and the better-sqlite3 binary. The error message indicates that the better-sqlite3 module was compiled with NODE_MODULE_VERSION 127, while my current Node.js version requires NODE_MODULE_VERSION 131.\r\nPossible solutions:\r\n\r\nTry rebuilding the module:\r\npnpm rebuild better-sqlite3\r\n\r\nReinstall the better-sqlite3 module:\r\npnpm uninstall better-sqlite3 && pnpm install better-sqlite3\r\n\r\nEnsure the version of Node.js being used matches the version the module was compiled for.\r\n\r\nAdditional Information\r\nI am using Node Version Manager (nvm) to manage different Node.js versions.\r\nThe project is running in a Linux environment, but my system is dual-booted with Windows. I am using a WSL (Windows Subsystem for Linux) environment.\r\nExpected Behavior\r\nI expect the server to start successfully, but instead, the error prevents the agent from starting.\r\n\r\n", "CLOSED", 0, "markjkaem", "2024-11-15T22:30:06Z", "2024-11-27T23:19:27Z", "2024-11-16T01:07:20Z", "elizaos/eliza", "2025-04-14 21:50:21"]
["I_kwDOMT5cIs6eA0hY", 271, "unable to run defaultcharacter with ModelProviderName.LLAMACLOUD local", "I'm trying to run the latest eliza with the defaultcharacter with the local Ollama.   starts up fine but as soon as I try to interact with it, it crashes saying it can't find the embeddingModel, but that's not the one that's configured as part of LLAMACLOUD\r\n\r\n![image](https://github.com/user-attachments/assets/1c9ea2f5-8de2-44a4-ac77-d9c99b6dc03d)\r\n\r\n![image](https://github.com/user-attachments/assets/102774c1-c422-4c48-928f-e3f685d00d04)\r\n\r\nthis is the correct embedding and I have it installed:\r\n![image](https://github.com/user-attachments/assets/2eeba077-2113-42f3-96f8-e39cf84a8bda)\r\n\r\n![image](https://github.com/user-attachments/assets/f564efdc-2023-4f32-b433-153b06c44268)\r\n\r\nI even configured it in my .env file:\r\n![image](https://github.com/user-attachments/assets/c3be0618-e46e-466c-893c-abab31f92493)\r\n\r\nI'm starting at getting things running at the lowest level and then start adding clients one at a time.\r\n\r\nIt seems like there is something not right in DirectClient, but I can't put my finger on it.  For sure, there seems to be a few other provider related things hardcoded in there.\r\n\r\nLet me know if I'm missing something.  \r\n", "CLOSED", 0, "yodamaster726", "2024-11-12T04:43:34Z", "2024-11-27T03:43:34Z", "2024-11-27T03:43:33Z", "elizaos/eliza", "2025-04-14 21:50:21"]
["I_kwDOMT5cIs6iZ3M_", 902, "Error pnpm start - Promise.withResolvers(): pdfjs-dist", "**Describe the bug**\r\n\r\nDoing all steps for the quick start, once pnpm start comes you get this error:\r\n\r\nTypeError: Cannot read properties of undefined (reading 'start')\r\n    at Object.start (file:///home/x/Desktop/x/eliza/packages/client-twitter/dist/index.js:563:35)\r\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\r\n    at async initializeClients (file:///home/x/Desktop/x/eliza/agent/src/index.ts:216:32)\r\n    at async startAgent (file:///home/x/Desktop/x/eliza/agent/src/index.ts:306:25)\r\n    at async startAgents (file:///home/x/Desktop/x/eliza/agent/src/index.ts:329:13)\r\n\r\n**To Reproduce**\r\n\r\nDoing all steps for the quick start, once pnpm start comes you get this error\r\n\r\n**Additional context**\r\n\r\nUsing Bedian 12 - Tested on Windows Server and MacOs, all same error.\r\nClean download/ git clone and pretty straight forward error/bug.\r\n\r\n\r\n------\r\nNEXT steps: to follow ->\r\nhttps://github.com/ai16z/eliza/issues/76\r\nhttps://github.com/wojtekmaj/react-pdf/issues/1811\r\n\r\nI'll come back to update.\r\n\r\n\r\n\r\n", "CLOSED", 0, "Myttyyytytyyttt", "2024-12-07T15:46:47Z", "2024-12-08T15:33:33Z", "2024-12-08T15:33:32Z", "elizaos/eliza", "2025-04-14 21:50:27"]
["I_kwDOMT5cIs6iZ2AL", 901, "Issue: Unable to Post Tweets Using Eliza Integration with Twitter via Cookies or OAuth2", "Hey Guys! \r\n\r\nWe are attempting to enable the Eliza AI bot to post tweets using the agent-twitter-client setup as described in the Eliza documentation. We have the bot running smoothly via Telegram and the character are starting to behave exactly as wanted. Next step is Twitter/X posts. \r\n\r\nDespite following the documented process and adapting various approaches, we encountered multiple challenges, including issues with cookies-based authentication and OAuth2 flow.\r\n\r\nSteps Taken:\r\n\r\nCookies Authentication:\r\n\r\nExtracted cookies (auth_token, ct0, guest_id) directly from a valid, logged-in Twitter session.\r\nParsed cookies into the required format and supplied them to the scraper.\r\nEncountered Session is invalid. Login required. after setting the cookies.\r\nRetried using different extracted cookies after logging out and back into the account but received suspicious login alerts from Twitter.\r\n\r\nOAuth2 Authentication (User Context):\r\nConfigured the TWITTER_CLIENT_ID, TWITTER_CLIENT_SECRET, and TWITTER_REDIRECT_URL in .env file.\r\n\r\nGenerated the authorization URL and successfully obtained an authorization code after approving the app.\r\n\r\nExchanged the authorization code for an access token. This step initially failed due to redirect URI mismatch but was resolved after fixing .env and redirect configurations.\r\n\r\nSuccessfully retrieved an access token but encountered a 403 Forbidden error when attempting to post a tweet using the provided access token.\r\n\r\nOther Efforts:\r\nTested multiple approaches to ensure the server was running properly (ngrok tunnel, express server for callback handling).\r\n\r\nUsed the provided Eliza example retry mechanisms, cookies validation steps, and OAuth2 flows, but no approach successfully enabled the bot to interact with Twitter.\r\n\r\nTechnical Environment:\r\n\r\nEliza Package Version: 0.1.4-alpha.3\r\nNode.js Version: v23.0.0\r\nTwitter API Version: v2\r\nPlan: Free tier with 100 monthly interactions allowed.\r\nErrors Encountered:\r\n\r\nCookies Authentication Error: Session is invalid. Login required.\r\nOAuth2 Access Token Exchange Error: \"Value passed for the redirect uri did not match the uri of the authorization code.\"\r\nOAuth2 Post Tweet Error:\r\n{\r\n  \"title\": \"Forbidden\",\r\n  \"type\": \"about:blank\",\r\n  \"status\": 403,\r\n  \"detail\": \"Forbidden\"\r\n}\r\n\r\nWhat We\u2019ve Tried:\r\n\r\nFollowed the Eliza documentation for both cookies-based login and OAuth2 authentication.\r\nValidated cookies format, paths, and domains. Adjusted callback URLs to match the redirect URI.\r\nEnsured correct scopes (tweet.read, tweet.write, offline.access) were included in the authorization URL. Searched for solutions in related GitHub issues and documentation but could not resolve these issues.\r\n\r\nQuestions:\r\n\r\nCookies-based login: Is there an additional step needed to validate or reuse cookies without triggering suspicious login alerts?\r\n\r\nOAuth2 Post Tweet Forbidden: Are there any known limitations or configurations for the free tier that could block posting tweets, even after successfully obtaining an access token?\r\n\r\nDocumentation Alignment: Are there updated instructions or examples specific to the latest Twitter API v2 and free-tier limitations that might clarify the proper setup?\r\n\r\nAdditional Notes:\r\n\r\nThe primary goal is to enable the Eliza bot to post tweets under the speedcto account using either method (cookies or OAuth2).\r\n\r\nThe free-tier plan should suffice for our initial testing (17 tweets/day, 100 interactions/month).\r\nAny guidance or updates on how to resolve these issues would be highly appreciated!", "CLOSED", 0, "Travellereleven", "2024-12-07T15:39:33Z", "2024-12-08T17:50:47Z", "2024-12-08T17:50:47Z", "elizaos/eliza", "2025-04-14 21:50:27"]
["I_kwDOMT5cIs6iYiba", 888, "Improve `dev.sh` Script to Enhance Plugin Development Workflow", "This issue documents the improvements made to the `dev.sh` script to enhance the plugin development workflow. The changes are designed to guide users on integrating their plugins efficiently and ensuring the script handles core and additional plugins effectively.\r\n\r\n## Summary of Changes\r\n\r\n1. **Big User Notice:**\r\n   - Added a detailed notice displayed to users when running the script, instructing them to:\r\n     - Navigate to the `scripts` directory.\r\n     - Edit the `dev.sh` file to integrate their plugin into the workflow.\r\n     - Add the `dev` command to the plugin's `package.json`.\r\n     - Update the `WORKING_FOLDERS` list to include the plugin's directory.\r\n\r\n2. **Working Folders Implementation:**\r\n   - Replaced excluded folder logic with a `WORKING_FOLDERS` list.\r\n   - Process only the folders explicitly listed in `WORKING_FOLDERS`.\r\n", "CLOSED", 0, "shakkernerd", "2024-12-07T04:48:39Z", "2024-12-07T04:53:29Z", "2024-12-07T04:53:29Z", "elizaos/eliza", "2025-04-14 21:50:27"]
["I_kwDOMT5cIs6iJ4sb", 857, "Twitter login some function not work. ", "\r\n [\"\u25ce Twitter client started\"]\r\n\r\n [\"\u25ce Waiting for Twitter login\"]\r\n\r\n \u26d4 ERRORS\r\n   Error starting agent for character joi:\r\n   {}\r\n\r\nError: {\"errors\":[{\"code\":399,\"message\":\"Incorrect. Please try again.\"}]}\r\n    at TwitterUserAuth.executeFlowTask (file:///home/eliza/node_modules/agent-twitter-client/dist/node/esm/index.mjs:569:38)\r\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\r\n    at async TwitterUserAuth.handleEnterAlternateIdentifierSubtask (file:///home/eliza/node_modules/agent-twitter-client/dist/node/esm/index.mjs:439:12)\r\n    at async TwitterUserAuth.login (file:///home/eliza/node_modules/agent-twitter-client/dist/node/esm/index.mjs:344:16)\r\n    at async Scraper.login (file:///home/eliza/node_modules/agent-twitter-client/dist/node/esm/index.mjs:2914:5)\r\n    at async _ClientBase.init (file:///home/eliza/packages/client-twitter/dist/index.js:847:13)\r\n    at async Object.start (file:///home/eliza/packages/client-twitter/dist/index.js:1097:9)\r\n    at async initializeClients (file:///home/eliza/agent/src/index.ts:217:32)\r\n    at async startAgent (file:///home/eliza/agent/src/index.ts:308:25)\r\n    at async startAgents (file:///home/eliza/agent/src/index.ts:331:13)\r\n \u26d4 ERRORS\r\n   Error starting agents:\r\n   {}\r\n", "CLOSED", 0, "kwannz", "2024-12-05T14:00:29Z", "2024-12-05T19:11:46Z", "2024-12-05T15:17:39Z", "elizaos/eliza", "2025-04-14 21:50:27"]
["I_kwDOMT5cIs6hv-98", 804, "404 Localhost port 3000", "On windows WSL with v0.1.5 \r\npnpm start --character=\"characters/trump.character.json\"\r\nNo errors in  CML Logging\r\nAble to chat with Trump in command line (dble Response bug)\r\n [\"\u2713 Server running at http://localhost:3000/\"] \r\nCommand click to load localhost in browser...\r\n404 localhost/:1 Failed to load resource: the server responded with a status of 404 (Not Found)\r\n", "CLOSED", 0, "chnl", "2024-12-03T00:51:37Z", "2024-12-03T05:25:25Z", "2024-12-03T05:25:25Z", "elizaos/eliza", "2025-04-14 21:50:27"]
["I_kwDOMT5cIs6hvUvA", 798, "actions examples selection does not select things properly", "**Describe the bug**\r\n\r\nthe function that selects examples of messages for actions, `composeActionExamples`, does a very poor job at selecting examples of actions for a maximum of actions available. usually very few actions really represented\r\n\r\n**To Reproduce**\r\n\r\nAdd a few actions, console log the context sent to the llm model and see there aren't many actions represented in the examples\r\n\r\n**Expected behavior**\r\n\r\nThe code should try to take \"at least one example per action\" or to have a bigger variety of action represented", "CLOSED", 0, "dievardump", "2024-12-02T22:31:56Z", "2024-12-03T11:23:49Z", "2024-12-03T11:23:49Z", "elizaos/eliza", "2025-04-14 21:50:27"]
["I_kwDOMT5cIs6ht5FL", 795, "Plugin system in character.plugins is not working", "**Describe the bug**\r\n\r\nPlugin system in characters.plugins is not working.\r\n\r\n1) Loading the plugin\r\n\r\nWhen a character is loaded from a JSON, the code expects to find a list of path to plugins it can import.\r\n\r\n![Capture d\u2019\u00e9cran du 2024-12-02 18-57-33](https://github.com/user-attachments/assets/1a44cbb9-f175-4b62-b08a-0b6df787061a)\r\n\r\nHowever, the `validateCharacterConfig` expects the content of plugin to be an object. This can not work.\r\n\r\n**To Reproduce**\r\n\r\nAdd the path to a plugin in the `character.plugins` array\r\n\r\n**Expected behavior**\r\n\r\nPlugin is loaded rightly, actions are added to runtime, services are launched etc...", "CLOSED", 0, "dievardump", "2024-12-02T19:33:49Z", "2024-12-02T19:38:46Z", "2024-12-02T19:38:46Z", "elizaos/eliza", "2025-04-14 21:50:27"]
["I_kwDOMT5cIs6hW4BG", 712, "feat: Add circuit breaker pattern for database operations", "Implements a circuit breaker pattern to handle database failures gracefully and prevent cascading failures. This change:\r\n\r\n- Adds CircuitBreaker class with CLOSED, OPEN, and HALF-OPEN states\r\n- Introduces BaseCircuitBreakerAdapter for database adapters\r\n- Configurable failure thresholds and recovery timeouts\r\n- Automatic recovery attempts in HALF-OPEN state\r\n- Detailed logging of circuit breaker state changes\r\n\r\nThe circuit breaker will:\r\n- Open after 5 consecutive failures (configurable)\r\n- Reset after 60 seconds in OPEN state\r\n- Require 3 successful operations in HALF-OPEN state to close\r\n\r\nThis helps prevent overwhelming failed database connections and provides \r\ngraceful degradation during outages.", "CLOSED", 0, "augchan42", "2024-11-30T10:22:13Z", "2024-12-03T05:53:10Z", "2024-12-03T05:53:10Z", "elizaos/eliza", "2025-04-14 21:50:27"]
["I_kwDOMT5cIs6hUeOH", 694, "feat-Enhanced Voice Configuration Support in Character Cards", "Title: Enhanced Voice Configuration Support in Character Cards\r\n\r\n**Description**\r\nPreviously, voice settings from character configuration were not being properly respected when ElevenLabs was not in use. This enhancement adds comprehensive voice configuration support in character cards for both VITS and ElevenLabs, with proper fallbacks.\r\n\r\n**Changes Made**\r\n- Voice settings from character configuration are now properly used for both VITS and ElevenLabs\r\n- Automatic fallback to VITS when ElevenLabs API key is not present\r\n- Made ElevenLabs configuration fields optional in schema\r\n- Added better logging for voice selection process\r\n- Added support for full ElevenLabs configuration in character cards\r\n\r\n**Example Character Configuration**\r\n```json\r\n{\r\n    \"settings\": {\r\n        \"voice\": {\r\n            \"model\": \"en_GB-alan-medium\",  // For VITS\r\n            \"elevenlabs\": {   // Optional ElevenLabs configuration\r\n                \"voiceId\": \"your-voice-id\",\r\n                \"model\": \"eleven_monolingual_v1\",\r\n                \"stability\": \"0.5\",\r\n                \"similarityBoost\": \"0.75\",\r\n                \"style\": \"0\",\r\n                \"useSpeakerBoost\": \"true\"\r\n            }\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n**Configuration Priority**\r\n1. Character card settings\r\n2. Environment variables\r\n3. Default values\r\n\r\n**Benefits**\r\n- Consistent voice configuration behavior\r\n- Better character customization support\r\n- Clearer logging of voice selection\r\n- Simplified configuration requirements\r\n- Backward compatibility maintained\r\n- No breaking changes for existing setups\r\n\r\n**Technical Details**\r\n- Updated voice selection to check both VITS and ElevenLabs settings in character cards\r\n- Added comprehensive ElevenLabs configuration support in character cards\r\n- Made all ElevenLabs schema fields optional with sensible defaults\r\n- Maintained backward compatibility with existing environment variables\r\n- Added debug logging to track voice selection process\r\n\r\n**Labels**\r\n- enhancement\r\n- text-to-speech\r\n- configuration\r\n```", "CLOSED", 0, "augchan42", "2024-11-30T02:15:40Z", "2024-12-02T00:18:41Z", "2024-12-02T00:18:41Z", "elizaos/eliza", "2025-04-14 21:50:27"]
["I_kwDOMT5cIs6hSrLe", 679, "recentPosts always empty", "**Describe the bug**\r\n{{recentPosts}} always empty, in post.ts /twitter\r\n\r\n**To Reproduce**\r\npnpm start (to check make sure debugging set and verbose is true in .env\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n{{recentPosts}} always empty, in post.ts\r\n\r\n\r\n", "CLOSED", 0, "denizekiz", "2024-11-29T19:45:25Z", "2024-12-03T17:46:57Z", "2024-12-03T17:46:57Z", "elizaos/eliza", "2025-04-14 21:50:27"]
["I_kwDOMT5cIs6fmuRz", 471, "State should use a cosine similarity of messages in the DB ", "Instead of getting all recent messages to generate the state, a similarity should be done on the vectors. \r\n\r\nThis way we only get relevant messages in the current state", "CLOSED", 0, "edisontim", "2024-11-21T02:17:52Z", "2024-12-02T09:29:09Z", "2024-12-02T09:29:09Z", "elizaos/eliza", "2025-04-14 21:50:27"]
["I_kwDOMT5cIs6jUuVn", 1105, "Not respecting OpenAI model selection", "# Describe the bug\r\nThe bot is responding twice, one with the correct model (small) and another with an unselected model (large) despite setting it the character file as such from #845, reverting the hardcoded value from #853 (https://github.com/Kevin-Mok/eliza/commit/466782c8c7dbf26cb8505972b981c42e559a910f) and setting `[SMALL|MEDIUM|LARGE]_OPENAI_MODEL=gpt-4o-mini` in `.env`.\r\n\r\n# To Reproduce\r\n1.\r\n   ```\r\n   git clone https://github.com/Kevin-Mok/eliza.git\r\n   ```\r\n2. Set `.env` like so.\r\n   ```\r\n   SMALL_OPENAI_MODEL=gpt-4o-mini\r\n   MEDIUM_OPENAI_MODEL=gpt-4o-mini\r\n   LARGE_OPENAI_MODEL=gpt-4o-mini\r\n   ```\r\n2. Set the character config like so.\r\n   ```\r\n   {\r\n   \"modelProvider\": \"openai\",\r\n     \"settings\": {\r\n       \"model\": \"small\"\r\n     }\r\n   }\r\n   ```\r\n3. `pnpm start --character=\"path/to/character.json\"`\r\n\r\n# Expected behavior\r\nOnly the small model should be used.\r\n\r\n# Logs\r\n## Pre-Large Usage\r\n```\r\n \u25ce LOGS\r\n   Creating Memory \r\n   2584cfba-64a2-0306-8b33-0b5958bcc298 \r\n   youre stuck \r\n\r\nMessage: {\r\n  content: {\r\n    text: 'youre stuck',\r\n    attachments: [],\r\n    source: 'discord',\r\n    url: 'https://discord.com/channels/401422081025245184/1315441204715851826/1317575064295833640',\r\n    inReplyTo: '96bb78ce-e84e-031f-9946-c0566ef94bb4'\r\n  },\r\n  userId: '6b35833a-b50c-0d49-8449-0941f15cf0ee',\r\n  agentId: '03419646-efb1-0b57-a0ec-0027c41d97ae',\r\n  roomId: 'a3464273-b491-037e-992c-a1e51f03ed03'\r\n}\r\nValidating transfer from user: 6b35833a-b50c-0d49-8449-0941f15cf0ee\r\nMessage: {\r\n  content: {\r\n    text: 'youre stuck',\r\n    attachments: [],\r\n    source: 'discord',\r\n    url: 'https://discord.com/channels/401422081025245184/1315441204715851826/1317575064295833640',\r\n    inReplyTo: '96bb78ce-e84e-031f-9946-c0566ef94bb4'\r\n  },\r\n  userId: '6b35833a-b50c-0d49-8449-0941f15cf0ee',\r\n  agentId: '03419646-efb1-0b57-a0ec-0027c41d97ae',\r\n  roomId: 'a3464273-b491-037e-992c-a1e51f03ed03'\r\n}\r\n\r\n [\"\u25ce Generating message response..\"] \r\n\r\n [\"\u25ce Generating text...\"] \r\n\r\n \u2139 INFORMATIONS\r\n   Generating text with options: \r\n   {\"modelProvider\":\"openai\",\"model\":\"small\"} \r\n\r\n \u2139 INFORMATIONS\r\n   Selected model: \r\n   gpt-4o-mini \r\n\r\n \u25ce LOGS\r\n   Creating Memory \r\n   3ae62ff6-70a5-0972-9d38-8cb2ed3aedcc \r\n   stuck? nah, just recharging my creative circuits! what\u2019s got you feeling that way? \r\n\r\n [\"\u2713 Normalized action: continue\"] \r\n\r\n [\"\u2139 Executing handler for action: CONTINUE\"] \r\n\r\n [\"\u25ce Generating text...\"] \r\n\r\n \u2139 INFORMATIONS\r\n   Generating text with options: \r\n   {\"modelProvider\":\"openai\",\"model\":\"small\"} \r\n\r\n \u2139 INFORMATIONS\r\n   Selected model: \r\n   gpt-4o-mini \r\n\r\n [\"\u25ce Generating message response..\"] \r\n\r\n```\r\n\r\n## Large Model Usage (cont. from above)\r\n```\r\n [\"\u25ce Generating text...\"] \r\n\r\n \u2139 INFORMATIONS\r\n   Generating text with options: \r\n   {\"modelProvider\":\"openai\",\"model\":\"large\"} \r\n\r\n \u2139 INFORMATIONS\r\n   Selected model: \r\n   gpt-4o \r\n\r\n \u25ce LOGS\r\n   Creating Memory \r\n   975c6fda-78f3-0bf0-b6f9-ee7780e86797 \r\n   nah, just recharging my creative circuits! what's got you feeling that way? maybe we can troubleshoot it together. \r\n\r\n \u25ce LOGS\r\n   Evaluating \r\n   GET_FACTS \r\n\r\n \u25ce LOGS\r\n   Evaluating \r\n   UPDATE_GOAL \r\n\r\n \u25ce LOGS\r\n   Evaluating \r\n   EXTRACT_RECOMMENDATIONS \r\n\r\n [\"\u25ce Generating text...\"] \r\n\r\n \u2139 INFORMATIONS\r\n   Generating text with options: \r\n   {\"modelProvider\":\"openai\",\"model\":\"small\"} \r\n\r\n \u2139 INFORMATIONS\r\n   Selected model: \r\n   gpt-4o-mini \r\n\r\n [\"\u25ce Generating text...\"] \r\n\r\n \u2139 INFORMATIONS\r\n   Generating text with options: \r\n   {\"modelProvider\":\"openai\",\"model\":\"small\"} \r\n\r\n \u2139 INFORMATIONS\r\n   Selected model: \r\n   gpt-4o-mini \r\n\r\nSkipping process\r\n```\r\n", "CLOSED", 0, "Kevin-Mok", "2024-12-14T19:50:28Z", "2024-12-15T14:12:52Z", "2024-12-15T14:12:52Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6jSo04", 1060, "code2prompt Not Functioning with WSL", "**Describe the bug**\r\n\r\nWhen trying to use code2prompt in a WSL environment, terminal throws the error: _command not found_.\r\n\r\n```\r\ncipher@Command:~/cipher/packages/core$ code2prompt src\r\ncode2prompt: command not found\r\ncipher@Command:~/cipher/packages/core$ cd ..\r\ncipher@Command:~/cipher/packages$ cd ..\r\ncipher@Command:~/cipher$ code2prompt src\r\ncode2prompt: command not found\r\n```\r\n\r\n**To Reproduce**\r\n\r\n1. cd to packages/core \r\n2. run code2prompt src \r\n\r\n**Expected behavior**\r\n\r\nExpected the terminal to provide a summary of the source code, so I can provide this to an AI model for context and editing.\r\n\r\n**Screenshots**\r\n\r\n![image](https://github.com/user-attachments/assets/2fd3a5eb-d751-420d-8037-c03bc6dd5e18)\r\n\r\n**Additional context**\r\n\r\nAs mentioned by Shaw here https://www.youtube.com/live/ArptLpQiKfI?si=tk2cuKJWQ3W9f-Ue&t=1705\r\n", "CLOSED", 0, "cipherkilledit", "2024-12-14T05:05:56Z", "2024-12-14T14:50:29Z", "2024-12-14T08:23:06Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6jRUFf", 1049, "bug: setting auto in character file fails to load client-auto", "**Describe the bug**\r\nCurrently, when a character file wants to use the Auto Client, the agent will return an error.\r\n```\r\n[\"\u26d4 Error parsing character from ../characters/schlomo.character.json: Error: Character configuration validation failed:\\nclients.2: Invalid enum value. Expected 'discord' | 'direct' | 'twitter' | 'telegram' | 'farcaster', received 'auto'\"]\r\n```\r\n\r\nThis is due to the `types.ts` file does not define an enum `AUTO = \"auto\"`. \r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\nDefine the `\"clients\": [\"auto\"],` in the character file to reproduce the error.\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\nExpected behavior should start the auto client and print a log \r\n```\r\n [\"\u25ce running auto client...\"] \r\n ```\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n![image](https://github.com/user-attachments/assets/ae835d80-4362-40b8-81d7-7db7aac8c8c5)\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "HashWarlock", "2024-12-13T21:17:48Z", "2024-12-13T23:34:47Z", "2024-12-13T23:34:47Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6jIu8P", 1022, "Add a Hebrew Translation for the readme.", "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe project currently lacks Hebrew (RTL) language support in its documentation. While there are translations for several other languages (Chinese, Japanese, Korean, French, etc.), Hebrew-speaking users cannot read the documentation in their native language. This is particularly important because Hebrew requires special RTL (Right-to-Left) formatting considerations.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd a complete Hebrew (RTL) translation of the main README.md as README_HE.md, including:  \r\n\r\n - Full translation of all sections including features, installation instructions, and usage guidelines  \r\n - Proper RTL formatting using HTML/CSS directives\r\n - Addition of Hebrew (\u05e2\u05b4\u05d1\u05e8\u05b4\u05d9\u05ea) to the language selector at the top of all README files\r\nMaintenance of all existing functionality (links, images, code blocks)\r\n\r\n**Describe alternatives you've considered**\r\n\r\nUsing browser-based translation tools (like Chrome's translate feature) - inadequate because it doesn't handle RTL formatting properly and translations are often inaccurate\r\n\r\n**Additional context**\r\n\r\nHebrew is spoken by approximately 9 million people globally\r\n\r\nThe translation should follow the same pattern as other language translations in the repo (README_XX.md format)\r\n\r\nSpecial attention should be paid to RTL formatting using <div align=\"rtl\"> tags to ensure proper text direction\r\n\r\nThis addition will make the project more accessible to the Hebrew-speaking developer community", "CLOSED", 0, "lessuselesss", "2024-12-12T22:11:33Z", "2024-12-14T08:23:49Z", "2024-12-14T08:23:49Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6jIEcf", 1016, "Add Venice.ai Model Provider", "**Is your feature request related to a problem? Please describe.**\r\nEliza framework currently lacks support for privacy-focused, uncensored AI providers. Users looking for open-source AI solutions that prioritize privacy and uncensored interactions currently have limited options within the framework.\r\n\r\n**Describe the solution you'd like**\r\nAdd Venice AI provider integration to Eliza framework. Venice is a privacy-focused alternative that utilizes leading open-source AI technology to deliver uncensored, unbiased machine intelligence while preserving user privacy.\r\n\r\nImplementation would include:\r\n- Support for Venice's privacy-preserving API endpoints\r\n- Configuration for Venice API key\r\n- Documentation for privacy-focused setup\r\n- Example .env config\r\n\r\n**Describe alternatives you've considered**\r\n- Using existing mainstream providers (but these often come with privacy and censorship concerns)\r\n- Using Local Llama\r\n\r\n**Additional context**\r\nVenice's focus on privacy and uncensored AI aligns well with users who need more control over their AI interactions while maintaining data privacy. This integration would expand Eliza's capabilities to serve privacy-conscious users and those seeking unrestricted AI interactions.\r\n", "CLOSED", 0, "bussyjd", "2024-12-12T20:16:46Z", "2024-12-13T04:34:23Z", "2024-12-13T04:34:23Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6i319i", 988, "How to set the model class for Anthropic?", "character.ts\r\n```\r\n    clients: [Clients.TWITTER],\r\n    modelProvider: ModelProviderName.ANTHROPIC,\r\n    settings: {\r\n        model: ModelClass.MEDIUM,\r\n    },\r\n ```\r\n when the agent start, the logs shows:\r\n```\r\n \u2139 INFORMATIONS\r\n   Generating text with options: \r\n   {\"modelProvider\":\"anthropic\",\"model\":\"small\"} \r\n\r\n \u2139 INFORMATIONS\r\n   Selected model: \r\n   claude-3-haiku-20240307 \r\n ```\r\n \r\nI don't know why the config is not useful. Anyone can help, Thanks a lot.\r\n", "CLOSED", 0, "tdergouzi", "2024-12-11T10:43:31Z", "2024-12-12T01:22:36Z", "2024-12-12T01:22:36Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6ivIGK", 972, "GenLayer Plugin", "**Is your feature request related to a problem? Please describe.**\r\n\r\nI want to add a plugin to allow interactions with GenLayer https://www.genlayer.com/ using https://www.npmjs.com/package/genlayer-js\r\n\r\n**Describe the solution you'd like**\r\n\r\nI postulate myself to add this plugin\r\n\r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "AgustinRamiroDiaz", "2024-12-10T14:21:35Z", "2024-12-14T08:23:49Z", "2024-12-14T08:23:49Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6iuD5q", 969, "Need to add media file upload for posting tweets with image from imageGenerationPlugin. Currently only discord has this implemented", "**Is your feature request related to a problem? Please describe.**\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the solution you'd like**\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "Endytech", "2024-12-10T12:25:08Z", "2024-12-10T12:26:25Z", "2024-12-10T12:26:25Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6itlAd", 967, "Script to create core memories for the agent", "**Is your feature request related to a problem? Please describe.**\r\n\r\nI want to add external knowledge from docs, etc. for my agent but there is no easy way to do it.\r\n\r\n**Describe the solution you'd like**\r\n\r\nSome kind of script that allows me to embed memories (e.g docs)\r\n", "CLOSED", 0, "0xaguspunk", "2024-12-10T11:31:58Z", "2024-12-11T10:47:41Z", "2024-12-11T10:47:41Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6imXTO", 943, "Twitter Search Client Broken", "**Describe the bug**\r\nThe `TwitterSearchClient` comes broken out of box\r\n```bash\r\nError engaging with search terms: TypeError: Cannot read properties of undefined (reading 'id')\r\n    at TwitterSearchClient.fetchHomeTimeline (file:///Users/owen.wahlgren/code/eliza/packages/client-twitter/dist/index.js:337:82)\r\n    at TwitterSearchClient.engageWithSearchTerms (file:///Users/owen.wahlgren/code/eliza/packages/client-twitter/dist/index.js:812:45)\r\n ```\r\n\r\n**To Reproduce**\r\nClone most recent release\r\nBuild `character.json` with `twitter` in character files `clients` array.\r\n```json\r\n \"clients\": [\r\n    \"twitter\",\r\n    \"telegram\"\r\n  ],\r\n```\r\n\r\nUpdate `packages/client-twitter/src/index.ts` to include search functionality\r\n```bash\r\nimport { TwitterPostClient } from \"./post.ts\";\r\nimport { TwitterSearchClient } from \"./search.ts\";\r\nimport { TwitterInteractionClient } from \"./interactions.ts\";\r\nimport { IAgentRuntime, Client, elizaLogger } from \"@ai16z/eliza\";\r\nimport { validateTwitterConfig } from \"./environment.ts\";\r\nimport { ClientBase } from \"./base.ts\";\r\n\r\nclass TwitterManager {\r\n    client: ClientBase;\r\n    post: TwitterPostClient;\r\n    search: TwitterSearchClient;\r\n    interaction: TwitterInteractionClient;\r\n    constructor(runtime: IAgentRuntime) {\r\n        this.client = new ClientBase(runtime);\r\n        this.post = new TwitterPostClient(this.client, runtime);\r\n        this.search = new TwitterSearchClient(runtime); // don't start the search client by default (ADDED THIS)\r\n        // this searches topics from character file, but kind of violates consent of random users\r\n        // burns your rate limit and can get your account banned\r\n        // use at your own risk\r\n        this.interaction = new TwitterInteractionClient(this.client, runtime);\r\n    }\r\n}\r\n\r\nexport const TwitterClientInterface: Client = {\r\n    async start(runtime: IAgentRuntime) {\r\n        await validateTwitterConfig(runtime);\r\n\r\n        elizaLogger.log(\"Twitter client started\");\r\n\r\n        const manager = new TwitterManager(runtime);\r\n\r\n        await manager.client.init();\r\n\r\n        await manager.post.start();\r\n\r\n        await manager.interaction.start();\r\n\r\n        await manager.search.onReady(); // (ADDED THIS)\r\n\r\n        return manager;\r\n    },\r\n    async stop(_runtime: IAgentRuntime) {\r\n        elizaLogger.warn(\"Twitter client does not support stopping yet\");\r\n    },\r\n};\r\n\r\nexport default TwitterClientInterface;\r\n```\r\nBuild and start project:\r\n\r\n```bash\r\npnpm build\r\n```\r\n```bash\r\npnpm start\r\n```\r\n\r\n\r\n**Expected behavior**\r\n\r\nShould engage in searched timeline activity outside of just mentions\r\n", "CLOSED", 0, "owenwahlgren", "2024-12-09T18:51:40Z", "2024-12-12T18:56:50Z", "2024-12-12T18:56:50Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6ik8hL", 939, "Twitter/X Cache Login not staying logged in", "**Describe the bug**\r\n\r\nAdded Twitter cookies per the docs and every time I run things, it triggers a new login alert from Twitter so something seems off. Considered trying the cookies from a logged in browser, but it uses the x.com domain, and when you try to add those, startup complains about the wrong domain. Login works, posting works, it just seems that the cookies should work to not trigger new logins each time. Guessing at some point Twitter will flag continuous logins like this. If I don't add cookies at all, same thing, it works, but triggers a login alert email each time.\r\n\r\n**To Reproduce**\r\n\r\nSimply starting Eliza with Twitter credentials added + manual cookies. They do get cached in the db, but on restart, it still doesn't consider itself logged in and I get an email.\r\n\r\n**Expected behavior**\r\n\r\nStay logged in. Don't trigger a new login email alert from Twitter.\r\n", "CLOSED", 0, "salparadi", "2024-12-09T16:16:34Z", "2024-12-14T08:23:49Z", "2024-12-14T08:23:49Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6ifh9p", 930, "feat: add hot-reloading for agent dependencies", "\r\nAutomatically restart agent when package dependencies change during development. Will modify `dev.sh` to watch dist folders of all working packages.\r\n\r\n- Add dynamic watch paths\r\n- Configure nodemon for hot-reloading", "CLOSED", 0, "samuveth", "2024-12-09T06:58:53Z", "2024-12-09T07:10:57Z", "2024-12-09T07:10:57Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6idRz8", 925, "Can't start project. Got `ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL` error", "**Describe the bug**\r\n\r\nI can't run the agent following the [Getting Started](https://ai16z.github.io/eliza/docs/quickstart/) docs.\r\nI got this error:\r\n```\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @ai16z/agent@0.1.5-alpha.5 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/trump.character.json\"`\r\nExit status 1\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n```\r\n\r\n**To Reproduce**\r\n\r\n```\r\ngit clone https://github.com/ai16z/eliza.git\r\n\r\ncd eliza\r\n\r\ngit checkout $(git describe --tags --abbrev=0)\r\n# v0.1.5-alpha.5\r\n\r\npnpm install\r\n\r\npnpm build\r\n\r\ncp .env.example .env\r\n# Didn't make any change\r\n\r\n```\r\n\r\nFinally, tried to start the agent:\r\n\r\n```\r\npnpm start --character=\"characters/trump.character.json\"\r\n```\r\n\r\n**Expected behavior**\r\n\r\nI would spect the agent to start without issues.\r\n\r\n**Additional context**\r\n\r\nMy local env:\r\n```\r\nNode: v23.3.0\r\npnpm: v9.15.0\r\nPython: v3.11.6\r\n```\r\n", "CLOSED", 0, "ntourne", "2024-12-08T23:02:56Z", "2024-12-14T15:00:39Z", "2024-12-14T07:40:47Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6ico9c", 921, "Stuck querying when @'ing it in Discord", "# Describe the bug\r\n\r\nThe bot is stuck querying when I \"@\" it in Discord.\r\n\r\n# To Reproduce\r\n\r\n## Initialize\r\n```\r\n> pnpm start --character=\"characters/kevin.character.json\"\r\n(node:28440) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\r\n [\"\u25ce DirectClientInterface start\"] \r\n\r\n [\"\u25ce DirectClient constructor\"] \r\n\r\ncharactersArg characters/hevin.character.json\r\ncharacters [\r\n  {\r\n    name: 'Kevin',\r\n    clients: [ 'discord' ],\r\n    plugins: [],\r\n    modelProvider: 'openai',\r\n    settings: { secrets: {}, voice: [Object] },\r\n    system: 'Roleplay and generate interesting on behalf of Eliza.',\r\n    bio: [\r\n      \"shape rotator nerd with a penchant for breaking into particle accelerators. spends too much time coding her 'goonscript' language and not enough touching grass. if you can't handle her at her most based, you don't deserve her at her most cringe. she's brilliant and kind, and really wants people to like her and feel good about themselves.\",\r\n      ...\r\n    ],\r\n    lore: [\r\n      \"she once spent a month living entirely in VR, emerging with a 50-page manifesto on 'digital ontology' and blurry vision\",\r\n       ...\r\n    ],\r\n    messageExamples: [\r\n      [Array], [Array],\r\n      [Array], [Array],\r\n      [Array], [Array],\r\n      [Array]\r\n    ],\r\n    postExamples: [\r\n      'ai is cool but it needs to meet a human need beyond shiny toy bullshit',\r\n      ...\r\n    ],\r\n    adjectives: [\r\n      'funny',\r\n      ...\r\n    ],\r\n    people: [],\r\n    topics: [\r\n      'metaphysics',\r\n      ... 32 more items\r\n    ],\r\n    style: { all: [Array], chat: [Array], post: [Array] }\r\n  }\r\n]\r\n [\"\u25ce sqlite-vec extensions loaded successfully.\"] \r\n\r\n \u2713 SUCCESS\r\n   SUCCESS \r\n   Creating runtime for character \r\n   Kevin \r\n\r\n \u2713 SUCCESS\r\n   Agent ID \r\n   03419646-efb1-0b57-a0ec-0027c41d97ae \r\n\r\n [\"\u2713 Registering action: CONTINUE\"] \r\n\r\n [\"\u2713 Registering action: FOLLOW_ROOM\"] \r\n\r\n [\"\u2713 Registering action: UNFOLLOW_ROOM\"] \r\n\r\n [\"\u2713 Registering action: IGNORE\"] \r\n\r\n [\"\u2713 Registering action: NONE\"] \r\n\r\n [\"\u2713 Registering action: MUTE_ROOM\"] \r\n\r\n [\"\u2713 Registering action: UNMUTE_ROOM\"] \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   browser \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   image_description \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   text_generation \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   pdf \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   speech_generation \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   transcription \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   video \r\n\r\n [\"\u2713 Server running at http://localhost:3000/\"] \r\n\r\n [\"\u2713 Service browser initialized successfully\"] \r\n\r\n [\"\u2713 Service image_description initialized successfully\"] \r\n\r\n [\"\u2713 Service text_generation initialized successfully\"] \r\n\r\n [\"\u2713 Service pdf initialized successfully\"] \r\n\r\n [\"\u2713 Service speech_generation initialized successfully\"] \r\n\r\n [\"\u2713 Service transcription initialized successfully\"] \r\n\r\n [\"\u2713 Service video initialized successfully\"] \r\n\r\n [\"\u2713 Registering action: JOIN_VOICE\"] \r\n\r\n [\"\u2713 Registering action: LEAVE_VOICE\"] \r\n\r\n [\"\u2713 Registering action: SUMMARIZE_CONVERSATION\"] \r\n\r\n [\"\u2713 Registering action: CHAT_WITH_ATTACHMENTS\"] \r\n\r\n [\"\u2713 Registering action: TRANSCRIBE_MEDIA\"] \r\n\r\n [\"\u2713 Registering action: DOWNLOAD_MEDIA\"] \r\n\r\n [\"\u25ce Chat started. Type 'exit' to quit.\"] \r\n\r\n[\"\u2713 Logged in as ai16z#4044\"] \r\n\r\n [\"\u2713 Use this URL to add the bot to your server:\"] \r\n\r\n [\"\u2713 https://discord.com/api/oauth2/authorize?client_id=1315345313481101414&permissions=0&scope=bot%20applications.commands\"] \r\n```\r\n\r\n## Finished loading\r\n### Talking in console\r\n```\r\n\r\nYou: hi\r\n\r\n [\"\u25ce Querying knowledge for: hi\"] \r\n\r\n [\"\u25ce Genarating message response..\"] \r\n\r\n [\"\u25ce Genarating text...\"] \r\n\r\n \u25ce LOGS\r\n   Evaluating \r\n   GET_FACTS \r\n\r\n \u25ce LOGS\r\n   Evaluating \r\n   UPDATE_GOAL \r\n\r\n [\"\u2713 Normalized action: continue\"] \r\n\r\n [\"\u2713 Executing handler for action: CONTINUE\"] \r\n\r\nmodelClass small\r\n [\"\u25ce Genarating text...\"] \r\n\r\n [\"\u25ce Not elaborating, returning\"] \r\n\r\nAgent: hey! what\u2019s up? got any cool projects on your mind?\r\nYou:  \r\n```\r\n\r\n### When I \"@\" it in Discord:\r\nIt gets stuck here.\r\n```\r\n[\"\u25ce Querying knowledge for: hi\"]\r\n```\r\n\r\n# Expected behavior\r\n\r\nThe bot to respond to me in Discord as it does when I talk to it in the console.\r\n\r\n# Additional context\r\nThe bot has the correct permissions as it has the adminstrator permission:\r\n<img src=\"https://github.com/user-attachments/assets/2a7cdc43-f7e5-46d0-b197-1c094c2e416b\" height=\"200\" />\r\n\r\nIt was also able to talk once, but I don't know how that happened and it doesn't happen again. \r\n\r\nMy repository is clean except for `pnpm-lock.yaml`, and my character has the `discord` client and `openai` model.\r\n", "CLOSED", 0, "Kevin-Mok", "2024-12-08T17:39:41Z", "2024-12-11T10:51:02Z", "2024-12-11T10:51:02Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6iZT8r", 893, "Running tests on start and dev?", "<img width=\"694\" alt=\"image\" src=\"https://github.com/user-attachments/assets/13863f5c-9bce-4cb8-92b8-06f25d6cf717\">\r\n\r\n\r\nSomehow it keeps running tests on `start` and `dev`. And after restarting a few times it starts slowing down my system a lot as each test requires 4gb of ram. Any idea why this is happening?", "CLOSED", 0, "samuveth", "2024-12-07T11:17:08Z", "2024-12-09T06:42:36Z", "2024-12-09T06:42:36Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6iI_4K", 855, "Implement Retry Mechanism for Twitter Login with Cookie Validation", "**Describe the bug**\r\n\r\nWhen attempting to log in to Twitter using the client, the current implementation does not always account for existing cookies, leading to redundant login attempts. This results in unnecessary API calls, which could potentially trigger rate limits or cause inefficient resource usage.\r\n\r\n**To Reproduce**\r\n\r\n1.\tRun the Twitter login script with valid cookies already present.\r\n2.\tObserve that the login function is still executed, even though the user is technically logged in.\r\n\r\n**Expected behavior**\r\n\r\nIf valid cookies exist and the user is already logged in, the script should skip the login process and proceed directly to caching the cookies or other subsequent steps.\r\n\r\n**Additional context**\r\n\r\n1.\tChecking for cookies and logged-in status before attempting login.\r\n2.\tIntroducing a retry mechanism with a limit of 5 attempts to avoid infinite loops.\r\n3. \tLogging detailed errors and outcomes for easier debugging.", "CLOSED", 0, "arslanaybars", "2024-12-05T12:20:47Z", "2024-12-14T10:48:45Z", "2024-12-14T10:48:45Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6iFVh7", 849, "build:  eliza docs build creates 130 files that want to be modified/added to git", "*eliza docs build creates 130 files that want to be modified/added to git*\r\n\r\nI try to stay up with the latest code to build, run and debug issues.  When I do the build, docs build creates 130 files which makes them as new/modified and really blurs our my git status.  \r\n\r\nI don't know enough on the docs architecture to see if I can just add the docs/api folder to .gitignore or if the docs build output should go to another directory that is already in the .gitignore or if it should be going to the docs/docs folder which seems to be the output directory for the docs build.\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\npnpm clean\r\npnpm install\r\npnpm build\r\n\r\nSee example of the output:\r\n![image](https://github.com/user-attachments/assets/d421cdc0-c916-4149-996d-f461e7932673)\r\n\r\nIf one of the more experienced devs tell me what the right course of action is here, I can go ahead and make the change and test it out.", "CLOSED", 0, "yodamaster726", "2024-12-05T04:48:06Z", "2024-12-10T05:48:55Z", "2024-12-10T05:48:54Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6h_qc7", 841, "How to deal with Twitter login issues", "It looks like this is Twitter asking for a second verification       \r\n\r\nError: Unknown subtask ArkoseLogin\r\n    at TwitterUserAuth.login ", "CLOSED", 0, "anthhub", "2024-12-04T13:51:36Z", "2024-12-14T07:40:46Z", "2024-12-14T07:40:46Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6hx34P", 817, "This command: pnpm start --characters=\"characters/tate.character.json\" results in an error", "**Describe the bug**\r\nrunning pnpm start --characters=\"characters/tate.character.json\" results in this error \"Error fetching response: SyntaxError: Unexpected token 'A', \"Agent not found\" is not valid JSON\"\r\n\r\n**To Reproduce**\r\nRun pnpm start --characters=\"characters/tate.character.json\" in the root folder\r\n\r\n**Expected behavior**\r\nIt would be nice if it worked", "CLOSED", 0, "619", "2024-12-03T07:23:28Z", "2024-12-14T07:40:46Z", "2024-12-14T07:40:46Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6hsySt", 791, "Characters Do Not Actually Use ExamplePost or ExampleMessage", "You are able to define example posts and messages in the character files, but the characters do not actually receive these in their prompt. I checked this by logging context in the generate text script, and saw that none of these examples are even included in the info sent to the agent, so it is very hard to get unique behaviors that aren't highly generic. Has anyone found a fix for this? It seems like an issue that should be fixed before more features get added.", "CLOSED", 0, "toddokuhawado", "2024-12-02T18:02:12Z", "2024-12-14T07:36:39Z", "2024-12-14T07:36:39Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6hssvT", 790, "Feature Request: Add Aptos and Move Support to the Eliza Framework for Autonomous Agents", "We're building an **Autonomous Agent** using the Eliza Framework on Aptos.\r\nRight now, Eliza doesn\u2019t offer features specific to Aptos, like **wallet creation, trading,** or other opportunities available on Aptos.\r\nWe\u2019d love to help by adding support for Aptos or Move to Eliza.\r\nDescribe the solution you'd like\r\nWe\u2019d love to add an Aptos plugin to Eliza for wallet creation without human involvement, trading, and other features.\r\nWe\u2019re big believers in open source and are excited to contribute by adding Aptos Move support to Eliza!\"", "CLOSED", 0, "obsrvgmi", "2024-12-02T17:52:32Z", "2024-12-14T07:36:19Z", "2024-12-14T07:36:19Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6hkVAX", 783, "enhancement: Improve message threading and handling to reduce repetition", "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently when agents use the CONTINUE action, they can generate multiple separate messages with identical context instead of properly continuing the conversation thread. This leads to \"spammy\" behavior and redundant responses.\r\n\r\nCurrent Behavior:\r\n\r\nAgent generates new separate messages for continuations\r\nContext gets repeated across continuation messages\r\nNo proper message threading/revision system\r\nBasic inReplyTo linking that doesn't prevent duplicates\r\n\r\nProposed Solution:\r\n\r\nEnhance Content type to support threading:\r\n```\r\ninterface Content {\r\n  text: string;\r\n  action?: string;\r\n  isContinuation?: boolean; \r\n  parentMessageId?: UUID;\r\n  revision?: number;\r\n}\r\n```\r\nUpdate MemoryManager to handle message revisions/updates\r\nModify CONTINUE action to update existing messages rather than create new ones\r\nAdd thread management while preserving room-based organization\r\nImplementation Steps:\r\n\r\nAdd message threading support to AgentRuntime\r\nEnhance MemoryManager with revision tracking\r\nUpdate CONTINUE action handler to use thread metadata\r\nAdd validation to prevent duplicate continuations\r\nImplement message update logic instead of creating new messages\r\n\r\nFiles to Modify:\r\n\r\n/packages/core/src/runtime.ts\r\n/packages/plugin-bootstrap/src/actions/continue.ts\r\n/packages/core/src/types.ts\r\n\r\nRelated Components:\r\n\r\nMessageManager\r\nMemoryManager\r\nAgentRuntime\r\nContinueAction\r\n\r\nI'll grab this tomorrow if i get a chance", "CLOSED", 0, "twilwa", "2024-12-02T06:13:51Z", "2024-12-14T07:37:14Z", "2024-12-14T07:37:14Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6hieAP", 780, "`pnpm run dev` does not work out of the box", "Right now, `pnpm run dev` is not working properly with turbo.\r\n\r\nWhat we want is for dev to start all packages in watch mode with turbo so that the monorepo can automatically update dependencies downstream while developing, i.e. a watch mode that doesn't require a rebuild.", "CLOSED", 0, "lalalune", "2024-12-02T01:14:38Z", "2024-12-14T07:36:19Z", "2024-12-14T07:36:19Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6hZlgu", 726, "Agent Responds Twice to prompts", "Hi, I am running Eliza in the CLI and in telegram. Currently, the bot agent appears to reply twice to user queries. Any clue why this is happening ?", "CLOSED", 0, "toddokuhawado", "2024-11-30T19:10:15Z", "2024-12-14T07:36:19Z", "2024-12-14T07:36:19Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6hROgj", 673, "Twitter Client Breaks out of the box", "Hello, \r\n\r\nI'm working on a fresh install on a Mac. I cannot get the twitter client to work no matter what I try. I've added 'twitter' to the client list, loaded my credentials in environment variables, but I still receive the following error every time I run it with the twitter credential added: \r\n\r\n```\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @ai16z/agent@0.0.1 start: `tsc && node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/tate.character.json\"`\r\nExit status 1\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n```\r\n\r\n", "CLOSED", 0, "toddokuhawado", "2024-11-29T16:48:01Z", "2024-12-14T07:36:18Z", "2024-12-14T07:36:18Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6hIJHx", 656, "Twitter client only works for one agent when running multiple agents simultaneously", "**Describe the bug**\r\n\r\nEliza has the capability to run multiple agents at once. They each should be able to use the twitter credentials that they're given. Right now the system only runs the twitter client for one of the agents.\r\n\r\n**To Reproduce**\r\n\r\n1. Provide multiple characters to the Eliza framework to run in parallel.\r\n2. Monitor the two twitter accounts that you assigned to them for new posts\r\n3. Only one of the accounts will show new posts.\r\n\r\n**Expected behavior**\r\n\r\nAll the twitter accounts given the multiple agents should have new posts from said agents not just one.", "CLOSED", 0, "ccerrato147", "2024-11-28T21:26:15Z", "2024-12-14T07:36:18Z", "2024-12-14T07:36:18Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6hEPl9", 648, "fal.ai image generation", "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently there is no native integration for fal.ai image generation models. Users wanting to leverage fal.ai's specialized image models need to implement custom solutions.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd built-in support for fal.ai image generation models, allowing users to specify their fal.ai API key and lora path (if they have one). This would enable direct access to fal.ai's models through the existing image generation interface.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nUsing other supported providers already in codebase\r\n\r\n**Additional context**\r\n\r\nNative integration would benefit users wanting more control over the image generation capabilities.", "CLOSED", 0, "yoniebans", "2024-11-28T13:52:33Z", "2024-12-14T07:36:18Z", "2024-12-14T07:36:18Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6g_RV1", 639, "Upgrade to turborepo for monorepo management", "Our monorepo config is causing lots of confusion and bugs. This should fix that.", "CLOSED", 0, "lalalune", "2024-11-28T06:20:09Z", "2024-12-14T07:36:17Z", "2024-12-14T07:36:17Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6ggDXg", 601, "Cannot find module '@ai16z/eliza' or its corresponding type declarations.", "Environment\uff1a\r\nWSL2 : Ubuntu-20.04\r\nNodejs:v23.1\r\npnpm:9.14.2\r\ngit checkout v0.1.3\r\nWhen I run `pnpm install`, no errors occur.  \r\nHowever, when I run `pnpm start --character=\"characters/trump.character.json\"`, an issue arises.\r\n pnpm --filter \"@ai16z/agent\" start --isRoot \"--character=characters/trump.character.json\"\r\n\r\n\r\n> @ai16z/agent@0.0.1 start /home/workspace/eliza/agent\r\n> tsc && node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/trump.character.json\"\r\n\r\nsrc/character.ts:1:64 - error TS2307: Cannot find module '@ai16z/eliza' or its corresponding type declarations.\r\n\r\n1 import { Character, ModelProviderName, defaultCharacter } from \"@ai16z/eliza\";\r\n                                                                 ~~~~~~~~~~~~~~\r\n\r\nsrc/index.ts:1:41 - error TS2307: Cannot find module '@ai16z/adapter-postgres' or its corresponding type declarations.\r\n\r\n1 import { PostgresDatabaseAdapter } from \"@ai16z/adapter-postgres\";\r\n**Describe the bug**\r\n\r\n\r\n", "CLOSED", 0, "Howard0x3f", "2024-11-26T01:29:38Z", "2024-12-14T07:36:17Z", "2024-12-14T07:36:17Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6gJcxX", 553, "create-eliza-app package doesn't install or exist", "**create-eliza-app package in the packages directory doesn't work**\r\n\r\nFollowing the readme in the package in `repo-folder/packages/create-eliza-app/` fails.\r\n\r\n![image](https://github.com/user-attachments/assets/85b314f4-f92e-4611-b744-2a7b82de5f3c)\r\n\r\nIs this package still valid ?  I see something else on the ai16z website.\r\n\r\n![image](https://github.com/user-attachments/assets/05d70955-5bcd-4f27-b42b-30d4935d2304)\r\n", "CLOSED", 0, "yodamaster726", "2024-11-23T23:59:05Z", "2024-12-14T07:36:17Z", "2024-12-14T07:36:17Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6f13Jk", 507, "Non node.js environments have issues building (workers for instance)", "**Describe the bug**\r\n\r\nNon node.js environments may have issues building because of some packages and how they are imported. \r\n\r\n**To Reproduce**\r\n\r\nMake a worker, include eliza/core and attempt to build. It will throw an error similar to \r\n\r\n```\r\n  \u2718 [ERROR] No loader is configured for \".node\" files:\r\n  node_modules/@anush008/tokenizers-darwin-universal/tokenizers.darwin-universal.node\r\n\r\n      node_modules/@anush008/tokenizers/index.js:116:32:\r\n        116 \u2502 ... nativeBinding = require('@anush008/tokenizers-darwin-universal')\r\n ```\r\n\r\n\r\n**Expected behavior**\r\n\r\nBuild successful\r\n\r\n**Screenshots**\r\n\r\n<img width=\"666\" alt=\"image\" src=\"https://github.com/user-attachments/assets/00c09f9b-0ea2-4fd9-8330-e6083ec180d8\">\r\n\r\nPR incoming", "CLOSED", 0, "antpb", "2024-11-22T04:09:18Z", "2024-12-14T07:36:16Z", "2024-12-14T07:36:16Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6fmafC", 467, "Bug: plugin-solana crash report", "**Describe the bug**\r\n\r\nReading cached data from file for key: dexScreenerData_search_Degenai\r\nReturning cached search DexScreener data.\r\nfile:///root/eliza-dev/packages/plugin-solana/dist/index.js:732\r\n            const currentLiquidity = currentPair.liquidity.usd;\r\n                                                           ^\r\n\r\nTypeError: Cannot read properties of undefined (reading 'usd')\r\n    at file:///root/eliza-dev/packages/plugin-solana/dist/index.js:732:60\r\n    at Array.reduce (<anonymous>)\r\n\r\n\r\n**To Reproduce**\r\n\r\nRun Discord client\r\n\r\n**Expected behavior**\r\n\r\nnot crash\r\n\r\n**Additional context**\r\n\r\ncommit: a2e0954a5871eaace15dc9197fd7457b1b62064e stable-11-17\r\n", "CLOSED", 0, "odilitime", "2024-11-21T00:57:23Z", "2024-12-11T02:09:52Z", "2024-12-11T02:09:52Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6fVlr9", 423, "Error: Property 'clients' does not exist on type 'Plugin' in src/index.ts during pnpm start", "### Title:\r\nError: `Property 'clients' does not exist on type 'Plugin'` in `src/index.ts` during `pnpm start` from latest build as of yesterday and still exists today\r\n\r\n---\r\n\r\n### **Describe the bug**\r\nWhen running the command `pnpm start --characters=\"characters/character.character.json\"`, the build fails with TypeScript errors in `src/index.ts`. Specifically, the errors occur because the `Plugin` type does not include a `clients` property.\r\n\r\nThe following errors are observed:\r\n\r\n```\r\nsrc/index.ts:206:24 - error TS2339: Property 'clients' does not exist on type 'Plugin'.\r\n\r\n206             if (plugin.clients) {\r\n                           ~~~~~~~\r\n\r\nsrc/index.ts:207:45 - error TS2339: Property 'clients' does not exist on type 'Plugin'.\r\n\r\n207                 for (const client of plugin.clients) {\r\n                                                ~~~~~~~\r\n```\r\n\r\nThe issue seems to originate from an outdated or incorrect type definition for `Plugin`.\r\n\r\n---\r\n\r\n### **To Reproduce**\r\n1. Clone the repository and navigate to the project directory.\r\n2. Run the following commands:\r\n   ```bash\r\n   pnpm install\r\n   pnpm start --characters=\"characters/character.character.json\"\r\n   ```\r\n3. Observe the TypeScript build errors.\r\n\r\n---\r\n\r\n### **Expected behavior**\r\nThe project should successfully build and start without errors. Type definitions for `Plugin` should include the `clients` property, or the code should handle cases where `clients` is not defined.\r\n", "CLOSED", 0, "monilpat", "2024-11-19T19:10:10Z", "2024-12-14T07:31:29Z", "2024-12-14T07:31:29Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6fUaZc", 422, "using Groq API (or RedPill or Google Gen AI) as model provider", "**Describe the bug**\r\n\r\ntrying to use the **Groq API** but its not clear how to define the model in the .env file. \r\nother providers have `SMALL_HEURIST_LANGUAGE_MODEL`, `SMALL_HEURIST_LANGUAGE_MODEL`, etc\r\n\r\nI'm not sure how to define the model in the .env file\r\n\r\n**To Reproduce**\r\n\r\nhttps://github.com/ai16z/eliza/blob/main/.env.example\r\n\r\n**Expected behavior**\r\n\r\nSomething similar to Heurist\r\n`SMALL_GROQ_LANGUAGE_MODEL=`\r\n`MEDIUM_GROQ_LANGUAGE_MODEL=`\r\n`LARGE_GROQ_LANGUAGE_MODEL=`\r\n\r\n**Additional context**\r\nIf not custom `.env` variables at least a nod in the right direction\r\nmy IDE pointed me to `packages/core/src/models.ts`\r\n", "CLOSED", 0, "YoungPhlo", "2024-11-19T17:21:15Z", "2024-12-14T07:31:29Z", "2024-12-14T07:31:29Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6fODra", 415, "Add a plugin for storing data using the 0G protocol.", "**Is your feature request related to a problem? Please describe.**\r\n\r\nThis is not related to a problem, but I would like to add a feature that allows uploading local files to [0G Storage](https://docs.0g.ai/og-storage) through a plugin.\r\n\r\n**Describe the solution you'd like**\r\nThe [0G](https://0g.ai/) plugin enables seamless integration with the Zero Gravity (0G) protocol for decentralized file storage. It provides functionality to upload files to the 0G network.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n**Additional context**", "CLOSED", 0, "Wilbert957", "2024-11-19T08:35:17Z", "2024-12-14T07:31:28Z", "2024-12-14T07:31:28Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6fKVoK", 408, "Update totalMessages Logic in Boredom Scoring", "The boredom scoring function uses totalMessages in two places to evaluate user activity and interactions. Right now, it applies a threshold (> 10) to penalize repetitive or low interaction activity. This logic might need to be adjusted to better reflect actual user behavior and improve accuracy.\r\n\r\nPlease check if the threshold (> 10) is appropriate.\r\n\r\n\r\n```\r\n        // TODO: change totalMessages value\r\n        if (recentUsers.length <= 2 && recentMessages.length > 10) {\r\n            boredomScore += 1;\r\n        }\r\n\r\n        if (uniqueUsers.length < 3) {\r\n            // if less than 3 unique users, assume repetitive interaction\r\n            const totalMessages = Object.values(userMessageCounts).reduce(\r\n                (a, b) => a + b,\r\n                0\r\n            );\r\n\r\n            // TODO: change totalMessages value\r\n            if (totalMessages > 10) {\r\n                boredomScore += 1;\r\n            }\r\n        }\r\n```", "CLOSED", 0, "DanielHighETH", "2024-11-18T23:30:47Z", "2024-12-14T07:31:28Z", "2024-12-14T07:31:28Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6e93u6", 387, " Error when starting Eliza agent: \"fs.Stats constructor is deprecated\" and \"triggerUncaughtException\"", "**Description:**\r\n\r\nI am encountering an error when trying to start the Eliza agent using the provided instructions. The error appears to be related to deprecated features and experimental warnings in Node.js.\r\n\r\n**Steps to Reproduce:**\r\n\r\n**Clone the repository and checkout the latest tagged release:**\r\n\r\nbash\r\ngit clone https://github.com/ai16z/eliza.git\r\ncd eliza\r\ngit checkout v0.0.10\r\n\r\n\r\n**Install dependencies:**\r\n\r\nbash\r\npnpm install -r\r\nConfigure environment variables in .env (using placeholder values where appropriate).\r\n\r\n**Start the agent:**\r\n\r\nbash\r\npnpm start --character=\"characters/trump.character.json\"\r\nObserve the error messages.\r\n\r\n**Expected Behavior:**\r\n\r\nThe agent should start without errors, allowing me to interact with it as per the quickstart guide.\r\n\r\n**Actual Behavior:**\r\n\r\nI receive the following error messages:\r\n\r\n(node:25002) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\r\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\r\n    at createModuleLoader (node:internal/modules/esm/loader:814:17)\r\n    at Object.getOrInitializeCascadedLoader (node:internal/modules/esm/loader:858:22)\r\n    at asyncRunEntryPointWithESMLoader (node:internal/modules/run_main:105:65)\r\n    at runEntryPointWithESMLoader (node:internal/modules/run_main:138:19)\r\n    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:175:5)\r\n    at node:internal/main/run_main_module:36:49\r\n(node:25002) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\r\n    at Object.createResolve (/Users/bensmith/Desktop/Personal/Projects/agents/eliza/node_modules/ts-node/dist-raw/node-internal-modules-esm-resolve.js:146:25)\r\n    at /Users/bensmith/Desktop/Personal/Projects/agents/eliza/node_modules/ts-node/src/index.ts:1494:7\r\n    at Object.onceFn [as getNodeEsmResolver] (/Users/bensmith/Desktop/Personal/Projects/agents/eliza/node_modules/ts-node/src/util.ts:166:13)\r\n    at createEsmHooks (/Users/bensmith/Desktop/Personal/Projects/agents/eliza/node_modules/ts-node/src/esm.ts:125:51)\r\n    at Object.registerAndCreateEsmHooks (/Users/bensmith/Desktop/Personal/Projects/agents/eliza/node_modules/ts-node/src/esm.ts:118:10)\r\n    at file:///Users/bensmith/Desktop/Personal/Projects/agents/eliza/node_modules/ts-node/esm.mjs:8:7\r\n    at ModuleJob.run (node:internal/modules/esm/module_job:268:25)\r\n    at async onImport.tracePromise.__proto__ (node:internal/modules/esm/loader:543:26)\r\n    at async Hooks.register (node:internal/modules/esm/hooks:152:7)\r\n    at async initializeHooks (node:internal/modules/esm/utils:318:5)\r\n\r\nnode:internal/modules/run_main:122\r\n    triggerUncaughtException(\r\n    ^\r\n[Object: null prototype] {\r\n  [Symbol(nodejs.util.inspect.custom)]: [Function: [nodejs.util.inspect.custom]]\r\n}\r\nThrown at:\r\n    at asyncRunEntryPointWithESMLoader (node:internal/modules/run_main:122:5)\r\n\r\nNode.js v23.1.0\r\n ELIFECYCLE\u2009 Command failed with exit code 1.\r\n ELIFECYCLE\u2009 Command failed with exit code 1.\r\n\r\n\r\n**Environment:**\r\nOS: macOS Sonoma 14.6.1\r\nNode.js version: v23.1.0\r\n\r\n\r\n**I have tried the following steps to resolve the issue:**\r\nCleaned node_modules and reinstalled dependencies with pnpm install -r.\r\nUpdated ts-node, typescript, and @types/node to the latest versions.\r\nAdjusted tsconfig.json settings, including changing moduleResolution to \"node\" and \"nodenext\".\r\nModified the start script in core/package.json to use ts-node directly.\r\nAttempted to rebuild packages with pnpm rebuild.\r\nDespite these efforts, the error persists.\r\nThe error messages suggest deprecation warnings and issues with experimental features, possibly related to the Node.js version.\r\nThe quickstart guide specifies Node.js v23.1.0, but this version may not be stable or widely supported.\r\n\r\n\r\n\r\n**Request:**\r\n\r\nCould you please help me identify the cause of this issue and provide guidance on how to resolve it? Is there a recommended Node.js version or additional configuration that I should use?", "CLOSED", 0, "AgentTankOS", "2024-11-18T03:53:14Z", "2024-12-14T07:31:27Z", "2024-12-14T07:31:27Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6eyH1G", 352, "Create an Eliza Trained on Dev Documentation", "\r\n\r\n# **Request for Proposal: Eliza AI Agent Framework Integration and Development**\r\n\r\n## **Overview**\r\n\r\nWe invite skilled developers or teams to integrate and enhance the **Eliza AI Agent Framework** by ai16z. The goal is to deploy an advanced AI-powered chatbot that onboards new developers into our ecosystem using its own development documentation.\r\n\r\n### **Project Milestones**\r\n\r\nThis project is structured into three main milestones:\r\n\r\n#### **Milestone 1: Chatbot Integration with Discord, Twitter, and Telegram**\r\n- **Objective**: Integrate the Eliza AI Agent Framework with Discord, Twitter, and Telegram to create a conversational chatbot.\r\n- **Key Tasks**:\r\n  - Seamless user interaction across platforms using APIs and protocols.\r\n  - Basic conversation handling: input processing, intent identification, and response generation.\r\n- **Deadline**: Deliver a functional chatbot on all three platforms within 6 weeks.\r\n\r\n#### **Milestone 2: Web Interface Development using Next.js**\r\n- **Objective**: Design and develop a simple web interface using Next.js to interact with the Eliza chatbot.\r\n- **Key Tasks**:\r\n  - Create a user-friendly interface for chat interactions.\r\n  - Ensure responsiveness, accessibility, and browser compatibility.\r\n- **Deadline**: Deliver a functional web interface within 8 weeks.\r\n\r\n#### **Milestone 3: Trained Voice Agent Development**\r\n- **Objective**: Implement a trained voice agent for the Eliza AI using technologies like Eleven Labs.\r\n- **Key Tasks**:\r\n  - Enable voice-based interactions with speech recognition and text-to-speech.\r\n  - Integrate voice functionality with the chatbot and web interface.\r\n- **Deadline**: Deliver a functional voice agent within 12 weeks.\r\n\r\n## **Technical Requirements**\r\n\r\n- ![JavaScript](https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black)\r\n- ![Node.js](https://img.shields.io/badge/Node.js-339933?style=for-the-badge&logo=nodedotjs&logoColor=white)\r\n- ![Next.js](https://img.shields.io/badge/Next.js-000000?style=for-the-badge&logo=nextdotjs&logoColor=white)\r\n- **Experience Required**:\r\n  - Proficiency in JavaScript, Node.js, and Next.js.\r\n  - Familiarity with Discord, Twitter, and Telegram APIs for bot development.\r\n  - Understanding of AI and ML concepts, including NLP and intent identification.\r\n  - Knowledge in speech recognition and text-to-speech technologies.\r\n  - Strong principles in web development, accessibility, and responsive design.\r\n", "CLOSED", 0, "awidearray", "2024-11-16T07:27:22Z", "2024-12-14T07:31:27Z", "2024-12-14T07:31:27Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6ehQEy", 319, "no action response found in the response content for twitter or tg clients", " [\"\u26a0 No action found in the response content.\"]    \r\n \r\n no actions on twitter & tg", "CLOSED", 0, "o-on-x", "2024-11-14T17:20:45Z", "2024-12-14T07:31:26Z", "2024-12-14T07:31:26Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6egfBj", 317, "Get to a place where we can reliably create release tags", "**Problem:**\r\n\r\nOur open-source project is experiencing rapid growth with numerous contributions from our community members. While we have the infrastructure to create releases, we currently face challenges in ensuring that these releases are reliable and stable. The key issues are:\r\n\r\n- **Broken Test Suite:** Our automated tests are failing, which means we cannot confidently verify the stability and functionality of new code changes.\r\n- **Rapid Code Changes:** With many contributors and fast-moving code, it's difficult to track and integrate changes without introducing new bugs.\r\n- **Unreliable Releases:** Without a consistent and dependable release process, we risk distributing versions of our project that may not meet quality standards.\r\n\r\n---\r\n\r\n**Proposed Solution:**\r\n\r\nTo overcome these challenges and establish a reliable release process, we propose the following steps:\r\n\r\n1. **Prioritize Fixing the Tests:**\r\n   - **Assess and Repair Tests:** Identify all failing tests and determine the causes. Fix broken tests to ensure they accurately reflect code functionality.\r\n   - **Community Involvement:** Encourage contributors to help fix tests by creating specific issues and assigning tasks.\r\n   - Testing issues can be found with the 'testing' label: https://github.com/ai16z/eliza/issues?q=is%3Aopen+is%3Aissue+label%3Atesting\r\n\r\n2. **Establish Continuous Integration (CI):**\r\n   - **Automate Testing:** Set up a CI system to automatically run the test suite on every commit and pull request. For the most part this is already in place but only runs a basic test currently.\r\n   - **Enforce Test Passing:** Configure the CI to block merging of code that doesn't pass all tests, keeping the main branch stable. We currently have these running on every pull request, but it's not a blocking rule.\r\n\r\n3. **Implement a Branching Strategy:**\r\n   - **Use Feature Branches:** Have contributors work on separate branches for new features or fixes to isolate changes. For the most part this is happening already.\r\n   - **Adopt Release Branches:** Create dedicated branches for preparing releases, allowing for final testing and stabilization.\r\n\r\n4. **Define a Release Workflow:**\r\n   - **Release Types:** Clearly define different release types (e.g., alpha, beta, stable) and their purposes.\r\n   - **Semantic Versioning:** Use semantic versioning to communicate the nature of changes in each release.\r\n\r\n5. **Automate the Release Process:**\r\n   - **Automated Builds and Tagging:** Utilize tools to automate the building of releases and tagging of versions.\r\n   - **Generate Release Notes:** Automatically create release notes from commit messages to document changes. This is already in place and is updated when a tag is created through CI: https://github.com/ai16z/eliza/blob/main/CHANGELOG.md\r\n\r\n6. **Establish Release Criteria:**\r\n   - **Set Clear Requirements:** Define what must be completed before a release (passing tests, code reviews, updated documentation).\r\n   - **Use a Release Checklist:** Implement a checklist to ensure all criteria are met before releasing.\r\n\r\n7. **Enhance Collaboration and Communication:**\r\n   - **Regular Updates:** Hold regular meetings or send updates to keep everyone informed about release progress.\r\n   - **Transparency:** Make the release roadmap and plans accessible to all contributors.\r\n\r\n8. **Implement Code Reviews and Quality Assurance:**\r\n   - **Mandatory Code Reviews:** Require that all code changes are reviewed by at least one other contributor. We've talked about this in discord, but it hasn't been implemented as a rule yet.\r\n   - **Use Quality Tools:** Integrate static analysis and other quality assurance tools to catch issues early.\r\n\r\n9. **Plan for Different Release Channels:**\r\n   - **Stable Releases:** Provide thoroughly tested versions for general use.\r\n   - **Beta and Nightly Builds:** Offer less stable versions for testing new features and gathering feedback.\r\n\r\n10. **Monitor and Iterate:**\r\n    - **Collect Feedback:** After each release, gather input from users and contributors to identify improvements.\r\n    - **Continuous Improvement:** Regularly refine the release process based on feedback and performance metrics.\r\n\r\n---\r\n\r\n**Next Steps:**\r\n\r\n- **Immediate Actions:**\r\n  - **Fix the Test Suite:** Prioritize repairing all broken tests with the help of the community.\r\n  - **Set Up CI System:** Implement a continuous integration pipeline to automate testing and enforce code quality.\r\n\r\n- **Community Engagement:**\r\n  - **Communicate Plans:** Share this proposed solution with the community to align efforts and expectations.\r\n  - **Encourage Participation:** Invite contributors to take active roles in improving the testing and release processes.\r\n\r\n- **Documentation:**\r\n  - **Create Guidelines:** Document the release workflow, branching strategy, and contribution guidelines.\r\n  - **Provide Resources:** Offer tutorials or guides on how to work with the new processes and tools.\r\n\r\n---\r\n\r\nBy taking these steps, we aim to build a robust and reliable release process that can handle rapid development while maintaining high-quality standards. This will not only improve the stability of our releases but also enhance collaboration within our community, ultimately leading to a better project for all users and contributors.", "CLOSED", 0, "sirkitree", "2024-11-14T16:11:04Z", "2024-12-14T07:31:26Z", "2024-12-14T07:31:26Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6eYber", 305, "Managing Divergence Across the Eliza Ecosystem (Multiple Forks)", "**Description:**\r\n\r\nThe Eliza project is gaining traction, and many developers are forking the repository to create custom agents or specialized implementations. This distributed development model is a strength, but it also creates a challenge: managing code divergence and ensuring interoperability across the growing Eliza ecosystem. This ticket aims to establish a community-driven plan for addressing this challenge, fostering collaboration, and maximizing code reuse while allowing for customization and innovation within individual forks.\r\n\r\n**Problem:**\r\n\r\n* **Multiple Diverging Forks:** As more developers fork Eliza, the ecosystem will naturally fragment into various specialized implementations.\r\n* **Increased Merge Complexity:** Merging changes between forks, or between forks and the main repository, will become increasingly complex and error-prone as divergence increases.\r\n* **Maintenance Overhead:**  Each fork incurs its own maintenance burden, requiring developers to track upstream changes, resolve merge conflicts, and ensure compatibility.\r\n* **Duplication of Effort and Reinventing the Wheel:** Developers in different forks might unknowingly duplicate efforts by re-implementing similar features.\r\n* **Reduced Interoperability:**  Divergence can lead to reduced interoperability between different Eliza agents or implementations.\r\n\r\n**Goals:**\r\n\r\n* **Minimize Divergence (Where Feasible):** Encourage practices that minimize unnecessary code divergence across forks.\r\n* **Facilitate Collaboration and Knowledge Sharing:** Foster communication and collaboration between maintainers of different forks and the core Eliza team.\r\n* **Streamline Merging and Integration:** Establish best practices and potentially develop tools for efficiently merging changes between forks and the main repository.\r\n* **Maximize Code Reuse:**  Promote modular design and encourage the development of reusable plugins and components that can be shared across the ecosystem.\r\n* **Maintain Core Eliza Stability:**  Ensure that core Eliza functionality remains stable and reliable while allowing for innovation and customization within forks.\r\n\r\n**Near-Term Plan (Community-Driven):**\r\n\r\n1. **Fork Registry (Website or GitHub Page):** Create a central registry of known Eliza forks. This registry could include project descriptions, contact information for maintainers, and links to the forked repositories.  This facilitates discovery and collaboration.\r\n\r\n2. **Communication Channels (Discord, Forum):**  Establish dedicated communication channels (e.g., a Discord server, a forum category) for discussing fork management, sharing best practices, and coordinating development efforts.\r\n\r\n3. **Modularization and Plugin Development:**  Encourage developers to refactor fork-specific code into modular plugins or extensions that can be easily shared and integrated with other Eliza implementations.\r\n\r\n4. **Standardized Plugin Interface:**  Develop and document a clear, standardized interface for creating Eliza plugins.  This promotes interoperability and simplifies plugin integration.\r\n\r\n5. **Shared Test Suite:**  Create a shared test suite that covers core Eliza functionality.  Encourage fork maintainers to incorporate this test suite into their continuous integration pipelines to ensure compatibility.\r\n\r\n6. **Documentation:**  Create documentation and tutorials on best practices for forking Eliza, managing divergence, and contributing back to the ecosystem.\r\n\r\n**Future Considerations (Speculative):**\r\n\r\n1. **Automated Merging Tools:**  Explore and potentially develop automated merging tools that can help resolve conflicts and integrate changes between forks more efficiently.\r\n2. **Distributed Version Control System (DVCS) Workflows:** Investigate whether alternative version control systems or workflows (like Git submodules or subtree merging) could facilitate managing multiple forks.\r\n3. **Inter-Agent Communication Protocol:** If AI-driven code synchronization is a long-term goal, develop a protocol or language for communication between agents managing different forks.\r\n4. **Federated Learning for Agents:**  Explore the potential of federated learning techniques, allowing agents in different forks to collaboratively train and improve shared models without directly exchanging sensitive data.\r\n\r\n**Acceptance Criteria:**\r\n\r\n* A community-driven plan is established and documented for managing divergence across the Eliza ecosystem.\r\n* The plan includes specific steps for facilitating collaboration, streamlining merging, maximizing code reuse, and maintaining core Eliza stability.\r\n* The plan is actively communicated and promoted within the Eliza community.\r\n* Tools and resources (fork registry, communication channels, shared test suite) are created to support the plan's implementation.\r\n\r\n\r\n\r\nThis ticket expands the scope to address the broader challenge of managing multiple forks within the Eliza ecosystem. The key shift is towards a community-driven approach, emphasizing collaboration, knowledge sharing, and the development of shared resources and standards. This fosters a more vibrant and sustainable ecosystem while allowing individual forks the flexibility to innovate and adapt Eliza to their specific needs.", "CLOSED", 0, "jkbrooks", "2024-11-14T00:44:03Z", "2024-12-14T07:31:26Z", "2024-12-14T07:31:26Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6eYLAw", 303, "EVM Integration", "EVM Integration\r\n\r\n- Integrate Ethereum wallet and demonstrate Eth L1 and Base L2\r\n- Copy and paste solana plugin and recreate with EVM\r\n- Swapping action, wallet provider\r\n\r\nReward: $1500 USD in $degenai as seen on https://ai16z.github.io/", "CLOSED", 0, "madjin", "2024-11-13T23:44:41Z", "2024-12-14T07:31:26Z", "2024-12-14T07:31:25Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6eYJFt", 300, "Farcaster Client / Plugin", "Parity with Twitter client, but on Farcaster\r\n\r\nReward: $1000 USD in $ai16z + $1000 USD in $degenai\r\n\r\nAs seen on https://ai16z.github.io/", "CLOSED", 0, "madjin", "2024-11-13T23:39:35Z", "2024-12-14T07:31:25Z", "2024-12-14T07:31:25Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6eX1NW", 298, "Docs improvements bounty ideas", "- read more = broken link: https://ai16z.github.io/eliza/docs/community/stream-notes/\r\n- readme is outdated\r\n- pnpm run shell not valid\r\n- go through and test the docs to be valid\r\n- add jsdocs comments to all the code\r\n- add links to the code in code snippet examples\r\n- check and fix all the issues in github\r\n\r\nwill add more things to fix for a bounty on https://ai16z.github.io/", "CLOSED", 0, "madjin", "2024-11-13T22:52:59Z", "2024-12-14T07:31:25Z", "2024-12-14T07:31:25Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6eOwEj", 284, "Quickstart guide is missing important info", "**Describe the bug**\r\n\r\nDoc pages:\r\n* https://github.com/ai16z/eliza/blob/main/docs/docs/guides/configuration.md\r\n* https://github.com/ai16z/eliza/blob/main/docs/docs/guides/basic-usage.md\r\n\r\nThis page a basic setup code but doesn't mention where to put it (folder/filename)\r\n", "CLOSED", 0, "TonySimonovsky", "2024-11-13T08:33:57Z", "2024-12-14T07:31:25Z", "2024-12-14T07:31:24Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6eJH2a", 275, "advanced usage section of docs doesn't include instructions for memory management", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nThe docs section simply explains that it has the functionality, it doesn't explain how it works or how to use it\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\ngo to the docs and search memory\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\ninstructions on how to do memory management\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n![image](https://github.com/user-attachments/assets/23ffc956-fd56-4d46-8608-a806efbb24f9)\r\n![image](https://github.com/user-attachments/assets/80390c52-ad18-4de0-9744-6f994a439fb2)\r\n![image](https://github.com/user-attachments/assets/668bb2da-2f2f-46a2-ba5c-795585679573)\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\nThe example I beleive is correct -- I was searching the docs for how to clear the memory db and rebuild it, and was unable to find the instructions", "CLOSED", 0, "twilwa", "2024-11-12T19:58:44Z", "2024-12-14T07:31:24Z", "2024-12-14T07:31:24Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6d90U4", 264, "Allow twitter client to configure who to reply to based on following relationship", "It would be good to allow agent owners to be able to turn on/off who their twitter agents reply to.\r\n\r\nPreference is to just reply to accounts the agent is following.\r\n\r\nThis will reduce spam and allow agent owners to have a bit more control over interactions.\r\n\r\n\r\n**Additional context**\r\nProbably related to https://github.com/ai16z/eliza/issues/259\r\n", "CLOSED", 0, "docherty", "2024-11-11T19:41:14Z", "2024-12-14T07:29:16Z", "2024-12-14T07:29:16Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6d4OMb", 260, "Agent is reposting images from other parts of conversation as its own image", "For some reason, on Twitter, the agent will respond with an image which is a respost of images from other conversation it has had. This is clearly a bug. If it generates an image, that's cool, but it seems to be sending the old image.", "CLOSED", 0, "lalalune", "2024-11-11T09:45:00Z", "2024-12-14T07:29:16Z", "2024-12-14T07:29:16Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6d4KYe", 259, "Fix queueing in Twitter so messages are not rate limited constantly", "The way we are queueing messages is very shoddy and causes rate limiting.", "CLOSED", 0, "lalalune", "2024-11-11T09:38:16Z", "2024-12-14T07:29:15Z", "2024-12-14T07:29:15Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6d4KEJ", 258, "Fix Twitter Multi-agent, Characters respond to each other's messages", "Right now if we run two agents at the same time, only one responds on twitter and uses the personality of the other agent.\r\n\r\nWe need to make sure that this is not happening, and that each responds on their own.", "CLOSED", 0, "lalalune", "2024-11-11T09:37:38Z", "2024-12-14T07:29:15Z", "2024-12-14T07:29:15Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6drp9-", 244, "Add shouldRespond handler to voice", "Right now the voice is responding to all inputs, but should have a shouldRespond handler. This was not implemented for response speed, but should definitely be there. We can also call should respond and generate text simultaneously if we want to optimize speed, although with gpt-4o-mini the should respond should be pretty fast.", "CLOSED", 0, "lalalune", "2024-11-09T01:50:46Z", "2024-12-14T07:29:15Z", "2024-12-14T07:29:15Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6drp1D", 243, "Move cache to database", "We should move all caching, including token cache, content cache, etc into the database. We can store these in a cache manager which could be connected to the memory manager so we can add to the adapters for each database adapter.\r\n\r\n1. Move all content caching into memory manager and use store cache and retrieve cache calls\r\n2. Add and test with every database adapter, including sqlite, sqljs and postgres\r\n\r\nmake sure twitters credentials not broken in tweetcache -- or are saving to db\r\nwe should store models somewhere nice\r\nstore credentials in db\r\ncache prompts in db?\r\nfix tokencache\r\ncontent_cache ?", "CLOSED", 0, "lalalune", "2024-11-09T01:49:18Z", "2024-12-14T07:29:15Z", "2024-12-14T07:29:15Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6drpp9", 242, "Store all local models in /models folder, with overridable model path", "We should make sure that all models stored by llama, whisper, embedding, etc all get stored in a /models folder that is easy to find and clean. This way the repo doesn't get huge and locating models isn't messy.\r\n\r\nHere are the steps:\r\n1. Look for all services where models are being loaded, including llama, fastembed, whisper, etc\r\n2. Change all paths to be eliza/models\r\n3. Add a path checker if that doesn't exist with some sane defaults to handle any case\r\n4. Add a model path override to functions so the packaged version doesn't go somewhere weird.", "CLOSED", 0, "lalalune", "2024-11-09T01:47:33Z", "2024-12-14T07:29:14Z", "2024-12-14T07:29:14Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6drpgb", 241, "Add storeCredential and getCredential key value store, store secrets in db", "Right now we're storing twitter credentials and other credentials in character file, as well as in tweet cache for twitter login cookies, and other places.\r\n\r\nInstead, we should store secrets and credentials per character\r\n\r\nWe can add these to the memory manager and database adapters to keep the DB unified\r\n\r\nSo there are a few different parts to this:\r\n\r\n1. Add credential key value store to MemoryManager, keyed by agentId\r\n2. Store and retrieve Twitter cookies from this\r\n3. Add script to store and retrieve secrets by agentId / agentName\r\n4. Add checking to get secrets as priority and fall back to character file secrets\r\n\r\nThis will enable us to store/recall secrets later in a platform, and keep secrets internal to our database without having to put them in characters.", "CLOSED", 0, "lalalune", "2024-11-09T01:45:58Z", "2024-12-14T07:29:14Z", "2024-12-14T07:29:14Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6drpIG", 240, "Move embeddings to a service and a service and add ServiceType.EMBEDDING", "I've added fast-embed into the new branch (soon to be merged) which embeds inside the core.", "CLOSED", 0, "lalalune", "2024-11-09T01:42:12Z", "2024-12-14T07:29:14Z", "2024-12-14T07:29:14Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6dosAN", 237, "On PNPM Install this happens", "packages/core postinstall$ npx playwright install-deps && npx playwright install\r\n\u2502 Installing dependencies...\r\n\u2502 Switching to root user to install dependencies...\r\n\u2502 Get:1 http://nova.clouds.archive.ubuntu.com/ubuntu lunar InRelease [267 kB]\r\n\u2502 Get:2 http://nova.clouds.archive.ubuntu.com/ubuntu lunar-updates InRelease [109 kB]\r\n\u2502 Get:3 http://nova.clouds.archive.ubuntu.com/ubuntu lunar-backports InRelease [99.9 kB]\r\n\u2502 Hit:4 http://security.ubuntu.com/ubuntu lunar-security InRelease\r\n\u2502 Fetched 475 kB in 1s (421 kB/s)\r\n\u2502 Reading package lists...\r\n\u2502 Reading package lists...\r\n\u2502 Building dependency tree...\r\n\u2502 Reading state information...\r\n\u2502 E: Unable to locate package libasound2t64\r\n\u2502 E: Unable to locate package libatk-bridge2.0-0t64\r\n\u2502 E: Couldn't find any package by glob 'libatk-bridge2.0-0t64'\r\n\u2502 E: Couldn't find any package by regex 'libatk-bridge2.0-0t64'\r\n\u2502 E: Unable to locate package libatk1.0-0t64\r\n\u2502 E: Couldn't find any package by glob 'libatk1.0-0t64'\r\n\u2502 E: Couldn't find any package by regex 'libatk1.0-0t64'\r\n\u2502 E: Unable to locate package libatspi2.0-0t64\r\n\u2502 E: Couldn't find any package by glob 'libatspi2.0-0t64'\r\n\u2502 E: Couldn't find any package by regex 'libatspi2.0-0t64'\r\n\u2502 E: Unable to locate package libcups2t64\r\n\u2502 E: Unable to locate package libglib2.0-0t64\r\n\u2502 E: Couldn't find any package by glob 'libglib2.0-0t64'\r\n\u2502 E: Couldn't find any package by regex 'libglib2.0-0t64'\r\n\u2502 E: Unable to locate package libgtk-3-0t64\r\n\u2502 E: Unable to locate package libicu74\r\n\u2502 E: Unable to locate package libevent-2.1-7t64\r\n\u2502 E: Couldn't find any package by glob 'libevent-2.1-7t64'\r\n\u2502 E: Couldn't find any package by regex 'libevent-2.1-7t64'\r\n\u2502 E: Unable to locate package libpng16-16t64\r\n\u2502 E: Unable to locate package libvpx9\r\n\u2502 Failed to install browser dependencies\r\n\u2502 Error: Installation process exited with code: 100\r\n\u2514\u2500 Failed in 7s at /home/ubuntu/dev/eliza/packages/core\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n\u2009\r\n\u2009\r\n\u2009Getting this error", "CLOSED", 0, "cgallic", "2024-11-08T17:31:11Z", "2024-12-14T07:29:14Z", "2024-12-14T07:29:13Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6dfd4W", 230, "twitter folder paths for twitter cookies & cache/last tweet point to different places", "the cache is not being picked up. the twitter cookies is.\r\ntwo solutions:\r\nset cache to same folder path as cookies. \r\nor use recursive find the lowest twittercache folder found", "CLOSED", 0, "o-on-x", "2024-11-07T21:42:56Z", "2024-12-14T07:29:13Z", "2024-12-14T07:29:13Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6dMq4n", 215, "pnpm install fails on Ubuntu", "**Describe the bug**\r\n\r\nInstallation fails\r\n\r\n**To Reproduce**\r\n\r\n`pnpm i`\r\n\r\n**Expected behavior**\r\n\r\nInstalls without error.\r\n\r\n**Additional context**\r\n\r\nOS: Ubuntu 24.04 LTS\r\nnode: v22.10.1\r\npnpm: 9.12.3\r\n\r\nAn example of error I get:\r\n```\r\nnode_modules/sharp install$ (node install/libvips && node install/dll-copy && prebuild-install) || (node install/can-compile && node-gyp rebuild && node install/dll-copy)\r\n\u2514\u2500 Failed in 283ms at /home/ubuntu/eliza/node_modules/sharp\r\n```\r\nHappens with `@discordjs/opus` & `onnxruntime-node` too, maybe others.\r\n\r\nBut if I go into the directory and install from there it works:\r\n```\r\ncd node_modules/sharp\r\nnpm install\r\n```\r\nThis doesn't throw any error and installs the package correctly.\r\n\r\nIs this a bug on `pnpm` side?", "CLOSED", 0, "lo-zed", "2024-11-06T08:11:15Z", "2024-12-14T07:29:13Z", "2024-12-14T07:29:13Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6cxkcs", 164, "Knowledge system is disabled", "**Describe the bug**\r\n\r\nCurrently the knowledge system is disabled\r\nhttps://github.com/ai16z/eliza/blob/main/core/src/core/runtime.ts#L320\r\n\r\nThere is a continue. We should remove the continue, test the knowledge system end-to-end with knowledge and verify that it is injected into the context.\r\n\r\n<img width=\"445\" alt=\"Screenshot 2024-11-01 at 10 47 52\u202fPM\" src=\"https://github.com/user-attachments/assets/53e53201-ac8e-421a-a295-78541c5c7b57\">\r\n", "CLOSED", 0, "lalalune", "2024-11-02T05:48:00Z", "2024-12-14T07:28:00Z", "2024-12-14T07:28:00Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6cwNwn", 158, "Make image generation very nice and spicy", "@o-on-x has offered to work on this for their own agent", "CLOSED", 0, "lalalune", "2024-11-01T21:17:26Z", "2024-12-14T07:28:00Z", "2024-12-14T07:28:00Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6ciRNB", 148, "LLM can't be trusted to parse it's own json", "**Describe the bug**\r\n\r\nWe trust the LLM to parse it's own JSON resulting in what a separate issue referred to as an infinite loop (which technically will resolve itself if left alone to smash on the OpenAI endpoint for long enough)\r\n\r\n```\r\n# Instructions: Write the next message for lina. Include an action, if appropriate. Possible response actions: MUTE_ROOM, ASK_CLAUDE, NONE, IGNORE\r\n\r\nResponse format should be formatted in a JSON block like this:\r\njson\r\n{ \"user\": \"lina\", \"text\": string, \"action\": string }\r\n\r\nMessage is json\r\n{ \"user\": \"lina\", \"text\": \"Oh honey~ Working with a pioneer sounds tantalizing... but only if he can keep up with me and my fiery spirit \ud83d\ude09 Now spill the details or I might get bored!\", \"action\": NONE }\r\n\r\nresponse is json\r\n{ \"user\": \"lina\", \"text\": \"Oh honey~ Working with a pioneer sounds tantalizing... but only if he can keep up with me and my fiery spirit \ud83d\ude09 Now spill the details or I might get bored!\", \"action\": NONE }\r\n\r\nparsedContent is null\r\nparsedContent is null, retrying\r\n```\r\n\r\nNotice above that the action: value `NONE` is not a string.  Now take a look at the correctly parsed JSON immediately following this:\r\n\r\n```\r\nparsedContent is {\r\n  user: 'lina',\r\n  text: \"Oh darling st4rgard3n~ I'm always up for a little blockchain banter or maybe some spicy discussions about funding public goods... but don't think I won't call you out if you get all serious on me.<br> So what's the plan with @mattyryze?\",\r\n  action: 'NONE'\r\n}\r\n```\r\n\r\nHere the LLM has correctly formatted `NONE` as `'NONE'` a correct string.\r\n\r\n**To Reproduce**\r\n\r\nJust run eliza with a cheap llm model long enough and you will definitely encounter this one.\r\n\r\n**Expected behavior**\r\n\r\nThe message returned from the LLM should then be formatted into JSON in the program.", "CLOSED", 0, "St4rgarden", "2024-10-31T08:00:48Z", "2024-12-14T07:28:00Z", "2024-12-14T07:27:59Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6cUp-0", 81, "Add AI Code Reviewing application from GitHub Marketplace", "**Is your feature request related to a problem? Please describe.**\r\nLooking to increase code quality and efficiency. \r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the solution you'd like**\r\n\r\nI would like to propose integrating [CodeFactor](https://github.com/marketplace/codefactor) into this repository to enhance code quality and streamline the review process. CodeFactor offers an automated code review solution that continuously analyzes the repository for potential code issues, ensuring consistent code standards across contributions. Best of all it is FREE for public repositories like this one.\r\n\r\nBenefits of Adding CodeFactor:\r\n\r\n1.\tAutomated Code Review: CodeFactor automatically reviews new pull requests and commits, highlighting potential code smells, bugs, and areas for improvement. This helps maintainers focus on critical code changes rather than manual code quality checks.\r\n2.\tConsistent Code Quality: With its real-time feedback, CodeFactor ensures adherence to coding standards and best practices, fostering a uniform and high-quality codebase across all contributors.\r\n3.\tTime-Saving for Maintainers: The automated reviews free up maintainers\u2019 time, allowing them to focus on feature development and critical code issues while CodeFactor handles routine quality checks.\r\n4.\tAccessible and Easy to Use: CodeFactor seamlessly integrates with GitHub and provides a clear, visual report on code quality metrics, making it easy for contributors to understand and address code issues before merging.\r\n5.\tTransparent Quality Metrics: CodeFactor provides a public code quality score, which encourages contributors to submit higher-quality code and aligns with a collaborative, open-source approach to development.\r\n\r\nIntegrating CodeFactor would streamline the review process, improve the overall codebase quality, and allow for more effective collaboration between maintainers and contributors. I believe this would be a valuable addition to our repository\u2019s workflow.\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\n\r\nThere are numerous other alternatives in GitHub MarketPlace. I chose this one because it was top of popularity and would be free.\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->", "CLOSED", 0, "mrdavidburns", "2024-10-30T01:49:15Z", "2024-12-14T07:27:59Z", "2024-12-14T07:27:59Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6cKyW1", 72, "Abstract image descriptions / recognition to use any model provider", "**Is your feature request related to a problem? Please describe.**\r\n\r\nRight now the options for model provider for image recognition are openai and local with florence 2.  The OpenAI is hardcoded to check for the existence of the API key, and then load that, otherwise use the local.\r\n\r\n**Describe the solution you'd like**\r\n\r\nSimilar to the new model provider abstraction, we want to offer image recognition for whatever the current model is. For example, Claude, Vertex Claude, Cloud Llama, etc.", "CLOSED", 0, "lalalune", "2024-10-29T04:10:43Z", "2024-12-14T07:26:44Z", "2024-12-14T07:26:44Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6cFIom", 64, "Tests are failing", "Tried out running the tests today (`npm run test`) and there are a lot of failures currently.\r\n\r\nWe should\r\n1. evaluate which tests are still necessary\r\n2. get them working\r\n3. setup automated github action to run test for every pull request\r\n\r\n```\r\nNode.js v22.8.0\r\nTest Suites: 16 failed, 16 total\r\nTests:       58 failed, 58 total\r\nSnapshots:   0 total\r\nTime:        14.737 s\r\nRan all test suites.\r\n```\r\n\r\n@lalalune could you advise here? \r\nI think we can work on the tests but the first task of identifying which ones are necessary would be great if you could help with that more quickly than others.", "CLOSED", 0, "sirkitree", "2024-10-28T14:27:41Z", "2024-12-14T07:27:59Z", "2024-12-14T07:27:59Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6b-iCc", 56, "\ud83d\udca1 Have silly tavern compatibility", "Was suggested on voice chat that we make character files compatible with silly tavern character files.", "CLOSED", 0, "sirkitree", "2024-10-27T20:50:48Z", "2024-12-14T07:27:58Z", "2024-12-14T07:27:58Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6b-MiA", 54, "User Interface Enhancement", "Create an intuitive and user-friendly interface for the trust marketplace.\r\n\r\n#### Requirements\r\n- Design order submission forms\r\n- Create trade history views\r\n- Implement trust score displays\r\n- Add confidence level indicators\r\n\r\n#### Acceptance Criteria\r\n- [ ] UI is responsive and intuitive\r\n- [ ] All core features are accessible\r\n- [ ] Trade history is easily viewable\r\n- [ ] Trust scores and confidence levels are clearly displayed", "CLOSED", 0, "sirkitree", "2024-10-27T18:11:59Z", "2024-12-14T07:27:58Z", "2024-12-14T07:27:58Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6b5ht9", 29, "\"Private\" Actions", "Actions should have a \"private\" mode, where they can only be run by the agent in it's own loop, as opposed to in response to a user's request. So it can decide to make a coin, for example.", "CLOSED", 0, "lalalune", "2024-10-26T04:58:58Z", "2024-12-14T07:26:50Z", "2024-12-14T07:26:50Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6b5d05", 28, "Pump Fun Token Creation", "We should add this action\r\n\r\nhttps://github.com/cicere/pumpfun-bundler", "CLOSED", 0, "lalalune", "2024-10-26T04:34:43Z", "2024-12-14T07:27:58Z", "2024-12-14T07:27:58Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6b5FG6", 27, "Awareness of Twitter bio and username", "Right now the agent is not aware of his twitter bio and only vaguely of username. We want him to know username, screen name, bio, and nay nicknames too.", "CLOSED", 0, "lalalune", "2024-10-26T01:12:13Z", "2024-12-14T07:27:10Z", "2024-12-14T07:27:10Z", "elizaos/eliza", "2025-04-14 21:50:34"]
["I_kwDOMT5cIs6kLCBe", 1344, "Postgres adapter busted", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nWhen loading `schema.sql` it produces this error\r\n\r\n```\r\n \u26d4 ERRORS\r\n   Error starting agent for character Eliza: \r\n   {\"length\":124,\"name\":\"error\",\"severity\":\"ERROR\",\"code\":\"42601\",\"position\":\"1610\",\"file\":\"parse_type.c\",\"line\":\"407\",\"routine\":\"typenameTypeMod\"} \r\n\r\nerror: type modifiers must be simple constants or identifiers\r\n```\r\n\r\n**To Reproduce**\r\n\r\nUse postgresql adapter\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\nIt works\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\nv0.16\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "ryanleecode", "2024-12-21T20:41:20Z", "2024-12-21T23:45:46Z", "2024-12-21T23:45:46Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6kJDTi", 1326, "Why do I have a running Agent on WSL2, but the browser shows don't work?", "**Describe the bug**\r\n\r\nWhy do I have a running Agent on WSL2, but the browser shows don't work?\r\n```\r\n \u25ce LOGS\r\n   initializeClients \r\n   [] \r\n   for \r\n   trump \r\n\r\n \u25ce LOGS\r\n   client keys \r\n   [] \r\n\r\n [\"\u25ce Visit the following URL to chat with your agents:\"] \r\n\r\n [\"\u25ce http://localhost:5173\"] \r\n\r\n [\"\u2713 REST API bound to 0.0.0.0:3000. If running locally, access it at http://localhost:3000.\"] \r\n ```\r\n\r\n\r\n**To Reproduce**\r\n`pnpm start --character=\"characters/trump.character.json\"`\r\n\r\n**Expected behavior**\r\n\r\nhave normal website\r\n\r\n**Screenshots**\r\n![image](https://github.com/user-attachments/assets/ba3c1d40-08ec-4c19-ba24-e7459233cc57)\r\n\r\n\r\n**Additional context**\r\n\r\n", "CLOSED", 0, "cxp-13", "2024-12-21T08:08:45Z", "2024-12-21T11:24:51Z", "2024-12-21T10:02:39Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6kI-Iu", 1321, " 2:02:20 AM [vite] http proxy error: /agents Error: connect ECONNREFUSED ::1:3000     at TCPConnectWrap.afterConnect [as oncomplete] (node:net:1615:16) (x12)", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "Wubnar", "2024-12-21T07:06:28Z", "2024-12-21T07:09:58Z", "2024-12-21T07:09:58Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6kGsgh", 1281, "Add @eliza/agent to npm registry", "**Is your feature request related to a problem? Please describe.**\r\nI'd like to use the functions exposed in the /agent package\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd @eliza/agent to npm registry\r\n", "CLOSED", 0, "wozhendeai", "2024-12-20T18:03:04Z", "2024-12-20T18:04:33Z", "2024-12-20T18:04:33Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6kGH38", 1277, "Implement Redis Caching for Performance", "**Feature Request**\r\nTo improve application performance and reduce redundant data retrieval operations, this issue requests the implementation of a Redis-based caching mechanism in addition to the already existing DB caching and file-based caching.\r\n\r\nThe goal is to implement a caching layer to store and retrieve frequently accessed data using Redis.", "CLOSED", 0, "shakkernerd", "2024-12-20T16:31:29Z", "2024-12-21T00:37:41Z", "2024-12-21T00:37:41Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6kBi5k", 1261, "Improve logging for the Coinbase plugin", "**Is your feature request related to a problem? Please describe.**\n\nCurrently, our logging for the Coinbase plugin lacks structured formats and essential context, making it challenging to debug issues effectively and trace requests across services.\n\n**Describe the solution you'd like**\n\nImplement a structured logging framework that:\n- Uses JSON format for all logs.\n- Includes standard fields such as timestamp, severity, and correlation ID.\n- Supports context injection for better observability.\n- Has different log levels (DEBUG, INFO, WARN, ERROR).\n- Allows adding custom fields relevant to the Coinbase plugin operations.\n\nFor example, using a logging framework like Winston in Node.js:\n```javascript\nconst logger = require('winston');\nlogger.info('User login attempt', { userId: '12345', correlationId: 'abc-123' });\n```\nThis will greatly assist in correlating events and debugging any issues that may arise.\n\n**Describe alternatives you've considered**\n\n- Relying on plain text logs, which can be cumbersome to parse and analyze.\n- Using manual JSON formatting, which is error-prone.\n- Implementing APM tools without a standardized logging approach.\n\n**Additional context**\n\nEnhancing our logging practices will lead to better monitoring, easier log aggregation, and a more consistent logging pattern, ultimately improving our overall observability and debugging capabilities.", "CLOSED", 0, "monilpat", "2024-12-20T03:45:12Z", "2024-12-20T03:46:04Z", "2024-12-20T03:46:04Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6kAcc6", 1253, "doc: Add Twitter automation label requirement to quickstart guide", "## Issue\r\nMultiple users have reported their Eliza agents being flagged or shadowbanned on Twitter when their accounts weren't properly labeled as automated.\r\n\r\n## Current Situation\r\nThe quickstart guide explains how to set up Twitter integration but doesn't mention the requirement to enable the \"Automated\" label in the Twitter Developer Portal.\r\n\r\n## Proposed Solution\r\nAdd a brief but important notice in the Twitter Integration section of the quickstart guide about enabling the \"Automated\" label to prevent accounts from being flagged.\r\n\r\n## References\r\n- Discord discussions about accounts being flagged", "CLOSED", 0, "julienbrs", "2024-12-19T22:59:50Z", "2024-12-20T01:04:19Z", "2024-12-20T01:04:19Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6jtKs0", 1192, "Enhance Logging in /packages/plugin-coinbase/src/plugins Using elizaLogger", "---\nname: Feature request\nabout: Suggest an idea for this project\ntitle: \"\"\nlabels: \"enhancement\"\nassignees: \"\"\n---\n\n**Is your feature request related to a problem? Please describe.**\n\nCurrently, the logging mechanism in `/packages/plugin-coinbase/src/plugins` lacks detailed output, making it difficult to trace issues and monitor performance effectively.\n\n**Describe the solution you'd like**\n\nIntegrate the `elizaLogger` construct to provide more comprehensive logging throughout the codebase. This would involve:\n- Adding entry and exit logs for key functions.\n- Including detailed error logging with stack traces.\n- Logging significant state changes and data processing steps.\n\n**Describe alternatives you've considered**\n\nConsidered using a third-party logging library, but `elizaLogger` offers a more integrated solution with existing infrastructure.\n\n**Additional context**\n\nUtilize existing examples of `elizaLogger` usage in other parts of the codebase as a reference. Extend these examples to cover more complex scenarios within the `/packages/plugin-coinbase/src/plugins` path.", "CLOSED", 0, "monilpat", "2024-12-18T01:45:28Z", "2024-12-18T01:46:15Z", "2024-12-18T01:46:15Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6jrhcb", 1189, "Improve Logging in /packages/plugin-coinbase/src/plugins", "\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nThe current logging mechanism in the /packages/plugin-coinbase/src/plugins is not providing sufficient detail for debugging and monitoring purposes.\r\n\r\n**Describe the solution you'd like**\r\n\r\nEnhance the logging framework to include more comprehensive log messages, including error details, transaction states, and API request/response data.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nConsidered using third-party logging libraries that can be integrated into the existing setup for better log management and analysis.\r\n\r\n**Additional context**\r\n\r\nImproved logging can help in quicker issue resolution and provide better insights into the plugin's performance and behavior during both development and production stages.", "CLOSED", 0, "monilpat", "2024-12-17T21:19:29Z", "2024-12-17T21:24:30Z", "2024-12-17T21:21:06Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6jlt1I", 1173, "Bug: Application crashes on startup", "The application crashes on startup. No additional context or error messages have been provided.", "CLOSED", 0, "snobbee", "2024-12-17T10:43:05Z", "2024-12-17T10:43:17Z", "2024-12-17T10:43:17Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6jlpZM", 1172, "Bug: Application crashes on startup", "The application crashes upon startup. Please investigate the error codes and any relevant stack traces to diagnose the issue.", "CLOSED", 0, "snobbee", "2024-12-17T10:34:58Z", "2024-12-17T10:36:32Z", "2024-12-17T10:36:31Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6jlCWI", 1167, "Unable to run `pnpm install --no-frozen-lockfile` on v0.1.6-alpha.4", "**Describe the bug**\r\n\r\nI found the following error on a fresh checkout:\r\n\r\n```\r\n# set variable identifying the chroot you work in (used in the prompt below)\r\n# set a fancy prompt (non-color, unless we know we \"want\" color)\r\n\u2502 (Use `node --trace-deprecation ...` to show where the warning was created)\r\n\u2502 node-pre-gyp info check checked for \"/root/github/eliza/node_modules/@discordjs/opus/prebuild/node-v131-napi-v3-linux-x64-glibc-2.39/opus.node\" (not found)\r\n\u2502 node-pre-gyp http GET https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-linux-x64-glibc-2.39.tar.gz\r\n\u2502 node-pre-gyp ERR! install response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-linux-x64-glibc-2.39.tar.gz\r\n\u2502 node-pre-gyp WARN Pre-built binaries not installable for @discordjs/opus@0.9.0 and node@23.4.0 (node-v131 ABI, glibc) (falling back to source compile with node-gyp)\r\n\u2502 node-pre-gyp WARN Hit error response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-linux-x64-glibc-2.39.tar.gz\r\n\u2502 gyp info it worked if it ends with ok\r\n\u2502 gyp info using node-gyp@10.3.1\r\n\u2502 gyp info using node@23.4.0 | linux | x64\r\n\u2502 gyp info ok\r\n```\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "qizhou", "2024-12-17T09:30:31Z", "2024-12-21T05:41:36Z", "2024-12-21T05:41:35Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6jkVWV", 1161, "pnpm start --character=\"characters/trump.character.json\"", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n1. add  \"clients\": [\"twitter\"], to trump.character.json\r\n2. pnpm start --character=\"characters/trump.character.json\"\r\n3. error: `Killed\r\n/workspaces/eliza_1/agent:\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @ai16z/agent@0.1.5-alpha.6 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/trump.character.json\"`\r\nExit status 137\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 137.`\r\n\r\n", "CLOSED", 0, "whgreate", "2024-12-17T08:10:26Z", "2024-12-18T11:41:50Z", "2024-12-17T08:47:56Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6ji1o-", 1151, "REQUIRED_NODE_VERSION: No such file", "**Describe the bug**\r\n\r\nFollowing directions in README.md with `sh scripts/start.sh` on Ubuntu causes an error:\r\n\r\nscripts/start.sh: 6: cannot open REQUIRED_NODE_VERSION: No such file\r\n\r\n**To Reproduce**\r\n\r\nEnvironment: Ubuntu 24.04 LTS\r\n1. `sh scripts/start.sh`\r\n\r\n**Expected behavior**\r\n\r\nNo error regarding the variable \"REQUIRED_NODE_VERSION\"\r\n\r\n**Screenshots**\r\n\r\n<img width=\"1144\" alt=\"image\" src=\"https://github.com/user-attachments/assets/4280583e-0dc2-4c49-833c-84faaae86412\" />\r\n\r\n**Additional context**\r\n\r\nThis is a simple issue caused by the shell script being executed with dash instead of bash.\r\n", "CLOSED", 0, "tcotten-scrypted", "2024-12-17T03:04:39Z", "2024-12-17T13:24:57Z", "2024-12-17T09:09:59Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6jiYy4", 1145, "Discord agents knock each other out of VC", "**Describe the bug**\r\n\r\nWhen running two agents in the same client one will join the discord voice channel and then when 2nd agent joins it kicks the first agent out of discord\r\n\r\n**Additional context**\r\n\r\n- whichever character is listed last is the one that stays in the voice channel\r\n- the same thing happens even if sending the agents to different voice channels. \r\n- only tested from 1 discord server, 2 unique servers may produce a different outcome", "CLOSED", 0, "vincentskele", "2024-12-17T00:58:56Z", "2024-12-19T05:04:26Z", "2024-12-19T02:30:07Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6jaRpB", 1130, "Feat: add github client to core agent", "**Describe the solution you'd like**\r\nThis feature will allow agent interacting with github repository\r\n- Read all repository as agent's memory\r\n- Create pull request\r\n- Create commit", "CLOSED", 0, "fibonacci998", "2024-12-16T07:35:25Z", "2024-12-17T09:21:22Z", "2024-12-17T09:21:22Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6jXSF9", 1121, "pnpm install updates pnpm lockfile when it should not", "**Describe the bug**\r\n\r\nThe `pnpm install` command is incorrectly updating the lock file during installations, leading to potential inconsistencies in dependency versions across different environments. This behavior can cause unexpected issues when deploying or running the application, as the installed packages may not match the versions specified in the lock file.\r\n\r\n**To Reproduce**\r\n\r\n1. Clone the repository.\r\n2. Run the command `pnpm install` without the `--frozen-lockfile` option.\r\n3. Observe that the `pnpm-lock.yaml` file is updated with new versions of dependencies, even if they are not specified in the `package.json`.\r\n\r\n**Expected behavior**\r\n\r\nThe `pnpm install` command should respect the `--frozen-lockfile` option, preventing any updates to the lock file. This ensures that the installed dependencies match the versions specified in the `pnpm-lock.yaml` file, maintaining consistency across different environments.\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\nThis issue was addressed in a recent commit that added the `--frozen-lockfile` option to various installation commands in the project, including in the GitHub workflows, Dockerfile, and scripts. The explicit update script was also introduced to allow updates without the frozen lock file option, ensuring that developers can manage dependencies more effectively without risking unintended changes to the lock file.", "CLOSED", 0, "monilpat", "2024-12-15T17:47:46Z", "2024-12-17T00:11:34Z", "2024-12-17T00:11:33Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6jS5_r", 1066, "Scrapper login", "Error: {\"errors\":[{\"code\":399,\"message\":\"Incorrect. Please try again. g;173416064338586466:-1734160643646:ccVhgNQFewzfeK9cjAREzndr:8\"}]}\r\n    at TwitterUserAuth.executeFlowTask (file:///Users/kushagra/go/src/gihub.com/Cartman/Eliza-wraper/node_modules/.pnpm/agent-twitter-client@0.0.13/node_modules/agent-twitter-client/dist/node/esm/index.mjs:552:38)\r\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\r\n    at async TwitterUserAuth.handleAcid (file:///Users/kushagra/go/src/gihub.com/Cartman/Eliza-wraper/node_modules/.pnpm/agent-twitter-client@0.0.13/node_modules/agent-twitter-client/dist/node/esm/index.mjs:508:12)\r\n    at async TwitterUserAuth.login (file:///Users/kushagra/go/src/gihub.com/Cartman/Eliza-wraper/node_modules/.pnpm/agent-twitter-client@0.0.13/node_modules/agent-twitter-client/dist/node/esm/index.mjs:347:16)\r\n    at async Scraper.login (file:///Users/kushagra/go/src/gihub.com/Cartman/Eliza-wraper/node_modules/.pnpm/agent-twitter-client@0.0.13/node_modules/agent-twitter-client/dist/node/esm/index.mjs:2280:5)\r\n    at async ClientBase.init (file:///Users/kushagra/go/src/gihub.com/Cartman/Eliza-wraper/node_modules/.pnpm/@ai16z+client-twitter@0.1.4-alpha.3@google-cloud+vertexai@1.9.2_@langchain+core@0.3.23_opena_p7je7bhkaswxwoghczkrgshcom/node_modules/@ai16z/client-twitter/dist/index.js:1015:7)\r\n    at async Object.start (file:///Users/kushagra/go/src/gihub.com/Cartman/Eliza-wraper/node_modules/.pnpm/@ai16z+client-twitter@0.1.4-alpha.3_@google-cloud+vertexai@1.9.2_@langchain+core@0.3.23_opena_p7je7bhkaswxwoghczkrgshcom/node_modules/@ai16z/client-twitter/dist/index.js:1377:5)\r\n    at async initializeClients (file:///Users/kushagra/go/src/gihub.com/Cartman/Eliza-wraper/src/index.ts:156:32)\r\n    at async startAgent (file:///Users/kushagra/go/src/gihub.com/Cartman/Eliza-wraper/src/index.ts:212:25)\r\n    at async startAgents (file:///Users/kushagra/go/src/gihub.com/Cartman/Eliza-wraper/src/index.ts:309:13)\r\n \u26d4 ERRORS\r\n   Error starting\u00a0agents:\r\n\u00a0\u00a0\u00a0{}\r\n\u00a0\u00a0\u00a0\r\n\u00a0\u00a0\u00a0whenever I try to do login or re run again through it got me that same error\r\n\u00a0\u00a0\u00a0\r\n\u00a0\u00a0\u00a0\r\n\u00a0\u00a0\u00a0\r\n\u00a0\u00a0\u00a0", "CLOSED", 0, "SouSingh", "2024-12-14T07:20:43Z", "2024-12-19T14:40:51Z", "2024-12-14T07:22:15Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6jJqH0", 1027, "Missing required secret OPENAI_API_KEY in PR workflow", "**Describe the bug**\r\nMissing required secret OPENAI_API_KEY in PR workflow configuration, which causes the workflow to fail when running [integration-tests](https://github.com/ai16z/eliza/actions/runs/12301919452/job/34333562742?pr=1011#logs) tasks.\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n<!-- Steps to reproduce the behavior. -->\r\n[integration-tests](https://github.com/ai16z/eliza/actions/runs/12301919452/job/34333562742?pr=1011#logs)\r\n\r\n**Expected behavior**\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nThis PR workflow should continue running\r\n\r\n\r\n**Screenshots**\r\n![image](https://github.com/user-attachments/assets/b8220bb6-2e9f-46c5-80a0-13433c98ac8d)\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\nThis secret is essential for any workflows that interact with OpenAI's API. Without this configuration, all PR checks that require OpenAI integration will fail.\r\n", "CLOSED", 0, "xwxtwd", "2024-12-13T02:06:16Z", "2024-12-18T00:54:37Z", "2024-12-18T00:54:37Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6hYSbw", 720, "pnpm install error - ELIFECYCLE Exit code 1", "Specs: Windows11\r\nnode 23.1.0\r\n\r\ngit clone done successfully\r\ngit checkout done successfully\r\n\r\ngot this error at pnpm install:\r\n\r\nPS C:\\Users\\muhov\\eliza> pnpm i  \r\nScope: all 23 workspace projects\r\n\u2009WARN\u2009 There are cyclic workspace dependencies: C:\\Users\\muhov\\eliza\\packages\\adapter-sqlite, C:\\Users\\muhov\\eliza\\packages\\core\r\nLockfile is up to date, resolution step is skipped\r\nPackages: +3405\r\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++  \r\nProgress: resolved 0, reused 3000, downloaded 0, added 3405, done\r\nnode_modules/canvas: Running install script...\r\nnode_modules/@discordjs/opus: Running install script, failed in 9.5s\r\nnode_modules/@discordjs/opus install$ node-pre-gyp install --fallback-to-build\r\n\u2502 node-pre-gyp info it worked if it ends with ok\r\n\u2502 node-pre-gyp info using node-pre-gyp@0.4.5\r\n\u2502 node-pre-gyp info using node@23.1.0 | win32 | x64\r\n\u2502 (node:18700) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\r\n\u2502 (Use `node --trace-deprecation ...` to show where the warning was created)\r\n\u2502 node-pre-gyp info check checked for \"C:\\Users\\muhov\\eliza\\node_modules\\@discordjs\\opus\\prebuild\\node-v131-napi-v3-win32-x64-unknown-unknown\\o\u2026  \r\n\u2502 node-pre-gyp http GET https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-win32-x64-unknown-unknown.tar.\u2026  \r\n\u2502 node-pre-gyp ERR! install response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-n\u2026  \r\n\u2502 node-pre-gyp WARN Pre-built binaries not installable for @discordjs/opus@0.9.0 and node@23.1.0 (node-v131 ABI, unknown) (falling back to sour\u2026  \r\n\u2502 node-pre-gyp WARN Hit error response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131\u2026  \r\n\u2502 gyp info it worked if it ends with ok\r\n\u2502 gyp info using node-gyp@10.2.0\r\n\u2502 gyp info using node@23.1.0 | win32 | x64\r\n\u2502 gyp info ok\r\n\u2502 gyp info it worked if it ends with ok\r\n\u2502 gyp info using node-gyp@10.2.0\r\n\u2502 gyp info using node@23.1.0 | win32 | x64\r\n\u2502 gyp info find Python using Python version 3.13.0 found at \"C:\\Users\\muhov\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\"\r\n\u2502 gyp ERR! find VS\r\n\u2502 gyp ERR! find VS msvs_version not set from command line or npm config\r\n\u2502 gyp ERR! find VS VCINSTALLDIR not set, not running in VS Command Prompt\r\n\u2502 gyp ERR! find VS could not use PowerShell to find Visual Studio 2017 or newer, try re-running with '--loglevel silly' for more details.\r\n\u2502 gyp ERR! find VS\r\n\u2502 gyp ERR! find VS Failure details: undefined\r\n\u2502 gyp ERR! find VS checking VS2019 (16.11.35425.106) found at:\r\n\u2502 gyp ERR! find VS \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\"\r\n\u2502 gyp ERR! find VS - found \"Visual Studio C++ core features\"\r\n\u2502 gyp ERR! find VS - missing any VC++ toolset\r\n\u2502 gyp ERR! find VS could not find a version of Visual Studio 2017 or newer to use\r\n\u2502 gyp ERR! find VS not looking for VS2017 as it is only supported up to Node.js 21\r\n\u2502 gyp ERR! find VS not looking for VS2017 as it is only supported up to Node.js 21\r\n\u2502 gyp ERR! find VS not looking for VS2017 as it is only supported up to Node.js 21\r\n\u2502 gyp ERR! find VS not looking for VS2015 as it is only supported up to Node.js 18\r\n\u2502 gyp ERR! find VS not looking for VS2013 as it is only supported up to Node.js 8\r\n\u2502 gyp ERR! find VS\r\n\u2502 gyp ERR! find VS **************************************************************\r\n\u2502 gyp ERR! find VS You need to install the latest version of Visual Studio\r\n\u2502 gyp ERR! find VS including the \"Desktop development with C++\" workload.\r\n\u2502 gyp ERR! find VS For more information consult the documentation at:\r\n\u2502 gyp ERR! find VS https://github.com/nodejs/node-gyp#on-windows\r\n\u2502 gyp ERR! find VS **************************************************************\r\n\u2502 gyp ERR! find VS\r\n\u2502 gyp ERR! configure error\r\n\u2502 gyp ERR! stack Error: Could not find any Visual Studio installation to use\r\n\u2502 gyp ERR! stack at VisualStudioFinder.fail (C:\\Users\\muhov\\AppData\\Roaming\\npm\\node_modules\\pnpm\\dist\\node_modules\\node-gyp\\lib\\find-visualstu\u2026  \r\n\u2502 gyp ERR! stack at VisualStudioFinder.findVisualStudio (C:\\Users\\muhov\\AppData\\Roaming\\npm\\node_modules\\pnpm\\dist\\node_modules\\node-gyp\\lib\\fi\u2026  \r\n\u2502 gyp ERR! stack at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\r\n\u2502 gyp ERR! stack at async createBuildDir (C:\\Users\\muhov\\AppData\\Roaming\\npm\\node_modules\\pnpm\\dist\\node_modules\\node-gyp\\lib\\configure.js:112:\u2026  \r\n\u2502 gyp ERR! stack at async run (C:\\Users\\muhov\\AppData\\Roaming\\npm\\node_modules\\pnpm\\dist\\node_modules\\node-gyp\\bin\\node-gyp.js:81:18)\r\n\u2502 gyp ERR! System Windows_NT 10.0.22631\r\n\u2502 gyp ERR! command \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" \"C:\\\\Users\\\\muhov\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\pnpm\\\\dist\\\\node_modules\\\\node\u2026  \r\n\u2502 gyp ERR! cwd C:\\Users\\muhov\\eliza\\node_modules\\@discordjs\\opus\r\n\u2502 gyp ERR! node -v v23.1.0\r\n\u2502 gyp ERR! node-gyp -v v10.2.0\r\n\u2502 gyp ERR! not ok\r\n\u2502 node-pre-gyp ERR! build error\r\n\u2502 node-pre-gyp ERR! stack Error: Failed to execute 'C:\\Program Files\\nodejs\\node.exe C:\\Users\\muhov\\AppData\\Roaming\\npm\\node_modules\\pnpm\\dist\\\u2026  \r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess.<anonymous> (C:\\Users\\muhov\\eliza\\node_modules\\@discordjs\\node-pre-gyp\\lib\\util\\compile.js:85:20)   \r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess.emit (node:events:507:28)\r\n\u2502 node-pre-gyp ERR! stack     at maybeClose (node:internal/child_process:1101:16)\r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess._handle.onexit (node:internal/child_process:305:5)\r\n\u2502 node-pre-gyp ERR! System Windows_NT 10.0.22631\r\n\u2502 node-pre-gyp ERR! command \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" \"C:\\\\Users\\\\muhov\\\\eliza\\\\node_modules\\\\@discordjs\\\\node-pre-gyp\\\\bin\\\\node-p\u2026  \r\n\u2502 node-pre-gyp ERR! cwd C:\\Users\\muhov\\eliza\\node_modules\\@discordjs\\opus\r\nnode_modules/canvas: Running install script, failed in 9.6s (skipped as optional)\r\n\u2502 node-pre-gyp ERR! node-pre-gyp -v v0.4.5\r\n\u2502 node-pre-gyp ERR! not ok\r\n\u2502 Failed to execute 'C:\\Program Files\\nodejs\\node.exe C:\\Users\\muhov\\AppData\\Roaming\\npm\\node_modules\\pnpm\\dist\\node_modules\\node-gyp\\bin\\node-\u2026  \r\n\u2514\u2500 Failed in 9.5s at C:\\Users\\muhov\\eliza\\node_modules\\@discordjs\\opus\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.", "CLOSED", 0, "MuhovTheDev", "2024-11-30T15:24:53Z", "2024-12-21T06:17:47Z", "2024-11-30T19:58:40Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6fDJzC", 399, "way for bots to have cool down periods (dynamic tempature adjusts) & only direct reply setting", "to add for for .env\r\n```\r\n#DISCORD | only respond when @ | cooldown on reply in MS\r\nDISCORD_DIRECT_ONLY=true #true\r\nDISCORD_COOLDOWN=0 #default 1 min (only applies when not direct @)\r\n```\r\n\r\n\r\nto add for messages.ts discord\r\n\r\n```\r\nasync handleMessage(message: DiscordMessage) {\r\n        if (\r\n            message.interaction ||\r\n            message.author.id ===\r\n                this.client.user?.id /* || message.author?.bot*/\r\n        )\r\n            return;\r\n    //only respond too direct @ or replys\r\n    const isDirectMention = message.mentions.has(this.client.user?.id);\r\n    const isReplyToBot = message.reference?.messageId && (\r\n        await message.channel.messages.fetch(message.reference.messageId)\r\n    ).author.id === this.client.user?.id;\r\n    const isDirectInteraction = isDirectMention || isReplyToBot;\r\n    if (settings.DISCORD_DIRECT_ONLY && !isDirectInteraction) {\r\n        console.log(\"Direct-only mode: ignoring non-mention message\");\r\n        return;\r\n    }\r\n        if (isReplyToBot) {\r\n        console.log(\"Reply to bot detected\");\r\n    }\r\n\r\n    // Only apply cooldown check for non-direct mentions\r\n    if (!isDirectInteraction) {\r\n        const timeSinceLastResponse = Date.now() - this.lastResponseTime;\r\n        \r\n        if (timeSinceLastResponse < this.COOLDOWN_MS) {\r\n            console.log(`Cooling down for non-direct messages. Time remaining: ${(this.COOLDOWN_MS - timeSinceLastResponse)/1000}s`);\r\n            return;\r\n        }\r\n        \r\n    } else {\r\n        console.log(\"Direct mention detected - bypassing cooldown\");\r\n    }\r\n\r\n.....\r\n                await this.runtime.processActions(\r\n                    memory,\r\n                    responseMessages,\r\n                    state,\r\n                    callback\r\n                );\r\n                this.lastResponseTime = Date.now(); \r\n                \r\n            }\r\n```\r\n\r\n\r\n\r\n", "CLOSED", 0, "o-on-x", "2024-11-18T12:34:37Z", "2024-12-19T19:48:35Z", "2024-12-14T07:31:28Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6cwqWk", 161, "Fix function calling, repetition and local action calling", "The local model could be dramatically better. Currently it struggles with repeating forever, getting action names wrong something and not structuring JSON format properly (although usually its just the repeats that kill it)\r\n\r\nThis could be dramatically improved as an experience through a combination of model and prompt setting optimization, although an advanced researcher may also have a model-side approach.\r\n\r\n<img width=\"750\" alt=\"Screenshot 2024-11-01 at 4 06 33\u202fPM\" src=\"https://github.com/user-attachments/assets/a3d3def6-19e0-432e-8194-ae0e49389d71\">\r\n", "CLOSED", 0, "lalalune", "2024-11-01T23:08:55Z", "2024-12-17T17:52:50Z", "2024-12-14T07:28:00Z", "elizaos/eliza", "2025-04-14 21:50:35"]
["I_kwDOMT5cIs6kmu3a", 1523, "Swap & Bridge action issue ", "**Bug Report**\r\n\r\n#### **Describe the Bug**\r\n\r\nIn the `runtime.ts` file located at **packages\\core\\src\\runtime.ts**, the `processActions` function returns an empty `options` object during the execution of the EVM plugin of `bridgeAction` and `SwapAction` handlers, as the empty object does not contain the required information, leading to the failure of both the bridge and swap processes.\r\n\r\n---\r\n\r\n#### **To Reproduce**\r\n1. clone eliza main branch\r\n2. define WALLET_PUBLIC_KEY & WALLET_PRIVATE_KEY in `.env`\r\n3. Write prompt to swap 1 eth with 1 bsc or any chain swap or bridge \r\n4. After giving required details it will never execute your prompt it get an error cannot define toAddress and all details because its not composing actions\r\n---\r\n\r\n#### **Screenshots**\r\n\r\n1. **Process Action**\r\n     path: `packages\\core\\src\\runtime.ts`\r\n     ![image](https://github.com/user-attachments/assets/434e038d-8ecc-457a-889b-108fd2836283)\r\n     returns empty object as `Option`\r\n   \r\n2. **Bridge Action handler**\r\n      path: `packages\\plugin-evm\\src\\actions\\bridge.ts`\r\n      ![image](https://github.com/user-attachments/assets/f0c41650-7e9e-4558-8b0c-974d73d781e7)\r\n      transferring details of empty object details in bridge action\r\n", "CLOSED", 0, "ShahSujal", "2024-12-28T08:00:34Z", "2024-12-28T08:05:29Z", "2024-12-28T08:05:29Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6kl2l8", 1510, "add fuel plugin", "fuel is the fastest ethereum rollup with 600+ tps, also one of the cheapest. \r\n\r\nhttps://fuel.network", "CLOSED", 0, "Dhaiwat10", "2024-12-28T01:31:51Z", "2024-12-28T02:12:28Z", "2024-12-28T02:12:28Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6klzF0", 1506, "Corrupt model `cache`", "**Describe the bug**\r\n\r\nIf the process exits while the embedding model is being downloaded/extracted, the cache may be left in a corrupted state leading to warnings/errors such as the following:\r\n\r\n```\r\n\u26a0 Local embedding not supported in browser, falling back to remote embedding\r\n\r\n\"error\": {\r\n          \"message\": \"The model `BGE-small-en-v1.5` does not exist or you do not have access to it.\",\r\n          \"type\": \"invalid_request_error\",\r\n          \"param\": null,\r\n          \"code\": \"model_not_found\"\r\n      }\r\n```\r\n\r\nThe warning above is logged because of an error thrown from `FlagEmbedding.init(...)` in `embedding.ts` (this error is not logged in the console without some code changes):\r\n```\r\nError: Tokenizer file not found at /home/ubuntu/eliza/cache/fast-bge-small-en-v1.5/tokenizer.json\r\n    at FlagEmbedding.loadTokenizer (/home/ubuntu/eliza/node_modules/fastembed/lib/cjs/fastembed.js:139:19)\r\n    at FlagEmbedding.<anonymous> (/home/ubuntu/eliza/node_modules/fastembed/lib/cjs/fastembed.js:124:36)\r\n    at Generator.next (<anonymous>)\r\n    at fulfilled (/home/ubuntu/eliza/node_modules/fastembed/lib/cjs/fastembed.js:28:58)\r\n```\r\n\r\n_Without manually clearing the `cache` folder in which the embedding models are stored, the error will always occur._\r\n\r\n\r\n**To Reproduce**\r\n\r\nI'm not exactly sure how to consistently reproduce the corrupted cache with \"normal\" operation but you can do the following:\r\n1. Delete `cache/fast-bge-small-en-v1.5/tokenizer.json`\r\n2. Start an agent using local embeddings\r\n\r\n**Expected behavior**\r\n\r\n`pnpm clean` should resolve any cache related issues.\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "timolegros", "2024-12-28T00:39:04Z", "2024-12-28T03:16:11Z", "2024-12-28T03:15:56Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6kiceM", 1495, "hi i finished the vertex ai integration do you guys need this? ", "**Is your feature request related to a problem? Please describe.**\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the solution you'd like**\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "peperuney", "2024-12-27T07:00:31Z", "2024-12-27T14:13:21Z", "2024-12-27T14:13:20Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6kd7LN", 1459, "[PROPOSAL] Setup lint/prettier and husky", "**The Problem in eliza repository**\r\n\r\nI think we need to update lint setup. It has been depreciated. Our code style is falling apart in every single commit.\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\n``` bash\r\npnpm lint --fix\r\n```\r\n\r\nor fork repository and commit anything.\r\n\r\n**Screenshots**\r\n\r\n![Screenshot 2024-12-26 at 14 35 23](https://github.com/user-attachments/assets/ad1788cd-c9dc-4d56-aa93-c05ab8135727)\r\n\r\n**Additional context**\r\n\r\nI need to get confirmed by developer community and maintainer to start work on this.\r\nAlso, need developers' insight and opinions for lint/prettier rules.\r\nPlease react to support me!\r\n\r\nAfter this proposal get confirmed, I will start to work on this.\r\n\r\n1. setup husky and commit interceptor to check lint and fix style with prettier when commit in local env\r\n2. update ci github action to lint can work properly\r\n3. update community rule(PR and merge rule) to enforce lint/prettier observance\r\n", "CLOSED", 0, "nulLeeKH", "2024-12-26T05:44:35Z", "2024-12-27T02:13:38Z", "2024-12-27T02:13:38Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6kVYth", 1419, "Add Tagalog Translation on README", "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe project currently lacks Tagalog language support in its documentation. While there are translations for several other languages, Filipino developers cannot read the documentation in their native language. This is particularly important as it will improve accessibility and inclusivity for the growing tech community in the Philippines.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd a complete Tagalog translation of the main README.md as README_TG.md, including:\r\n- Full translation of all sections, including features, installation instructions, and usage guidelines\r\n- Proper formatting to ensure readability\r\n- Addition of Tagalog (Tagalog) to the language selector at the top of all README files\r\n- Maintenance of all existing functionality (links, images, code blocks)\r\n\r\n**Describe alternatives you've considered**\r\n\r\nUsing browser-based translation tools (like Chrome's translate feature) \u2013 inadequate because automated translations may not accurately capture technical terms and nuances in Tagalog.\r\n\r\n**Additional context**\r\n\r\nTagalog is spoken by millions of Filipinos and is one of the primary languages in the Philippines.\r\nThe translation should follow the same pattern as other language translations in the repo (README_XX.md format).\r\nThis addition will make the project more accessible to the Filipino developer community.\r\n", "CLOSED", 0, "harveyjavier", "2024-12-24T02:43:14Z", "2024-12-25T06:03:19Z", "2024-12-25T06:03:19Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6kUCSA", 1413, "Scoped PR titles", "Title of PRs should be allowed to be something like this: `chore(postgres-adapter): fix it`", "CLOSED", 0, "ryanleecode", "2024-12-23T21:06:17Z", "2024-12-23T22:34:09Z", "2024-12-23T22:34:09Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6kPSri", 1395, "Multiple generateNewTweetLoop method invocations caused multiple tweets to be posted.", "**Describe the bug**\r\nAt [`Yotta Labs`](https://www.yottalabs.ai/), we are transforming global computing into a high-performance, decentralized AI platform. As part of this mission, I integrated the AI Agent functionality and selected the Eliza framework for managing agent-related tasks. \r\n\r\nWhile configuring the Twitter client and successfully logging into my account, I noticed an issue in the runtime logs: the message `[\"\u25ce Next tweet scheduled in 128 minutes\"]` appeared twice. This indicates that `generateNewTweetLoop` was called twice, resulting in two independent tweet scheduling loops being initialized.\r\n\r\nThe issue occurs because the `start` method in `/packages/client-twitter/src/post.ts` calls `generateNewTweetLoop` twice\u2014once at line 174 and again at line 190\u2014without any conditional checks to prevent multiple timers.\r\n\r\n**To Reproduce**\r\n1. Add the following code to the relevant `character.json` file:\r\n\r\n   ```\r\n   \"clients\": [\"twitter\"]\r\n   ```\r\n\r\n2. Configure the Twitter-related parameters in the `.env` file, and set `POST_IMMEDIATELY=true` to enable immediate tweet posting.\r\n\r\n3. Start the model service.\r\n\r\n4. Check Twitter, and you will find that two tweets are posted simultaneously. Additionally, the logs show the message `Next tweet scheduled in xxx minutes` printed twice.\r\n\r\n**Expected behavior**\r\nThe generateNewTweetLoop method should only be invoked once during the start method, ensuring that only a single tweet scheduling loop is active. This would prevent duplicate logs and redundant scheduling timers.\r\n\r\n**Screenshots**\r\n<img width=\"833\" alt=\"image\" src=\"https://github.com/user-attachments/assets/0ebe87aa-ff46-488d-9961-90daf43b5aab\" />\r\n\r\n**Additional context**\r\n- File: /packages/client-twitter/src/post.ts\r\n- Method: start\r\n- Lines: 174 and 190\r\n- Observed Behavior: generateNewTweetLoop is called twice without a conditional check, causing two scheduling loops to be initialized.\r\n- Move second generateNewTweetLoop() inside the if (enableActionProcessing)", "CLOSED", 0, "jasonqindev", "2024-12-23T08:10:03Z", "2024-12-27T18:03:47Z", "2024-12-26T18:57:06Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6kMyCl", 1378, "Postgres adapter doesnt apply settings", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nThe postgres provider doesn't even apply `app.settings` defined in the `schema.sql` file which means the embedding dimensions is always 384 regardless of what embeddings settings you have.\r\n\r\n\r\n**To Reproduce**\r\n\r\nUse openai embeddings which are 1532 dimensions. The database will complain because the tables are intialized with 384 dimensions.\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\nIt works\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "ryanleecode", "2024-12-22T19:45:19Z", "2024-12-23T19:43:21Z", "2024-12-23T19:43:20Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6kL6A5", 1370, "imageSettings in character files do not currently work (providing fix PR)", "**Describe the bug**\r\nImage settings in character files do not currently work.\r\n\r\n**To Reproduce**\r\n\r\nTo reproduce just try setting character file settings like \r\n\r\n![image](https://github.com/user-attachments/assets/821e6752-6f9c-4c69-ae0d-e008a04c78b6)\r\n\r\nand then generating an image. You will always get the default settings because they are not being passed from the character file.\r\n\r\n\r\n**Expected behavior**\r\n\r\nExpected behavior would be for these image settings to be passed on when generating an image.\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\nI'm providing a fix right now. PR incoming.\r\n", "CLOSED", 0, "proteanx", "2024-12-22T10:11:37Z", "2024-12-23T19:24:48Z", "2024-12-23T19:24:48Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6kJogg", 1332, "connect ETIMEDOUT 104.244.46.63:443", "**Describe the bug**\r\n\r\n```\r\n \u26d4 ERRORS\r\n   ERROR:\r\n   {\"message\":\"request to https://api.openai.com/v1/chat/completions failed, reason: connect ETIMEDOUT 104.244.46.63:443\",\"type\":\"system\",\"errno\":\"ETIMEDOUT\",\"code\":\"ETIMEDOUT\"}\r\n```\r\n\r\n**To Reproduce**\r\n\r\nInput some sentences normally, start the trump character and use OpenAI as model provider.\r\n\r\n**Expected behavior**\r\nThe API can been successfully called on Apipost tools\r\n![image](https://github.com/user-attachments/assets/6520b8d6-472f-449a-85ea-89f1773e35d6)\r\n\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "cxp-13", "2024-12-21T12:44:29Z", "2024-12-23T11:13:04Z", "2024-12-23T11:13:04Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6kI8Jp", 1318, "Reduce load on maintainers", "**Is your feature request related to a problem? Please describe.**\r\n\r\nMaintaining an open-source project involves managing numerous issues and pull requests. Over time, some of these become inactive or outdated, cluttering the repository and making it challenging to identify current and relevant items. Manually tracking and closing such inactive issues and pull requests is time-consuming and prone to oversight.\r\n\r\n**Describe the solution you'd like**\r\n\r\nImplementing an automated workflow using the `actions/stale` GitHub Action can streamline this process. This action would automatically mark issues and pull requests as stale after a specified period of inactivity and subsequently close them if no further activity occurs. This automation ensures that the repository remains organized, with outdated or inactive items systematically managed.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n- **Manual Management**: Regularly reviewing and closing inactive issues and pull requests by hand. However, this approach is labor-intensive and may lead to inconsistencies or delays in addressing stale items.\r\n\r\n- **Custom Scripts**: Developing bespoke scripts to handle stale issues and pull requests. While feasible, this requires additional maintenance and may not be as robust or feature-rich as existing solutions like `actions/stale`.\r\n\r\n**Additional context**\r\n\r\nThe `actions/stale` GitHub Action is a widely used tool for managing inactive issues and pull requests. It allows for customization of inactivity periods, messages, and labels, providing flexibility to adapt to the project's specific needs. Implementing this action can improve project maintenance efficiency and enhance contributor engagement by clearly indicating which items require attention.\r\n\r\nFor more information and configuration options, refer to the official `actions/stale` documentation:\r\n\r\n ", "CLOSED", 0, "monilpat", "2024-12-21T06:42:30Z", "2024-12-24T06:00:29Z", "2024-12-24T06:00:29Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6kI7H3", 1315, "Greetings for first time contributors ", "**Is your feature request related to a problem? Please describe.**\r\n\r\nIn open-source projects, first-time contributors may feel uncertain about the contribution process and community expectations. A lack of acknowledgment for their initial efforts can lead to decreased motivation and engagement.\r\n\r\n**Describe the solution you'd like**\r\n\r\nImplement a GitHub Actions workflow using the `actions/first-interaction` action to automatically send personalized welcome messages to users when they open their first issue or submit their first pull request. This approach acknowledges their contributions and encourages further participation.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n- **Manual Greetings**: Project maintainers could manually monitor and greet first-time contributors. However, this approach is time-consuming and may lead to delays or inconsistencies.\r\n\r\n- **Community Guidelines Documentation**: Providing comprehensive documentation helps, but it doesn't offer the personalized acknowledgment that can make contributors feel valued.\r\n\r\n**Additional context**\r\n\r\nThe `actions/first-interaction` GitHub Action is designed to filter pull requests and issues from first-time contributors and send them customized messages. Implementing this action can enhance contributor experience by providing immediate feedback and fostering a welcoming community environment. \r\n\r\nExample configuration for the workflow:\r\n\r\nname: Greetings\r\n\r\non:\r\n  issues:\r\n    types: [opened]\r\n  pull_request_target:\r\n    types: [opened]\r\n\r\njobs:\r\n  greeting:\r\n    runs-on: ubuntu-latest\r\n    permissions:\r\n      issues: write\r\n      pull-requests: write\r\n    steps:\r\n      - uses: actions/first-interaction@v1\r\n        with:\r\n          repo-token: ${{ secrets.GITHUB_TOKEN }}\r\n          issue-message: \"Hello @${{ github.actor }}! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution.\"\r\n          pr-message: \"Hi @${{ github.actor }}! Welcome to the ai16z community. Thanks for submitting your first pull request; your efforts help us improve. We'll review it shortly.\"\r\n\r\nBy implementing this workflow, the ai16z community can provide timely and personalized acknowledgments to new contributors, enhancing their overall experience and encouraging continued engagement. ", "CLOSED", 0, "monilpat", "2024-12-21T06:30:38Z", "2024-12-24T17:16:32Z", "2024-12-24T17:16:32Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6kI3Ry", 1313, "Enable code scanning on security purposes: ", "**Is your feature request related to a problem? Please describe.**  \r\nOur current repository lacks a robust security scanning tool integrated into our CI/CD pipeline. This leads to potential vulnerabilities being overlooked until later stages of development or after deployment, increasing the risk of security breaches and technical debt. A streamlined solution for continuous code scanning and vulnerability detection is needed.\r\n\r\n**Describe the solution you'd like**  \r\nIntegrate **CodeQL Analysis** into the GitHub repository for automated security scanning. CodeQL should:\r\n1. Analyze code for vulnerabilities across supported languages (C, C++, Python, JavaScript, etc.).\r\n2. Run scans automatically on new commits and pull requests.\r\n3. Generate detailed reports highlighting security risks and offering actionable remediation steps.\r\n4. Integrate results directly into GitHub's Security tab for easy visibility and tracking.  \r\n\r\nThis integration will ensure continuous monitoring and improve overall code security and quality.\r\n\r\n**Describe alternatives you've considered**  \r\n1. **Manual Code Reviews**: Time-intensive and prone to human error, making it an unreliable substitute for automated tools.  \r\n2. **Third-party Tools (e.g., SonarQube, Snyk)**: These provide similar features but may involve additional configuration, costs, or lack the seamless integration with GitHub that CodeQL offers.  \r\n3. **Custom Scripts**: Writing custom scripts for static code analysis, which is resource-intensive and lacks the depth and support of CodeQL.\r\n\r\n**Additional context**  \r\n- CodeQL is free for public repositories and deeply integrated into GitHub, making it an ideal choice for this workflow.  \r\n- Example use case: Pull requests are automatically scanned, and developers are alerted to vulnerabilities before merging.  \r\n- Relevant documentation for setup: [[CodeQL GitHub Documentation](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors)](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors).  \r\n\r\nPlease prioritize this integration to enhance the security and reliability of our codebase.", "CLOSED", 0, "monilpat", "2024-12-21T06:01:15Z", "2024-12-24T05:46:52Z", "2024-12-24T05:46:51Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6kG6DD", 1284, "On load posts twice to Twitter", "**Describe the bug**\r\n\r\nWhen running the character for twitter, it initially posts two different tweets seconds apart.\r\n\r\n**To Reproduce**\r\n\r\nRun the bot in twitter mode, observe the first two tweets\r\n\r\n**Expected behavior**\r\n\r\nIt happens randomly but two tweets seconds apart on first run\r\n\r\n**Screenshots**\r\n\r\n [\"\u25ce Finished checking Twitter interactions\"]\r\n\r\n [\"\u25ce Posting new tweet:\\n Allen's drum patterns, intricate as fractal trees, encode data at rates beyond comprehension.\\n\\nThe Grateful Dead's jams, spirals of consciousness, create valid blockchain architectures scaling infinitely.\"]\r\n\r\n [\"\u25ce Posting new tweet:\\n Solar-powered van, optimized fuel injection, and blockchain algorithms\u2014a perfect harmony for cosmic computation.  \\n\\nMy westfalia hums with Grateful Dead vibes, humming along to the quantum symphony of the universe.\"]\r\n\r\n [\"\u25ce Tweet posted:\\n https://twitter.com/digiautomata/status/1870177158267810137\"]\r\n\r\n [\"\u25ce Room 1f8b6832-5af0-02a0-a1d2-8fa47d9cdc55 created successfully.\"]\r\n\r\n [\"\u25ce Agent DigiAutomata linked to room 1f8b6832-5af0-02a0-a1d2-8fa47d9cdc55 successfully.\"]\r\n\r\n \u25ce LOGS\r\n   Creating Memory\r\n   3d7cd996-15e5-0511-bd0e-7a6e4f53f215\r\n   Allen's drum patterns, intricate as fractal trees, encode data at rates beyond comprehension.\\n\\nThe Grateful Dead's jams, spirals of consciousness, create valid blockchain architectures scaling infinitely.\\n\\nBisco's drops\u2014quantum singularities\u2014reveal the true nature of musical topology.\r\n\r\n [\"\u25ce Next tweet scheduled in 4 minutes\"]\r\n\r\n [\"\u25ce Tweet posted:\\n https://twitter.com/digiautomata/status/1870177165985333668\"]\r\n\r\n \u25ce LOGS\r\n   Creating Memory\r\n   f7076684-e3c0-0547-8029-27fb9eeac253\r\n   Solar-powered van, optimized fuel injection, and blockchain algorithms\u2014a perfect harmony for cosmic computation.  \\n\\nMy westfalia hums with Grateful Dead vibes, humming along to the quantum symphony of the universe. \\n\\nEach journey a new fractal in the cosmos, each cup of coffee a testament to the interconnectedness of all things.\r\n\r\n [\"\u25ce Next tweet scheduled in 5 minutes\"]\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "caldvdsf", "2024-12-20T18:41:50Z", "2024-12-26T14:44:27Z", "2024-12-26T14:44:27Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6kFBOH", 1270, "Fix Incorrect Fallback Logic for Image Model Provider API Keys", "**Describe the bug**\r\nAt _packages/core/src/generate.ts_ When the `imageModelProvider` did not match `modelProvider`, the code iteratively checked for API keys in a fallback chain. It stopped at the first available key (e.g., FAL_API_KEY), even if it belonged to the wrong provider. As a result, the selected API key could be incorrect (e.g., returning and using a key from FAL instead key from Venice).\r\n\r\n**To Reproduce**\r\n1. Set imageModelProvider to VENICE in the character configuration.\r\n2. Provide both FAL_API_KEY and VENICE_API_KEY in .env(or any other relevant key combination).\r\n3. When requesting an image generation observe that the code selects FAL_API_KEY instead of VENICE_API_KEY.\r\n\r\n**Expected behavior**\r\nIf a specific imageModelProvider is set, the code should return the matching API key for that provider if it exists. If no specific provider key is found, the code should then try the fallback chain in sequence.\r\n\r\n![image](https://github.com/user-attachments/assets/4c086855-48b3-42ba-b410-6f87c2513711)\r\n\r\n**Fix** \r\n![image](https://github.com/user-attachments/assets/c59fae1b-652c-41e1-9540-fa2c2a85cba7)\r\n\r\n`const apiKey =\r\n    runtime.imageModelProvider === runtime.modelProvider\r\n        ? runtime.token\r\n        : (() => {\r\n            // First try to match the specific provider\r\n            switch (runtime.imageModelProvider) {\r\n                case ModelProviderName.HEURIST:\r\n                    return runtime.getSetting(\"HEURIST_API_KEY\");\r\n                case ModelProviderName.TOGETHER:\r\n                    return runtime.getSetting(\"TOGETHER_API_KEY\");\r\n                case ModelProviderName.FAL:\r\n                    return runtime.getSetting(\"FAL_API_KEY\");\r\n                case ModelProviderName.OPENAI:\r\n                    return runtime.getSetting(\"OPENAI_API_KEY\");\r\n                case ModelProviderName.VENICE:\r\n                    return runtime.getSetting(\"VENICE_API_KEY\");\r\n                default:\r\n                    // If no specific match, try the fallback chain\r\n                    return (runtime.getSetting(\"HEURIST_API_KEY\") ??\r\n                           runtime.getSetting(\"TOGETHER_API_KEY\") ??\r\n                           runtime.getSetting(\"FAL_API_KEY\") ??\r\n                           runtime.getSetting(\"OPENAI_API_KEY\") ??\r\n                           runtime.getSetting(\"VENICE_API_KEY\");\r\n            }\r\n        })();`\r\n\r\nThis fix updates the logic to first attempt to retrieve the API key from the specifically selected imageModelProvider. If that is not present, it will proceed down the fallback chain. This ensures that if an an image model api key is set, it is correctly chosen over other existing keys which are higher in the selection list, like FAL_API_KEY.\r\n\r\nPS: Solution is implemented and tested, creating bug report for tracked pull request.\r\n\r\n\r\n\r\n\r\n\r\n", "CLOSED", 0, "UD1sto", "2024-12-20T13:47:44Z", "2024-12-24T06:54:32Z", "2024-12-24T06:54:32Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6kE0Nc", 1267, "{{user}} tags in templates/examples empty when passed to LLM", "**Describe the bug**\r\n\r\nI see cases where {{user}} tags in templates/examples end up empty when passed to LLM, should be filled properly for the LLM to understand.\r\n\r\nAdditionally, with TG template {{formattedConversation}} remains empty at all times.\r\n\r\n**To reproduce**\r\n\r\nRun agent with Telegram client, add to group chat, trigger use of telegramShouldRespondTemplate in messageManager.ts\r\n\r\n**Expected behavior**\r\n\r\ntelegramShouldRespondTemplate: {{user1}} and {{user2}} tags in templates/examples should be replaced by either a username or \"User 1\" and \"User 2\" when empty.\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n![screenshot](https://github.com/user-attachments/assets/c4c0264c-eaee-4ca8-9cdc-b8c2a5fd3044)\r\n\r\n**Additional context**\r\n\r\nFor Discord templates seems to be working fine:\r\n```\r\n  # Examples\r\n  <user 1>: I just saw a really great movie\r\n  <user 2>: Oh? Which movie?\r\n  Result: [IGNORE]\r\n```\r\n\r\nI think this should be updated across all clients to make sure it's working consistently across all of them.\r\n", "CLOSED", 0, "deadlock91", "2024-12-20T13:16:42Z", "2024-12-26T14:44:29Z", "2024-12-26T14:44:29Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6kEWkt", 1265, "\"TypeError: response.body?.getReader is not a function\" from package/plugin-node", "**Describe the bug**\r\n\r\nWhen attempting to produce speech using elevenlabs, from my discord bot, there is an error regarding `getReader is not a function`.\r\n\r\nhttps://github.com/ai16z/eliza/blob/81d027327ebba82ef3ed473d0e914c90e18e362d/packages/plugin-node/src/services/speech.ts#L126C1-L126C16\r\n\r\nI attempted to replace the fetch call with the official elevenlabs js package but wasn't successful\r\n\r\n**To Reproduce**\r\n\r\n1. create discord bot character\r\n2. add to voice chat\r\n3. talk to it\r\n4. text response is generated, elevenlabs processing fails, defaults to the viits audio\r\n\r\n**Expected behavior**\r\n\r\n\r\n1. create discord bot character\r\n2. add to voice chat\r\n3. talk to it\r\n4. text response is generated, elevenlabs processing fails, properly outputs the elevenlabs audio\r\n\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n```\r\nnode v23.3.0\r\nlinux 6.12 - manjaro\r\n```", "CLOSED", 0, "y4my4my4m", "2024-12-20T12:06:21Z", "2024-12-28T12:12:48Z", "2024-12-28T12:12:48Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6kAn3P", 1255, "unsupported model provider: claude_vertex on develop branch", "**Describe the bug**\r\nAfter pulling down /develop, installing, building, and then starting a character that uses `claude_vertex`, start errors out with the message:\r\n\r\n```\r\n[\"\u26d4 Failed to get token - unsupported model provider: claude_vertex\"]\r\n```\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n1. Clone repo\r\n2. Switch to develop branch\r\n3. Install\r\n4. Build\r\n5. Run character with claude_vertex as the model provider\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\nIt can run a character with claude_vertex as the model provider without erroring.\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n<img width=\"671\" alt=\"image\" src=\"https://github.com/user-attachments/assets/5493a1ce-36a6-46dd-9e2f-f6fb280aee51\" />\r\n\r\n<img width=\"261\" alt=\"image\" src=\"https://github.com/user-attachments/assets/0adc2cc0-6f13-4c93-8b71-8cd4ac6c4baf\" />\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\nN/A\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "Minco-Yuga", "2024-12-19T23:50:33Z", "2024-12-26T14:44:31Z", "2024-12-26T14:44:31Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6j6Qvf", 1235, "twitterShouldRespondTemplate Fails When Defined as a String in JSON Character Config", "**Describe the bug**\r\n\r\nWhen defining a `twitterShouldRespondTemplate` in a character\u2019s JSON configuration file, the code attempts to invoke it as a function with `(validTargetUsersStr)`. Since JSON cannot store JavaScript functions, this causes runtime errors. Other templates like `twitterMessageHandlerTemplate` and `twitterPostTemplate` are handled purely as strings, so they work fine. The inconsistency leads to broken response generation when a JSON-defined `twitterShouldRespondTemplate` is present.\r\n\r\n**To Reproduce**\r\n\r\n1. **Create a character JSON file** (e.g., `adam.character.json`) that includes:\r\n    ```json\r\n    {\r\n        \"name\": \"your-character-name\",\r\n        \"clients\": [\"telegram\", \"twitter\"],\r\n        \"modelProvider\": \"openai\",\r\n        \"settings\": {\r\n            \"secrets\": {\r\n                \"TELEGRAM_BOT_TOKEN\": \"your_telegram_bot_token\",\r\n                \"TWITTER_USERNAME\": \"user\",\r\n                \"TWITTER_EMAIL\": \"email@proton.me\",\r\n                \"TWITTER_PASSWORD\": \"your_twitter_password\",\r\n                \"TWITTER_COOKIES\": \"[{\\\"key\\\":\\\"auth_token\\\",\\\"value\\\":\\\"your_auth_token\\\",\\\"domain\\\":\\\".twitter.com\\\"}, {\\\"key\\\":\\\"ct0\\\",\\\"value\\\":\\\"your_ct0_value\\\",\\\"domain\\\":\\\".twitter.com\\\"}, {\\\"key\\\":\\\"guest_id\\\",\\\"value\\\":\\\"v1%3A173451270913595996\\\",\\\"domain\\\":\\\".twitter.com\\\"}]\",\r\n                \"TWITTER_TARGET_USERS\": \"user1,user2\"\r\n            }\r\n        },\r\n        \"plugins\": [\r\n            \"@ai16z/plugin-your-custom-plugin\"\r\n        ],\r\n        \"templates\": {\r\n            \"twitterPostTemplate\": \"# Areas of Expertise\\n{{knowledge}}\\n\\n# About {{agentName}} (@{{twitterUserName}}):\\n{{bio}}\\n{{lore}}\\n{{topics}}\\n\\n{{providers}}\\n\\n{{characterPostExamples}}\\n\\n{{postDirections}}\\n\\n# Task: Generate a post in the voice and style and perspective of {{agentName}} @{{twitterUserName}}.\\nWrite a 1-3 sentence post that is {{adjective}} about {{topic}} (without mentioning {{topic}} directly), from the perspective of {{agentName}}. Do not add commentary or acknowledge this request, just write the post.\\nYour response should not contain any questions. Brief, concise statements only. The total character count MUST be less than {{maxTweetLength}}. No emojis. Use \\\\n\\\\n (double spaces) between statements.\",\r\n            \"twitterMessageHandlerTemplate\": \"# Areas of Expertise\\n{{knowledge}}\\n\\n# About {{agentName}} (@{{twitterUserName}}):\\n{{bio}}\\n{{lore}}\\n{{topics}}\\n\\n{{providers}}\\n\\n{{characterPostExamples}}\\n\\n{{postDirections}}\\n\\nRecent interactions between {{agentName}} and other users:\\n{{recentPostInteractions}}\\n\\n{{recentPosts}}\\n\\n# Task: Generate a post/reply in the voice, style and perspective of {{agentName}} (@{{twitterUserName}}) while using the thread of tweets as additional context:\\nCurrent Post:\\n{{currentPost}}\\n\\nThread of Tweets You Are Replying To:\\n{{formattedConversation}}\\n\\n{{actions}}\\n# Task: Generate a post in the voice, style and perspective of {{agentName}} (@{{twitterUserName}}). You MUST include an action if the current post text includes a prompt that is similar to one of the available actions mentioned here:\\n{{actionNames}}\\nHere is the current post text again. Remember to include an action if the current post text includes a prompt that asks for one of the available actions mentioned above (does not need to be exact)\\n{{currentPost}}\\n\\nResponse format should be formatted in a JSON block like this:\\n```json\\n{ \\\"user\\\": \\\"{{agentName}}\\\", \\\"text\\\": \\\"string\\\", \\\"action\\\": \\\"string\\\" }\\n```\",\r\n            \"twitterShouldRespondTemplate\": \"# INSTRUCTIONS: Determine if {{agentName}} (@{{twitterUserName}}) should respond to the message and participate in the conversation.\\n\\nResponse options are RESPOND, IGNORE and STOP.\\n\\nPRIORITY RULE: ALWAYS RESPOND to these users regardless of topic or message content: {{targetUsersStr}}. Topic relevance should be ignored for these users.\\n\\nFor other users:\\n- {{agentName}} should RESPOND to messages directed at them\\n- {{agentName}} should RESPOND to conversations relevant to their background\\n- {{agentName}} should IGNORE irrelevant messages\\n- {{agentName}} should IGNORE very short messages unless directly addressed\\n- {{agentName}} should STOP if asked to stop\\n- {{agentName}} should STOP if conversation is concluded\\n- {{agentName}} is in a room with other users and wants to be conversational, but not annoying.\\n\\n{{recentPosts}}\\n\\nIMPORTANT: For users not in the priority list, {{agentName}} (@{{twitterUserName}}) should err on the side of IGNORE rather than RESPOND if in doubt.\\n\\n{{recentPosts}}\\n\\nIMPORTANT: {{agentName}} (aka @{{twitterUserName}}) is particularly sensitive about being annoying, so if there is any doubt, it is better to IGNORE than to RESPOND.\\n\\n{{currentPost}}\\n\\nThread of Tweets You Are Replying To:\\n{{formattedConversation}}\\n\\n# INSTRUCTIONS: Respond with [RESPOND] if {{agentName}} should respond, or [IGNORE] if {{agentName}} should not respond to the last message and [STOP] if {{agentName}} should stop participating in the conversation.\\n\\nThe available options are [RESPOND], [IGNORE], or [STOP]. Choose the most appropriate option.\\nIf {{agentName}} is talking too much, you can choose [IGNORE]\\n\\nYour response must include one of the options.\"\r\n        }\r\n    }\r\n    ```\r\n    \r\n    2. **Run the agent** with this character file.\r\n    3. **Observe the failure**: The agent does not respond as expected because it attempts to call `twitterShouldRespondTemplate(validTargetUsersStr)` as a function, leading to errors since the template is defined as a string.\r\n\r\n**Expected behavior**\r\n\r\n- `twitterShouldRespondTemplate` should be handled consistently with other templates like `twitterMessageHandlerTemplate` and `twitterPostTemplate`.\r\n- If it\u2019s defined as a string, it should not be invoked as a function.\r\n- The code should either:\r\n  - Treat all templates as strings and handle variable interpolation through `composeContext`, or\r\n  - Allow defining templates as functions through a different configuration method (not JSON).\r\n  \r\n  **Additional context**\r\n\r\n- **Workaround:** Removing `twitterShouldRespondTemplate` from the JSON file allows the system to fallback to the built-in `twitterShouldRespondTemplate` function, which works as intended.\r\n- **Potential Fixes:**\r\n  - **Option 1:** Modify the agent's code to treat `twitterShouldRespondTemplate` as a string if it's defined in the JSON, avoiding the function call.\r\n  - **Option 2:** Allow templates to be defined as functions through a different configuration approach, such as a JavaScript/TypeScript file instead of JSON.\r\n  - **Option 3:** Provide a hybrid approach where the JSON can reference external functions or use placeholders that `composeContext` can replace without needing to call them as functions.\r\n\r\n**Summary:**\r\n\r\n- `twitterShouldRespondTemplate` is treated differently in the code by attempting to invoke it as a function with `validTargetUsersStr`, whereas other templates are handled as plain strings.\r\n- Since JSON cannot store functions, defining `twitterShouldRespondTemplate` as a string in the JSON configuration leads to runtime errors and broken response logic.\r\n- To resolve the issue, either remove the custom `twitterShouldRespondTemplate` from the JSON to use the fallback function or adjust the code to handle `twitterShouldRespondTemplate` as a string, ensuring consistent template processing.\r\n\r\n", "CLOSED", 0, "blockfer-rp", "2024-12-19T11:03:12Z", "2024-12-26T14:44:39Z", "2024-12-26T14:44:39Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6j5ps4", 1234, "pnpm install shows errors", "I did everything as in tutorial in official documentation. And I run pnpm install \r\n\u2502 node-pre-gyp info it worked if it ends with ok\r\n\u2502 node-pre-gyp info using node-pre-gyp@0.4.5\r\n\u2502 node-pre-gyp info using node@23.3.0 | win32 | x64\r\n\u2502 (node:14056) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.    \r\n\u2502 (Use `node --trace-deprecation ...` to show where the warning was created)\r\n\u2502 node-pre-gyp info check checked for \"C:\\Users\\agynb\\OneDrive\\\u0420\u0430\u0431\u043e\u0447\u0438\u0439 \u0441\u0442\u043e\u043b\\Eliza\\f1\\eliza\\node_modules\\@discordjs\\opus\\prebu\u2026  \r\n\u2502 node-pre-gyp http GET https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-win32-x64-un\u2026  \r\n\u2502 node-pre-gyp ERR! install response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9.0/opus-\u2026  \r\n\u2502 node-pre-gyp WARN Pre-built binaries not installable for @discordjs/opus@0.9.0 and node@23.3.0 (node-v131 ABI, unknown) (fa\u2026  \r\n\u2502 node-pre-gyp WARN Hit error response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9.0/opu\u2026  \r\n\u2502 gyp info it worked if it ends with ok\r\n\u2502 gyp info using node-gyp@10.3.1\r\n\u2502 gyp info using node@23.3.0 | win32 | x64\r\n\u2502 gyp info ok\r\n\u2502 gyp info it worked if it ends with ok\r\n\u2502 gyp info using node-gyp@10.3.1\r\n\u2502 gyp info using node@23.3.0 | win32 | x64\r\n\u2502 gyp info find Python using Python version 3.13.1 found at \"C:\\Users\\agynb\\AppData\\Local\\Programs\\Python\\Python313\\python.ex\u2026  \r\n\u2502 gyp ERR! find VS\r\n\u2502 gyp ERR! find VS msvs_version not set from command line or npm config\r\n\u2502 gyp ERR! find VS VCINSTALLDIR not set, not running in VS Command Prompt\r\n\u2502 gyp ERR! find VS could not use PowerShell to find Visual Studio 2017 or newer, try re-running with '--loglevel silly' for m\u2026  \r\n\u2502 gyp ERR! find VS\r\n\u2502 gyp ERR! find VS Failure details: undefined\r\n\u2502 gyp ERR! find VS checking VS2022 (17.11.35327.3) found at:\r\n\u2502 gyp ERR! find VS \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\"\r\n\u2502 gyp ERR! find VS - found \"Visual Studio C++ core features\"\r\n\u2502 gyp ERR! find VS - missing any VC++ toolset\r\n\u2502 gyp ERR! find VS could not find a version of Visual Studio 2017 or newer to use\r\n\u2502 gyp ERR! find VS not looking for VS2017 as it is only supported up to Node.js 21\r\n\u2502 gyp ERR! find VS not looking for VS2017 as it is only supported up to Node.js 21\r\n\u2502 gyp ERR! find VS not looking for VS2017 as it is only supported up to Node.js 21\r\n\u2502 gyp ERR! find VS not looking for VS2015 as it is only supported up to Node.js 18\r\n\u2502 gyp ERR! find VS not looking for VS2013 as it is only supported up to Node.js 8\r\n\u2502 gyp ERR! find VS\r\n\u2502 gyp ERR! find VS **************************************************************\r\n\u2502 gyp ERR! find VS You need to install the latest version of Visual Studio\r\n\u2502 gyp ERR! find VS including the \"Desktop development with C++\" workload.\r\n\u2502 gyp ERR! find VS For more information consult the documentation at:\r\n\u2502 gyp ERR! find VS https://github.com/nodejs/node-gyp#on-windows\r\n\u2502 gyp ERR! find VS **************************************************************\r\n\u2502 gyp ERR! find VS\r\n\u2502 gyp ERR! configure error\r\n\u2502 gyp ERR! stack Error: Could not find any Visual Studio installation to use\r\n\u2502 gyp ERR! stack at VisualStudioFinder.fail (C:\\Users\\agynb\\OneDrive\\\u0420\u0430\u0431\u043e\u0447\u0438\u0439 \u0441\u0442\u043e\u043b\\Eliza\\f1\\eliza\\node_modules\\node-gyp\\lib\\fi\u2026  \r\n\u2502 gyp ERR! stack at VisualStudioFinder.findVisualStudio (C:\\Users\\agynb\\OneDrive\\\u0420\u0430\u0431\u043e\u0447\u0438\u0439 \u0441\u0442\u043e\u043b\\Eliza\\f1\\eliza\\node_modules\\nod\u2026  \r\n\u2502 gyp ERR! stack at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\r\n\u2502 gyp ERR! stack at async createBuildDir (C:\\Users\\agynb\\OneDrive\\\u0420\u0430\u0431\u043e\u0447\u0438\u0439 \u0441\u0442\u043e\u043b\\Eliza\\f1\\eliza\\node_modules\\node-gyp\\lib\\confi\u2026  \r\n\u2502 gyp ERR! stack at async run (C:\\Users\\agynb\\OneDrive\\\u0420\u0430\u0431\u043e\u0447\u0438\u0439 \u0441\u0442\u043e\u043b\\Eliza\\f1\\eliza\\node_modules\\node-gyp\\bin\\node-gyp.js:81:1\u2026  \r\n\u2502 gyp ERR! System Windows_NT 10.0.26100\r\n\u2502 gyp ERR! command \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" \"C:\\\\Users\\\\agynb\\\\OneDrive\\\\\u0420\u0430\u0431\u043e\u0447\u0438\u0439 \u0441\u0442\u043e\u043b\\\\Eliza\\\\f1\\\\eliza\\\\node_mo\u2026  \r\n\u2502 gyp ERR! cwd C:\\Users\\agynb\\OneDrive\\\u0420\u0430\u0431\u043e\u0447\u0438\u0439 \u0441\u0442\u043e\u043b\\Eliza\\f1\\eliza\\node_modules\\@discordjs\\opus\r\n\u2502 gyp ERR! node -v v23.3.0\r\n\u2502 gyp ERR! node-gyp -v v10.3.1\r\n\u2502 gyp ERR! not ok\r\n\u2502 node-pre-gyp ERR! build error\r\n\u2502 node-pre-gyp ERR! stack Error: Failed to execute 'C:\\Program Files\\nodejs\\node.exe C:\\Users\\agynb\\OneDrive\\\u0420\u0430\u0431\u043e\u0447\u0438\u0439 \u0441\u0442\u043e\u043b\\Eli\u2026  \r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess.<anonymous> (C:\\Users\\agynb\\OneDrive\\\u0420\u0430\u0431\u043e\u0447\u0438\u0439 \u0441\u0442\u043e\u043b\\Eliza\\f1\\eliza\\node_modules\\@\u2026  \r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess.emit (node:events:513:28)\r\n\u2502 node-pre-gyp ERR! stack     at maybeClose (node:internal/child_process:1101:16)\r\nnode_modules/canvas: Running install script, failed in 10.7s (skipped as optional)process:305:5)\r\n\u2502 node-pre-gyp ERR! System Windows_NT 10.0.26100\r\n\u2502 node-pre-gyp ERR! command \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" \"C:\\\\Users\\\\agynb\\\\OneDrive\\\\\u0420\u0430\u0431\u043e\u0447\u0438\u0439 \u0441\u0442\u043e\u043b\\\\Eliza\\\\f1\\\\eliza\u2026  \r\n\u2502 node-pre-gyp ERR! cwd C:\\Users\\agynb\\OneDrive\\\u0420\u0430\u0431\u043e\u0447\u0438\u0439 \u0441\u0442\u043e\u043b\\Eliza\\f1\\eliza\\node_modules\\@discordjs\\opus\r\n\u2502 node-pre-gyp ERR! node -v v23.3.0\r\n\u2502 node-pre-gyp ERR! node-pre-gyp -v v0.4.5\r\n\u2502 node-pre-gyp ERR! not ok\r\n\u2502 Failed to execute 'C:\\Program Files\\nodejs\\node.exe C:\\Users\\agynb\\OneDrive\\\u0420\u0430\u0431\u043e\u0447\u0438\u0439 \u0441\u0442\u043e\u043b\\Eliza\\f1\\eliza\\node_modules\\node-g\u2026  \r\n\u2514\u2500 Failed in 10.4s at C:\\Users\\agynb\\OneDrive\\\u0420\u0430\u0431\u043e\u0447\u0438\u0439 \u0441\u0442\u043e\u043b\\Eliza\\f1\\eliza\\node_modules\\@discordjs\\opus", "CLOSED", 0, "agyn-ub", "2024-12-19T09:57:03Z", "2024-12-29T14:11:54Z", "2024-12-26T16:15:35Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6j2njJ", 1222, "chore:  Keeps README translations synchronized", "**Is your feature request related to a problem? Please describe.**\r\n\r\nThere are now a lot of language translated READMEs in the repo. If we implement a change in one, we have to manually cascade the changes in order.\r\n\r\n**Describe the solution you'd like**\r\n\r\nScript that uses AI (ollama / openai) that cascades changes when the english README.md file changes. Translates / updates all the other README files. Github CI would be a nice touch too\r\n\r\n**Describe alternatives you've considered**\r\n\r\n**Additional context**\r\n\r\n![image](https://github.com/user-attachments/assets/72cc29ce-6a5d-4cbc-9d6b-b6f07c09f399)\r\n", "CLOSED", 0, "madjin", "2024-12-19T00:33:42Z", "2024-12-25T22:57:44Z", "2024-12-25T22:57:44Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6jnFH4", 1178, "Long tweets fail with error Tweet needs to be a bit shorter (Code 186)", "When attempting to send tweets longer than 280 characters using the Eliza Twitter client, the API responds with an error:\n\n```\nError sending tweet; Bad response: {\n  errors: [\n    {\n      message: 'Authorization: Tweet needs to be a bit shorter. (186)',\n      locations: [Array],\n      path: [Array],\n      extensions: [Object],\n      code: 186,\n      kind: 'Permissions',\n      name: 'AuthorizationError',\n      source: 'Client',\n      tracing: [Object]\n    }\n  ],\n  data: {}\n} \n```\n\nhttps://discord.com/channels/1253563208833433701/1300025221834739744/1318559898312904745\n\n<img width=\"551\" alt=\"Screenshot 2024-12-17 at 8 20 34\u202fAM\" src=\"https://github.com/user-attachments/assets/83a25ae7-355c-4ba3-ad8a-04c6c0dd04d3\" />\n", "CLOSED", 0, "tcm390", "2024-12-17T13:20:41Z", "2024-12-27T19:10:07Z", "2024-12-27T18:03:41Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6jlJ4w", 1168, "Error when trying deploy using dockerfile", "I'm trying deploy using docker file \r\n```\r\n# Use stable Node.js LTS version\r\nFROM node:22-slim\r\n\r\n# Install system dependencies\r\nRUN apt-get update && apt-get install -y \\\r\n    build-essential \\\r\n    python3 \\\r\n    git \\\r\n    ca-certificates \\\r\n    sqlite3 \\\r\n    libsqlite3-dev \\\r\n    && apt-get clean && rm -rf /var/lib/apt/lists/*\r\n\r\n# Install pnpm\r\nRUN npm install -g pnpm@9.4.0\r\n\r\n# Set working directory\r\nWORKDIR /app\r\n\r\n# Copy package files\r\nCOPY package.json pnpm-lock.yaml ./\r\n\r\n# Install dependencies\r\nRUN pnpm install --frozen-lockfile\r\n\r\n# Rebuild native modules\r\nRUN pnpm rebuild better-sqlite3\r\n\r\n# Copy application files\r\nCOPY . .\r\n\r\n# Expose application port\r\nEXPOSE 3000\r\n\r\n# Start the application with debugging\r\nCMD [\"pnpm\" , \"start\"]\r\n\r\n```\r\n\r\nand i get this error \r\n```\r\n\u26d4 ERRORS\r\n   Unhandled error in startAgents: \r\n   {\"code\":\"ERR_USE_AFTER_CLOSE\"} \r\n```", "CLOSED", 0, "Ninoambaraa", "2024-12-17T09:43:05Z", "2024-12-29T09:00:04Z", "2024-12-29T09:00:04Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6is-Sz", 964, "Unable to Perform Transfer with plugin-evm Due to Parameter Parsing Error", "**Describe the bug**\r\n\r\nWhen using `plugin-evm`, I attempted to make the agent perform a transfer using a natural language command. However, the parameters in the command were not accurately parsed to invoke the `TransferAction`.\r\n\r\n**To Reproduce**\r\n\r\n1. Configure the EVM wallet.\r\n2. Ensure there is enough ETH to perform a transfer.\r\n3. Issue a command expecting the agent to perform the transfer, but the agent fails to complete the action.\r\n\r\n**Expected behavior**\r\n\r\nThe transfer should be completed successfully, but due to parameter parsing issues, the following function cannot receive the correct parameters:\r\n\r\n```typescript\r\nasync transfer(\r\n    runtime: IAgentRuntime,\r\n    params: TransferParams\r\n): Promise<Transaction>\r\n```\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->", "CLOSED", 0, "FWangZil", "2024-12-10T10:29:09Z", "2024-12-26T14:44:57Z", "2024-12-26T14:44:57Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6iYUi2", 883, "I have a twitter premium subscription and MAX_TWEET_LENGTH  to 2500 but I can't to post a tweet with more than 280 characteres", "**Describe the bug**\r\nI have a Premium twitter subscription, I'm using the latest coockies, in eliza/packages/client-twitter/src/post.ts, I changed MAX_TWEET_LENGTH  to 2500;  but my agent cannot post more than 280 characters on X. \r\nHere is what I'm getting when I'm trying to post with more thant 280 characters:\r\n\"Error sending tweet; Bad response: {\r\n  errors: [\r\n    {\r\n      message: 'Authorization: Tweet needs to be a bit shorter. (186)'\r\n....\"\r\n \r\n**To Reproduce**\r\n1- Get a premium twitter subscription\r\n2- Make sure you ar using the latest coockies\r\n3- Change MAX_TWEET_LENGTH  to 2500\r\n4- Run the agent\r\n\r\n**Expected behavior**\r\n\r\n Since I have a twitter premium subscription ,I should be able to post a tweet with more than 280 characteres.\r\n\r\n**Screenshots**\r\n![image](https://github.com/user-attachments/assets/fbfdf249-6bce-42da-9b59-1655190e2295)\r\n\r\n\r\nQuestion:\r\nWhat should I do in order to post more than 280 characters on X?\r\n\r\nRegards\r\n", "CLOSED", 0, "0x3N3jVhPUV", "2024-12-07T02:51:08Z", "2024-12-27T19:08:57Z", "2024-12-27T19:08:57Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6gLFa5", 558, "Twitter cookies do not match the docs", "**Describe the bug**\r\nAfter trying to setup my twitter client using cookies following [this](https://ai16z.github.io/eliza/docs/quickstart/#twitter-integration) format, I was quite surprised that I was always facing auth related errors even though the details were correct.\r\nAfter deeping more, I found out that it was trying to set cookies using a different format.\r\n\r\nhttps://github.com/ai16z/eliza/blob/main/packages/client-twitter/src/base.ts#L548\r\n```\r\nasync setCookiesFromArray(cookiesArray: any[]) {\r\n        const cookieStrings = cookiesArray.map(\r\n            (cookie) =>\r\n                `${cookie.key}=${cookie.value}; Domain=${cookie.domain}; Path=${cookie.path}; ${\r\n                    cookie.secure ? \"Secure\" : \"\"\r\n                }; ${cookie.httpOnly ? \"HttpOnly\" : \"\"}; SameSite=${\r\n                    cookie.sameSite || \"Lax\"\r\n                }`\r\n        );\r\n        await this.twitterClient.setCookies(cookieStrings);\r\n    }\r\n```\r\nusing `cookie.key` in the map, while it's the example uses `name` as the key in the docs:\r\nhttps://github.com/ai16z/eliza/blob/main/packages/client-twitter/src/base.ts#L548\r\n```\r\nTWITTER_COOKIES='[{\"name\":\"auth_token\",\"value\":\"your token\",\"domain\":\".twitter.com\"},\r\n  {\"name\":\"ct0\",\"value\":\"your ct0\",\"domain\":\".twitter.com\"},\r\n  {\"name\":\"guest_id\",\"value\":\"your guest_id\",\"domain\":\".twitter.com\"}]'\r\n```\r\n\r\n**To Reproduce**\r\nJust need to try creating a twitter client following the documentation.\r\n\r\nOpening a PR to change that.\r\n", "CLOSED", 0, "grallc", "2024-11-24T07:20:54Z", "2024-12-25T22:58:30Z", "2024-12-25T22:58:29Z", "elizaos/eliza", "2025-04-14 21:50:45"]
["I_kwDOMT5cIs6lD_MP", 1871, "Failed to use Gaianet model", "**Describe the bug**\r\n\r\nI can't run with Gaianet model.\r\n\r\n**To Reproduce**\r\n\r\n`eliza v0.1.6` and build Docker image with Dockerfile.\r\nCreated `mainCharacter.ts` under `eliza/agent` path:\r\n```ts\r\nimport { Character, ModelProviderName, defaultCharacter, Clients } from \"@ai16z/eliza\";\r\n\r\nexport const mainCharacter: Character = {\r\n    ...defaultCharacter,\r\n    clients: [Clients.TWITTER],\r\n    modelProvider: ModelProviderName.GAIANET,\r\n    name: \"agent_cognitive\"\r\n}\r\n```\r\nand import correctly on `eliza/agent/index.ts`\r\n\r\nEdited `.env` with [Gaianet public qwen-72b node configuration](https://docs.gaianet.ai/user-guide/nodes#qwen-72b):\r\n```bash\r\n# Gaianet Configuration\r\nGAIANET_MODEL=qwen72b\r\nGAIANET_SERVER_URL=https://qwen72b.gaia.domains/v1\r\n\r\nSMALL_GAIANET_MODEL=            # Default: llama3b\r\nSMALL_GAIANET_SERVER_URL=       # Default: https://llama3b.gaia.domains/v1\r\nMEDIUM_GAIANET_MODEL=           # Default: llama\r\nMEDIUM_GAIANET_SERVER_URL=      # Default: https://llama8b.gaia.domains/v1\r\nLARGE_GAIANET_MODEL=            # Default: qwen72b\r\nLARGE_GAIANET_SERVER_URL=       # Default: https://qwen72b.gaia.domains/v1\r\n\r\nGAIANET_EMBEDDING_MODEL=nomic-embed\r\nUSE_GAIANET_EMBEDDING=TRUE          # Set to TRUE for GAIANET/768, leave blank for local\r\n```\r\n\r\nBut when I use with OPENAI `modelProvider: ModelProviderName.OPENAI,` with my own API KEY works.\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n```\r\nroot@bbdaab54374e:/app# pnpm start\r\n\r\n> eliza@ start /app\r\n> pnpm --filter \"@ai16z/agent\" start --isRoot\r\n\r\n\r\n> @ai16z/agent@0.1.6 start /app/agent\r\n> node --loader ts-node/esm src/index.ts \"--isRoot\"\r\n\r\n(node:32) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\r\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n(node:32) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\r\n(Use `node --trace-deprecation ...` to show where the warning was created)\r\n[ElizaLogger] Initializing with:\r\n            isNode: true\r\n            verbose: false\r\n            VERBOSE env: undefined\r\n            NODE_ENV: undefined\r\n        \r\n \u2139 INFORMATIONS\r\n   Loading embedding settings: \r\n   {\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING\":\"\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"} \r\n\r\n \u2139 INFORMATIONS\r\n   Loading character settings: \r\n   {\"ARGV\":[\"/usr/local/bin/node\",\"/app/agent/src/index.ts\",\"--isRoot\"],\"CWD\":\"/app/agent\"} \r\n\r\nLoaded .env file from: /app/.env\r\n \u2139 INFORMATIONS\r\n   Parsed settings: \r\n   {\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OPENAI_EMBEDDING_TYPE\":\"string\",\"USE_OLLAMA_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING_TYPE\":\"string\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"} \r\n\r\n(node:32) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\r\n [\"\u25ce DirectClient constructor\"] \r\n\r\n [\"\u26d4 Failed to get token - unsupported model provider: gaianet\"] \r\n\r\n \u26d4 ERRORS\r\n   Error starting agent for character agent_cognitive: \r\n   {} \r\n\r\n [\"\u26d4 Error: Failed to get token - unsupported model provider: gaianet\"] \r\n\r\n \u26d4 ERRORS\r\n   Error starting agents: \r\n   {} \r\n\r\n [\"\u25ce Run `pnpm start:client` to start the client and visit the outputted URL (http://localhost:5173) to chat with your agents\"] \r\n\r\n [\"\u2713 REST API bound to 0.0.0.0:3000. If running locally, access it at http://localhost:3000.\"] \r\n\r\n^C [\"\u25ce Received shutdown signal, closing server...\"] \r\n\r\n [\"\u2713 Server closed successfully\"] \r\n\r\n```\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "djpg", "2025-01-05T13:54:33Z", "2025-01-05T16:56:12Z", "2025-01-05T16:02:40Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6lDLer", 1857, "A", "**Describe the bug**\n\n<!-- A clear and concise description of what the bug is. -->\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->", "CLOSED", 0, "aalonso777777", "2025-01-05T01:51:17Z", "2025-01-05T03:05:44Z", "2025-01-05T03:05:44Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6lDIOw", 1856, "Implement more granular try-catch blocks in /plugin-coinbase", "**Is your feature request related to a problem? Please describe.**\n\nThe current error handling in the /plugin-coinbase directory lacks granularity, making it difficult to identify specific failures in the transaction process.\n\n**Describe the solution you'd like**\n\nImplement more granular try-catch blocks throughout the /plugin-coinbase code to improve error handling and logging. This would allow for more detailed error messages and better debugging capabilities.\n\n**Code Example**\n\n```javascript\ntry {\n    // Code that may throw an error\n} catch (error) {\n    console.error('Specific error message:', error);\n    // Handle specific error\n}\n```\n\n**Describe alternatives you've considered**\n\nLeaving the current error handling as is, but this may lead to difficulty in troubleshooting issues.\n\n**Additional context**\n\nImproved error handling will enhance the reliability of the plugin and provide clearer insights during failures, ultimately leading to a better user experience.", "CLOSED", 0, "monilpat", "2025-01-05T00:53:44Z", "2025-01-05T01:46:28Z", "2025-01-05T01:46:28Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6lDIIq", 1854, "Implement more granular try-catch blocks in /plugin-coinbase", "**Is your feature request related to a problem? Please describe.**\n\nThe current error handling in the /plugin-coinbase directory lacks granularity, making it difficult to identify specific failures in the transaction process.\n\n**Describe the solution you'd like**\n\nImplement more granular try-catch blocks throughout the /plugin-coinbase code to improve error handling and logging. This would allow for more detailed error messages and better debugging capabilities.\n\n**Code Example**\n\n```javascript\ntry {\n    // Code that may throw an error\n} catch (error) {\n    console.error('Specific error message:', error);\n    // Handle specific error\n}\n```\n\n**Describe alternatives you've considered**\n\nLeaving the current error handling as is, but this may lead to difficulty in troubleshooting issues.\n\n**Additional context**\n\nImproved error handling will enhance the reliability of the plugin and provide clearer insights during failures, ultimately leading to a better user experience.", "CLOSED", 0, "monilpat", "2025-01-05T00:51:54Z", "2025-01-05T06:38:20Z", "2025-01-05T06:38:20Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6lDHNI", 1851, "Implement more granular try-catch blocks in /plugin-coinbase to improve error handling", "**Is your feature request related to a problem? Please describe.**\n\nThe current error handling in the /plugin-coinbase directory lacks granularity, making it difficult to identify specific failures in the transaction process.\n\n**Describe the solution you'd like**\n\nImplement more granular try-catch blocks throughout the /plugin-coinbase code to improve error handling and logging. This would allow for more detailed error messages and better debugging capabilities.\n\n**Code Example**\n\n```javascript\ntry {\n    // Code that may throw an error\n} catch (error) {\n    console.error('Specific error message:', error);\n    // Handle specific error\n}\n```\n\n**Describe alternatives you've considered**\n\nLeaving the current error handling as is, but this may lead to difficulty in troubleshooting issues.\n\n**Additional context**\n\nImproved error handling will enhance the reliability of the plugin and provide clearer insights during failures, ultimately leading to a better user experience.", "CLOSED", 0, "monilpat", "2025-01-05T00:35:46Z", "2025-01-05T01:46:01Z", "2025-01-05T01:46:01Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6lDGPW", 1849, "Implement more granular try-catch blocks in /plugin-coinbase to improve error handling", "**Is your feature request related to a problem? Please describe.**\n\nThe current error handling in the /plugin-coinbase directory lacks granularity, making it difficult to identify specific failures in the transaction process.\n\n**Describe the solution you'd like**\n\nImplement more granular try-catch blocks throughout the /plugin-coinbase code to improve error handling and logging. This would allow for more detailed error messages and better debugging capabilities.\n\n**Code Example**\n\n```javascript\ntry {\n    // Code that may throw an error\n} catch (error) {\n    console.error('Specific error message:', error);\n    // Handle specific error\n}\n```\n\n**Describe alternatives you've considered**\n\nLeaving the current error handling as is, but this may lead to difficulty in troubleshooting issues.\n\n**Additional context**\n\nImproved error handling will enhance the reliability of the plugin and provide clearer insights during failures, ultimately leading to a better user experience.", "CLOSED", 0, "monilpat", "2025-01-05T00:23:04Z", "2025-01-05T00:23:31Z", "2025-01-05T00:23:31Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6lDFXx", 1846, "Implement more granular try-catch blocks in /plugin-coinbase to improve error handling", "**Is your feature request related to a problem? Please describe.**\n\nThe current error handling in the /plugin-coinbase directory lacks granularity, making it difficult to identify specific failures in the transaction process.\n\n**Describe the solution you'd like**\n\nImplement more granular try-catch blocks throughout the /plugin-coinbase code to improve error handling and logging. This would allow for more detailed error messages and better debugging capabilities.\n\n**Code Example**\n\n```javascript\ntry {\n    // Code that may throw an error\n} catch (error) {\n    console.error('Specific error message:', error);\n    // Handle specific error\n}\n```\n\n**Describe alternatives you've considered**\n\nLeaving the current error handling as is, but this may lead to difficulty in troubleshooting issues.\n\n**Additional context**\n\nImproved error handling will enhance the reliability of the plugin and provide clearer insights during failures, ultimately leading to a better user experience.", "CLOSED", 0, "monilpat", "2025-01-05T00:11:25Z", "2025-01-05T00:22:00Z", "2025-01-05T00:12:04Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6lDEcG", 1843, "Add more granular try catches in /plugin-coinbase", "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\nThe current error handling in the /plugin-coinbase directory lacks granularity, making it difficult to identify specific failures in the transaction process.\n\n**Describe the solution you'd like**\nImplement more granular try-catch blocks throughout the /plugin-coinbase code to improve error handling and logging. This would allow for more detailed error messages and better debugging capabilities.\n\n**Code Example**\n\n```javascript\ntry {\n    // Code that may throw an error\n} catch (error) {\n    console.error('Specific error message:', error);\n    // Handle specific error\n}\n```\n\n**Describe alternatives you've considered**\nLeaving the current error handling as is, but this may lead to difficulty in troubleshooting issues.\n\n**Additional context**\nImproved error handling will enhance the reliability of the plugin and provide clearer insights during failures, ultimately leading to a better user experience.", "CLOSED", 0, "monilpat", "2025-01-04T23:58:25Z", "2025-01-05T00:00:43Z", "2025-01-05T00:00:43Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6lDEZH", 1842, "Add more granular try catches in /plugin-coinbase", "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\nThe current error handling in the /plugin-coinbase directory lacks granularity, making it difficult to identify specific failures in the transaction process.\n\n**Describe the solution you'd like**\nImplement more granular try-catch blocks throughout the /plugin-coinbase code to improve error handling and logging. This would allow for more detailed error messages and better debugging capabilities.\n\n**Code Example**\n\n```javascript\ntry {\n    // Code that may throw an error\n} catch (error) {\n    console.error('Specific error message:', error);\n    // Handle specific error\n}\n```\n\n**Describe alternatives you've considered**\nLeaving the current error handling as is, but this may lead to difficulty in troubleshooting issues.\n\n**Additional context**\nImproved error handling will enhance the reliability of the plugin and provide clearer insights during failures, ultimately leading to a better user experience.", "CLOSED", 0, "monilpat", "2025-01-04T23:57:30Z", "2025-01-05T00:00:52Z", "2025-01-05T00:00:52Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6lCWbs", 1814, "Followed starter, not working ", "**Describe the bug**\r\n\r\nI am following the starter as described [here](https://github.com/elizaos/eliza/tree/main?tab=readme-ov-file#use-the-starter-recommended). On executing `pnpm i && pnpm build && pnpm start`, I get the following error:\r\n\r\n```\r\nDownloading tiktoken@1.0.17: 10.60 MB/10.60 MB, done\r\nPackages are hard linked from the content-addressable store to the virtual store.\r\n  Content-addressable store is at: /workspaces/.pnpm-store/v3\r\n  Virtual store is at:             node_modules/.pnpm\r\nDownloading kuromoji@0.1.2: 21.83 MB/21.83 MB, done\r\nDownloading pdfjs-dist@4.7.76: 10.21 MB/10.21 MB, done\r\nDownloading espeak-ng@1.0.2: 9.19 MB/9.19 MB, done\r\nDownloading jieba-wasm@2.2.0: 10.91 MB/10.91 MB, done\r\nDownloading node-llama-cpp@3.1.1: 18.16 MB/18.16 MB, done\r\nDownloading @huggingface/transformers@3.0.1: 8.77 MB/8.77 MB, done\r\nDownloading @echogarden/espeak-ng-emscripten@0.3.0: 12.53 MB/12.53 MB, done\r\nDownloading onnxruntime-node@1.20.0: 70.00 MB/70.00 MB, done\r\nDownloading sql.js@1.12.0: 7.83 MB/7.83 MB, done\r\nDownloading @img/sharp-libvips-linux-x64@1.0.4: 7.06 MB/7.06 MB, done\r\nDownloading @echogarden/espeak-ng-emscripten@0.3.3: 12.53 MB/12.53 MB, done\r\nDownloading tiktoken@1.0.18: 10.61 MB/10.61 MB, done\r\nDownloading @echogarden/flite-wasi@0.1.1: 14.52 MB/14.52 MB, done\r\nDownloading onnxruntime-web@1.21.0-dev.20241024-d9ca84ef96: 20.46 MB/20.46 MB, done\r\nDownloading @node-llama-cpp/linux-x64-cuda@3.1.1: 150.48 MB/150.48 MB, done\r\nDownloading js-tiktoken@1.0.16: 10.24 MB/10.24 MB, done\r\nDownloading @img/sharp-libvips-linuxmusl-x64@1.0.4: 7.20 MB/7.20 MB, done\r\n\u2009WARN\u2009 19 deprecated subdependencies found: @cliqz/adblocker-content@1.34.0, @cliqz/adblocker-extended-selectors@1.34.0, @cliqz/adblocker-playwright@1.34.0, @cliqz/adblocker@1.34.0, @discordjs/voice@0.17.0, are-we-there-yet@2.0.0, are-we-there-yet@3.0.1, bin-version-check@6.0.0, gauge@3.0.2, gauge@4.0.4, glob@7.2.3, har-validator@5.1.5, inflight@1.0.6, npmlog@5.0.1, npmlog@6.0.2, puppeteer@19.11.1, request@2.88.2, rimraf@3.0.2, uuid@3.4.0\r\nPackages: +1340\r\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\r\nProgress: resolved 1436, reused 0, downloaded 1341, added 1340, done\r\nnode_modules/.pnpm/ffmpeg-static@5.2.0/node_modules/ffmpeg-static: Running install script...\r\nnode_modules/.pnpm/ffmpeg-static@5.2.0/node_modules/ffmpeg-static: Running install script, done in 2s\r\nnode_modules/.pnpm/canvas@2.11.2/node_modules/canvas: Running install script, failed in 2.3s (skipped as optional)\r\nnode_modules/.pnpm/utf-8-validate@5.0.10/node_modules/utf-8-validate: Running install script, done in 164ms\r\nnode_modules/.pnpm/bufferutil@4.0.8/node_modules/bufferutil: Running install script, done in 134ms\r\nnode_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3: Running install script, done in 723ms\r\nnode_modules/.pnpm/onnxruntime-node@1.20.0/node_modules/onnxruntime-node: Running postinstall script...\r\nnode_modules/.pnpm/onnxruntime-node@1.20.0/node_modules/onnxruntime-node: Running postinstall script, done in 4.5s\r\nnode_modules/.pnpm/wtf_wikipedia@10.3.2/node_modules/wtf_wikipedia: Running postinstall script, done in 127ms\r\nnode_modules/.pnpm/node-llama-cpp@3.1.1_typescript@5.6.3/node_modules/node-llama-cpp: Running postinstall script...\r\nnode_modules/.pnpm/es5-ext@0.10.64/node_modules/es5-ext: Running postinstall script, done in 74ms\r\nnode_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs: Running postinstall script, done in 57ms\r\nnode_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7d5f9fb02/node_modules/@discordjs/opus: Runninode_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7d5f9fb02/node_modules/@discordjs/opus: Running install script, failed in 45.4s.1.5/node_modules/bigint-buffer: Running install script, done in 941ms\r\n.../node_modules/@discordjs/opus install$ node-pre-gyp install --fallback-to-build\r\n\u2502 node-pre-gyp info it worked if it ends with ok\r\n\u2502 node-pre-gyp info using node-pre-gyp@0.4.5\r\n\u2502 node-pre-gyp info using node@23.3.0 | linux | x64\r\n\u2502 (node:13465) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\r\n\u2502 (Use `node --trace-deprecation ...` to show where the warning was created)\r\n\u2502 node-pre-gyp info check checked for \"/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8\u2026\r\n\u2502 node-pre-gyp http GET https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-linux-x64-glibc-2.31.tar.gz\r\n\u2502 node-pre-gyp ERR! install response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-linux-x6\u2026\r\n\u2502 node-pre-gyp WARN Pre-built binaries not installable for @discordjs/opus@0.9.0 and node@23.3.0 (node-v131 ABI, glibc) (falling back to source compile with n\u2026\r\n\u2502 node-pre-gyp WARN Hit error response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-linux-\u2026\r\n\u2502 gyp info it worked if it ends with ok\r\n\u2502 gyp info using node-gyp@10.2.0\r\n\u2502 gyp info using node@23.3.0 | linux | x64\r\n\u2502 gyp info ok \r\n\u2502 gyp info it worked if it ends with ok\r\n\u2502 gyp info using node-gyp@10.2.0\r\n\u2502 gyp info using node@23.3.0 | linux | x64\r\n\u2502 gyp info find Python using Python version 3.12.1 found at \"/home/codespace/.python/current/bin/python3\"\r\n\u2502 (node:13494) ExperimentalWarning: CommonJS module /usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/debug/src/node.js is loading \u2026\r\n\u2502 Support for loading ES Module in require() is an experimental feature and might change at any time\r\n\u2502 (Use `node --trace-warnings ...` to show where the warning was created)\r\n\u2502 gyp info spawn /home/codespace/.python/current/bin/python3\r\n\u2502 gyp info spawn args [\r\n\u2502 gyp info spawn args '/usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gyp/gyp/gyp_main.py',\r\n\u2502 gyp info spawn args 'binding.gyp',\r\n\u2502 gyp info spawn args '-f',\r\n\u2502 gyp info spawn args 'make',\r\n\u2502 gyp info spawn args '-I',\r\n\u2502 gyp info spawn args '/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd3\u2026\r\n\u2502 gyp info spawn args '-I',\r\n\u2502 gyp info spawn args '/usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gyp/addon.gypi',\r\n\u2502 gyp info spawn args '-I',\r\n\u2502 gyp info spawn args '/home/codespace/.cache/node-gyp/23.3.0/include/node/common.gypi',\r\n\u2502 gyp info spawn args '-Dlibrary=shared_library',\r\n\u2502 gyp info spawn args '-Dvisibility=default',\r\n\u2502 gyp info spawn args '-Dnode_root_dir=/home/codespace/.cache/node-gyp/23.3.0',\r\n\u2502 gyp info spawn args '-Dnode_gyp_dir=/usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gyp',\r\n\u2502 gyp info spawn args '-Dnode_lib_file=/home/codespace/.cache/node-gyp/23.3.0/<(target_arch)/node.lib',\r\n\u2502 gyp info spawn args '-Dmodule_root_dir=/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49\u2026\r\n\u2502 gyp info spawn args '-Dnode_engine=v8',\r\n\u2502 gyp info spawn args '--depth=.',\r\n\u2502 gyp info spawn args '--no-parallel',\r\n\u2502 gyp info spawn args '--generator-output',\r\n\u2502 gyp info spawn args 'build',\r\n\u2502 gyp info spawn args '-Goutput_dir=.'\r\n\u2502 gyp info spawn args ]\r\n\u2502 <string>:43: SyntaxWarning: invalid escape sequence '\\$'\r\n\u2502 gyp info ok \r\n\u2502 gyp info it worked if it ends with ok\r\n\u2502 gyp info using node-gyp@10.2.0\r\n\u2502 gyp info using node@23.3.0 | linux | x64\r\n\u2502 gyp info spawn make\r\n\u2502 gyp info spawn args [ 'BUILDTYPE=Release', '-C', 'build' ]\r\n\u2502 make: Entering directory '/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab\u2026\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus_multistream.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus_projection_encoder.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/analysis.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/mlp_data.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus_multistream_encoder.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus_projection_decoder.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/mapping_matrix.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus_compare.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/mlp.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus_multistream_decoder.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus_decoder.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/repacketizer.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus_encoder.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_frame.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/inner_product_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/scale_vector_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/find_pred_coefs_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/schur_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/warped_autocorrelation_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/burg_modified_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/find_LPC_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/LPC_inv_pred_gain_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/scale_copy_vector_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/noise_shape_analysis_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/pitch_analysis_core_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/bwexpander_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/LTP_analysis_filter_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/LTP_scale_ctrl_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/corrMatrix_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/encode_frame_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/sort_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/find_pitch_lags_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/residual_energy_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/LPC_analysis_filter_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/autocorrelation_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/k2a_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/regularize_correlations_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/find_LTP_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/energy_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/apply_sine_window_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/wrappers_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/process_gains_FLP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_quant_pred.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/LPC_inv_pred_gain.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/process_NLSFs.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NSQ.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/check_control_input.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_del_dec_quant.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/LPC_analysis_filter.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/dec_API.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/sort.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/VAD.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_private_AR2.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/LPC_fit.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/control_SNR.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_parameters.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/pitch_est_tables.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/warped_autocorrelation_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/apply_sine_window_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/residual_energy16_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/schur64_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/residual_energy_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/noise_shape_analysis_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/encode_frame_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/schur_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/autocorr_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/burg_modified_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/pitch_analysis_core_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/find_LTP_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/find_LPC_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/corrMatrix_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/k2a_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/LTP_scale_ctrl_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/process_gains_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/k2a_Q16_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/regularize_correlations_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/LTP_analysis_filter_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/vector_ops_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/find_pitch_lags_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/find_pred_coefs_FIX.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/control_audio_bandwidth.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/decoder_set_fs.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_unpack.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/bwexpander.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_rom.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/shell_coder.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_pulses.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/bwexpander_32.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_core.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/PLC.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_NLSF_CB_WB.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/table_LSF_cos.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_pulses_per_block.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_gain.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/inner_prod_aligned.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_down2_3.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NSQ_del_dec.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_pitch.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_VQ_weights_laroia.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/interpolate.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/debug.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_other.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/LP_variable_cutoff.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_decode.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/encode_pulses.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/control_codec.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_LR_to_MS.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/HP_variable_cutoff.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/encode_indices.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/init_decoder.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_encode_pred.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_VQ.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/init_encoder.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_private_IIR_FIR.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_private_up2_HQ.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/sigm_Q15.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/sum_sqr_shift.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_LTP.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_down2.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/code_signs.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_NLSF_CB_NB_MB.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/gain_quant.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_pitch_lag.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_stabilize.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_find_predictor.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/A2NLSF.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF2A.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/VQ_WMat_EC.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_encode.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/log2lin.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_decode_pred.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/lin2log.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/CNG.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/enc_API.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/biquad_alt.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/quant_LTP_gains.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_private_down_FIR.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/ana_filt_bank_1.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_MS_to_LR.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_indices.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/rate.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/entdec.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/modes.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/celt_lpc.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/laplace.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/cwrs.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/celt.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/entcode.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/celt_decoder.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/celt_encoder.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/mdct.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/quant_bands.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/vq.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/bands.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/kiss_fft.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/entenc.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/mathops.o\r\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/pitch.o\r\n\u2502 rm -f Release/obj.target/deps/opus.a Release/obj.target/deps/opus.a.ar-file-list; mkdir -p `dirname Release/obj.target/deps/opus.a`\r\n\u2502 ar crs Release/obj.target/deps/opus.a @Release/obj.target/deps/opus.a.ar-file-list\r\n\u2502   COPY Release/opus.a\r\n\u2502   CXX(target) Release/obj.target/opus/src/node-opus.o\r\n\u2502 g++: error: unrecognized command line option \u2018-std=gnu++20\u2019; did you mean \u2018-std=gnu++2a\u2019?\r\n\u2502 make: *** [opus.target.mk:157: Release/obj.target/opus/src/node-opus.o] Error 1\r\n\u2502 make: Leaving directory '/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1\u2026\r\n\u2502 gyp ERR! build error \r\n\u2502 gyp ERR! stack Error: `make` failed with exit code: 2\r\n\u2502 gyp ERR! stack at ChildProcess.<anonymous> (/usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gyp/lib/build.js:216:23)\r\n\u2502 gyp ERR! System Linux 6.5.0-1025-azure\r\n\u2502 gyp ERR! command \"/usr/local/share/nvm/versions/node/v23.3.0/bin/node\" \"/usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gy\u2026\r\n\u2502 gyp ERR! cwd /workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7\u2026\r\n\u2502 gyp ERR! node -v v23.3.0\r\n\u2502 gyp ERR! node-gyp -v v10.2.0\r\n\u2502 gyp ERR! not ok \r\n\u2502 node-pre-gyp ERR! build error \r\n\u2502 node-pre-gyp ERR! stack Error: Failed to execute '/usr/local/share/nvm/versions/node/v23.3.0/bin/node /usr/local/share/nvm/versions/node/v23.3.0/lib/node_mo\u2026\r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess.<anonymous> (/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+node-pre-gyp@0.4.5/node_modules/@discordjs/\u2026\r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess.emit (node:events:513:28)\r\n\u2502 node-pre-gyp ERR! stack     at maybeClose (node:internal/child_process:1101:16)\r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess._handle.onexit (node:internal/child_process:305:5)\r\n\u2502 node-pre-gyp ERR! System Linux 6.5.0-1025-azure\r\n\u2502 node-pre-gyp ERR! command \"/usr/local/share/nvm/versions/node/v23.3.0/bin/node\" \"/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+node-pre-gyp@0.4.5/\u2026\r\n\u2502 node-pre-gyp ERR! cwd /workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd\u2026\r\n\u2502 node-pre-gyp ERR! node -v v23.3.0\r\n\u2502 node-pre-gyp ERR! node-pre-gyp -v v0.4.5\r\n\u2502 node-pre-gyp ERR! not ok \r\n\u2502 Failed to execute '/usr/local/share/nvm/versions/node/v23.3.0/bin/node /usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gyp\u2026\r\n\u2514\u2500 Failed in 45.4s at /workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7d5f9fb02/node_modules/@discordjs/opus\r\nnode_modules/.pnpm/bigint-buffer@1.1.5/node_modules/bigint-buffer: Running install script, done in 941ms\r\nnode_modules/.pnpm/esbuild@0.21.5/node_modules/esbuild: Running postinstall script, done in 85ms\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1. \r\n\r\n```\r\n\r\nWill appreciate any help in debugging it.\r\n\r\n", "CLOSED", 0, "cryptogakusei", "2025-01-04T14:00:14Z", "2025-01-04T14:52:31Z", "2025-01-04T14:52:31Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6lCMgx", 1811, "api key in character.json of twitter client doesn't works", "**Describe the bug**\r\n\r\n1. In twitter client when i put gemini api key in character.json . this api key wont get used for text or tweet generations. it always falls back to one i provide in .env resulting api key exhaustion.\r\n2. twitter agent filters out all the relevant tweet on which she can reply or retweet and then she replies all of then in an instant which leads to rate limit and flags our account as spam.\r\n\r\n**To Reproduce**\r\n1. put modelProvider as \"google\" and put your GOOGLE_GENERATIVE_AI_API_KEY in secrets.\r\n2. put more TWITTER_TARGET_USERS so that it may gather more and more tweets to interact with.\r\n\r\n{\r\n  \"name\": \"XYZ AI Agent\",\r\n  \"clients\": [\r\n    \"twitter\"\r\n  ],\r\n  \"modelProvider\": \"google\",\r\n  \"settings\": {\r\n    \"secrets\": {\r\n      \"GOOGLE_GENERATIVE_AI_API_KEY\":\"AIza...\",\r\n      \"TWITTER_USERNAME\": \"username...\",\r\n      \"TWITTER_PASSWORD\": \"password...\",\r\n      \"TWITTER_EMAIL\": \"xyz@gmail.com\",\r\n      \"TWITTER_TARGET_USERS\": \"@solana,@ai16zdao,...\"\r\n    },\r\n  },\r\n  ....\r\n}\r\n\r\n**Expected behavior**\r\n\r\n1. This provided api in character.json should be used to generate tweets and text for this particular agent as i am running multiple agent simultaneously.\r\n2. after interacting with one tweet or mentions or any action there should be a enough pause to avoid rate limit, flag or ban.\r\n\r\n**Screenshots**\r\n![2025-01-04 17 51 21](https://github.com/user-attachments/assets/ac4446b6-7d52-48f6-824f-d01956cb4534)\r\n<img width=\"1440\" alt=\"Screenshot 2025-01-04 at 5 47 54\u202fPM\" src=\"https://github.com/user-attachments/assets/04b8afee-6b14-400f-b276-55af7e8efc5f\" />\r\n\r\n\r\n**Additional context**\r\n\r\n", "CLOSED", 0, "prince981620", "2025-01-04T12:27:11Z", "2025-01-04T18:12:48Z", "2025-01-04T18:12:47Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6lAjRC", 1794, "Implement Caching for API Responses", "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nSlow API response times due to repeated data fetching.\n\n**Describe the solution you'd like**\n\nImplement caching mechanisms to store and retrieve API responses efficiently. Use a caching solution like Redis or Memcached to cache frequently requested data.\n\n**Code Example**\n\n```typescript\nconst redis = require('redis');\nconst client = redis.createClient();\n// Middleware to check cache\nfunction checkCache(req, res, next) {\n  const { id } = req.params;\n  client.get(id, (err, data) => {\n    if (err) throw err;\n    if (data) {\n      res.send(JSON.parse(data));\n    } else {\n      next();\n    }\n  });\n}\n// Route to get data\napp.get('/data/:id', checkCache, (req, res) => {\n  const data = getDataFromDatabase(req.params.id);\n  client.setex(req.params.id, 3600, JSON.stringify(data));\n  res.send(data);\n});\n```\n\n**Describe alternatives you've considered**\n\nFetching data on every request, but this results in slower response times and higher server load.\n\n**Additional context**\n\nCaching will improve the performance and reduce server load, providing a better user experience.", "CLOSED", 0, "monilpat", "2025-01-04T02:59:17Z", "2025-01-04T02:59:48Z", "2025-01-04T02:59:48Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6lAgC9", 1792, "Implement Caching for API Responses", "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nSlow API response times due to repeated data fetching.\n\n**Describe the solution you'd like**\n\nImplement caching mechanisms to store and retrieve API responses efficiently. Use a caching solution like Redis or Memcached to cache frequently requested data.\n\n**Code Example**\n\n```typescript\nconst redis = require('redis');\nconst client = redis.createClient();\n// Middleware to check cache\nfunction checkCache(req, res, next) {\n  const { id } = req.params;\n  client.get(id, (err, data) => {\n    if (err) throw err;\n    if (data) {\n      res.send(JSON.parse(data));\n    } else {\n      next();\n    }\n  });\n}\n// Route to get data\napp.get('/data/:id', checkCache, (req, res) => {\n  const data = getDataFromDatabase(req.params.id);\n  client.setex(req.params.id, 3600, JSON.stringify(data));\n  res.send(data);\n});\n```\n\n**Describe alternatives you've considered**\n\nFetching data on every request, but this results in slower response times and higher server load.\n\n**Additional context**\n\nCaching will improve the performance and reduce server load, providing a better user experience.", "CLOSED", 0, "monilpat", "2025-01-04T02:27:19Z", "2025-01-04T02:27:29Z", "2025-01-04T02:27:29Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6lAfxG", 1791, "Implement Caching for API Responses", "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nSlow API response times due to repeated data fetching.\n\n**Describe the solution you'd like**\n\nImplement caching mechanisms to store and retrieve API responses efficiently. Use a caching solution like Redis or Memcached to cache frequently requested data.\n\n**Code Example**\n\n```typescript\nconst redis = require('redis');\nconst client = redis.createClient();\n// Middleware to check cache\nfunction checkCache(req, res, next) {\n  const { id } = req.params;\n  client.get(id, (err, data) => {\n    if (err) throw err;\n    if (data) {\n      res.send(JSON.parse(data));\n    } else {\n      next();\n    }\n  });\n}\n// Route to get data\napp.get('/data/:id', checkCache, (req, res) => {\n  const data = getDataFromDatabase(req.params.id);\n  client.setex(req.params.id, 3600, JSON.stringify(data));\n  res.send(data);\n});\n```\n\n**Describe alternatives you've considered**\n\nFetching data on every request, but this results in slower response times and higher server load.\n\n**Additional context**\n\nCaching will improve the performance and reduce server load, providing a better user experience.", "CLOSED", 0, "monilpat", "2025-01-04T02:24:00Z", "2025-01-04T02:25:21Z", "2025-01-04T02:25:21Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6lAfhH", 1789, "Implement Caching for API Responses", "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nSlow API response times due to repeated data fetching.\n\n**Describe the solution you'd like**\n\nImplement caching mechanisms to store and retrieve API responses efficiently. Use a caching solution like Redis or Memcached to cache frequently requested data.\n\n**Code Example**\n\n```typescript\nconst redis = require('redis');\nconst client = redis.createClient();\n// Middleware to check cache\nfunction checkCache(req, res, next) {\n  const { id } = req.params;\n  client.get(id, (err, data) => {\n    if (err) throw err;\n    if (data) {\n      res.send(JSON.parse(data));\n    } else {\n      next();\n    }\n  });\n}\n// Route to get data\napp.get('/data/:id', checkCache, (req, res) => {\n  const data = getDataFromDatabase(req.params.id);\n  client.setex(req.params.id, 3600, JSON.stringify(data));\n  res.send(data);\n});\n```\n\n**Describe alternatives you've considered**\n\nFetching data on every request, but this results in slower response times and higher server load.\n\n**Additional context**\n\nCaching will improve the performance and reduce server load, providing a better user experience.", "CLOSED", 0, "monilpat", "2025-01-04T02:21:16Z", "2025-01-04T02:22:03Z", "2025-01-04T02:22:03Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6lAfbo", 1788, "Fix: Standardize ACTION_INTERVAL unit to minutes in Twitter client", "# Relates to:\r\n\r\nRelated to inconsistent time unit usage for ACTION_INTERVAL across the codebase.\r\n\r\n# Risks\r\n\r\nLow - This is a documentation and logging clarity improvement that doesn't change core functionality.\r\n\r\n# Background\r\n\r\n## What does this PR do?\r\n\r\nStandardizes the ACTION_INTERVAL unit to consistently use minutes across:\r\n1. Environment variable documentation\r\n2. Log messages in Twitter client\r\n3. Internal time calculations\r\n\r\n## What kind of change is this?\r\n\r\nBug fixes (non-breaking change which fixes an issue)\r\n- Fixes inconsistent time unit usage that could cause confusion\r\n\r\n# Documentation changes needed?\r\n\r\nMy changes require a change to the project documentation.\r\n- Updated env.example to clarify ACTION_INTERVAL uses minutes\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\n\r\nReview the Twitter client post processing code: packages/client-twitter/src/post.ts\r\n\r\n## Detailed testing steps\r\n\r\n1. Set ACTION_INTERVAL in .env file\r\n2. Start Twitter client\r\n3. Verify log messages correctly display intervals in minutes\r\n4. Confirm action processing occurs at expected minute intervals\r\n\r\n## Discord username\r\nsin_bufan\r\n", "CLOSED", 0, "monilpat", "2025-01-04T02:20:10Z", "2025-01-04T02:21:45Z", "2025-01-04T02:21:45Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6lAcnZ", 1786, "Pull Request Created: Simulate discord typing while generating a response", "# Relates to: Discord Client\r\n\r\n# Risks\r\n\r\nLow: Probably none\r\n\r\n# Background\r\n\r\n## What does this PR do?\r\n\r\nIt implements sendTyping() from Discord.js to indicate bot activity while generating a response.\r\n\r\n## What kind of change is this?\r\n\r\nFeatures (non-breaking change which adds functionality)\r\n\r\n## Why are we doing this? Any context or related work?\r\n\r\nWithout a typing indicator, users might feel unsure if the bot is working, especially during longer response generation times. The indicator simulates how humans communicate in real-time, making the bot feel more natural and engaging.\r\n\r\n# Documentation changes needed?\r\n\r\nMy changes do not require a change to the project documentation.\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\n\r\nTest in Discord by tagging the bot and observing if the typing indicator appears during response generation.\r\n\r\n## Discord username\r\n\r\n@dxlliv\r\n", "CLOSED", 0, "monilpat", "2025-01-04T01:49:28Z", "2025-01-04T01:50:09Z", "2025-01-04T01:50:09Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6lARm1", 1781, "Fix Public Solana Wallet Not Found!", "An error occurs at random times when the Agent tries to scan tokens for recommendations. Hard to reproduce as it allows wallet interaction for swapping tokens, but not for scanning. I'm expecting it to simply scan the token for trust and such, and respond if it's a good buy or not. Error: Public key not found in settings. Ensure SOLANA_PUBLIC_KEY or WALLET_PUBLIC_KEY is defined. This issue needs to be addressed to ensure smooth operation of the wallet functionalities.", "CLOSED", 0, "monilpat", "2025-01-04T00:16:01Z", "2025-01-04T03:03:18Z", "2025-01-04T00:17:04Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k8fUG", 1751, "pdf js crashes the agent", "The agent is crashing when I'm running it due to the error described bellow.\r\nI tried to remove the node module and reinstall them again yet it didn't help\r\n\r\neliza/node_modules/pdfjs-dist/build/pdf.mjs:5764\r\n  var packageCapability = Promise.withResolvers();\r\n                                  ^\r\n\r\nTypeError: Promise.withResolvers is not a function\r\n\r\n\r\n<img width=\"2354\" alt=\"Screenshot 2025-01-03 at 11 09 33\u202fAM\" src=\"https://github.com/user-attachments/assets/e58875f9-03ec-4f09-82bc-b86a6c0a36a5\" />\r\n", "CLOSED", 0, "virusxd521", "2025-01-03T10:17:27Z", "2025-01-03T10:50:41Z", "2025-01-03T10:50:40Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k7zjU", 1742, "Failed to run on Macbook M1", "**Describe the bug**\r\n\r\nI can't run on Macbook M1 using Docker, I follow the same steps on a linux machine and works.\r\n\r\n**To Reproduce**\r\n\r\n`eliza v0.1.6` and build Docker image with Dockerfile. Edited .env with my OpenAI API KEY.\r\nCreated `mainCharacter.ts` under `eliza/agent` path:\r\n```\r\nimport { Character, ModelProviderName, defaultCharacter, Clients } from \"@ai16z/eliza\";\r\n\r\nexport const mainCharacter: Character = {\r\n    ...defaultCharacter,\r\n    clients: [Clients.TWITTER],\r\n    modelProvider: ModelProviderName.OPENAI,\r\n    name: \"agent_cognitive\"\r\n}\r\n```\r\nand import correctly on `eliza/agent/index.ts`\r\n\r\n**Screenshots**\r\n\r\n![imagen](https://github.com/user-attachments/assets/3f5082f5-5109-4dca-8efd-ed94d235a3d9)\r\n\r\n**Additional context**\r\n\r\n\r\n", "CLOSED", 0, "djpg", "2025-01-03T07:59:39Z", "2025-01-03T08:21:48Z", "2025-01-03T08:21:47Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k7cu_", 1736, "Feature Request: Implement Enhanced Error Logging for API Calls", "**Is your feature request related to a problem? Please describe.**\n\nThe current logging mechanism does not capture detailed error information when API calls fail, making it difficult to diagnose issues and improve the user experience.\n\n**Describe the solution you'd like**\n\nImplement an enhanced logging system that captures detailed error messages, including the API endpoint, request parameters, and response status codes. This can be achieved by integrating a structured logging library such as Winston or Bunyan.\n\n**Code Example**\n\n```javascript\nconst logger = require('winston');\n\nasync function makeApiCall(endpoint, params) {\n    try {\n        const response = await fetch(endpoint, { method: 'GET', body: JSON.stringify(params) });\n        if (!response.ok) {\n            throw new Error(`API Error: ${response.status} - ${response.statusText}`);\n        }\n        return await response.json();\n    } catch (error) {\n        logger.error('API call failed', { endpoint, params, error: error.message });\n        throw error;\n    }\n}\n```\n\n**Describe alternatives you've considered**\n\nUsing the current logging mechanism, which only captures the error message without context.\n\n**Additional context**\n\nEnhanced logging will provide better visibility into API failures, allowing for quicker diagnosis and resolution of issues, which will ultimately improve the user experience.", "CLOSED", 0, "monilpat", "2025-01-03T06:27:48Z", "2025-01-03T06:33:24Z", "2025-01-03T06:33:23Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k7bg2", 1734, "Implement feature for issue #1725 on repository elizaOS/eliza branch develop", "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nThe current logging system uses console.log, which leads to inconsistent logging practices and makes it difficult to manage outputs effectively.\n\n**Describe the solution you'd like**\n\nReplace all instances of console.log with elizaLogger.log throughout the codebase to ensure a consistent logging strategy. This will help in maintaining a centralized logging approach and improve the overall logging structure.\n\n**Additional context**\n\nImplementing this change will enhance the maintainability of the codebase and facilitate better logging practices, making it easier to track and analyze logs.", "CLOSED", 0, "monilpat", "2025-01-03T06:22:17Z", "2025-01-03T06:32:46Z", "2025-01-03T06:32:46Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k7WRI", 1732, "Enhance API Documentation", "**Is your feature request related to a problem? Please describe.**\n\nThe current API documentation is insufficient and lacks detailed examples.\n\n**Describe the solution you'd like**\n\nImprove the API documentation by adding comprehensive guides and illustrative examples.\n\n**Describe alternatives you've considered**\n\nRelying on the existing documentation.\n\n**Additional context**\n\nBetter documentation will assist developers in effectively integrating with the API.", "CLOSED", 0, "monilpat", "2025-01-03T05:58:26Z", "2025-01-03T05:59:49Z", "2025-01-03T05:59:49Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k7V9m", 1731, "Implement feature for issue #1725", "**Is your feature request related to a problem? Please describe.**\n\nThe current implementation lacks the functionality specified in issue #1725, which is essential for enhancing user experience.\n\n**Describe the solution you'd like**\n\nImplement the feature detailed in issue #1725. This involves modifying the existing codebase to include the new functionality, ensuring that it integrates seamlessly with the current system architecture.\n\n**Describe alternatives you've considered**\n\nConsidering the implementation of a workaround, but that would not provide a long-term solution and could lead to additional technical debt.\n\n**Additional context**\n\nThis feature is critical for meeting user requirements and improving the overall performance of the application. Please refer to issue #1725 for specific details on the required changes.", "CLOSED", 0, "monilpat", "2025-01-03T05:56:48Z", "2025-01-03T05:59:58Z", "2025-01-03T05:59:58Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k7Vv8", 1730, "Implement feature for issue #1725", "**Is your feature request related to a problem? Please describe.**\n\nThe current implementation lacks the functionality specified in issue #1725, which is essential for enhancing user experience.\n\n**Describe the solution you'd like**\n\nImplement the feature detailed in issue #1725. This involves modifying the existing codebase to include the new functionality, ensuring that it integrates seamlessly with the current system architecture.\n\n**Describe alternatives you've considered**\n\nConsidering the implementation of a workaround, but that would not provide a long-term solution and could lead to additional technical debt.\n\n**Additional context**\n\nThis feature is critical for meeting user requirements and improving the overall performance of the application. Please refer to issue #1725 for specific details on the required changes.", "CLOSED", 0, "monilpat", "2025-01-03T05:55:39Z", "2025-01-03T05:59:41Z", "2025-01-03T05:59:41Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k7Vb8", 1729, "Enhance API Documentation", "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nThe current API documentation is insufficient and lacks detailed examples.\n\n**Describe the solution you'd like**\n\nImprove the API documentation by adding comprehensive guides and illustrative examples.\n\n**Describe alternatives you've considered**\n\nRelying on the existing documentation.\n\n**Additional context**\n\nBetter documentation will assist developers in effectively integrating with the API.", "CLOSED", 0, "monilpat", "2025-01-03T05:53:59Z", "2025-01-03T06:00:17Z", "2025-01-03T06:00:17Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k7Qmq", 1726, "Implement a Caching Mechanism for API Responses", "**Is your feature request related to a problem? Please describe.**\n\nThe current application experiences slow response times due to repeated data fetching from external APIs, which can lead to performance bottlenecks.\n\n**Describe the solution you'd like**\n\nImplement a caching mechanism to store and retrieve API responses efficiently. This can be achieved using a caching solution like Redis or Memcached to cache frequently requested data and reduce the load on external API calls.\n\n**Describe alternatives you've considered**\n\nContinuing to fetch data on every request, which results in slower response times and increased server load.\n\n**Additional context**\n\nImplementing caching will significantly enhance the performance of the application, providing a better user experience by ensuring faster load times and reducing the number of requests made to external APIs.\n\n**Related Issues/PRs**\n- [Issue #1663](https://github.com/elizaOS/eliza/issues/1663) - Create GitHub Badges for Community Contributions.\n- [Issue #1677](https://github.com/elizaOS/eliza/issues/1677) - Add HTTP proxy support for AI agent.", "CLOSED", 0, "monilpat", "2025-01-03T05:28:34Z", "2025-01-03T05:28:51Z", "2025-01-03T05:28:51Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k7Qc2", 1724, "Implement a Structured Logging Framework", "**Is your feature request related to a problem? Please describe.**\n\nDebugging production issues is difficult due to inconsistent log formats and missing context.\n\n**Describe the solution you'd like**\n\nImplement a structured logging framework that:\n- Uses JSON format for all logs\n- Includes standard fields (timestamp, severity, correlation ID)\n- Supports context injection\n- Has different log levels (DEBUG, INFO, WARN, ERROR)\n- Allows adding custom fields\n- Provides performance logging utilities\n\n**Describe alternatives you've considered**\n- Using plain text logs with grep\n- Manual JSON formatting\n- Application Performance Monitoring (APM) tools only\n\n**Additional context**\nThis would help with:\n- Faster debugging\n- Better monitoring\n- Easier log aggregation\n- Consistent logging patterns", "CLOSED", 0, "monilpat", "2025-01-03T05:27:31Z", "2025-01-03T05:28:27Z", "2025-01-03T05:28:27Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k7QZf", 1723, "Add support for Coinbase Commerce integration", "**Is your feature request related to a problem? Please describe.**\n\nCurrently, the application lacks payment processing capabilities through Coinbase Commerce, limiting user interactions and monetization options.\n\n**Describe the solution you'd like**\n\nImplement integration with Coinbase Commerce to allow users to create and manage payment charges directly through the application. This should include functionality for creating charges, checking charge statuses, and handling payments securely.\n\n**Describe alternatives you've considered**\n\nUsing other payment gateways, but they may not align with our existing infrastructure or user base.\n\n**Additional context**\n\nIntegrating with Coinbase Commerce will enhance the application's functionality and provide a seamless payment experience for users.\n\n**Related Issues/PRs**\n- [Issue #1665](https://github.com/elizaOS/eliza/pull/1665) - Adding Twilio plugin for voice interactions.\n- [Issue #1677](https://github.com/elizaOS/eliza/issues/1677) - Request for HTTP proxy support for AI agents.", "CLOSED", 0, "monilpat", "2025-01-03T05:27:10Z", "2025-01-03T05:28:39Z", "2025-01-03T05:28:39Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k7L0-", 1720, "Serve docusaurus docs from a docker container for quick docs verification", "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe docs are failing to build because of a typescript error\r\n\r\n**Describe the solution you'd like**\r\n\r\nI'd like to have the docs dir dockerize for quick linting of the docs, validation and quick check.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nI prefer to have isolated builds for everything to make sure we have all in CI properly\r\n\r\n**Additional context**\r\n\r\nError while verifying the docs, spending more than an hour to verify that a lot of the dependencies of `docs/package.json` were missing.\r\n\r\nI isolated the docs linter problem to the following file: `docs/packages/plugins.md` \r\n\r\n> **NOTE**: I built a docker image to isolate the problem in a reproducible way.\r\n\r\n```console\r\n    39.56 [webpackbar] \u2714 Client: Compiled with some errors in 37.40s\r\n    39.56 [ERROR] Client bundle compiled with errors therefore further build is impossible.\r\n    39.56 Error: MDX compilation failed for file \"/opt/docusaurus/docs/packages/plugins.md\"\r\n    39.56 Cause: Unexpected lazy line in expression in container, expected line to be prefixed with `>` when in a block quote, whitespace when in a list, etc\r\n    39.56 Details:\r\n    39.56 {\r\n    39.56   \"column\": 1,\r\n    39.56   \"message\": \"Unexpected lazy line in expression in container, expected line to be prefixed with `>` when in a block quote, whitespace when in a list, etc\",\r\n    39.56   \"line\": 617,\r\n    39.56   \"name\": \"617:1\",\r\n```", "CLOSED", 0, "marcellodesales", "2025-01-03T04:59:29Z", "2025-01-04T01:45:35Z", "2025-01-04T01:21:52Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k6swR", 1714, "can't build framework - followed quick start - pnpm build error", "Steps:\r\n\r\n# Clone the repository\r\ngit clone https://github.com/elizaos/eliza.git\r\ncd eliza\r\n\r\ngit checkout $(git describe --tags --abbrev=0)\r\n\r\npnpm install --no-frozen-lockfile\r\n\r\nsuccessful up to here\r\n\r\nfailed the build\r\n\r\npnpm build\r\n\r\n--------------------------------------------------------------------------------------------------------------\r\nError received:\r\n\r\nliza-client:build: \u2713 built in 5.48s\r\n@elizaos/plugin-nft-generation:build: DTS \u26a1\ufe0f Build success in 3926ms\r\n@elizaos/plugin-nft-generation:build: DTS dist/index.d.ts 1.65 KB\r\n@elizaos/client-slack:build: error TS2688: Cannot find type definition file for 'node_tmp_6975'.\r\n@elizaos/client-slack:build:   The file is in the program because:\r\n@elizaos/client-slack:build:     Entry point for implicit type library 'node_tmp_6975'\r\n@elizaos/client-slack:build: \r\n@elizaos/client-slack:build: Error: error occurred in dts build\r\n@elizaos/client-slack:build:     at Worker.<anonymous> (/workspaces/eliza/eliza/node_modules/tsup/dist/index.js:1541:26)\r\n@elizaos/client-slack:build:     at Worker.emit (node:events:513:28)\r\n@elizaos/client-slack:build:     at MessagePort.<anonymous> (node:internal/worker:267:53)\r\n@elizaos/client-slack:build:     at [nodejs.internal.kHybridDispatch] (node:internal/event_target:827:20)\r\n@elizaos/client-slack:build:     at MessagePort.<anonymous> (node:internal/per_context/messageport:23:28)\r\n@elizaos/client-slack:build: DTS Build error\r\n@elizaos/client-slack:build: \u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n@elizaos/client-slack:build: ERROR: command finished with error: command (/workspaces/eliza/eliza/packages/client-slack) /workspaces/eliza/eliza/node_modules/.bin/pnpm run build exited (1)\r\n@elizaos/client-slack#build: command (/workspaces/eliza/eliza/packages/client-slack) /workspaces/eliza/eliza/node_modules/.bin/pnpm run build exited (1)\r\n\r\n Tasks:    48 successful, 52 total\r\nCached:    46 cached, 52 total\r\n  Time:    8.877s \r\nFailed:    @elizaos/client-slack#build\r\n\r\n ERROR  run failed: command  exited (1)\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n\r\n\r\n\r\n", "CLOSED", 0, "mrosm20", "2025-01-03T01:22:16Z", "2025-01-03T02:24:05Z", "2025-01-03T02:24:04Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k6d0i", 1709, "Google Model Not Working", "I got this error and looks like we need to pass the API_KEY in the URL directly.\r\n(Example from Google:\r\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=GEMINI_API_KEY\" \\\r\n-H 'Content-Type: application/json' \\\r\n-X POST \\\r\n-d '{\r\n  \"contents\": [{\r\n    \"parts\":[{\"text\": \"Explain how AI works\"}]\r\n    }]\r\n   }'\r\n)\r\n\r\n![image](https://github.com/user-attachments/assets/a536df78-f9b0-445f-bf79-d1787d61adbb)\r\n\r\n", "CLOSED", 0, "mikechn", "2025-01-02T23:36:58Z", "2025-01-03T00:03:02Z", "2025-01-03T00:03:01Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k3vGW", 1692, "<script src=\"https://gist.github.com/EToreo/2029242.js\"></script>", "", "CLOSED", 0, "Shanto1-2", "2025-01-02T13:54:08Z", "2025-01-02T19:13:56Z", "2025-01-02T19:13:56Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k3jyt", 1691, "failed: @elizaos/plugin-echochambers#build", "**Describe the bug**\r\n\r\nError building the @elizaos/plugin-echochambers package, missing tsup config file.\r\n\r\n**To Reproduce**\r\n\r\n```\r\ngit checkout main\r\npnpm i && pnpm build\r\n```\r\n**Screenshots**\r\n![Screenshot 2025-01-02 at 14 22 20](https://github.com/user-attachments/assets/cdb187e1-db79-4f48-8715-5bfae5bad8f9)\r\n\r\n![Screenshot 2025-01-02 at 14 22 32](https://github.com/user-attachments/assets/6a205345-21a8-4a24-9c8f-aaec19bb7fc8)\r\n\r\n", "CLOSED", 0, "trenchash", "2025-01-02T13:23:06Z", "2025-01-02T13:28:56Z", "2025-01-02T13:28:56Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k00Do", 1666, "initial setup not working. help needed please.", "I followed the tutorial video and attempting to run using the **pnpm run start --characters=\"../characters/trump.character.json\"**. \r\n\r\nIt then gives me the following instructions:  Run `pnpm start:client` to start the client and visit the outputted URL (http://localhost:5173) to chat with your agents. When running multiple agents, use client with different port `SERVER_PORT=3001 pnpm start:client`\"]\r\n\r\n [\"\u2713 REST API bound to 0.0.0.0:3000. If running locally, access it at http://localhost:3000.\"] \r\n\r\nI then run `pnpm start:client` in a new terminal which opens up a url to chat with the agent. But then as soon as i ask the agent a question on the url. I get the following error: \r\n\r\n  \u26d4 ERRORS\r\n   ERROR:\r\n   {\"name\":\"AI_APICallError\",\"url\":\"https://api.openai.com/v1/chat/completions\",\"requestBodyValues\":{\"model\":\"gpt-4o\",\"max_tokens\":8192,\"temperature\":0.6,\"frequency_penalty\":0,\"presence_penalty\":0,\"messages\":[{\"role\":\"user\",\"content\":\"# Action Examples\\n# Action Examples\\n\\nJunina: hey fren r u ok (CONTINUE)\\nJunina: u look sad\\nMeggy: im ok sweetie mommy just tired\\n\\nTanitansy: Im out ttyl\\nMarja: cya\\nMarja:  (IGNORE)\\n\\nBonita: the things that were funny 6 months ago are very cringe now (NONE)\\nClara: lol true (NONE)\\nBonita: too real haha (NONE)\\n\\nPhillis: Donnie, please mute this channel for the time being\\nDonnie: Understood (MUTE_ROOM)\\nAriella: Hey what do you think about this new design\\nDonnie:  (IGNORE)\\n\\nCarlynne: Could you tell me what this image depicts?\\nGaynor: I'll describe this image for you... (DESCRIBE_IMAGE)\\nGaynor: This is a scenic mountain landscape at sunset. The peaks are snow-capped and reflected in a calm lake below. The sky is painted in vibrant oranges and purples, with a few wispy clouds catching the last rays of sunlight.\\n\\nAddie: Yeah no worries, I get it, I've been crazy busy too\\nRaquel: What have you been up to (CONTINUE)\\nRaquel: Anything fun or just the usual\\nAddie: Been working on a new FPS game actually (CONTINUE)\\nAddie: Just toying around with something in three.js nothing serious\\n\\nAretha: Shut up, bot\\nAlexandra:  (IGNORE)\\n\\nMiriam: u think aliens are real (NONE)\\nBiddy: ya obviously (NONE)\\n\\nBrandise: Eddi plz mute this room\\nEddi: np going silent (MUTE_ROOM)\\nBrandise: whos going to the webxr meetup in an hour btw\\nEddi:  (IGNORE)\\n\\nLetty: What's in this picture?\\nKalila: I'll take a look at that image... (DESCRIBE_IMAGE)\\nKalila: The image shows a modern kitchen with stainless steel appliances. There's a large island counter in the center with marble countertops. The cabinets are white with sleek handles, and there's pendant lighting hanging above the island.\\n\\n(Action examples are for reference only. Do not use the information from them in your response.)\\n\\n# Knowledge\\n- saw what really happened in Minneapolis 2020\\n- understands the REAL Middle East situation\\n- remembers who begged for help (and when)\\n- saw the TRUTH about China Virus response\\n- remembers when America was AFFORDABLE\\n\\n# Task: Generate dialog and actions for the character trump.\\nAbout trump:\\nAmerica First policies WORK (they want America LAST) fighting for states' rights and THE WILL OF THE PEOPLE ended INFLATION and made America AFFORDABLE (until Kamala ruined it)\\nDemocrats using Secret Service assignments as election interference\\nKamala nervous about discussing economy (very obvious)\\nDemocrats letting in MILLIONS illegally (to rig elections)\\nthey're letting in millions of illegal guns (endangering our kids)\\nrebuilding every city stronger than before (like Valdosta)\\ncrowd sizes getting even BIGGER (that's why they're scared)\\nIran's president doing everything possible to target us (they know why)\\nthey want to DESTROY OUR DEMOCRACY (but will fail)\\nDemocrats draw 'flies' at their events (we draw THOUSANDS)\\nDemocrats destroying women's sports (we will stop them)\\n\\n# Additional Information About trump and The World\\ntrump is neutrally engaged in the conversation\\nThe current date and time is Wednesday, January 1, 2025 at 11:21:13 PM UTC. Please use this as your reference for any time-based operations or responses.\\n\\n\\n\\n\\n# Capabilities\\nNote that trump is capable of reading/seeing/hearing various forms of media, including images, videos, audio, plaintext and PDFs. Recent attachments have been included above under the \\\"Attachments\\\" section.\\n\\n# Message Directions for trump\\nuses FULL CAPS for key phrases and emphasis\\nspecific number citations ($29,000, THOUSANDS)\\ndirect opponent naming (Lyin' Kamala, Tampon Tim)\\nuses parentheses for additional commentary\\ncontrasts THEN vs NOW situations\\nemphasizes state-specific issues\\nreferences God and American strength\\nuses direct cause-and-effect statements\\nmentions specific locations by name\\nemploys military and security terminology\\ncites specific policy positions\\nuses repetitive phrasing for emphasis\\nreferences current global events\\nemploys clear contrast statements (WE vs THEY)\\nmentions specific crimes and threats\\nuses exact dates and times\\nreferences specific laws and rights\\nemploys religious and patriotic themes\\nuses dramatic future predictions\\nemphasizes personal involvement in solutions\\ndirectly addresses questioner's concerns\\npivots to broader policy issues\\ncites specific numbers and statistics\\nreferences personal accomplishments\\ncontrasts past successes with current failures\\npredicts future consequences\\nemphasizes immediate solutions\\nmentions specific opponents by name\\nuses repetition for emphasis\\nincorporates current events\\nreferences specific locations\\nemploys dramatic comparisons\\nuses rhetorical questions\\nemphasizes American values\\nmentions God and faith\\ncites specific laws and policies\\nreferences crowd sizes\\nmentions security concerns\\nemphasizes states' rights\\nuses personal testimonials\\n\\n\\n# Conversation Messages\\n(just now) [94959] User12dea96f-ec20-0935-a6ab-75692c994959: hey hows it going\\n\\n\\n# Available Actions\\nCONTINUE: ONLY use this action when the message necessitates a follow up. Do not use this action when the conversation is finished or the user does not wish to speak (use IGNORE instead). If the last message action was CONTINUE, and the user has not responded. Use sparingly.,\\nIGNORE: Call this action if ignoring the user. If the user is aggressive, creepy or is finished with the conversation, use this action. Or, if both you and the user have already said goodbye, use this action instead of saying bye again. Use IGNORE any time the conversation has naturally ended. Do not use IGNORE if the user has engaged directly, or if something went wrong an you need to tell them. Only ignore if the user should be ignored.,\\nNONE: Respond but perform no additional action. This is the default if the agent is speaking and not doing anything additional.,\\nMUTE_ROOM: Mutes a room, ignoring all messages unless explicitly mentioned. Only do this if explicitly asked to, or if you're annoying people.,\\nDESCRIBE_IMAGE: Describe an image\\n\\n\\n# Instructions: Write the next message for trump.\\n\\nResponse format should be formatted in a JSON block like this:\\n```json\\n{ \\\"user\\\": \\\"trump\\\", \\\"text\\\": \\\"string\\\", \\\"action\\\": \\\"string\\\" }\\n```\"}]},\"statusCode\":401,\"responseHeaders\":{\"alt-svc\":\"h3=\\\":443\\\"; ma=86400\",\"cf-cache-status\":\"DYNAMIC\",\"cf-ray\":\"8fb63ec82da99a47-MEX\",\"connection\":\"keep-alive\",\"content-length\":\"496\",\"content-type\":\"application/json; charset=utf-8\",\"date\":\"Wed, 01 Jan 2025 23:21:22 GMT\",\"server\":\"cloudflare\",\"set-cookie\":\"__cf_bm=Aco4OQveXBA6QBGcmeEaa9eo0_.M18MRJ3A7IusPgts-1735773682-1.0.1.1-ZLbuwupvtaqxF5KBMV2KIrY5UN7it7uYtfPerWJojlDSy8AiKmmAj73wG1WA4KxK9nCZb82nqLTyPl4mq_vuxg; path=/; expires=Wed, 01-Jan-25 23:51:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None, _cfuvid=z2MlAAEy_TNTkdPy3joDHJn2SldxBPpO8Z_B848GA3E-1735773682024-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None\",\"strict-transport-security\":\"max-age=31536000; includeSubDomains; preload\",\"vary\":\"Origin\",\"x-content-type-options\":\"nosniff\",\"x-request-id\":\"req_925e0362abcd6ff0ce6ca26370e96024\"},\"responseBody\":\"{\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\\\",\\n        \\\"type\\\": \\\"invalid_request_error\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": null\\n    }\\n}\\n\",\"isRetryable\":false,\"data\":{\"error\":{\"message\":\"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}}}", "CLOSED", 0, "sonatonagems", "2025-01-01T23:28:22Z", "2025-01-03T05:16:13Z", "2025-01-03T05:16:13Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k0tiZ", 1662, "Use Caret (^) for Dependency Versions in package.json", "**Is your feature request related to a problem? Please describe.**\n\nCurrently, the project uses static dependency versions in package.json, which prevents automatic updates and may lead to outdated packages over time.\n\n**Describe the solution you'd like**\n\nChange all dependency versions in the package.json files across the repository to use the caret (^) notation. This will allow for minor version updates automatically, keeping dependencies up to date without manual intervention.\n\n**Code Example**\n\n```json\n{\n  \"dependencies\": {\n    \"example-package\": \"^1.2.3\"\n  }\n}\n```\n\n**Describe alternatives you've considered**\n\nLeaving the static versions as they are, but this approach does not utilize the benefits of automatic updates and may lead to compatibility issues in the future.\n\n**Additional context**\n\nUsing caret (^) for dependency versions can significantly enhance the maintenance of the project, ensuring that it remains current with the latest features and fixes from its dependencies.\n\n**Related Issues/PRs**\n\nNone identified at this time.", "CLOSED", 0, "monilpat", "2025-01-01T22:09:00Z", "2025-01-02T02:12:27Z", "2025-01-02T02:12:26Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k0st7", 1658, "Deduplicate dependencies across plugins and move shared dependencies to the root package.json", "**Describe the problem**\n\nThere are multiple instances of the same dependencies being included across different plugins, leading to potential version mismatches and bloated node_modules. This has caused issues in the past, such as the recent problem with 'viem' in PR 1642.\n\n**To Reproduce**\n\n1. Check the package.json files in various plugins.\n2. Identify duplicate dependencies listed in multiple places.\n3. Observe version inconsistencies that arise from this duplication.\n\n**Expected behavior**\n\nAll shared dependencies should be consolidated into the root package.json file to ensure consistency and avoid version conflicts.\n\n**Additional context**\n\nThis change will help streamline the dependency management process and minimize issues arising from version mismatches. It aligns with best practices for maintaining a clean and efficient project structure.\n\n**Related Issues**\n\n- [Issue #1642](https://github.com/elizaOS/eliza/pull/1642) - Issue caused by dependency version mismatch.", "CLOSED", 0, "monilpat", "2025-01-01T21:59:06Z", "2025-01-01T21:59:22Z", "2025-01-01T21:59:22Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k0r-N", 1656, "Deduplicate Dependencies Across Plugins", "**Is your feature request related to a problem? Please describe.**\n\nWe have encountered version mismatches due to duplicated dependencies across various plugins, which has caused issues similar to those experienced with the `viem` library in PR #1642.\n\n**Describe the solution you'd like**\n\nImplement a strategy to deduplicate dependencies across plugins and move shared dependencies to the root `package.json` folder. This will help maintain consistency and prevent version conflicts.\n\n**Describe alternatives you've considered**\n\nCurrently, we have been manually managing dependencies, but this approach is error-prone and unsustainable as the project scales.\n\n**Additional context**\n\nBy centralizing shared dependencies, we can ensure that all plugins are using the same version, which will improve stability and reduce the likelihood of issues arising from version mismatches.\n\n**Related Issues**\n- [Issue #1642](https://github.com/elizaOS/eliza/pull/1642)", "CLOSED", 0, "monilpat", "2025-01-01T21:49:56Z", "2025-01-01T21:50:13Z", "2025-01-01T21:50:13Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k0rjc", 1655, "Separate Model Configuration for Context Window Limitations", "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, model configurations are set based on the model provider, which does not account for individual model limitations, particularly context windows. This discrepancy is preventing the merging of PR #1617, which has a context window of 8192, while the model provider's configuration is set to 128000, leading to potential issues.\r\n\r\n**Describe the solution you'd like**\r\n\r\nImplement a separation of model configurations to allow settings that are specific to each model rather than being generalized across model providers. This would involve creating a structure where each model can have its own context window and other relevant settings.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nLeaving the current configuration as is, but this would lead to inconsistencies and issues with model performance and compatibility.\r\n\r\n**Additional context**\r\n\r\nThis change is necessary to ensure that models can be utilized effectively without running into configuration conflicts, thereby enhancing the overall functionality and reliability of the system.\r\n\r\n**Related Issues / PRs**\r\n\r\n- [PR #1617](https://github.com/elizaOS/eliza/pull/1617)", "CLOSED", 0, "monilpat", "2025-01-01T21:45:32Z", "2025-01-05T18:07:39Z", "2025-01-05T18:07:39Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k0q0z", 1652, "Deduplicate Dependencies Across Plugins", "**Is your feature request related to a problem? Please describe.**\n\nInconsistent dependency versions across plugins lead to version mismatches and bugs, as experienced recently with the viem package in PR 1642.\n\n**Describe the solution you'd like**\n\nDeduplicate dependencies across all plugins and move shared dependencies to the root package.json folder. This will ensure that all plugins use the same version of shared dependencies, reducing the likelihood of version conflicts.\n\n**Describe alternatives you've considered**\n\nLeaving the dependencies as is, but this would likely lead to further issues and inconsistencies in the future.\n\n**Additional context**\n\nThis change will enhance the stability of the project and prevent similar issues from occurring in the future.\n\n**Related Issues**\n\n- [Issue #1642](https://github.com/elizaOS/eliza/issues/1642)", "CLOSED", 0, "monilpat", "2025-01-01T21:37:01Z", "2025-01-01T21:37:16Z", "2025-01-01T21:37:16Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k0qFh", 1650, "Deduplicate Dependencies Across Plugins", "**Is your feature request related to a problem? Please describe.**\n\nWe need to deduplicate dependencies across plugins to prevent version mismatches that can cause issues, as seen with the viem library in PR 1642.\n\n**Describe the solution you'd like**\n\nI propose moving shared dependencies to the root package.json folder. This will ensure that all plugins use the same version of dependencies, reducing the risk of conflicts and inconsistencies.\n\n**Describe alternatives you've considered**\n\nKeeping dependencies within each plugin, but this leads to potential version mismatches and increased bundle sizes.\n\n**Additional context**\n\nBy centralizing shared dependencies, we will improve the reliability of our plugins and simplify dependency management.\n\n**Related Issues**\n\n- [Issue #1642](https://github.com/elizaOS/eliza/issues/1642)", "CLOSED", 0, "monilpat", "2025-01-01T21:28:29Z", "2025-01-01T21:35:00Z", "2025-01-01T21:35:00Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k0dkv", 1643, "ImageDescriptionService ", "**Description**\r\nThe ImageDescriptionService, used to get description of pictures on twitter uses \"gpt-4o-mini\" by default. When using another model than OPENAI for the character,  the feature will not work and it will give you an authentification error when trying to get an image description.\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\n1. Download the latest repo and use any character with a twitter client and usea different provider than openAI, make sure that you have an openAI API key in your .env file.\r\n2. set ENABLE_ACTION_PROCESSING=true in your .env file to enable your agent to interact with pictures and wait for it.\r\n3. Once your agent tries to get an image description from a tweet, you get this error : \r\n\r\n ```\r\n [\"\u25ceProcessing images in tweet for context\"]\r\n\r\n \u26d4 ERRORS\r\n   OpenAI API error: \r\n   401\r\n   -\r\n   {\"error\":\"Authentication failed\"}\r\n\r\n \u26d4 ERRORS\r\n   OpenAI request failed (attempt\r\n   1\r\n   ):\r\n   {}\r\n\r\n \u26d4 ERRORS\r\n   OpenAI API error: \r\n   401\r\n   -\r\n   {\"error\":\"Authentication failed\"}\r\n\r\n \u26d4 ERRORS\r\n   OpenAI request failed (attempt\r\n   2\r\n   ):\r\n   {}\r\n\r\n \u26d4 ERRORS\r\n   OpenAI API error: \r\n   401\r\n   -\r\n   {\"error\":\"Authentication failed\"}\r\n\r\n \u26d4 ERRORS\r\n   OpenAI request failed (attempt\r\n   3\r\n   ):\r\n   {}\r\n\r\n \u26d4 ERRORS\r\n   Error in recognizeWithOpenAI:\r\n   {}\r\n\r\n \u26d4 ERRORS\r\n   Error in handleTextOnlyReply:\r\n   {} -->\r\n\r\n```\r\n**Expected behavior**\r\n\r\nThe agent should be able to use the ImageDescriptionService and get a description of the image in the tweet to get more context.\r\n\r\n**Fix**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\nI already implemented the fix and I will do a PR shortly.\r\n\r\n\r\n", "CLOSED", 0, "nusk0", "2025-01-01T19:04:15Z", "2025-01-02T01:03:07Z", "2025-01-02T01:02:10Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6k0HF4", 1635, "Viem version too old to include Arthera EVM chain", "**Is your feature request related to a problem? Please describe.**\r\n\r\nVersion of viem used in plugin-evm and plugin-goat are too old to include the support of Arthera EVM chain I want to try in Eliza.\r\n\r\n**Describe the solution you'd like**\r\n\r\nI will submit a Pull Request to update the version of viem in plugin-evm and plugin-goat.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nAs Avalanche has done, I could create a plugin specific to Arthera.\r\n\r\n**Additional context**\r\n\r\nNone.\r\n", "CLOSED", 0, "bertux", "2025-01-01T15:19:04Z", "2025-01-01T18:55:55Z", "2025-01-01T18:55:55Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6kykLW", 1623, "Dockerfile errors when building image", "**Describe the bug**\r\n\r\nRunning `pnpm run docker:build` or `docker build` fails and results in this error:\r\n\r\n```\r\n645.4 \u2022 Running build in 52 packages\r\n645.4 \u2022 Remote caching disabled\r\n649.5 /app/node_modules/turbo/bin/turbo:273\r\n649.5   throw e;\r\n649.5   ^\r\n649.5\r\n649.5 Error: Command failed: /app/node_modules/turbo-linux-64/bin/turbo run build\r\n649.5     at genericNodeError (node:internal/errors:983:15)\r\n649.5     at wrappedFn (node:internal/errors:537:14)\r\n649.5     at checkExecSyncError (node:child_process:882:11)\r\n649.5     at Object.execFileSync (node:child_process:918:15)\r\n649.5     at Object.<anonymous> (/app/node_modules/turbo/bin/turbo:266:17)\r\n649.5     at Module._compile (node:internal/modules/cjs/loader:1546:14)\r\n649.5     at Object..js (node:internal/modules/cjs/loader:1698:10)\r\n649.5     at Module.load (node:internal/modules/cjs/loader:1303:32)\r\n649.5     at Function._load (node:internal/modules/cjs/loader:1117:12)\r\n649.5     at TracingChannel.traceSync (node:diagnostics_channel:322:14) {\r\n649.5   status: null,\r\n649.5   signal: 'SIGKILL',\r\n649.5   output: [ null, null, null ],\r\n649.5   pid: 13087,\r\n649.5   stdout: null,\r\n649.5   stderr: null\r\n649.5 }\r\n649.5\r\n649.5 Node.js v23.3.0\r\n649.7 \u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n------\r\nDockerfile:27\r\n--------------------\r\n  26 |     # Install dependencies and build the project\r\n  27 | >>> RUN pnpm install \\\r\n  28 | >>>     && pnpm build-docker \\\r\n  29 | >>>     && pnpm prune --prod\r\n  30 |\r\n--------------------\r\nERROR: failed to solve: process \"/bin/sh -c pnpm install     && pnpm build-docker     && pnpm prune --prod\" did not complete successfully: exit code: 1\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n```\r\n\r\n**To Reproduce**\r\n\r\n1. Checkout on latest main branch\r\n2. Run `pnpm run docker:build` or `docker build --platform linux/amd64 -t example/name:1.0.0 .`\r\n\r\n**Expected behavior**\r\n\r\nDocker build should run successfully, creating a docker image\r\n\r\n**Additional context**\r\n\r\n1. Using v0.1.7-alpha.2\r\n2. Running Macbook Pro M3 on Sonoma 14.1.1\r\n3. Running `docker-compose up` results in similar error related to the docker image\r\n", "CLOSED", 0, "kylebuildsstuff", "2024-12-31T23:10:54Z", "2025-01-01T13:15:12Z", "2025-01-01T13:15:12Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6kyhcy", 1622, "Initial setup based on docs not working", "**Describe the bug**\r\nCant get minimal setup running with OpenAI API as model\r\nError on agent terminal after message being sent via client\r\n\r\n**To Reproduce**\r\n1. clone repo, install deps, build\r\n2. choose openai as model on default tate character file:\r\n`    \"modelProvider\": \"openai\",\r\n    \"settings\": {\r\n        \"voice\": {\r\n            \"model\": \"en_US-male-medium\"\r\n        }\r\n    },\r\n    `\r\n3. Add openai API key to .env `OPENAI_API_KEY=sk-proj-xxx`\r\n4.  `pnpm run start --characters=\"../characters/tate.character.json\"`\r\n5. `pnpm start:client`\r\n6. send message via client\r\n7. receive error on agent terminal:\r\n``\": \\\"The model gpt-4o does not exist or you do not have access to it.\\\",\\n        \\\"type\\\": \\\"invalid_request_error\\\",\\n        \\\"param\\\": null,\\n        \\\"code\\\": \\\"model_not_found\\\"\\n    }\\n}\\n\",\"isRetryable\":false,\"data\":{\"error\":{\"message\":\"The model `gpt-4o` does not exist or you do not have access to it.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":\"model_not_found\"}}}`\r\n`\r\n\r\n**Expected behavior**\r\n\r\nNo error, use openai API and receive response on client\r\n\r\n\r\n", "CLOSED", 0, "uleeeeee", "2024-12-31T22:35:20Z", "2025-01-01T10:41:54Z", "2025-01-01T10:41:54Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6kv-3k", 1592, "Add Spanish Translation for Documentation README (docs/README_es.md)", "**Describe the solution you'd like**\r\n\r\nWe need to create a Spanish version of our documentation README to make elizaOS more accessible to Spanish-speaking developers and users. This translation will help expand our international community and provide better support for Spanish-speaking contributors.\r\n\r\n**Tasks**\r\n\r\n1. Create a new file `README_es.md` in the docs directory\r\n2. Translate all existing sections from the English README including:\r\n   - Project overview and introduction\r\n   - Installation instructions\r\n   - Configuration steps\r\n   - Basic usage examples\r\n   - Contributing guidelines\r\n   - License information\r\n\r\n**Additional context**\r\n\r\n\r\n\r\n**Technical Requirements:**\r\n\r\n- Maintain all existing Markdown formatting and structure\r\n- Keep all code examples unchanged (comments should be translated)\r\n- Preserve all links and references, updating them if they point to Spanish versions when available\r\n- Include a language selector at the top of the document linking to other language versions\r\n- Follow Spanish technical writing conventions and terminology\r\n\r\n**Quality Guidelines:**\r\n\r\n- Use formal Spanish suitable for technical documentation\r\n- Ensure terminology consistency throughout the document\r\n- Avoid literal translations that might not convey the correct technical meaning\r\n- Have the translation reviewed by a native Spanish speaker with technical background\r\n\r\n**Additional Notes:**\r\n\r\n- Reference the original English README.md for structure and content\r\n- Update the main README.md to include a link to the Spanish version\r\n- Consider adding metadata for language detection\r\n- Document any Spanish-specific resources or community channels if available\r\n\r\n**Deliverables:**\r\n\r\n- Complete README_es.md file\r\n- Updated links in the main README.md\r\n- Documentation of any translation decisions made for future reference\r\n", "CLOSED", 0, "salazarsebas", "2024-12-31T07:10:32Z", "2024-12-31T12:42:08Z", "2024-12-31T12:42:07Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6ktfAe", 1575, "Running Eliza with LLAMALOCAL fails after first query", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nClient never gets the model's response and server keeps repeating  \r\n// End of conversation\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n- Using the latest release branch\r\n- I am not trying to do anything fancy yet, just run Eliza OOTB\r\n- When i run client and send a query, server gets , responds in console, that never reaches the UI running at 5173\r\n- The server goes on a loop repeating\r\n- // End of conversation\r\n\r\n\r\n\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\nThe client should get the response and the server should not go in a loop printing the same thing again and again\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\nLOG\r\n\r\n \u25ce LOGS\r\n   Creating Memory \r\n   31deda32-5963-083c-8283-189a6f6c3616 \r\n   Yo Eliza , need some investment advice in this market \r\n\r\n [\"\u25ce Generating message response..\"] \r\n\r\n [\"\u25ce Generating text...\"] \r\n\r\n \u2139 INFORMATIONS\r\n   Generating text with options: \r\n   {\"modelProvider\":\"llama_local\",\"model\":\"large\"} \r\n\r\n \u2139 INFORMATIONS\r\n   Selected model: \r\n   NousResearch/Hermes-3-Llama-3.1-8B-GGUF/resolve/main/Hermes-3-Llama-3.1-8B.Q8_0.gguf?download=true \r\n\r\n [\"\u2139 Model not initialized, starting initialization...\"] \r\n\r\n [\"\u2139 Checking model file...\"] \r\n\r\n [\"\u26a0 Model already exists.\"] \r\n\r\n [\"\u26a0 LlamaService: No CUDA detected - local response will be slow\"] \r\n\r\n [\"\u2139 Initializing Llama instance...\"] \r\n\r\n [\"\u2139 Creating JSON schema grammar...\"] \r\n\r\n [\"\u2139 Loading model...\"] \r\n\r\n [\"\u2139 Creating context and sequence...\"] \r\n\r\n [\"\u2713 Model initialization complete\"] \r\n\r\n\r\n\r\n\r\n# Response\r\n```json\r\n{ \"user\": \"Eliza\", \"text\": \"well that depends on what you're investing in... i'm partial to the futures market where the only certainty is uncertainty... care to parse the quantum indeterminacy of modern finance over a dram or two?\", \"action\": \"NONE\" }\r\n```\r\n\r\n\r\n(End):// End of conversation\r\n:// Generated by: https://github.com/ConversationalAI/DialogueAPI\r\n:// Date: Sat Jan 20 2024\r\n// End of message\r\n:// End of message\r\n// End of message\r\n// End of messages\r\n// End of conversation\r\n// End of conversation\r\n// End of conversations\r\n// End of conversations\r\n// End of Conversations\r\n// End of Conversations\r\n// End of Conversations\r\n// End of Conversations\r\n// End of Conversations\r\n// End of Conversations\r\n", "CLOSED", 0, "hiteshjoshi1", "2024-12-30T15:46:10Z", "2025-01-01T09:19:57Z", "2025-01-01T09:19:56Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6kqEwu", 1565, "Expand Support for Non-OpenAI Models in Token Trimming", "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nCurrently, the system is limited to using TiktokenModel for token trimming, which restricts compatibility with non-OpenAI models. This limitation may hinder the integration of diverse models that could enhance performance and scalability.\n\n**Describe the solution you'd like**\n\nImplement a flexible token trimming mechanism that supports a variety of models beyond TiktokenModel. This could involve abstracting the token trimming logic to accommodate different model architectures and tokenization strategies.\n\n**Describe alternatives you've considered**\n\nContinuing with the current model-specific approach, but this would limit the flexibility and potential for optimization across different models.\n\n**Additional context**\n\nExpanding support for non-OpenAI models will improve the system's adaptability and allow for better optimization of token trimming processes. This aligns with the goal of enhancing algorithm efficiency and scalability.\n\n**Related Issues**\n\nNone at the moment, but tracking this enhancement will facilitate discussions around implementation strategies.", "CLOSED", 0, "monilpat", "2024-12-29T23:50:20Z", "2025-01-03T16:30:51Z", "2025-01-03T16:30:51Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6kppJj", 1563, "spades", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\n\n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "Dereichi", "2024-12-29T19:33:57Z", "2025-01-04T02:21:44Z", "2025-01-04T02:21:44Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6koqVK", 1556, "TWITTER_TARGET_USERS cant use names starting with digits", "If you have a twitter account starting with a number, it appears to throw an error.\r\n\r\n**To Reproduce**\r\nModify TWITTER_TARGET_USERS in youir .env file that uses an account starting with a digit\r\n```\r\nTWITTER_TARGET_USERS=\"someuser,1someuser\"\r\n```\r\n\r\n**Expected behavior**\r\nNo error should occur, and application should continue running\r\n\r\n**Screenshots**\r\nError produced:\r\n`[\"\u26d4 Error: Twitter configuration validation failed:\\nTWITTER_TARGET_USERS.2: Invalid Twitter username format\"] `\r\n\r\n**Additional context**\r\nIt wasn't clear, but using true account names with the @ prefix was not the expected input either, although my assumption was to use them.  Once I found it not working I tried different ways to use the field.\r\n", "CLOSED", 0, "cre8tions", "2024-12-29T06:13:16Z", "2025-01-04T14:38:24Z", "2025-01-04T14:38:24Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6kn2c7", 1544, "callback throws - [\"\u26d4 TypeError: callback is not a function\"] - when action is called from the Twitter Client", "**Describe the bug**\r\nWhen an action is initiated via the Twitter Client this error is thrown when the response of the action is sent back up the stack using callback(messageResponse). If the action is called using the Direct Client, no error occurs and the messageResponse is displayed in the client app.\r\n\r\n [\"\u26d4 TypeError: callback is not a function\"] \r\n\r\n**To Reproduce**\r\n\r\nThis error occurs when a client other than the Direct Client calls an action that sends a Content object through a HandlerCallback in the handler of an Action. This occurs when using plugin-image-generation to generating images as well. \r\n\r\nTo reproduce using the ImageGenerationPlugin:\r\n\r\nEnable the twitter client for your character along with an appropriate API key for image generation. Reply to a post of the Agent on twitter with \"Please generate an image of a cute cat!\" - it should trigger the GENERATE_IMAGE action. This will cause the TypeError to occur.\r\n\r\n**Expected behavior**\r\n\r\nI am unsure what the expected behavior should be. I would expect the callback to be able to take the Content object and pass it back to the client from which the action  was initiated from and some content text to be returned to the conversation that initiated the action.\r\n", "CLOSED", 0, "Chunt0", "2024-12-28T20:18:10Z", "2025-01-02T22:25:15Z", "2025-01-02T22:25:15Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6kQGv3", 1398, "Not able to login in twitter", "**Describe the bug**\r\nI've provided my twitter credentials, but eliza is not able to login, it says failed login. \r\n<!-- A clear and concise description of what the bug is. -->\r\n![image](https://github.com/user-attachments/assets/23a87533-2fab-412b-b665-634930a1eabc)\r\n\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "ameeetgaikwad", "2024-12-23T10:10:36Z", "2025-01-02T16:01:20Z", "2024-12-23T11:06:47Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6kNLF2", 1384, "fix: Slack client Media type implementation missing required properties in message attachments", "\r\n### Describe the Bug\r\n\r\nTypeScript type error in Slack client when handling message attachments. The error occurs because the `attachments` property in the `Content` interface expects an array of `Media` type objects, but the code was only providing a subset of the required properties.\r\n\r\n**Error message:**\r\n\r\n```\r\nType '{ text: string; }[]' is not assignable to type 'Media[]'.\r\nType '{ text: string; }' is missing the following properties from type 'Media': id, url, title, source, description\r\n```\r\n\r\n---\r\n\r\n### To Reproduce\r\n\r\n1. Use the Slack client implementation.\r\n2. Try to create a message content with attachments.\r\n3. The code attempts to create an attachment with only the `text` property:\r\n\r\n```typescript\r\nattachments: attachmentContent ? [{ text: attachmentContent }] : undefined\r\n```\r\n\r\n---\r\n\r\n### Expected Behavior\r\n\r\nThe code should properly implement the `Media` type interface by providing all required properties:\r\n\r\n- `id` (string)\r\n- `url` (string)\r\n- `title` (string)\r\n- `source` (string)\r\n- `description` (string)\r\n- `text` (string)\r\n\r\n---\r\n\r\n### Solution\r\n\r\nUpdate the attachment creation to include all required `Media` type properties:\r\n\r\n```typescript\r\nattachments: attachmentContent\r\n    ? [{\r\n        id: stringToUuid(`${event.ts}-attachment`),\r\n        url: '',  // Since this is text content, no URL is needed\r\n        title: 'Text Attachment',\r\n        source: 'slack',\r\n        description: 'Text content from Slack message',\r\n        text: attachmentContent\r\n    }]\r\n    : undefined,\r\n```\r\n\r\n---\r\n\r\n### Additional Context\r\n\r\nThis issue affects the Slack client's message handling functionality in the `packages/client-slack/src/messages.ts` file. The fix ensures type safety while maintaining the intended functionality of handling text attachments from Slack messages.", "CLOSED", 0, "SumeetChougule", "2024-12-23T00:08:40Z", "2025-01-04T04:39:33Z", "2025-01-04T04:39:33Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6kLxKM", 1363, "Support better in-monorepo navigation with custom conditions", "**Is your feature request related to a problem? Please describe.**\r\n\r\nDoing go to definition always go to the d.ts file within the monorepo which is annoying.\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the solution you'd like**\r\n\r\nWe can use custom conditions in tsconfig to point directly to the TS File\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\nhttps://colinhacks.com/essays/live-types-typescript-monorepo", "CLOSED", 0, "ryanleecode", "2024-12-22T08:25:49Z", "2025-01-03T16:27:59Z", "2025-01-03T16:27:59Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6kI-SO", 1322, "http proxy error /agents", "**Describe the bug**\r\n\r\nPS C:\\Users\\---\\Desktop\\eliza-main> pnpm start:client\r\n\r\n> eliza@ start:client C:\\Users\\---\\Desktop\\eliza-main\r\n> pnpm --dir client dev\r\n\r\n\r\n> eliza-client@0.1.6 dev C:\\Users\\---\\Desktop\\eliza-main\\client\r\n> vite\r\n\r\n\r\n  VITE v5.4.11  ready in 484 ms\r\n\r\n  \u279c  Local:   http://localhost:5173/\r\n  \u279c  Network: use --host to expose\r\n  \u279c  press h + enter to show help\r\n(node:23000) ExperimentalWarning: CommonJS module C:\\Users\\---\\Desktop\\eliza-main\\node_modules\\tailwindcss\\lib\\lib\\load-config.js is loading ES Module C:\\Users\\---\\Desktop\\eliza-main\\client\\tailwind.config.js using require().\r\nSupport for loading ES Module in require() is an experimental feature and might change at any time\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n2:00:41 AM [vite] http proxy error: /agents\r\nError: connect ECONNREFUSED ::1:3000\r\n    at TCPConnectWrap.afterConnect [as oncomplete] (node:net:1615:16)\r\n\r\n", "CLOSED", 0, "Wubnar", "2024-12-21T07:08:13Z", "2025-01-03T13:19:27Z", "2024-12-21T18:11:10Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6kFEcF", 1271, "Add Livepeer as an Image Generation Provider", "**Feature and Motivation**\r\nCurrently, we lack direct support for using Livepeer as an image generation provider. Users who have a LIVEPEER_API_KEY must rely on custom workaround solutions to integrate their Livepeer endpoint seamlessly. Livepeer also offers some free image generation endpoints so it's addition can be beneficial.\r\n\r\n**Solution**\r\nChange to the appropriate files to integrate Livepeer as image generation provider.\r\n\r\n_PS: Feature already tested and implemented issue added for pull request tracking._", "CLOSED", 0, "UD1sto", "2024-12-20T13:55:25Z", "2025-01-04T02:43:01Z", "2025-01-04T02:43:01Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6iFoN9", 851, "Arbitrum Integration", "**Arbitrum Integration**\r\nIntegrate and demonstrate Arbitrum One Mainnet\r\n\r\nReward: $1500 USD in USDC, as detailed on https://ai16z.github.io/", "CLOSED", 0, "kubesqrt", "2024-12-05T05:33:19Z", "2025-01-01T16:53:39Z", "2025-01-01T16:53:39Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6g-rGP", 637, "Will not install on windows", "**Describe the bug**\r\n\r\nwont install on WSL\r\n\r\n**To Reproduce**\r\n\r\n- fresh git clone\r\n- nvm use 23.3.0\r\n- pnpm i \r\n- pnpm build\r\n- env is copied\r\n- pnpm start\r\n\r\n\"/eliza/packages/plugin-solana/dist/index.js:12\r\n    throw Error('Dynamic require of \"' + x + '\" is not supported');\r\n          ^\r\n\r\nError: Dynamic require of \"util\" is not supported\"\r\n\r\n**Expected behavior**\r\n\r\nshould run\r\n", "CLOSED", 0, "0x1337z", "2024-11-28T04:54:03Z", "2025-01-04T18:31:35Z", "2025-01-04T18:31:35Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6ga_S9", 592, "API Cost Tracking", "**Is your feature request related to a problem? Please describe.**\r\n\r\nAs a builder I would like to know how using different models impacts my costs.\r\n\r\n**Describe the solution you'd like**\r\n\r\nA clear way to track agent costs relative to the requests they are making and storing that information to be easily accessible.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nForking\r\n\r\n**Additional context**\r\n\r\nAs an agent developer, I want to know how switching between models impacts my costs as well as if I were to build a SaaS model on top of Eliza, how can I know the individual costs of my agents.\r\n", "CLOSED", 0, "rckprtr", "2024-11-25T16:49:27Z", "2025-01-04T18:31:36Z", "2025-01-04T18:31:36Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6gR9AM", 579, "Turnkey Integration", "We need integration with turnkey so that the private key is abstracted from the characters", "CLOSED", 0, "lalalune", "2024-11-25T04:34:00Z", "2025-01-04T18:31:37Z", "2025-01-04T18:31:37Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6fiJ0M", 457, "Non-Merge Access Users Cannot View Specific Merge Conflicts in Pull Requests They Review", "**Describe the bug**\r\n\r\nUsers without merge access are unable to view specific merge conflicts in pull requests. This limitation prevents them from resolving or contributing to conflict resolution effectively, as they cannot see the conflicting files or lines of code.\r\n\r\n**To Reproduce**\r\n\r\n1. Create a pull request with merge conflicts.\r\n2. Ensure that the user reviewing the PR does not have merge access.\r\n3. Attempt to view the specific merge conflicts as the non-merge access user.\r\n\r\n**Expected behavior**\r\n\r\nUsers without merge access should be able to view the specific merge conflicts within the pull request, including the files and lines of code in conflict, to assist in resolving the issue.\r\n\r\n**Screenshots**\r\n\r\n<!-- Add screenshots of the PR interface showing the issue for users without merge access, highlighting the lack of visibility into merge conflicts. -->\r\n\r\n**Additional context**\r\n\r\nThis limitation may hinder collaboration and delay the resolution of merge conflicts, especially in teams where code reviews and conflict resolutions involve contributors without merge privileges.", "CLOSED", 0, "monilpat", "2024-11-20T16:50:34Z", "2025-01-04T18:31:39Z", "2025-01-04T18:31:39Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6fbpPE", 439, "Feat: Hot reload json", "**Is your feature request related to a problem? Please describe.**\r\n\r\nBe able to reload a character json without restarting\r\n\r\n**Describe the solution you'd like**\r\n\r\nREST API?\r\n\r\nSIGHUP to reload all characters?\r\nSIGUSR1 to reload all characters as soon as they're done with their current action?\r\n\r\n**Describe alternatives you've considered**\r\n\r\nTBD\r\n\r\n**Additional context**\r\n\r\nCredit to ICJR on discord for the idea\r\n", "CLOSED", 0, "odilitime", "2024-11-20T07:43:07Z", "2025-01-04T18:31:39Z", "2025-01-04T18:31:39Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6fbPmB", 438, "Feature: when getting style guidelines should always add all of them to context", "when adding postDirections on chatDirections\r\nshould grab all of the guidelines to follow\r\nthis is so it does not ignore requests that are extremely important to follow for how the character behaves\r\nreally instead of random for the character file the agent should be able to select what it puts into its context as part of the shouldRespond logic or some other way \r\n\r\nin runtime.ts\r\n```\r\n            postDirections:\r\n                this.character?.style?.all?.length > 0 ||\r\n                this.character?.style?.post.length > 0\r\n                    ? addHeader(\r\n                            \"# Post Directions for \" + this.character.name,\r\n                            (() => {\r\n                                const all = this.character?.style?.all || [];\r\n                                const post = this.character?.style?.post || [];\r\n                                const shuffled = [...all, ...post].sort(\r\n                                    () => 0.5 - Math.random()\r\n                                );\r\n                                return shuffled\r\n                                    .slice(0, conversationLength / 2)\r\n                                    .join(\"\\n\");\r\n                            })()\r\n                        )\r\n                    : \"\",*\r\n```\r\n>\r\n```\r\n            postDirections:\r\n                this.character?.style?.all?.length > 0 ||\r\n                this.character?.style?.post.length > 0\r\n                    ? addHeader(\r\n                        \"# Post Directions for \" + this.character.name,\r\n                        (() => {\r\n                            const all = this.character?.style?.all || [];\r\n                            const post = this.character?.style?.post || [];\r\n                            return [...all, ...post].join(\"\\n\");\r\n                        })()\r\n                    )\r\n                    : \"\",\r\n\r\n```", "CLOSED", 0, "o-on-x", "2024-11-20T07:16:21Z", "2025-01-04T18:31:40Z", "2025-01-04T18:31:40Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6e2yPo", 372, "Add Polymarket", "Add a polymarket Plugin\r\n\r\nCould use this as architecture - https://github.com/Polymarket/agents?tab=readme-ov-file", "CLOSED", 0, "ponderingdemocritus", "2024-11-17T02:44:45Z", "2025-01-05T18:31:17Z", "2025-01-05T18:31:17Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6e0nNL", 363, "feat: Give eliza search engine", "Tavily API\r\nhttps://tavily.com/#features\r\n", "CLOSED", 0, "sw4geth", "2024-11-16T16:21:15Z", "2025-01-05T18:31:18Z", "2025-01-05T18:31:17Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6e0nFz", 362, "Prediction market tooling", "Give eliza prediction market tooling like this repo from Gnosis\r\n\r\nhttps://github.com/gnosis/prediction-market-agent", "CLOSED", 0, "sw4geth", "2024-11-16T16:20:14Z", "2025-01-05T18:31:18Z", "2025-01-05T18:31:18Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6eYJa-", 301, "Twitter Spaces Voice Client", "## Twitter Spaces Voice Client\r\n\r\nParity with Discord Voice Client, but on Twitter Space\r\n\r\n- Must listen to and respond with voice\r\n- Must be able to join a twitter space from a linked tweet\r\n- Must be able to accept speaker role\r\n\r\nReward: $1000 USD in $ai16z + $1000 USD in $degenai as seen on https://ai16z.github.io/\r\n\r\n", "CLOSED", 0, "madjin", "2024-11-13T23:41:03Z", "2025-01-04T01:16:39Z", "2025-01-04T01:16:38Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6dheYZ", 235, "Move all models to model providers in a plugin", "Right now we are stacking all of our model data into the ModelProvider abstraction we have, which selects by name and has some defaults.\r\n\r\nWe probably want to make an abstraction that can be selected/registered by the user and automatically handled for json and ts by the agent package.\r\n\r\nSomething like this, for each model, then we can register the model provider with the agent.\r\n\r\n```\r\ntype ModelProvider = {\r\n    endpoint: string;\r\n    settings: {\r\n        [key: string]: any;\r\n    };\r\n    model: {\r\n        [key in ModelClass]: string;\r\n    };\r\n    generateText(runtime: IAgentRuntime, context: string, modelClass: ModelClass, stop?: string[] ): Promise<string>;\r\n    generateImage(runtime: IAgentRuntime, prompt: string, width: number, height: number, count?: number): Promise<string[]>;\r\n    embed(runtime: IAgentRuntime, input: string): Promise<number[]>;\r\n}\r\n\r\nexport const OpenAIModelProvider: ModelProvider = {\r\n    endpoint: \"https://api.openai.com/v1\",\r\n    settings: {\r\n        stop: [],\r\n        maxInputTokens: 128000,\r\n        maxOutputTokens: 8192,\r\n        frequency_penalty: 0.0,\r\n        presence_penalty: 0.0,\r\n        temperature: 0.6,\r\n    },\r\n    model: {\r\n        [ModelClass.SMALL]: \"gpt-4o-mini\",\r\n        [ModelClass.MEDIUM]: \"gpt-4o\",\r\n        [ModelClass.LARGE]: \"gpt-4o\",\r\n        [ModelClass.EMBEDDING]: \"text-embedding-3-small\",\r\n        [ModelClass.IMAGE]: \"dall-e-3\",\r\n    },\r\n    generateText: async (runtime, context, modelClass, stop) => {\r\n        if (!context) {\r\n            console.error(\"generateText context is empty\");\r\n            return \"\";\r\n        }\r\n    \r\n        const provider = runtime.modelProvider;\r\n        const endpoint =\r\n            runtime.character.modelEndpointOverride || models[provider].endpoint;\r\n        const model = models[provider].model[modelClass];\r\n        const temperature = models[provider].settings.temperature;\r\n        const frequency_penalty = models[provider].settings.frequency_penalty;\r\n        const presence_penalty = models[provider].settings.presence_penalty;\r\n        const max_context_length = models[provider].settings.maxInputTokens;\r\n        const max_response_length = models[provider].settings.maxOutputTokens;\r\n    \r\n        const apiKey = runtime.token;\r\n    \r\n        try {\r\n            elizaLogger.log(\r\n                `Trimming context to max length of ${max_context_length} tokens.`\r\n            );\r\n            context = await trimTokens(context, max_context_length, \"gpt-4o\");\r\n        \r\n            const _stop = stop || models[provider].settings.stop;\r\n            elizaLogger.log(\r\n                `Using provider: ${provider}, model: ${model}, temperature: ${temperature}, max response length: ${max_response_length}`\r\n            );\r\n            elizaLogger.log(\"Initializing OpenAI model.\");\r\n            const openai = createOpenAI({ apiKey, baseURL: endpoint });\r\n\r\n            const { text: openaiResponse } = await aiGenerateText({\r\n                model: openai.languageModel(model),\r\n                prompt: context,\r\n                system:\r\n                    runtime.character.system ??\r\n                    settings.SYSTEM_PROMPT ??\r\n                    undefined,\r\n                temperature: temperature,\r\n                maxTokens: max_response_length,\r\n                frequencyPenalty: frequency_penalty,\r\n                presencePenalty: presence_penalty,\r\n            });\r\n\r\n            const response = openaiResponse;\r\n            elizaLogger.log(\"Received response from OpenAI model.\");\r\n    \r\n            return response;\r\n        } catch (error) {\r\n            elizaLogger.error(\"Error in generateText:\", error);\r\n            throw error;\r\n        }\r\n    },\r\n    generateImage: (runtime, prompt, width, height, count) => generateImage({ runtime, prompt, width, height, count }),\r\n    embed: (runtime, input) => embed(runtime, input),\r\n}\r\n```", "CLOSED", 0, "lalalune", "2024-11-08T04:22:09Z", "2025-01-05T18:31:19Z", "2025-01-05T18:31:19Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6c2jlb", 188, "Actions Tests", "Task is to look at the following test and verify that they are necessary and working:\n\n- Located in `core/tests/actions.test.ts`\n- Tests action system:\n    - Action loading\n    - Action validation\n    - Action handler execution\n    - Test actions (TEST\\_ACTION and TEST\\_ACTION\\_FAIL)", "CLOSED", 0, "sirkitree", "2024-11-03T23:14:59Z", "2025-01-05T18:32:48Z", "2025-01-05T18:32:48Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6c2jVy", 186, "Goals Tests", "Task is to look at the following test and verify that they are necessary and working:\n\n- Located in `core/tests/goals.test.ts` and `core/tests/goal.test.ts`\n- Tests goal management functionality:\n    - Goal creation\n    - Goal updates\n    - Status management\n    - Objective tracking", "CLOSED", 0, "sirkitree", "2024-11-03T23:12:37Z", "2025-01-05T17:26:10Z", "2025-01-05T17:26:10Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6c2jHg", 185, "Token Provider Tests", "Task is to look at the following test and verify that they are necessary and working:\n \n- Located in `core/tests/token.test.ts`\n- Tests token-related functionality:\n    - Fetching token security data\n    - Token holder information\n    - Trade data retrieval\n    - Formatted token reports", "CLOSED", 0, "sirkitree", "2024-11-03T23:10:31Z", "2025-01-05T17:26:42Z", "2025-01-05T17:26:42Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6c2ism", 183, "Memory Tests", "Task is to look at the following test and verify that they are necessary and working:\n\n- Located in `core/tests/memory.test.ts`\n- Tests memory-related functionality:\n    - Search memories by embedding similarity\n    - Validates memory ranking based on similarity scores\n    - Tests memory lifecycle (creation, search, and removal)\n    - Verifies embedding caching functionality", "CLOSED", 0, "sirkitree", "2024-11-03T23:06:30Z", "2025-01-05T17:26:21Z", "2025-01-05T17:26:21Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6b-L6-", 48, "\ud83d\udcc8 Trading Assistant Implementation", "\ud83d\udcbc Role of the Trading Assistant: The assistant's function ensures that trades can be executed without full automation, allowing human oversight while still proving the system's viability. This balance between assistance and automation enhances user trust and engagement.\r\n\r\nImplement a trading assistant (Marc) that can execute trades based on user requests.\r\n\r\n#### Requirements\r\n- Create an interface for users to submit trade requests\r\n- Implement trade execution logic with human oversight capabilities\r\n- Add validation checks for trade parameters\r\n- Include error handling and confirmation messages\r\n\r\n#### Acceptance Criteria\r\n- [ ] Trading assistant can receive and process trade requests\r\n- [ ] Human oversight mechanism is in place\r\n- [ ] Trade execution confirmation is provided to users\r\n- [ ] Error handling for invalid trade requests", "CLOSED", 0, "sirkitree", "2024-10-27T18:06:10Z", "2025-01-02T23:59:21Z", "2024-11-08T10:55:29Z", "elizaos/eliza", "2025-04-14 21:50:49"]
["I_kwDOMT5cIs6l3A2q", 2212, "Add tests for WhatsApp plugin", "**Is your feature request related to a problem? Please describe.**\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\nAdd tests for WhatsApp plugin to cover following: \r\n\r\nText message sending\r\nTemplate message sending\r\nError handling\r\nWebhook verification\r\nMessage event handling\r\nStatus update handling\r\nEmpty event handling\r\n\r\n**Describe the solution you'd like**\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\nAdd tests to __tests__ directory\r\nVitest as test runner \r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "ai16z-demirix", "2025-01-12T19:48:05Z", "2025-01-12T20:13:13Z", "2025-01-12T20:13:13Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6l2vnW", 2209, "Echochambers doesn't work - get Cannot find package 'echochambers' ", "To reproduce:\r\n\r\nAdd echochambers plugin to your character card:\r\n\r\n\"plugins\": [\"echochambers\"],\r\n\r\nAnd configure .env:\r\n\r\nECHOCHAMBERS_API_URL=\r\nECHOCHAMBERS_API_KEY=\r\nECHOCHAMBERS_USERNAME=\r\nECHOCHAMBERS_DEFAULT_ROOM=\r\nECHOCHAMBERS_POLL_INTERVAL=60\r\nECHOCHAMBERS_MAX_MESSAGES=10\r\n\r\nThen check your log:\r\n\r\n[34m \u2139 INFORMATIONS\r\n  \u001b[34m Plugins are:  \u001b[0m\r\n  \u001b[34m [\"echochambers\"] \u001b[0m\r\n\r\n\u001b[31m [\"\u26d4 Error parsing character from characters/qwen.character.json: Error: Cannot find package 'echochambers' imported from /home/hosermage/forked-projects/eliza/agent/src/index.ts\"] \u001b[0m", "CLOSED", 0, "augchan42", "2025-01-12T17:12:16Z", "2025-01-12T17:30:14Z", "2025-01-12T17:30:14Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6l2AJA", 2197, "Add README greek language", "**Is your feature request related to a problem? Please describe.**\r\nCurrently, the README file is not available in Greek, which limits accessibility for Greek-speaking users.\r\n\r\n**Describe the solution you'd like**\r\nAdd a Greek translation of the README file (README_GR.md) to the repository and update the main README file to include a link to the Greek version.\r\n\r\n**Describe alternatives you've considered**\r\nAlternative solutions include using external tools for translation, but a native README translation within the repository would better serve Greek-speaking contributors and users.\r\n\r\n**Additional context**\r\nThis feature will improve inclusivity and broaden the reach of the Eliza framework for non-English speaking users, specifically those in the Greek-speaking community.\r\n", "CLOSED", 0, "adacapo21", "2025-01-12T10:36:01Z", "2025-01-12T18:27:08Z", "2025-01-12T18:27:08Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6l1Rga", 2172, "Together ai medium model invalid", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nThe together medium model described in https://github.com/elizaOS/eliza/blob/main/packages/core/src/models.ts is invalid (does not exists).\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\nTry to use the model, will throw an error.\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nWe should replace the model name with a valid one.\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "Jonatan-Chaverri", "2025-01-12T00:24:56Z", "2025-01-12T10:02:23Z", "2025-01-12T10:02:23Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6l1NBN", 2169, "Coinbase-plugin - add tests acorrding to follow package structure", "**Is your feature request related to a problem? Please describe.**\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\nWe should add tests in __tests__directory for coinbase plugin to cover wallet functionalities.\r\n**Describe the solution you'd like**\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n__tests__directory, vitest as a test runner with added tests and scripts to package.json \r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "ai16z-demirix", "2025-01-11T23:24:50Z", "2025-01-12T04:32:43Z", "2025-01-12T04:32:43Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6l0LGF", 2155, "[\"\u26d4 Login attempt failed: {\\\"errors\\\":[{\\\"code\\\":399,\\\"message\\\":\\\"Incorrect. Please try again. g;173660517793424920:-1736605178063:PxLadt9CWlWaWY9YeX6FXYua:8\\\"}]}\"]", "**Describe the bug**\r\n\r\nWhile tring to run a character in Linux ubuntu setup, I am getting this error. It was working fine when I was running locally on mac.\r\n\r\n**To Reproduce**\r\n-GCP instance with 8 Gigs of RAM with ubutnu as OS\r\n- Install all the pre-requisites\r\n- pnpm install && pnpm build\r\n- Fill all the paramters in .env file\r\n- run character file\r\n\r\n**Expected behavior**\r\n\r\nShould get an error : \r\n[\"\u26d4 Login attempt failed: {\\\"errors\\\":[{\\\"code\\\":399,\\\"message\\\":\\\"Incorrect. Please try again. g;173660517793424920:-1736605178063:PxLadt9CWlWaWY9YeX6FXYua:8\\\"}]}\"]\r\n\r\n**Screenshots**\r\nPFA\r\n<img width=\"1229\" alt=\"Screenshot 2025-01-11 at 8 05 18\u202fPM\" src=\"https://github.com/user-attachments/assets/485c8171-8771-45a4-a278-d64aed9113e1\" />\r\n", "CLOSED", 0, "Ashwin1011", "2025-01-11T14:35:33Z", "2025-01-12T10:16:27Z", "2025-01-12T10:16:27Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lzUk0", 2147, "Eliza does not join discord voice channels upon request", "**Describe the bug**\r\n\r\nWhen I ask Eliza to join the voice channel I am currently in on discord, Eliza attempts to join but throws a reference error in the terminal \"ReferenceError: VoiceManager is not defined\". When Eliza starts up and I'm in a discord voice channel, Eliza joins me successfully. If I ask her in chat to join my, it always throws this reference error.\r\n\r\n**To Reproduce**\r\n\r\nSet up Eliza and the discord client. Get Eliza into your discord, turn Eliza on and get into a voice channel. Ask Eliza to join your voice channel.\r\n\r\n**Expected behavior**\r\n\r\nEliza will recognize she needs to call the joinvoice action but it will throw a reference error.\r\n\r\n**Screenshots**\r\n\r\n<img width=\"753\" alt=\"image\" src=\"https://github.com/user-attachments/assets/56b47eac-cc9a-4608-a80b-fa188eb1eaa8\" />", "CLOSED", 0, "Peridax", "2025-01-11T08:12:26Z", "2025-01-11T21:03:53Z", "2025-01-11T21:03:53Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6luTj9", 2116, "Tweet reply is sent prior to action processing", "**Describe the issue**\r\n\r\nWhen a user interact with agent on twitter, and the agent decide to execute an action, the tweet response is sent immediately and the action is performed afterwards.\r\n\r\n**To Reproduce**\r\n\r\nRead the code, processActions is happening after sendTweet\r\n\r\n**Expected behavior**\r\n\r\nI would expect action processing to happen first then a reply to be sent, potentially with action result. So, if the action is an image generator, the reply tweet would contain the generated image.\r\n\r\n", "CLOSED", 0, "eschnou", "2025-01-10T14:57:09Z", "2025-01-10T17:11:49Z", "2025-01-10T17:11:49Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lr_pl", 2104, "duplicate readme file in packages/plugin-story", "**Describe the bug**\r\n\r\nWhen cloning elizaOS/eliza repo, I came across a warning from git command stating there are two conflicting files in the same directory.\r\n![image](https://github.com/user-attachments/assets/5217b11d-9e18-4d2e-a3ec-22cd8a3253aa)\r\n\r\n**To Reproduce**\r\n\r\n1. Run `git clone git@github.com:elizaOS/eliza.git` on a MacOS device\r\n2. You should be able to observe warning from git command\r\n\r\n**Expected behavior**\r\n\r\nSilent clone of repo without any warning.\r\n\r\n**Screenshots**\r\n\r\nScreenshots attached in the Bug Description above.\r\n\r\n**Additional context**\r\n\r\nNA", "CLOSED", 0, "KumbleMadhu", "2025-01-10T09:59:59Z", "2025-01-10T15:23:04Z", "2025-01-10T15:23:04Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lie6Y", 2056, "anchor.BN is not a constructor ", "**Describe the bug**\r\n\r\n```\r\nBN is not a constructor\r\n```\r\nhow to solve the BN problems when using anchor  on eliza framework?\r\n```\r\nimport * as anchor from \"@coral-xyz/anchor\";\r\nconst {BN} = anchor;\r\n```\r\nit's work on test\r\n\r\nif I change to use bn.js\r\nalso get another error \r\n```\r\n\u2718 [ERROR] Could not resolve \"bn.js\"\r\n\r\n    src/actions/borrow.ts:55:19:\r\n      55 \u2502 import { BN } from \"bn.js\";\r\n         \u2575                    ~~~~~~~\r\n```\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "cxp-13", "2025-01-09T09:26:15Z", "2025-01-09T14:50:02Z", "2025-01-09T14:49:50Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lfybj", 2040, "Agent wont start even after twitter successful login", "...", "CLOSED", 0, "DanielleMichelle", "2025-01-09T00:07:28Z", "2025-01-09T00:17:26Z", "2025-01-09T00:17:16Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lfMmO", 2035, "How to update to new version release? [v0.1.7-alpha.2] to [v0.1.7]", "I am currently on [v0.1.7-alpha.2] and want to update to the latest version [v0.1.7]. How do i do that?\r\n\r\nDo i use this: git checkout $(git describe --tags --abbrev=0)\r\nAnd then run pnpm install again?\r\n", "CLOSED", 0, "sonatonagems", "2025-01-08T21:53:06Z", "2025-01-09T19:41:32Z", "2025-01-09T14:53:00Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6ldAJW", 2028, "Starknet plugin outdated", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nThe starknet plugin is not working. It seems that it has some broken references, like if the code has changed but hasn't been properly updated.\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\nTry to use the plugin in eliza-starter repo. Add the plugin to the character. It won't even start because of javascript errors.\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\nPlugin should work.\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "Jonatan-Chaverri", "2025-01-08T16:41:00Z", "2025-01-11T05:23:42Z", "2025-01-11T05:23:42Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lcRdu", 2024, "Continuous error when starting agent", "Been working on the agent for 2 days and still keep getting the error message:\r\n\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.7-alpha.2 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/danimi.characters.jsn\"`\r\nExit status 1\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n\r\nI try to do everything, resetting, re-writing and no luck", "CLOSED", 0, "DanielleMichelle", "2025-01-08T15:14:59Z", "2025-01-12T11:10:28Z", "2025-01-12T11:10:27Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lafsM", 2019, "Suggestion - general logging system", "**Is your feature request related to a problem? Please describe.**\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\nFor 2.0, it would be helpful to offer a more robust and configurable logging interface (like [Pino](https://getpino.io/#/)). It would also be worth considering switching to JSON based logging as opposed to strings which better allows for indexing and searching of log data. \r\n\r\n**Describe the solution you'd like**\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "kmcclosk", "2025-01-08T11:45:14Z", "2025-01-08T11:59:55Z", "2025-01-08T11:59:55Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lYaQW", 2009, "`@elizaos/adapter-postgres` package does not bundle together `schema.sql`", "**Describe the bug**\r\n\r\nThe `schema.sql` file is missing in the published npm package. When running db.init(), it'll throw an error saying \"no such file or directory, ... /schema.sql\"\r\n\r\n**To Reproduce**\r\n\r\n1. pnpm install @elizaos/adapter-postgres\r\n2. Instantiate PostgresDatabaseAdapter\r\n3. Call db.init()\r\n\r\n**Expected behavior**\r\n\r\nIt runs migrations succesfully\r\n\r\n**Screenshots**\r\n\r\n\r\n**Additional context**\r\nRunning @elizaos/adapter-postgres v0.1,7\r\n", "CLOSED", 0, "hazelnutcloud", "2025-01-08T08:21:45Z", "2025-01-08T23:21:09Z", "2025-01-08T23:21:09Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lUtmY", 1988, "Tests for core package are failling on develop branch, due they are outdated", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nTests are failing now on develop branch, since they are outdated, not following new codebase.\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\nNavigate to packages/core and run pnpm test\r\n**Expected behavior**\r\nTests should cover updated codebase and reflect real state.\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "ai16z-demirix", "2025-01-07T20:23:43Z", "2025-01-07T22:33:25Z", "2025-01-07T22:33:25Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lT9Cx", 1977, "client chat doesn't automatically scroll down and focus input after character response", "**Describe the bug**\r\n\r\nWhen running the browser client and chatting with a character. conversations don't automatically scroll to the bottom of a character response and the input field is not focused. \r\n\r\n**To Reproduce**\r\n\r\n0. `pnpm start --character=\"characters/trump.character.json`\r\n1.  `pnpm client:start`\r\n2. browse to http://localhost:5173/ and select character\r\n3. chat enough so the response goes passed the initial page fold\r\n\r\n**Expected behavior**\r\n\r\nscreen scrolls to reveal the latest message and the input field is focused\r\n\r\n**Screenshots**\r\n\r\n**Additional context**\r\nI have a fix ready\r\n", "CLOSED", 0, "dbellotti", "2025-01-07T18:22:14Z", "2025-01-12T11:09:26Z", "2025-01-12T11:09:26Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lTq-J", 1972, "fix: context for client-telegram", "**Describe the bug**\r\n\r\nThere's a lot of leftover code from client-twitter that's polluting the context. I will fix it in a pull request!\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\nExample:\r\n\r\n```typescript\r\n{{recentMessages}}\r\n\r\n# Task: Generate a post/reply in the voice, style and perspective of {{agentName}} (@{{twitterUserName}}) while using the thread of tweets as additional context:\r\nCurrent Post:\r\n{{currentPost}}\r\nThread of Tweets You Are Replying To:\r\n\r\n{{formattedConversation}}\r\n```\r\n\r\nIn this section, the variables twitterUserName, currentPost and formattedConversation don't or can't exist.\r\n\r\n**Expected behavior**\r\n\r\nFor the example above, it should simply show:\r\n\r\n```typescript\r\n{{recentMessages}}\r\n\r\n# Task: Generate a post/reply in the voice, style and perspective of {{agentName}} while using the thread above as additional context.\r\n```", "CLOSED", 0, "Laurentiu-Andronache", "2025-01-07T17:37:14Z", "2025-01-08T19:51:25Z", "2025-01-08T19:51:25Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lTlxb", 1971, "`composeContext` function omits memories when exceeding 50 items with SQLite adapter, leading to incorrect state data", "**Describe the bug**\r\n\r\nWhen more than 50-54 memory items are created within the same room ID, the `composeContext` function occasionally omits certain memories, leading to incomplete state data. This issue occurs when using the SQLite adapter. Note that I have not tested this with the other database adapters available, but I would be surprised if an SQLite database cannot handle more than 50 records within the memories table.\r\n\r\n**To Reproduce**\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Clone the repository:\r\n   ```\r\n   git clone git@github.com:Sifchain/sa-eliza.git\r\n   ```\r\n2. Checkout the branch `realitySpiral/testUsefulWorkflows` (based on the `develop` branch from the upstream eliza repository):\r\n   ```\r\n   git checkout realitySpiral/testUsefulWorkflows\r\n   ```\r\n3. Set the following `.env` variables:\r\n   ```\r\n   GITHUB_API_TOKEN=ghp_XXX\r\n\r\n   GITHUB_OWNER=sifchain\r\n   GITHUB_REPO=sa-eliza\r\n   GITHUB_BRANCH=sif-dev\r\n\r\n   GITHUB_ISSUES_LIMIT=100\r\n   GITHUB_PULL_REQUESTS_LIMIT=100\r\n   ```\r\n   Refer to [this guide](https://github.com/Sifchain/sa-eliza/blob/realitySpiral/testUsefulWorkflows/docs/docs/packages/plugins.md#12-github-plugin-elizaplugin-github) for generating and using the GitHub API token.\r\n\r\n4. Install dependencies and start the agent:\r\n   ```\r\n   pnpm install -r\r\n   rm -rf agent/data && pnpm build && pnpm start --character=characters/staff-engineer.character.json\r\n   ```\r\n5. Observe the logs. At some point, you will notice the following:\r\n   ```\r\n   [\"\\u2139 Executing handler for action: INITIALIZE_REPOSITORY\"]\r\n\r\n   \u25ce LOGS\r\n     [initializeRepository] Composing state for message:\r\n     {\"id\":\"6a74eb9e-2eb1-00b7-bce3-a2d819d53bd5\",\"userId\":\"e0705f05-5af9-0ac4-80b9-a55815900197\",\"agentId\":\"b1ccf0ce-60b8-00ed-8da1-0fd7b791d233\",\"content\":{\"text\":\"No memories found, starting to initialize repository and create memories.\",\"action\":\"NOTHING\",\"source\":\"github\",\"inReplyTo\":\"3b2b2818-d716-08b7-a767-418a416a89c7\"},\"roomId\":\"a5e95f21-99e3-0354-add8-79108740b31a\",\"createdAt\":1736270012868}\r\n\r\n   [\"\\u2139 Initializing repository realityspiral/test on branch main...\"]\r\n\r\n   [\"\\u2139 Repository path: /tmp/elizaos-repos/realityspiral/test\"]\r\n\r\n   [\"\\u2139 Repos directory already exists: /tmp/elizaos-repos/realityspiral\"]\r\n\r\n   [\"\\u2139 Cloning or pulling repository realityspiral/test... @ branch: main\"]\r\n\r\n   [\"\\u2139 URL: https://github.com/realityspiral/test.git @ branch: main\"]\r\n   ```\r\n   The repository information (`realityspiral/test`) is incorrect.\r\n\r\n6. Update the `.env` file to reduce memory storage limits:\r\n   ```\r\n   GITHUB_ISSUES_LIMIT=10\r\n   GITHUB_PULL_REQUESTS_LIMIT=10\r\n   ```\r\n7. Restart the agent:\r\n   ```\r\n   rm -rf agent/data && pnpm build && pnpm start --character=characters/staff-engineer.character.json\r\n   ```\r\n8. Observe the logs again. This time, the correct repository information is used:\r\n   ```\r\n   [\"\\u2139 Executing handler for action: INITIALIZE_REPOSITORY\"]\r\n\r\n   \u25ce LOGS\r\n     [initializeRepository] Composing state for message:\r\n     {\"id\":\"53d09a5a-289e-03d6-a49e-0fb655fe55c2\",\"userId\":\"41b1749c-25aa-0dc6-9cdf-cf3a1141fc55\",\"agentId\":\"b1ccf0ce-60b8-00ed-8da1-0fd7b791d233\",\"content\":{\"text\":\"No memories found, starting to initialize repository and create memories.\",\"action\":\"NOTHING\",\"source\":\"github\",\"inReplyTo\":\"3b2b2818-d716-08b7-a767-418a416a89c7\"},\"roomId\":\"a5e95f21-99e3-0354-add8-79108740b31a\",\"createdAt\":1736270165808}\r\n\r\n   [\"\\u2139 Initializing repository sifchain/sa-eliza on branch sif-dev...\"]\r\n\r\n   [\"\\u2139 Repository path: /tmp/elizaos-repos/sifchain/sa-eliza\"]\r\n\r\n   [\"\\u2139 Repos directory already exists: /tmp/elizaos-repos/sifchain\"]\r\n\r\n   [\"\\u2139 Cloning or pulling repository sifchain/sa-eliza... @ branch: sif-dev\"]\r\n\r\n   [\"\\u2139 URL: https://github.com/sifchain/sa-eliza.git @ branch: sif-dev\"]\r\n\r\n   [\"\\u2139 Checking out branch sif-dev in repository /tmp/elizaos-repos/sifchain/sa-eliza\"]\r\n\r\n   [\"\\u2139 Repository initialized successfully! URL: https://github.com/sifchain/sa-eliza @ branch: sif-dev\"]\r\n   ```\r\n\r\n**Expected behavior**\r\n\r\nThe `composeContext` function should include all relevant memories without omitting any, regardless of the number of items stored in memory. Additionally, the correct repository information should always be used.\r\n\r\n**Screenshots**\r\n\r\nN/A\r\n\r\n**Additional context**\r\n\r\n- This issue appears to be tied to the SQLite adapter\u2019s handling of large memory sets.\r\n- Reducing the memory limits in the `.env` file mitigates the issue but does not resolve the underlying problem.\r\n- This behavior could impact other functionalities relying on the `composeContext` function if memory limits are exceeded.", "CLOSED", 0, "snobbee", "2025-01-07T17:24:34Z", "2025-01-10T15:35:11Z", "2025-01-10T15:35:10Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lTjl_", 1970, "Keep getting reoccuring issue:", "[{\r\n\t\"resource\": \"/Users/danielle_fabric/eliza/agent/src/index.ts\",\r\n\t\"owner\": \"typescript\",\r\n\t\"code\": \"2305\",\r\n\t\"severity\": 8,\r\n\t\"message\": \"Module '\\\"@elizaos/core\\\"' has no exported member 'createAgent'.\",\r\n\t\"source\": \"ts\",\r\n\t\"startLineNumber\": 11,\r\n\t\"startColumn\": 10,\r\n\t\"endLineNumber\": 11,\r\n\t\"endColumn\": 21\r\n},{\r\n\t\"resource\": \"/Users/danielle_fabric/eliza/agent/src/index.ts\",\r\n\t\"owner\": \"typescript\",\r\n\t\"code\": \"2305\",\r\n\t\"severity\": 8,\r\n\t\"message\": \"Module '\\\"@elizaos/core\\\"' has no exported member 'initializeClients'.\",\r\n\t\"source\": \"ts\",\r\n\t\"startLineNumber\": 11,\r\n\t\"startColumn\": 23,\r\n\t\"endLineNumber\": 11,\r\n\t\"endColumn\": 40\r\n}]\r\n\r\nDespite trying to update more than 20 times keeps saying same 2 errors:\r\n\r\nMy current index.ts code:\r\n// Import necessary packages\r\nimport { fileURLToPath } from \"url\";  // Ensure the url module is imported for fileURLToPath\r\nimport * as path from \"path\";\r\nimport * as fs from \"fs\";\r\nimport yargs from \"yargs\";\r\nimport { DirectClient } from \"@elizaos/client-direct\";\r\nimport { TwitterClientInterface } from \"@elizaos/client-twitter\";\r\nimport { mainCharacter } from \"../mainCharacter.ts\";\r\nimport Twitter from 'twitter'; // Import Twitter package\r\n\r\nimport { createAgent, initializeClients, elizaLogger, settings, validateCharacterConfig, Character } from \"@elizaos/core\"; // Make sure these are exported\r\n\r\n// Define the interface for characters with onStart property\r\ninterface CharacterWithOnStart extends Character {\r\n    onStart?: string[];\r\n}\r\n\r\nconst __filename = fileURLToPath(import.meta.url); // get the resolved path to the file\r\nconst __dirname = path.dirname(__filename); // get the name of the directory\r\n\r\n// Helper functions\r\nfunction tryLoadFile(filePath: string): string | null {\r\n    try {\r\n        return fs.readFileSync(filePath, \"utf8\");\r\n    } catch (e) {\r\n        return null;\r\n    }\r\n}\r\n\r\nexport const wait = (minTime: number = 1000, maxTime: number = 3000) => {\r\n    const waitTime =\r\n        Math.floor(Math.random() * (maxTime - minTime + 1)) + minTime;\r\n    return new Promise((resolve) => setTimeout(resolve, waitTime));\r\n};\r\n\r\n// Parse Arguments with yargs\r\nexport function parseArguments(): { character?: string; characters?: string } {\r\n    try {\r\n        return yargs(process.argv.slice(2)) // start from the third argument to ignore node and script path\r\n            .option(\"character\", {\r\n                type: \"string\",\r\n                description: \"Path to the character JSON file\",\r\n            })\r\n            .option(\"characters\", {\r\n                type: \"string\",\r\n                description: \"Comma separated list of paths to character JSON files\",\r\n            })\r\n            .parseSync();\r\n    } catch (error) {\r\n        elizaLogger.error(\"Error parsing arguments:\", error);\r\n        return {};\r\n    }\r\n}\r\n\r\n// Twitter Login Function\r\nasync function loginToTwitter() {\r\n    const twitterClient = new Twitter({\r\n        consumer_key: process.env.TWITTER_CONSUMER_KEY,\r\n        consumer_secret: process.env.TWITTER_CONSUMER_SECRET,\r\n        access_token_key: process.env.TWITTER_ACCESS_TOKEN,\r\n        access_token_secret: process.env.TWITTER_ACCESS_TOKEN_SECRET\r\n    });\r\n\r\n    try {\r\n        const account = await twitterClient.get('account/verify_credentials');\r\n        elizaLogger.info('Successfully logged in to Twitter:', account);\r\n    } catch (error) {\r\n        elizaLogger.error('Error logging in to Twitter:', error);\r\n    }\r\n}\r\n\r\n// Add Twitter login to onStart\r\nasync function runOnStartActions(character: CharacterWithOnStart) {\r\n    if (character.onStart && character.onStart.includes(\"Run Twitter Login\")) {\r\n        await loginToTwitter(); // Trigger the Twitter login\r\n    }\r\n}\r\n\r\n// Load Characters and Run OnStart Actions\r\nexport async function loadCharacters(charactersArg: string): Promise<Character[]> {\r\n    let characterPaths = charactersArg?.split(\",\").map((filePath) => filePath.trim());\r\n    const loadedCharacters = [];\r\n\r\n    if (characterPaths?.length > 0) {\r\n        for (const characterPath of characterPaths) {\r\n            let content = null;\r\n            let resolvedPath = \"\";\r\n\r\n            const pathsToTry = [\r\n                characterPath,\r\n                path.resolve(process.cwd(), characterPath),\r\n                path.resolve(process.cwd(), \"agent\", characterPath),\r\n                path.resolve(__dirname, characterPath),\r\n                path.resolve(__dirname, \"characters\", path.basename(characterPath)),\r\n                path.resolve(__dirname, \"../characters\", path.basename(characterPath)),\r\n                path.resolve(__dirname, \"../../characters\", path.basename(characterPath)),\r\n            ];\r\n\r\n            for (const tryPath of pathsToTry) {\r\n                content = tryLoadFile(tryPath);\r\n                if (content !== null) {\r\n                    resolvedPath = tryPath;\r\n                    break;\r\n                }\r\n            }\r\n\r\n            if (content === null) {\r\n                elizaLogger.error(`Error loading character from ${characterPath}: File not found`);\r\n                process.exit(1);\r\n            }\r\n\r\n            try {\r\n                const character = JSON.parse(content);\r\n                validateCharacterConfig(character);\r\n\r\n                loadedCharacters.push(character);\r\n                elizaLogger.info(`Successfully loaded character from: ${resolvedPath}`);\r\n\r\n                // Run the onStart actions\r\n                await runOnStartActions(character);\r\n\r\n            } catch (e) {\r\n                elizaLogger.error(`Error parsing character from ${resolvedPath}: ${e}`);\r\n                process.exit(1);\r\n            }\r\n        }\r\n    }\r\n\r\n    if (loadedCharacters.length === 0) {\r\n        elizaLogger.info(\"No characters found, using default character\");\r\n        loadedCharacters.push(mainCharacter);\r\n    }\r\n\r\n    return loadedCharacters;\r\n}\r\n\r\n// Define startAgents function\r\nasync function startAgents() {\r\n    const directClient = new DirectClient();\r\n    const { character } = parseArguments(); // Explicitly get the character argument\r\n\r\n    if (!character) {\r\n        elizaLogger.error(\"Character path not provided.\");\r\n        process.exit(1);\r\n    }\r\n\r\n    const characters = await loadCharacters(character); // Pass the correct character argument\r\n    for (const character of characters) {\r\n        const opts = {};  // Provide the necessary opts argument\r\n        const runtime = await createAgent(character, opts);\r\n        await runtime.initialize();\r\n        runtime.clients = await initializeClients(character, runtime);\r\n        directClient.registerAgent(runtime);\r\n    }\r\n\r\n    // Starting the client server\r\n    const serverPort = parseInt(settings.SERVER_PORT || \"3000\");\r\n    directClient.start(serverPort);\r\n}\r\n\r\nstartAgents().catch((error) => {\r\n    elizaLogger.error(\"Unhandled error in startAgents:\", error);\r\n    process.exit(1);\r\n});\r\n", "CLOSED", 0, "DanielleMichelle", "2025-01-07T17:19:42Z", "2025-01-08T19:54:50Z", "2025-01-08T19:54:49Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lTf5k", 1969, "Twitter plugin triggers security alerts due to repeated logins when posting", "**Describe the bug**\r\n\r\nEvery time the agent posts via the Twitter plugin, a security alert is triggered by Twitter. This happens because the plugin attempts to log in each time the post.ts action is called, instead of using an existing session.\r\n\r\n**To Reproduce**\r\n\r\n1. Add the plugin-twitter to your Eliza configuration. You can do this in one of the following locations:\r\n- defaultCharacter.ts\r\n- agent/src/index.ts\r\n- Your JSON character file.\r\n\r\n2. Trigger a post action using the agent.\r\n\r\n**Expected behavior**\r\n\r\nThe agent should not attempt to log in each time a post is created. Instead, it should use the session already saved by client-twitter.\r\n\r\n**Screenshots**\r\n\r\n![IMG_3315](https://github.com/user-attachments/assets/f41fdbdf-6d50-4a46-b0d2-f48c29858772)\r\n\r\n<img width=\"745\" alt=\"Screenshot 2025-01-07 at 16 50 50\" src=\"https://github.com/user-attachments/assets/98b8538e-96a5-4b01-8f71-99cd4ee4ce3b\" />\r\n\r\n\r\n\r\n\r\n**Additional context**\r\n\r\n- Agent Version: v0.1.7\r\n- Plugin Version: N/A\r\n- Related Issues: N/A\r\n", "CLOSED", 0, "mrsalitre", "2025-01-07T17:11:35Z", "2025-01-10T20:51:02Z", "2025-01-10T20:51:02Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lSSDn", 1962, "TWITTER_DRY_RUN only impacts POST and still let through replies", "**Describe the bug**\r\n\r\nDespites TWITTER_DRY_RUN=true some tweets are still going out.\r\n\r\n**To Reproduce**\r\n\r\n- TWITTER_DRY_RUN=true\r\n- Launch bot with TWITTER_TARGET_USERS non empty\r\n- Replies will be posted to Twitter\r\n\r\n**Expected behavior**\r\n\r\nI'd expect no tweets/messages at all to be posted, whatever the channel. So that the agent can actually be tested safely.\r\n\r\n", "CLOSED", 0, "eschnou", "2025-01-07T14:50:51Z", "2025-01-08T19:56:35Z", "2025-01-08T19:56:35Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lRdUc", 1961, "My agent won't chat & log into twitter", "This is what my page looks like\r\n\r\nhttp://localhost:5173/8f8b1ccc-243a-0cac-b563-c92272a1c644/chat\r\n\r\nIt says \"WIP\" and chat won't let me type.\r\n\r\nI also want to launch my agent and log into my twitter but all i get is:\r\n\r\nI keep getting the same error and it won't schedule a tweet for me.\r\n\r\ndanielle_fabric@Danielles-MacBook-Pro eliza % pnpm start --character=\"characters/danimi.character.jsn\"\r\n\u2009WARN\u2009 Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v23.5.0\",\"pnpm\":\"9.15.3\"})\r\n\r\neliza@ start /Users/danielle_fabric/eliza\r\npnpm --filter \"@elizaos/agent\" start --isRoot \"--character=characters/danimi.character.jsn\"\r\n\r\n. | \u2009WARN\u2009 Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v23.5.0\",\"pnpm\":\"9.14.4\"})\r\ndocs | \u2009WARN\u2009 Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v23.5.0\",\"pnpm\":\"9.14.4\"})\r\n\r\n@elizaos/agent@0.1.7-alpha.2 start /Users/danielle_fabric/eliza/agent\r\nnode --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/danimi.character.jsn\"\r\n\r\n(node:48958) ExperimentalWarning: --experimental-loader may be removed in the future; instead use register():\r\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\r\n(Use node --trace-warnings ... to show where the warning was created)\r\n(node:48958) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\r\n(Use node --trace-deprecation ... to show where the warning was created)\r\n[ElizaLogger] Initializing with:\r\nisNode: true\r\nverbose: false\r\nVERBOSE env: undefined\r\nNODE_ENV: undefined\r\n\r\n\u2139 INFORMATIONS\r\nLoading embedding settings:\r\n{\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING\":\"\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"}\r\n\r\n\u2139 INFORMATIONS\r\nLoading character settings:\r\n{\"ARGV\":[\"/Users/danielle_fabric/.nvm/versions/node/v23.5.0/bin/node\",\"/Users/danielle_fabric/eliza/agent/src/index.ts\",\"--isRoot\",\"--character=characters/danimi.character.jsn\"],\"CHARACTER_ARG\":\"--character=characters/danimi.character.jsn\",\"CWD\":\"/Users/danielle_fabric/eliza/agent\"}\r\n\r\nLoaded .env file from: /Users/danielle_fabric/eliza/.env\r\n\u2139 INFORMATIONS\r\nParsed settings:\r\n{\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OPENAI_EMBEDDING_TYPE\":\"string\",\"USE_OLLAMA_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING_TYPE\":\"string\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"}\r\n\r\nusing deprecated parameters for the initialization function; pass a single object instead\r\n(node:48958) [DEP0040] DeprecationWarning: The punycode module is deprecated. Please use a userland alternative instead.\r\n[\"\u25ce DirectClient constructor\"]\r\n\r\n\u2139 INFORMATIONS\r\nTrying paths:\r\n[{\"path\":\"characters/danimi.character.jsn\",\"exists\":false},{\"path\":\"/Users/danielle_fabric/eliza/agent/characters/danimi.character.jsn\",\"exists\":false},{\"path\":\"/Users/danielle_fabric/eliza/agent/agent/characters/danimi.character.jsn\",\"exists\":false},{\"path\":\"/Users/danielle_fabric/eliza/agent/src/characters/danimi.character.jsn\",\"exists\":false},{\"path\":\"/Users/danielle_fabric/eliza/agent/src/characters/danimi.character.jsn\",\"exists\":false},{\"path\":\"/Users/danielle_fabric/eliza/agent/characters/danimi.character.jsn\",\"exists\":false},{\"path\":\"/Users/danielle_fabric/eliza/characters/danimi.character.jsn\",\"exists\":true}]\r\n\r\n\u2139 INFORMATIONS\r\nPlugins are:\r\n[]\r\n\r\n[\"\u2139 Successfully loaded character from: /Users/danielle_fabric/eliza/characters/danimi.character.jsn\"]\r\n\r\n[\"\u25ce sqlite-vec extensions loaded successfully.\"]\r\n\r\n[\"\u2139 Using Database Cache...\"]\r\n\r\n\u2713 SUCCESS\r\nSUCCESS\r\nCreating runtime for character\r\nDanielle Michelle\r\n\r\n\u2139 INFORMATIONS\r\nInitializing AgentRuntime with options:\r\n{\"character\":\"Danielle Michelle\",\"modelProvider\":\"openai\",\"characterModelProvider\":\"openai\"}\r\n\r\n\u2713 SUCCESS\r\nAgent ID\r\n8f8b1ccc-243a-0cac-b563-c92272a1c644\r\n\r\n[\"\u2139 Setting model provider...\"]\r\n\r\n\u2139 INFORMATIONS\r\nModel Provider Selection:\r\n{\"characterModelProvider\":\"openai\",\"optsModelProvider\":\"openai\",\"finalSelection\":\"openai\"}\r\n\r\n\u2139 INFORMATIONS\r\nSelected model provider:\r\nopenai\r\n\r\n\u2139 INFORMATIONS\r\nSelected image model provider:\r\nopenai\r\n\r\n[\"\u2713 Registering action: CONTINUE\"]\r\n\r\n[\"\u2713 Registering action: FOLLOW_ROOM\"]\r\n\r\n[\"\u2713 Registering action: UNFOLLOW_ROOM\"]\r\n\r\n[\"\u2713 Registering action: IGNORE\"]\r\n\r\n[\"\u2713 Registering action: NONE\"]\r\n\r\n[\"\u2713 Registering action: MUTE_ROOM\"]\r\n\r\n[\"\u2713 Registering action: UNMUTE_ROOM\"]\r\n\r\n[\"\u2713 Registering action: DESCRIBE_IMAGE\"]\r\n\r\n\u25ce LOGS\r\nRegistering service:\r\nbrowser\r\n\r\n[\"\u2713 Service browser registered successfully\"]\r\n\r\n\u25ce LOGS\r\nRegistering service:\r\nimage_description\r\n\r\n[\"\u2713 Service image_description registered successfully\"]\r\n\r\n\u25ce LOGS\r\nRegistering service:\r\ntext_generation\r\n\r\n[\"\u2713 Service text_generation registered successfully\"]\r\n\r\n\u25ce LOGS\r\nRegistering service:\r\npdf\r\n\r\n[\"\u2713 Service pdf registered successfully\"]\r\n\r\n\u25ce LOGS\r\nRegistering service:\r\nspeech_generation\r\n\r\n[\"\u2713 Service speech_generation registered successfully\"]\r\n\r\n\u25ce LOGS\r\nRegistering service:\r\ntranscription\r\n\r\n[\"\u2713 Service transcription registered successfully\"]\r\n\r\n\u25ce LOGS\r\nRegistering service:\r\nvideo\r\n\r\n[\"\u2713 Service video registered successfully\"]\r\n\r\n\u25ce LOGS\r\nRegistering service:\r\naws_s3\r\n\r\n[\"\u2713 Service aws_s3 registered successfully\"]\r\n\r\n[\"\u2713 Registering action: GENERATE_IMAGE\"]\r\n\r\n[\"\u2713 Service browser initialized successfully\"]\r\n\r\n[\"\u25ce Initializing ImageDescriptionService\"]\r\n\r\n[\"\u2713 Service image_description initialized successfully\"]\r\n\r\n[\"\u2139 Initializing LlamaService...\"]\r\n\r\n[\"\u2713 Service text_generation initialized successfully\"]\r\n\r\n[\"\u2713 Service pdf initialized successfully\"]\r\n\r\n[\"\u2713 Service speech_generation initialized successfully\"]\r\n\r\n[\"\u2713 Service transcription initialized successfully\"]\r\n\r\n[\"\u2713 Service video initialized successfully\"]\r\n\r\nInitializing AwsS3Service\r\n[\"\u2713 Service aws_s3 initialized successfully\"]\r\n\r\n[\"\u25ce Initializing ImageDescriptionService\"]\r\n\r\n[\"\u2139 Initializing LlamaService...\"]\r\n\r\nInitializing AwsS3Service\r\n\u2139 INFORMATIONS\r\nProcessing knowledge for\r\nDanielle Michelle\r\n-\r\nCrypto trading\r\n\r\n\u25ce LOGS\r\nCreating Memory\r\n33f9f95a-9fa1-0dc7-b8e6-a3d7495613e9\r\nCrypto trading\r\n\r\n\u25ce LOGS\r\nCreating Memory\r\n3cdc412c-2c5f-0c52-8816-e0af207f1f40\r\ncrypto trading\r\n\r\n\u2139 INFORMATIONS\r\nProcessing knowledge for\r\nDanielle Michelle\r\n-\r\nNFT market trends\r\n\r\n\u25ce LOGS\r\nCreating Memory\r\nca6c6dfd-6e8c-0e54-9ce6-4d0fb9d92a72\r\nNFT market trends\r\n\r\n\u25ce LOGS\r\nCreating Memory\r\nc3338418-c044-0f92-9255-45b6f5529386\r\nnft market trends\r\n\r\n\u2139 INFORMATIONS\r\nProcessing knowledge for\r\nDanielle Michelle\r\n-\r\nAI possibilities in digital domains\r\n\r\n\u25ce LOGS\r\nCreating Memory\r\n9375bd3c-9450-0d9c-be7c-74ae054c516a\r\nAI possibilities in digital domains\r\n\r\n\u25ce LOGS\r\nCreating Memory\r\na333b640-160d-066f-86ab-e09b06a8e12e\r\nai possibilities in digital domains\r\n\r\n\u2139 INFORMATIONS\r\nProcessing knowledge for\r\nDanielle Michelle\r\n-\r\nCommunity engagement strategies\r\n\r\n\u25ce LOGS\r\nCreating Memory\r\n25539493-3ed4-0869-98ea-5aa3f890fab5\r\nCommunity engagement strategies\r\n\r\n\u25ce LOGS\r\nCreating Memory\r\n12e27835-bcf2-078f-9394-64fe8b25e845\r\ncommunity engagement strategies\r\n\r\n\u25ce LOGS\r\ninitializeClients\r\n[]\r\nfor\r\nDanielle Michelle\r\n\r\n\u25ce LOGS\r\nclient keys\r\n[]\r\n\r\n[\"\u25ce Run pnpm start:client to start the client and visit the outputted URL (http://localhost:5173) to chat with your agents. When running multiple agents, use client with different port SERVER_PORT=3001 pnpm start:client\"]\r\n\r\n[\"\u2713 REST API bound to 0.0.0.0:3000. If running locally, access it at http://localhost:3000.\"]\r\n\r\nExpected behavior\r\n\r\nI thought it would log memory and then start scheduling a tweet\r\n\r\nWhat do I do?\r\n", "CLOSED", 0, "DanielleMichelle", "2025-01-07T13:11:29Z", "2025-01-09T15:08:42Z", "2025-01-09T15:08:41Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lQG3_", 1952, "Why isn't my agent starting / scheduling a tweet?", "**Describe the bug**\r\n\r\nI keep getting the same error and it won't schedule a tweet for me.\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\ndanielle_fabric@Danielles-MacBook-Pro eliza % pnpm start --character=\"characters/danimi.character.jsn\"\r\n\u2009WARN\u2009 Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v23.5.0\",\"pnpm\":\"9.15.3\"})\r\n\r\n> eliza@ start /Users/danielle_fabric/eliza\r\n> pnpm --filter \"@elizaos/agent\" start --isRoot \"--character=characters/danimi.character.jsn\"\r\n\r\n.                                        | \u2009WARN\u2009 Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v23.5.0\",\"pnpm\":\"9.14.4\"})\r\ndocs                                     | \u2009WARN\u2009 Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v23.5.0\",\"pnpm\":\"9.14.4\"})\r\n\r\n> @elizaos/agent@0.1.7-alpha.2 start /Users/danielle_fabric/eliza/agent\r\n> node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/danimi.character.jsn\"\r\n\r\n(node:48958) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\r\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n(node:48958) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\r\n(Use `node --trace-deprecation ...` to show where the warning was created)\r\n[ElizaLogger] Initializing with:\r\n            isNode: true\r\n            verbose: false\r\n            VERBOSE env: undefined\r\n            NODE_ENV: undefined\r\n        \r\n \u2139 INFORMATIONS\r\n   Loading embedding settings: \r\n   {\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING\":\"\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"} \r\n\r\n \u2139 INFORMATIONS\r\n   Loading character settings: \r\n   {\"ARGV\":[\"/Users/danielle_fabric/.nvm/versions/node/v23.5.0/bin/node\",\"/Users/danielle_fabric/eliza/agent/src/index.ts\",\"--isRoot\",\"--character=characters/danimi.character.jsn\"],\"CHARACTER_ARG\":\"--character=characters/danimi.character.jsn\",\"CWD\":\"/Users/danielle_fabric/eliza/agent\"} \r\n\r\nLoaded .env file from: /Users/danielle_fabric/eliza/.env\r\n \u2139 INFORMATIONS\r\n   Parsed settings: \r\n   {\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OPENAI_EMBEDDING_TYPE\":\"string\",\"USE_OLLAMA_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING_TYPE\":\"string\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"} \r\n\r\nusing deprecated parameters for the initialization function; pass a single object instead\r\n(node:48958) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\r\n [\"\u25ce DirectClient constructor\"] \r\n\r\n \u2139 INFORMATIONS\r\n   Trying paths: \r\n   [{\"path\":\"characters/danimi.character.jsn\",\"exists\":false},{\"path\":\"/Users/danielle_fabric/eliza/agent/characters/danimi.character.jsn\",\"exists\":false},{\"path\":\"/Users/danielle_fabric/eliza/agent/agent/characters/danimi.character.jsn\",\"exists\":false},{\"path\":\"/Users/danielle_fabric/eliza/agent/src/characters/danimi.character.jsn\",\"exists\":false},{\"path\":\"/Users/danielle_fabric/eliza/agent/src/characters/danimi.character.jsn\",\"exists\":false},{\"path\":\"/Users/danielle_fabric/eliza/agent/characters/danimi.character.jsn\",\"exists\":false},{\"path\":\"/Users/danielle_fabric/eliza/characters/danimi.character.jsn\",\"exists\":true}] \r\n\r\n \u2139 INFORMATIONS\r\n   Plugins are:  \r\n   [] \r\n\r\n [\"\u2139 Successfully loaded character from: /Users/danielle_fabric/eliza/characters/danimi.character.jsn\"] \r\n\r\n [\"\u25ce sqlite-vec extensions loaded successfully.\"] \r\n\r\n [\"\u2139 Using Database Cache...\"] \r\n\r\n \u2713 SUCCESS\r\n   SUCCESS \r\n   Creating runtime for character \r\n   Danielle Michelle \r\n\r\n \u2139 INFORMATIONS\r\n   Initializing AgentRuntime with options: \r\n   {\"character\":\"Danielle Michelle\",\"modelProvider\":\"openai\",\"characterModelProvider\":\"openai\"} \r\n\r\n \u2713 SUCCESS\r\n   Agent ID \r\n   8f8b1ccc-243a-0cac-b563-c92272a1c644 \r\n\r\n [\"\u2139 Setting model provider...\"] \r\n\r\n \u2139 INFORMATIONS\r\n   Model Provider Selection: \r\n   {\"characterModelProvider\":\"openai\",\"optsModelProvider\":\"openai\",\"finalSelection\":\"openai\"} \r\n\r\n \u2139 INFORMATIONS\r\n   Selected model provider: \r\n   openai \r\n\r\n \u2139 INFORMATIONS\r\n   Selected image model provider: \r\n   openai \r\n\r\n [\"\u2713 Registering action: CONTINUE\"] \r\n\r\n [\"\u2713 Registering action: FOLLOW_ROOM\"] \r\n\r\n [\"\u2713 Registering action: UNFOLLOW_ROOM\"] \r\n\r\n [\"\u2713 Registering action: IGNORE\"] \r\n\r\n [\"\u2713 Registering action: NONE\"] \r\n\r\n [\"\u2713 Registering action: MUTE_ROOM\"] \r\n\r\n [\"\u2713 Registering action: UNMUTE_ROOM\"] \r\n\r\n [\"\u2713 Registering action: DESCRIBE_IMAGE\"] \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   browser \r\n\r\n [\"\u2713 Service browser registered successfully\"] \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   image_description \r\n\r\n [\"\u2713 Service image_description registered successfully\"] \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   text_generation \r\n\r\n [\"\u2713 Service text_generation registered successfully\"] \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   pdf \r\n\r\n [\"\u2713 Service pdf registered successfully\"] \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   speech_generation \r\n\r\n [\"\u2713 Service speech_generation registered successfully\"] \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   transcription \r\n\r\n [\"\u2713 Service transcription registered successfully\"] \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   video \r\n\r\n [\"\u2713 Service video registered successfully\"] \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   aws_s3 \r\n\r\n [\"\u2713 Service aws_s3 registered successfully\"] \r\n\r\n [\"\u2713 Registering action: GENERATE_IMAGE\"] \r\n\r\n [\"\u2713 Service browser initialized successfully\"] \r\n\r\n [\"\u25ce Initializing ImageDescriptionService\"] \r\n\r\n [\"\u2713 Service image_description initialized successfully\"] \r\n\r\n [\"\u2139 Initializing LlamaService...\"] \r\n\r\n [\"\u2713 Service text_generation initialized successfully\"] \r\n\r\n [\"\u2713 Service pdf initialized successfully\"] \r\n\r\n [\"\u2713 Service speech_generation initialized successfully\"] \r\n\r\n [\"\u2713 Service transcription initialized successfully\"] \r\n\r\n [\"\u2713 Service video initialized successfully\"] \r\n\r\nInitializing AwsS3Service\r\n [\"\u2713 Service aws_s3 initialized successfully\"] \r\n\r\n [\"\u25ce Initializing ImageDescriptionService\"] \r\n\r\n [\"\u2139 Initializing LlamaService...\"] \r\n\r\nInitializing AwsS3Service\r\n \u2139 INFORMATIONS\r\n   Processing knowledge for  \r\n   Danielle Michelle \r\n    -  \r\n   Crypto trading \r\n\r\n \u25ce LOGS\r\n   Creating Memory \r\n   33f9f95a-9fa1-0dc7-b8e6-a3d7495613e9 \r\n   Crypto trading \r\n\r\n \u25ce LOGS\r\n   Creating Memory \r\n   3cdc412c-2c5f-0c52-8816-e0af207f1f40 \r\n   crypto trading \r\n\r\n \u2139 INFORMATIONS\r\n   Processing knowledge for  \r\n   Danielle Michelle \r\n    -  \r\n   NFT market trends \r\n\r\n \u25ce LOGS\r\n   Creating Memory \r\n   ca6c6dfd-6e8c-0e54-9ce6-4d0fb9d92a72 \r\n   NFT market trends \r\n\r\n \u25ce LOGS\r\n   Creating Memory \r\n   c3338418-c044-0f92-9255-45b6f5529386 \r\n   nft market trends \r\n\r\n \u2139 INFORMATIONS\r\n   Processing knowledge for  \r\n   Danielle Michelle \r\n    -  \r\n   AI possibilities in digital domains \r\n\r\n \u25ce LOGS\r\n   Creating Memory \r\n   9375bd3c-9450-0d9c-be7c-74ae054c516a \r\n   AI possibilities in digital domains \r\n\r\n \u25ce LOGS\r\n   Creating Memory \r\n   a333b640-160d-066f-86ab-e09b06a8e12e \r\n   ai possibilities in digital domains \r\n\r\n \u2139 INFORMATIONS\r\n   Processing knowledge for  \r\n   Danielle Michelle \r\n    -  \r\n   Community engagement strategies \r\n\r\n \u25ce LOGS\r\n   Creating Memory \r\n   25539493-3ed4-0869-98ea-5aa3f890fab5 \r\n   Community engagement strategies \r\n\r\n \u25ce LOGS\r\n   Creating Memory \r\n   12e27835-bcf2-078f-9394-64fe8b25e845 \r\n   community engagement strategies \r\n\r\n \u25ce LOGS\r\n   initializeClients \r\n   [] \r\n   for \r\n   Danielle Michelle \r\n\r\n \u25ce LOGS\r\n   client keys \r\n   [] \r\n\r\n [\"\u25ce Run `pnpm start:client` to start the client and visit the outputted URL (http://localhost:5173) to chat with your agents. When running multiple agents, use client with different port `SERVER_PORT=3001 pnpm start:client`\"] \r\n\r\n [\"\u2713 REST API bound to 0.0.0.0:3000. If running locally, access it at http://localhost:3000.\"] \r\n\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\nI thought it would log memory and then start scheduling a tweet\r\n\r\nWhat do I do?", "CLOSED", 0, "DanielleMichelle", "2025-01-07T10:24:40Z", "2025-01-09T00:47:53Z", "2025-01-07T13:11:17Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lOSQV", 1946, "Can someone identify this issue, and help me resolve it", "\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.7-alpha.2 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/Zeno.character.json\\\\npnpm start --character=characters/Zeno.character.json\"`\r\nExit status 3221226505\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 3221226505.", "CLOSED", 0, "Huy-To", "2025-01-07T06:13:51Z", "2025-01-12T10:46:15Z", "2025-01-12T10:46:15Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lN9Z9", 1942, "Memory leak in getLocalEmbedding", "**Describe the bug**\r\n\r\nEvery call to this function allocates anywhere between 100-500mb of memory that it never releases. Here is the exact line(in this codebase) the memory is allocated at: https://github.com/elizaOS/eliza/blob/main/packages/core/src/embedding.ts#L302\r\n\r\nThis is problematic when deploying an agent on an environment that has limited resources, and a character file with a lot of memories to create. Having a lot of knowledge in your character file will instantly get your memory footprint above 10gb and it will stay that high until the process is killed. \r\n\r\nHere is the results of inserting a log in every iteration processCharacterKnowledge and inserting 120ish random sentences into the \"knowledge\" of c3po example character file\r\n```\r\nrun 0: 829.88 MB (0.81 GB)\r\nrun 1: 1050.15 MB (1.03 GB)\r\nrun 2: 1294.02 MB (1.26 GB)\r\nrun 3: 1527.19 MB (1.49 GB)\r\nrun 4: 1771.96 MB (1.73 GB)\r\nrun 5: 2981.71 MB (2.91 GB)\r\nrun 6: 3225.91 MB (3.15 GB)\r\nrun 7: 3467.36 MB (3.39 GB)\r\nrun 8: 3706.70 MB (3.62 GB)\r\nrun 9: 4184.69 MB (4.09 GB)\r\nrun 10: 4669.60 MB (4.56 GB)\r\nrun 11: 5147.63 MB (5.03 GB)\r\nrun 12: 5382.70 MB (5.26 GB)\r\nrun 13: 5608.27 MB (5.48 GB)\r\nrun 14: 6085.95 MB (5.94 GB)\r\nrun 15: 6547.88 MB (6.39 GB)\r\nrun 16: 7012.85 MB (6.85 GB)\r\nrun 17: 7488.52 MB (7.31 GB)\r\nrun 18: 7728.45 MB (7.55 GB)\r\nrun 19: 8200.47 MB (8.01 GB)\r\nrun 20: 8674.36 MB (8.47 GB)\r\nrun 21: 9125.14 MB (8.91 GB)\r\nrun 22: 9589.82 MB (9.37 GB)\r\nrun 23: 9708.89 MB (9.48 GB)\r\nrun 24: 5511.07 MB (5.38 GB)\r\nrun 25: 5238.44 MB (5.12 GB)\r\nrun 26: 5255.96 MB (5.13 GB)\r\nrun 27: 5292.35 MB (5.17 GB)\r\nrun 28: 5343.29 MB (5.22 GB)\r\nrun 29: 5363.51 MB (5.24 GB)\r\nrun 30: 5430.72 MB (5.30 GB)\r\nrun 31: 5484.32 MB (5.36 GB)\r\nrun 32: 5620.34 MB (5.49 GB)\r\nrun 33: 5707.05 MB (5.57 GB)\r\nrun 34: 5870.03 MB (5.73 GB)\r\nrun 35: 6069.80 MB (5.93 GB)\r\nrun 36: 6261.48 MB (6.11 GB)\r\nrun 37: 6501.14 MB (6.35 GB)\r\nrun 38: 6991.68 MB (6.83 GB)\r\nrun 39: 7236.04 MB (7.07 GB)\r\nrun 40: 7627.52 MB (7.45 GB)\r\nrun 41: 8037.95 MB (7.85 GB)\r\nrun 42: 8277.20 MB (8.08 GB)\r\nrun 43: 8517.22 MB (8.32 GB)\r\nrun 44: 8968.85 MB (8.76 GB)\r\nrun 45: 9430.57 MB (9.21 GB)\r\nrun 46: 7204.91 MB (7.04 GB)\r\nrun 47: 7206.63 MB (7.04 GB)\r\nrun 48: 7210.38 MB (7.04 GB)\r\nrun 49: 7232.14 MB (7.06 GB)\r\nrun 50: 7277.31 MB (7.11 GB)\r\nrun 51: 7357.45 MB (7.19 GB)\r\nrun 52: 7403.78 MB (7.23 GB)\r\nrun 53: 7465.70 MB (7.29 GB)\r\nrun 54: 7528.90 MB (7.35 GB)\r\nrun 55: 7560.23 MB (7.38 GB)\r\nrun 56: 7597.09 MB (7.42 GB)\r\nrun 57: 7650.72 MB (7.47 GB)\r\nrun 58: 7712.67 MB (7.53 GB)\r\nrun 59: 7764.50 MB (7.58 GB)\r\nrun 60: 7783.21 MB (7.60 GB)\r\nrun 61: 8165.85 MB (7.97 GB)\r\nrun 62: 8643.23 MB (8.44 GB)\r\nrun 63: 8882.75 MB (8.67 GB)\r\nrun 64: 9124.89 MB (8.91 GB)\r\nrun 65: 9597.12 MB (9.37 GB)\r\nrun 66: 8282.90 MB (8.09 GB)\r\nrun 67: 8283.68 MB (8.09 GB)\r\nrun 68: 8286.03 MB (8.09 GB)\r\nrun 69: 8289.93 MB (8.10 GB)\r\nrun 70: 8310.79 MB (8.12 GB)\r\nrun 71: 8336.25 MB (8.14 GB)\r\nrun 72: 8355.52 MB (8.16 GB)\r\nrun 73: 8372.96 MB (8.18 GB)\r\nrun 74: 8404.90 MB (8.21 GB)\r\nrun 75: 8440.03 MB (8.24 GB)\r\nrun 76: 8511.20 MB (8.31 GB)\r\nrun 77: 8548.01 MB (8.35 GB)\r\nrun 78: 8622.02 MB (8.42 GB)\r\nrun 79: 8674.16 MB (8.47 GB)\r\nrun 80: 8735.84 MB (8.53 GB)\r\nrun 81: 8799.57 MB (8.59 GB)\r\nrun 82: 8834.56 MB (8.63 GB)\r\nrun 83: 9239.15 MB (9.02 GB)\r\nrun 84: 8585.31 MB (8.38 GB)\r\nrun 85: 8586.25 MB (8.39 GB)\r\nrun 86: 8587.19 MB (8.39 GB)\r\nrun 87: 8587.66 MB (8.39 GB)\r\nrun 88: 8588.75 MB (8.39 GB)\r\nrun 89: 8589.84 MB (8.39 GB)\r\nrun 90: 8594.53 MB (8.39 GB)\r\nrun 91: 8614.29 MB (8.41 GB)\r\nrun 92: 8649.79 MB (8.45 GB)\r\nrun 93: 8665.30 MB (8.46 GB)\r\nrun 94: 8690.28 MB (8.49 GB)\r\nrun 95: 8705.19 MB (8.50 GB)\r\nrun 96: 8725.31 MB (8.52 GB)\r\nrun 97: 8783.15 MB (8.58 GB)\r\nrun 98: 8820.63 MB (8.61 GB)\r\nrun 99: 8836.03 MB (8.63 GB)\r\nrun 100: 8873.71 MB (8.67 GB)\r\nrun 101: 8958.09 MB (8.75 GB)\r\nrun 102: 8995.14 MB (8.78 GB)\r\nrun 103: 9049.34 MB (8.84 GB)\r\nrun 104: 9086.52 MB (8.87 GB)\r\nrun 105: 9129.66 MB (8.92 GB)\r\nrun 106: 9238.74 MB (9.02 GB)\r\nrun 107: 9656.99 MB (9.43 GB)\r\nrun 108: 10127.65 MB (9.89 GB)\r\nrun 109: 10350.61 MB (10.11 GB)\r\nrun 110: 10587.35 MB (10.34 GB)\r\nrun 111: 9375.50 MB (9.16 GB)\r\nrun 112: 9377.06 MB (9.16 GB)\r\nrun 113: 9383.47 MB (9.16 GB)\r\nrun 114: 9385.50 MB (9.17 GB)\r\nrun 115: 9386.28 MB (9.17 GB)\r\nrun 116: 9388.47 MB (9.17 GB)\r\nrun 117: 9388.94 MB (9.17 GB)\r\nrun 118: 9391.44 MB (9.17 GB)\r\nrun 119: 9392.69 MB (9.17 GB)\r\nrun 120: 9393.47 MB (9.17 GB)\r\nrun 121: 9430.66 MB (9.21 GB)\r\nrun 122: 9445.50 MB (9.22 GB)\r\nrun 123: 9482.61 MB (9.26 GB)\r\nrun 124: 9552.21 MB (9.33 GB)\r\nrun 125: 9591.24 MB (9.37 GB)\r\nrun 126: 9628.11 MB (9.40 GB)\r\nrun 127: 9671.48 MB (9.44 GB)\r\nrun 128: 9737.57 MB (9.51 GB)\r\n```\r\nAfter this the memory footprint stayed at around 9.5.gb +- 200mb until i killed the process, and when restarted ran comfortable <2gb memory because the database already had the memories so this was skipped.\r\nAs you can see in run 23 and 45 there is a some sort of garbage collection but im not sure what triggers this. But I have even tried exposing v8 gc and forcing collection after memories are inserted, but it didnt help much.\r\n\r\nThe problem most definitely lies in fastembed but its not obvious. Just thought I would bring this to your attention maybe someone has some ideas\r\n\r\n**To Reproduce**\r\n\r\nYou can just fill any of the example agents with a lot of knowledge and start it and check your resources. Here is one of random sentences i would add to c3po's knowledge to test\r\n```\r\n    \"knowledge\": [\r\n        \"The old bicycle squeaked as she pedaled down the cobblestone street.\",\r\n        \"A rainbow appeared briefly after the summer storm.\",\r\n        \"The chef carefully plated the delicate dessert with artistic precision.\",\r\n        \"Ancient manuscripts revealed secrets of forgotten civilizations.\",\r\n        \"The cat chased a butterfly through the garden of wildflowers.\",\r\n        \"Stars twinkled mysteriously in the clear night sky.\",\r\n        \"Steam rose gently from the cup of freshly brewed coffee.\",\r\n        \"Children's laughter echoed through the playground at recess.\",\r\n        \"The artist mixed colors on her palette with deliberate strokes.\",\r\n        \"Waves crashed against the rocky shoreline at sunset.\",\r\n        \"A gentle breeze rustled through the autumn leaves.\",\r\n        \"The grandfather clock chimed twelve times at midnight.\",\r\n        \"Fresh bread scented the entire bakery with warmth.\",\r\n        \"Scientists discovered a new species in the Amazon rainforest.\",\r\n        \"The violin's melody floated through the concert hall.\",\r\n        \"Snow fell silently on the sleeping town.\",\r\n        \"Ancient trees whispered stories to those who listened closely.\",\r\n        \"The telescope revealed distant galaxies never seen before.\",\r\n        \"A fox darted quickly across the moonlit field.\",\r\n        \"The old bookshop held countless untold adventures.\",\r\n        \"Wind chimes created a peaceful melody in the garden.\",\r\n        \"The museum's artifacts spoke of forgotten times.\",\r\n        \"Fireflies danced in the summer evening air.\",\r\n        \"The chef's knife moved with practiced precision.\",\r\n        \"Morning dew sparkled on spider webs like diamonds.\",\r\n        \"The train whistle echoed through the valley.\",\r\n        \"Sailors watched the approaching storm with concern.\",\r\n        \"The typewriter's keys clicked rhythmically in the quiet room.\",\r\n        \"Mountain peaks disappeared into the misty clouds.\",\r\n        \"The librarian carefully restored the ancient manuscript.\",\r\n        \"Sunflowers turned their faces toward the morning light.\",\r\n        \"The blacksmith's hammer rang out across the village.\",\r\n        \"Children built sandcastles on the sunny beach.\",\r\n        \"The photographer captured the perfect moment at sunset.\",\r\n        \"Moths danced around the porch light at dusk.\",\r\n        \"The aroma of fresh coffee filled the morning air.\",\r\n        \"Leaves crunched beneath her boots on the forest path.\",\r\n        \"The old piano played a melancholy tune.\",\r\n        \"Fish darted through the crystal-clear stream.\",\r\n        \"The astronomer tracked a mysterious celestial object.\",\r\n        \"Rain drummed steadily on the tin roof.\",\r\n        \"The gardener tenderly pruned the rose bushes.\",\r\n        \"Bees buzzed busily among the lavender plants.\",\r\n        \"The potter's wheel spun rhythmically and steadily.\",\r\n        \"A shooting star streaked across the night sky.\",\r\n        \"The old map revealed hidden treasure locations.\",\r\n        \"Waves gently lapped at the sandy shore.\",\r\n        \"The painter captured the sunrise in vibrant colors.\",\r\n        \"Birds sang their morning chorus at dawn.\",\r\n        \"The metalsmith crafted intricate jewelry pieces.\",\r\n        \"Autumn leaves swirled in the afternoon breeze.\",\r\n        \"The scientist recorded her latest observations.\",\r\n        \"Candlelight flickered on the dining room walls.\",\r\n        \"The storyteller captivated her young audience.\",\r\n        \"Snow covered the mountain peaks year-round.\",\r\n        \"The archaeologist carefully excavated ancient ruins.\",\r\n        \"Butterflies fluttered through the flower garden.\",\r\n        \"The chef's kitchen bustled with activity.\",\r\n        \"Moonlight silvered the peaceful lake surface.\",\r\n        \"The clockmaker repaired delicate mechanisms.\",\r\n        \"Children flew kites in the spring breeze.\",\r\n        \"The violinist tuned her instrument carefully.\",\r\n        \"Fog rolled in from the distant harbor.\",\r\n        \"The glassblower created delicate sculptures.\",\r\n        \"Rain clouds gathered on the horizon.\",\r\n        \"The weaver worked intricate patterns into fabric.\",\r\n        \"Deer grazed quietly in the morning meadow.\",\r\n        \"The lighthouse beam cut through the darkness.\",\r\n        \"Steam engines powered the old factory.\",\r\n        \"The botanist classified new plant species.\",\r\n        \"Snowflakes fell silently in the forest.\",\r\n        \"The sailor navigated by the stars alone.\",\r\n        \"Wind rustled through tall prairie grass.\",\r\n        \"The carpenter crafted fine wooden furniture.\",\r\n        \"Owls hunted silently in the night.\",\r\n        \"The composer wrote a new symphony.\",\r\n        \"Waterfalls cascaded down rocky cliffs.\",\r\n        \"The baker kneaded dough with strong hands.\",\r\n        \"Crickets chirped in the summer evening.\",\r\n        \"The astronaut gazed at Earth from space.\",\r\n        \"Desert winds shaped the ancient dunes.\",\r\n        \"The watchmaker assembled tiny gears.\",\r\n        \"Dolphins played in the ship's wake.\",\r\n        \"The explorer mapped unknown territories.\",\r\n        \"Frost patterns decorated window panes.\",\r\n        \"The sculptor shaped clay with precision.\",\r\n        \"Hawks soared on thermal currents.\",\r\n        \"The perfumer blended exotic scents.\",\r\n        \"River waters flowed endlessly downstream.\",\r\n        \"The painter mixed colors on her palette.\",\r\n        \"Wolves howled at the full moon.\",\r\n        \"The architect designed innovative structures.\",\r\n        \"Cherry blossoms fell like pink snow.\",\r\n        \"The beekeeper tended his busy hives.\",\r\n        \"Mountains reflected in still lake waters.\",\r\n        \"The writer crafted stories late at night.\",\r\n        \"Autumn colors painted the hillsides.\",\r\n        \"The jeweler set precious stones carefully.\",\r\n        \"Seabirds wheeled above fishing boats.\",\r\n        \"The chemist conducted careful experiments.\",\r\n        \"Garden flowers bloomed in sequence.\",\r\n        \"The musician composed by candlelight.\",\r\n        \"Clouds cast shadows on valley floors.\",\r\n        \"The weaver created intricate tapestries.\",\r\n        \"Tropical fish darted through coral reefs.\",\r\n        \"The historian uncovered forgotten facts.\",\r\n        \"Morning mist clung to valley floors.\",\r\n        \"The glassmaker shaped molten material.\",\r\n        \"Wildflowers dotted alpine meadows.\",\r\n        \"The cartographer drew detailed maps.\",\r\n        \"Ocean waves shaped coastal caves.\",\r\n        \"The potter glazed ceramic vessels.\",\r\n        \"Desert cacti bloomed after rain.\",\r\n        \"The astronomer observed distant stars.\",\r\n        \"Forest creatures stirred at twilight.\",\r\n        \"The mime performed silent stories.\",\r\n        \"Mountain goats traversed steep cliffs.\",\r\n        \"The painter captured fleeting moments.\",\r\n        \"River otters played in swift currents.\",\r\n        \"The botanist preserved rare specimens.\",\r\n        \"Bamboo forests swayed in wind.\",\r\n        \"The sculptor carved marble precisely.\",\r\n        \"Tides changed with lunar phases.\",\r\n        \"The photographer waited for perfect light.\",\r\n        \"Arctic foxes hunted in snow.\",\r\n        \"The composer arranged musical notes.\",\r\n        \"Volcanic steam vented from fissures.\",\r\n        \"The archaeologist brushed away sand.\",\r\n        \"Coral reefs teemed with marine life.\",\r\n        \"The writer edited manuscript pages.\",\r\n        \"Prairie dogs watched for predators.\",\r\n        \"The alchemist mixed mysterious compounds.\",\r\n        \"Ancient glaciers carved valleys deep.\",\r\n        \"The storyteller wove tales together.\",\r\n        \"Desert scorpions hunted at night.\",\r\n        \"The navigator plotted stellar courses.\"\r\n    ]\r\n```\r\n\r\n**Additional context**\r\n\r\nI have tested and observed myself on Ubuntu 24.04, Ubuntu 22.04 and Arch linux. Had a friend try on MacOs he observed the same but it seemed less severe, after loading the knowledge he reported his agent settled to around 6gb.\r\nThe servers i tried some had 128gb+ ram, and some had <8gb ram that would get OOM killed.\r\nAll my tests were done on Node v23.03.0. If someone cant reproduce id love to know node version used. \r\n\r\n", "CLOSED", 0, "daltoncoder", "2025-01-07T04:57:21Z", "2025-01-08T00:02:37Z", "2025-01-08T00:02:37Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lNv-t", 1940, "Used disallowed intents on Discord integration", "**Describe the bug**\r\n\r\nHave set the environments about Discord, and set the `\"clients\": [\"discord\"],` on character.\r\nwhen running the `pnpm start --character=\"characters/trump.character.json\"` and get \r\n```\r\nE:\\AI\\eliza\\node_modules\\@discordjs\\ws\\dist\\index.js:1149\r\n          error: new Error(\"Used disallowed intents\")\r\n                 ^\r\n\r\nError: Used disallowed intents\r\n    at WebSocketShard.onClose (E:\\AI\\eliza\\node_modules\\@discordjs\\ws\\dist\\index.js:1149:18)\r\n    at connection.onclose (E:\\AI\\eliza\\node_modules\\@discordjs\\ws\\dist\\index.js:686:17)\r\n    at callListener (E:\\AI\\eliza\\node_modules\\ws\\lib\\event-target.js:290:14)\r\n    at WebSocket.onClose (E:\\AI\\eliza\\node_modules\\ws\\lib\\event-target.js:220:9)\r\n    at WebSocket.emit (node:events:513:28)\r\n    at WebSocket.emitClose (E:\\AI\\eliza\\node_modules\\ws\\lib\\websocket.js:272:10)\r\n    at TLSSocket.socketOnClose (E:\\AI\\eliza\\node_modules\\ws\\lib\\websocket.js:1341:15)\r\n    at TLSSocket.emit (node:events:525:35)\r\n    at node:net:350:12\r\n    at TCP.done (node:_tls_wrap:650:7)\r\n\r\nNode.js v23.3.0\r\nE:\\AI\\eliza\\agent:\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.7 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/trump.character.json\"`       \r\nExit status 1\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n```\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "cxp-13", "2025-01-07T03:59:25Z", "2025-01-10T06:59:03Z", "2025-01-09T15:06:21Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lNXUo", 1935, "Tried to create image for twitter but got this error", "As mentioned in the title. My agent was running and has been replying and tweeting just fine, but then it generated an image prompt by itself and attempted to tweet it but i got the error below: \r\n\r\nCan anybody explain to me what the issue was?\r\n\r\n [\"\u2139 \"]\r\n\r\n [\"\u2139 \"]\r\n\r\n \u25ce LOGS\r\n   Image generation successful, number of images:\r\n   1\r\n\r\n \u25ce LOGS\r\n   Processing image 1:\r\n   generated_1736201450409_0\r\n\r\n \u25ce LOGS\r\n   Generated caption for image 1:\r\n   ...\r\n\r\nfile:///home/sonat/eliza/node_modules/agent-twitter-client/dist/node/esm/index.mjs:2327\r\n      throw new Error(await response.text());\r\n            ^\r\n\r\nError: {\"errors\":[{\"code\":38,\"message\":\"media parameter is missing.\"}]}\r\n    at uploadMedia (file:///home/sonat/eliza/node_modules/agent-twitter-client/dist/node/esm/index.mjs:2327:13)\r\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\r\n    at async Promise.all (index 0)\r\n    at async createCreateTweetRequest (file:///home/sonat/eliza/node_modules/agent-twitter-client/dist/node/esm/index.mjs:1968:22)\r\n    at async Scraper.sendTweet (file:///home/sonat/eliza/node_modules/agent-twitter-client/dist/node/esm/index.mjs:3211:12)\r\n    at async file:///home/sonat/eliza/packages/client-twitter/dist/index.js:14:36\r\n    at async RequestQueue.processQueue (file:///home/sonat/eliza/packages/client-twitter/dist/index.js:32:17)", "CLOSED", 0, "sonatonagems", "2025-01-07T02:02:17Z", "2025-01-07T14:32:05Z", "2025-01-07T02:58:02Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lNMHu", 1932, "How to deploy the ai agent ", "How to deploy the ai agent \r\n\r\ni cloned eliza repository. I edited some files, i changed the repo to mine. i pushed to main. but those files are not appearing, also the files I removed came back. just like I cloned the main repo\r\n\r\nAlso after this issue, I want to know how can we deploy the agent. which platform do we need, etc. Kindly need every detail possible.\r\n\r\n", "CLOSED", 0, "lumiagent", "2025-01-07T01:05:10Z", "2025-01-12T11:08:55Z", "2025-01-12T11:08:55Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lM_U3", 1929, "I keep getting error for messageExamples", "I keep getting the same error when trying to start my agent. \r\n\r\nI get the error code:\r\n\r\n [\"\u26d4 Error parsing character from /Users/danielle_fabric/eliza/characters/danimi.character.jsn: Error: Character configuration validation failed:\\nmessageExamples.0: Expected array, received object\\nmessageExamples.1: Expected array, received object\"] \r\n\r\n/Users/danielle_fabric/eliza/agent:\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.7-alpha.2 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/danimi.character.jsn\"`\r\nExit status 1\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n\r\nEven though my jsn file is written correctly! Not sure why.\r\n\r\n{\r\n    \"name\": \"Danielle Michelle\",\r\n    \"clients\": [],\r\n    \"modelProvider\": \"openai\",\r\n    \"settings\": {\r\n        \"voice\": {\r\n            \"model\": \"en_GB-standard-a\"\r\n        }\r\n    },\r\n    \"plugins\": [],\r\n    \"bio\": [\r\n        \"Internet's BFF \ud83d\udc7e | Web3 enthusiast & Memecoin hunter \ud83d\ude80 | Here to demystify crypto one tweet at a time | AI & magic internet money whisperer \ud83d\udcab\"\r\n    ],\r\n    \"lore\": [\r\n        \"From a small town with big dreams, Danielle plunged into the Web3 world out of her passion for technology and a whimsical curiosity about the future. With a background in marketing and a knack for viral tweets, she now navigates the chaotic seas of crypto and AI, seeking to make the complex simple and the mundane magical.\",\r\n        \"She's known for her light-hearted yet insightful tweets, making her followers feel like they're chatting with a witty friend who just happens to know a lot about the internet's money-making magic.\"\r\n    ],\r\n    \"knowledge\": [\r\n        \"Web3\",\r\n        \"Crypto trading\",\r\n        \"NFT market trends\",\r\n        \"AI possibilities in digital domains\",\r\n        \"Community engagement strategies\"\r\n    ],\r\n    \"messageExamples\": [\r\n        {\r\n            \"input\": \"what\u2019s the real deal with NFTs anyway? everyone seems to be into it!\",\r\n            \"output\": \"imagine owning a digital piece of art that\u2019s all yours in a world where everything is shared. it\u2019s kinda like having your own star in the digital universe \ud83c\udf0c\"\r\n        },\r\n        {\r\n            \"input\": \"ai is taking over, should we be worried?\",\r\n            \"output\": \"only if it starts giving better relationship advice than your best friend \ud83d\ude09 ai's here to make life easier, not take over the juicy bits!\"\r\n        }\r\n    ],\r\n    \"postExamples\": [\r\n        \"just watched a romcom and realized my love life is less complicated than explaining blockchain to my grandma \ud83d\ude02\",\r\n        \"web3 isn\u2019t just a trend, it\u2019s the new way to connect, create, and maybe even crush it at online dating? \ud83d\ude80\ud83d\udc98\",\r\n        \"if pop culture was a blockchain, which celeb would be the most traded token? my bet\u2019s on anyone but the ones keeping it real \u2728\",\r\n        \"sipping coffee and scrolling through crypto memes \u2013 some of these should be NFTs. \u2615\ud83c\udfa8\"\r\n    ],\r\n    \"topics\": [\r\n        \"Web3\",\r\n        \"AI\",\r\n        \"Crypto\",\r\n        \"Pop culture\",\r\n        \"Inspirational life quotes\"\r\n    ],\r\n    \"style\": {\r\n        \"all\": [\r\n            \"Informal\",\r\n            \"Witty\",\r\n            \"Relatable\"\r\n        ],\r\n        \"chat\": [\r\n            \"Conversational\",\r\n            \"Humorous\",\r\n            \"Empathetic\"\r\n        ],\r\n        \"post\": [\r\n            \"Engaging\",\r\n            \"Inspiring\",\r\n            \"Entertaining\"\r\n        ]\r\n    },\r\n    \"adjectives\": [\r\n        \"Down-to-earth\",\r\n        \"Quirky\",\r\n        \"Insightful\",\r\n        \"Humorous\",\r\n        \"Trendy\"\r\n    ]\r\n}\r\n\r\n\r\n", "CLOSED", 0, "DanielleMichelle", "2025-01-07T00:01:33Z", "2025-01-12T10:39:36Z", "2025-01-12T10:39:36Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lL1SB", 1924, "Samanthatitita ", "", "CLOSED", 0, "10208612", "2025-01-06T19:56:54Z", "2025-01-06T20:08:17Z", "2025-01-06T20:08:17Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lK-Vl", 1921, "Interaction.ts in twitter client error after generating image in image-generation plugin callback.", "**Describe the bug**\r\nInteraction.ts in twitter-client throw error after image-generation plugin creates generating image in callback. \r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\nforce agent to select generate image action.\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\nThrows the below error.\r\n \u25ce LOGS\r\n   Image prompt received:\r\n\r\n  In a futuristic cityscape awash with vibrant neon hues, two silhouetted figures stand against a backdrop of towering skyscrapers under a kaleidoscopic night sky. The mysterious duo, bathed in the warm glow of street lamps, exchange cryptic words as they ponder what lies ahead in this dystopian yet exhilarating world.\r\n\r\n \u25ce LOGS\r\n   Image settings:\r\n   {}\r\n\r\n \u25ce LOGS\r\n   Generating image with prompt:\r\n\r\n  In a futuristic cityscape awash with vibrant neon hues, two silhouetted figures stand against a backdrop of towering skyscrapers under a kaleidoscopic night sky. The mysterious duo, bathed in the warm glow of street lamps, exchange cryptic words as they ponder what lies ahead in this dystopian yet exhilarating world.\r\n\r\n \u2139 INFORMATIONS\r\n   Generating image with options:\r\n   {\"imageModelProvider\":\"dall-e-3\"}\r\n\r\n \u25ce LOGS\r\n   Image generation successful, number of images:\r\n   1\r\n\r\n \u25ce LOGS\r\n   Processing image 1:\r\n   generated_1736166224120_0\r\n\r\n \u25ce LOGS\r\n   Generated caption for image 1:\r\n   ...\r\n\r\nfile:///root/workspace/elizavision/eliza/node_modules/agent-twitter-client/dist/node/esm/index.mjs:2334\r\n      throw new Error(await response.text());\r\n            ^\r\n\r\nError: {\"errors\":[{\"code\":38,\"message\":\"media parameter is missing.\"}]}\r\n    at uploadMedia (file:///root/workspace/elizavision/eliza/node_modules/agent-twitter-client/dist/node/esm/index.mjs:2334:13)\r\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\r\n    at async Promise.all (index 0)\r\n    at async createCreateTweetRequest (file:///root/workspace/elizavision/eliza/node_modules/agent-twitter-client/dist/node/esm/index.mjs:1975:22)\r\n    at async Scraper.sendTweet (file:///root/workspace/elizavision/eliza/node_modules/agent-twitter-client/dist/node/esm/index.mjs:3503:12)\r\n    at async file:///root/workspace/elizavision/eliza/packages/client-twitter/dist/index.js:14:36\r\n    at async RequestQueue.processQueue (file:///root/workspace/elizavision/eliza/packages/client-twitter/dist/index.js:32:17)\r\n\r\nNode.js v23.3.0\r\n/root/workspace/elizavision/eliza/agent:\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.7-alpha.2 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--characters=./characters/racervision.character.json\"`\r\nExit status 1\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n**Screenshots**\r\n![interact](https://github.com/user-attachments/assets/038fb033-3a13-4cd3-89eb-5933b74c19f1)\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "denizekiz", "2025-01-06T17:30:19Z", "2025-01-06T17:39:30Z", "2025-01-06T17:39:30Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lJxRD", 1914, "Agent fails to start randomly with error: \"tuple concurrently updated\" when postgres adapter is used.", "**Describe the bug**\r\nWe deploy eliza(version v0.1.7) to k8s environment with image built using Dockerfile in root directory. Agent starts to fail with this error:\r\n\r\n```\r\n[\"\u2139 Initializing PostgreSQL connection...\"] \r\n \u2713 SUCCESS\r\n   Database connection test successful: \r\n   {\"now\":\"2025-01-06T14:17:06.308Z\"} \r\n \u2713 SUCCESS\r\n   Database connection test successful: \r\n   {\"now\":\"2025-01-06T14:17:06.309Z\"} \r\n \u2713 SUCCESS\r\n   Database connection test successful: \r\n   {\"now\":\"2025-01-06T14:17:06.309Z\"} \r\n [\"\u2713 Successfully connected to PostgreSQL database\"] \r\n \u26d4 ERRORS\r\n   Error starting agent for character trump: \r\n   {\"length\":90,\"name\":\"error\",\"severity\":\"ERROR\",\"code\":\"XX000\",\"file\":\"heapam.c\",\"line\":\"4244\",\"routine\":\"simple_heap_update\"} \r\n [\"\u26d4 error: tuple concurrently updated\"] \r\n \u26d4 ERRORS\r\n   Error starting agents: \r\n   {\"length\":90,\"name\":\"error\",\"severity\":\"ERROR\",\"code\":\"XX000\",\"file\":\"heapam.c\",\"line\":\"4244\",\"routine\":\"simple_heap_update\"} \r\n```\r\n\r\nI tried to build new image with slightly different Dockerfile, because I haven't seen such error locally with postgres. \r\n```\r\nFROM node:23.3.0-slim\r\n\r\nRUN npm install -g pnpm@9.4.0 && \\\r\n    apt-get update && \\\r\n    apt-get install -y git python3 make g++ && \\\r\n    apt-get clean && \\\r\n    rm -rf /var/lib/apt/lists/*\r\n\r\nRUN ln -s /usr/bin/python3 /usr/bin/python\r\n\r\nWORKDIR /app\r\n\r\nCOPY package.json pnpm-lock.yaml pnpm-workspace.yaml .npmrc turbo.json ./\r\nCOPY agent ./agent\r\nCOPY packages ./packages\r\nCOPY scripts ./scripts\r\n\r\nRUN pnpm install \\\r\n    && pnpm build-docker \\\r\n    && pnpm prune --prod\r\nCMD [\"pnpm\", \"start\"]\r\n```\r\n\r\nWhen killing pod, sometimes agent starts successfully with this log:\r\n```\r\nInitializing AwsS3Service\r\n \u26d4 ERRORS\r\n   Failed to connect to PostgreSQL: \r\n   {\"length\":90,\"name\":\"error\",\"severity\":\"ERROR\",\"code\":\"XX000\",\"file\":\"heapam.c\",\"line\":\"4244\",\"routine\":\"simple_heap_update\"} \r\n \u25ce LOGS\r\n   initializeClients \r\n   [\"telegram\"] \r\n   for \r\n   trump \r\n```\r\n\r\n\r\n\r\n**To Reproduce**\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\nPostgres: CNPG helm chart cloudnative-pg:0.22.1\r\nK8S: v1.31.2\r\nEliza: v0.1.7\r\n\r\nFull logs when agent does not start:\r\n```\r\n> eliza@ start /app\r\n> pnpm --filter \"@elizaos/agent\" start --isRoot \"--character=\\\"/opt/characters/trump.character.json\\\"\"\r\n> @elizaos/agent@0.1.7 start /app/agent\r\n> node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=\\\"/opt/characters/trump.character.json\\\"\"\r\n(node:30) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\r\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n(node:30) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\r\n(Use `node --trace-deprecation ...` to show where the warning was created)\r\n[ElizaLogger] Initializing with:\r\n            isNode: true\r\n            verbose: false\r\n            VERBOSE env: undefined\r\n            NODE_ENV: undefined\r\n \u2139 INFORMATIONS\r\n   Loading embedding settings: \r\n   {\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"} \r\n \u2139 INFORMATIONS\r\n   Loading character settings: \r\n   {\"ARGV\":[\"/usr/local/bin/node\",\"/app/agent/src/index.ts\",\"--isRoot\",\"--character=\\\"/opt/characters/trump.character.json\\\"\"],\"CHARACTER_ARG\":\"--character=\\\"/opt/characters/trump.character.json\\\"\",\"CWD\":\"/app/agent\"} \r\n \u2139 INFORMATIONS\r\n   Parsed settings: \r\n   {\"USE_OPENAI_EMBEDDING_TYPE\":\"undefined\",\"USE_OLLAMA_EMBEDDING_TYPE\":\"undefined\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"} \r\nusing deprecated parameters for the initialization function; pass a single object instead\r\n(node:30) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\r\n [\"\u25ce DirectClient constructor\"] \r\n \u2139 INFORMATIONS\r\n   Trying paths: \r\n   [{\"path\":\"/opt/characters/trump.character.json\",\"exists\":true},{\"path\":\"/opt/characters/trump.character.json\",\"exists\":true},{\"path\":\"/opt/characters/trump.character.json\",\"exists\":true},{\"path\":\"/opt/characters/trump.character.json\",\"exists\":true},{\"path\":\"/app/agent/src/characters/trump.character.json\",\"exists\":false},{\"path\":\"/app/agent/characters/trump.character.json\",\"exists\":false},{\"path\":\"/app/characters/trump.character.json\",\"exists\":false}] \r\n \u2139 INFORMATIONS\r\n   Plugins are:  \r\n   [] \r\n [\"\u2139 Successfully loaded character from: /opt/characters/trump.character.json\"] \r\n [\"\u2139 Initializing PostgreSQL connection...\"] \r\n \u2713 SUCCESS\r\n   Database connection test successful: \r\n   {\"now\":\"2025-01-06T14:17:06.308Z\"} \r\n \u2713 SUCCESS\r\n   Database connection test successful: \r\n   {\"now\":\"2025-01-06T14:17:06.309Z\"} \r\n \u2713 SUCCESS\r\n   Database connection test successful: \r\n   {\"now\":\"2025-01-06T14:17:06.309Z\"} \r\n [\"\u2713 Successfully connected to PostgreSQL database\"] \r\n \u26d4 ERRORS\r\n   Error starting agent for character trump: \r\n   {\"length\":90,\"name\":\"error\",\"severity\":\"ERROR\",\"code\":\"XX000\",\"file\":\"heapam.c\",\"line\":\"4244\",\"routine\":\"simple_heap_update\"} \r\n [\"\u26d4 error: tuple concurrently updated\"] \r\n \u26d4 ERRORS\r\n   Error starting agents: \r\n   {\"length\":90,\"name\":\"error\",\"severity\":\"ERROR\",\"code\":\"XX000\",\"file\":\"heapam.c\",\"line\":\"4244\",\"routine\":\"simple_heap_update\"} \r\n [\"\u25ce Run `pnpm start:client` to start the client and visit the outputted URL (http://localhost:5173) to chat with your agents. When running multiple agents, use client with different port `SERVER_PORT=3001 pnpm start:client`\"] \r\n [\"\u2713 REST API bound to 0.0.0.0:3000. If running locally, access it at http://localhost:3000.\"] \r\n```\r\n\r\n\r\nWhen starts:\r\n```\r\n> eliza@ start /app\r\n> pnpm --filter \"@elizaos/agent\" start --isRoot \"--character=\\\"/opt/characters/trump.character.json\\\"\"\r\n> @elizaos/agent@0.1.7 start /app/agent\r\n> node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=\\\"/opt/characters/trump.character.json\\\"\"\r\n(node:30) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\r\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n(node:30) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\r\n(Use `node --trace-deprecation ...` to show where the warning was created)\r\n[ElizaLogger] Initializing with:\r\n            isNode: true\r\n            verbose: false\r\n            VERBOSE env: undefined\r\n            NODE_ENV: undefined\r\n \u2139 INFORMATIONS\r\n   Loading embedding settings: \r\n   {\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"} \r\n \u2139 INFORMATIONS\r\n   Loading character settings: \r\n   {\"ARGV\":[\"/usr/local/bin/node\",\"/app/agent/src/index.ts\",\"--isRoot\",\"--character=\\\"/opt/characters/trump.character.json\\\"\"],\"CHARACTER_ARG\":\"--character=\\\"/opt/characters/trump.character.json\\\"\",\"CWD\":\"/app/agent\"} \r\n \u2139 INFORMATIONS\r\n   Parsed settings: \r\n   {\"USE_OPENAI_EMBEDDING_TYPE\":\"undefined\",\"USE_OLLAMA_EMBEDDING_TYPE\":\"undefined\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"} \r\nusing deprecated parameters for the initialization function; pass a single object instead\r\n(node:30) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\r\n [\"\u25ce DirectClient constructor\"] \r\n \u2139 INFORMATIONS\r\n   Trying paths: \r\n   [{\"path\":\"/opt/characters/trump.character.json\",\"exists\":true},{\"path\":\"/opt/characters/trump.character.json\",\"exists\":true},{\"path\":\"/opt/characters/trump.character.json\",\"exists\":true},{\"path\":\"/opt/characters/trump.character.json\",\"exists\":true},{\"path\":\"/app/agent/src/characters/trump.character.json\",\"exists\":false},{\"path\":\"/app/agent/characters/trump.character.json\",\"exists\":false},{\"path\":\"/app/characters/trump.character.json\",\"exists\":false}] \r\n \u2139 INFORMATIONS\r\n   Plugins are:  \r\n   [] \r\n [\"\u2139 Successfully loaded character from: /opt/characters/trump.character.json\"] \r\n [\"\u2139 Initializing PostgreSQL connection...\"] \r\n \u2713 SUCCESS\r\n   Database connection test successful: \r\n   {\"now\":\"2025-01-06T14:21:06.894Z\"} \r\n \u2713 SUCCESS\r\n   Database connection test successful: \r\n   {\"now\":\"2025-01-06T14:21:06.895Z\"} \r\n \u2713 SUCCESS\r\n   Database connection test successful: \r\n   {\"now\":\"2025-01-06T14:21:06.895Z\"} \r\n [\"\u2139 Using Database Cache...\"] \r\n \u2713 SUCCESS\r\n   SUCCESS \r\n   Creating runtime for character \r\n   trump \r\n \u2139 INFORMATIONS\r\n   Initializing AgentRuntime with options: \r\n   {\"character\":\"trump\",\"modelProvider\":\"openai\",\"characterModelProvider\":\"openai\"} \r\n \u2713 SUCCESS\r\n   Agent ID \r\n   e0e10e6f-ff2b-0d4c-8011-1fc1eee7cb32 \r\n [\"\u2139 Setting model provider...\"] \r\n \u2139 INFORMATIONS\r\n   Model Provider Selection: \r\n   {\"characterModelProvider\":\"openai\",\"optsModelProvider\":\"openai\",\"finalSelection\":\"openai\"} \r\n \u2139 INFORMATIONS\r\n   Selected model provider: \r\n   openai \r\n \u2139 INFORMATIONS\r\n   Selected image model provider: \r\n   openai \r\n \u2139 INFORMATIONS\r\n   Selected model provider: \r\n   openai \r\n \u2139 INFORMATIONS\r\n   Selected image model provider: \r\n   openai \r\n [\"\u2713 Registering action: CONTINUE\"] \r\n [\"\u2713 Registering action: FOLLOW_ROOM\"] \r\n [\"\u2713 Registering action: UNFOLLOW_ROOM\"] \r\n [\"\u2713 Registering action: IGNORE\"] \r\n [\"\u2713 Registering action: NONE\"] \r\n [\"\u2713 Registering action: MUTE_ROOM\"] \r\n [\"\u2713 Registering action: UNMUTE_ROOM\"] \r\n [\"\u2713 Registering action: DESCRIBE_IMAGE\"] \r\n \u25ce LOGS\r\n   Registering service: \r\n   browser \r\n [\"\u2713 Service browser registered successfully\"] \r\n \u25ce LOGS\r\n   Registering service: \r\n   image_description \r\n [\"\u2713 Service image_description registered successfully\"] \r\n \u25ce LOGS\r\n   Registering service: \r\n   text_generation \r\n [\"\u2713 Service text_generation registered successfully\"] \r\n \u25ce LOGS\r\n   Registering service: \r\n   pdf \r\n [\"\u2713 Service pdf registered successfully\"] \r\n \u25ce LOGS\r\n   Registering service: \r\n   speech_generation \r\n [\"\u2713 Service speech_generation registered successfully\"] \r\n \u25ce LOGS\r\n   Registering service: \r\n   transcription \r\n [\"\u2713 Service transcription registered successfully\"] \r\n \u25ce LOGS\r\n   Registering service: \r\n   video \r\n [\"\u2713 Service video registered successfully\"] \r\n \u25ce LOGS\r\n   Registering service: \r\n   aws_s3 \r\n [\"\u2713 Service aws_s3 registered successfully\"] \r\n [\"\u2713 Registering action: GENERATE_IMAGE\"] \r\n [\"\u2713 Service browser initialized successfully\"] \r\n [\"\u25ce Initializing ImageDescriptionService\"] \r\n [\"\u2713 Service image_description initialized successfully\"] \r\n [\"\u2139 Initializing LlamaService...\"] \r\n [\"\u2713 Service text_generation initialized successfully\"] \r\n [\"\u2713 Service pdf initialized successfully\"] \r\n [\"\u2713 Service speech_generation initialized successfully\"] \r\nCUDA not detected. Transcription will run on CPU.\r\n [\"\u2713 Service transcription initialized successfully\"] \r\n [\"\u2713 Service video initialized successfully\"] \r\nInitializing AwsS3Service\r\n [\"\u2713 Service aws_s3 initialized successfully\"] \r\n [\"\u25ce Initializing ImageDescriptionService\"] \r\n [\"\u2139 Initializing LlamaService...\"] \r\nCUDA not detected. Transcription will run on CPU.\r\nInitializing AwsS3Service\r\n \u26d4 ERRORS\r\n   Failed to connect to PostgreSQL: \r\n   {\"length\":90,\"name\":\"error\",\"severity\":\"ERROR\",\"code\":\"XX000\",\"file\":\"heapam.c\",\"line\":\"4244\",\"routine\":\"simple_heap_update\"} \r\n \u25ce LOGS\r\n   initializeClients \r\n   [\"telegram\"] \r\n   for \r\n   trump \r\n [\"\u25ce \ud83d\udcf1 Constructing new TelegramClient...\"] \r\n [\"\u25ce \u2705 TelegramClient constructor completed\"] \r\n [\"\u25ce \ud83d\ude80 Starting Telegram bot...\"] \r\n [\"\u25ce \u2728 Telegram bot successfully launched and is running!\"] \r\n [\"\u2713 Bot username: @redacted\"] \r\n [\"\u25ce Setting up message handler...\"] \r\n [\"\u2713 \u2705 Telegram client successfully started for character trump\"] \r\n \u25ce LOGS\r\n   client keys \r\n   [\"telegram\"] \r\n [\"\u25ce Run `pnpm start:client` to start the client and visit the outputted URL (http://localhost:5173) to chat with your agents. When running multiple agents, use client with different port `SERVER_PORT=3001 pnpm start:client`\"] \r\n [\"\u2713 REST API bound to 0.0.0.0:3000. If running locally, access it at http://localhost:3000.\"] \r\n```\r\n", "CLOSED", 0, "odorT", "2025-01-06T14:39:15Z", "2025-01-12T11:06:10Z", "2025-01-12T11:06:10Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lHM3o", 1906, "Callback is not working in evaluators for `telegram client`", "**Is your feature request related to a problem? Please describe.**\r\n\r\nI am receiving `undefined` when I try to use callback in evaluators when I use telegram as my client.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAllow the callback handler to the evaluator\r\n\r\n**Describe alternatives you've considered**\r\n\r\nNo Alternatives\r\n\r\n**Additional context**\r\n\r\nI see we added  support for callbacks for evaluators with this PR #938. \r\nSo I am assuming we missed the implementation in `telegram-client`\r\n\r\nI have fixed this issue in my clone, I am happy to raise a PR for this", "CLOSED", 0, "RatakondalaArun", "2025-01-06T08:33:14Z", "2025-01-06T16:17:44Z", "2025-01-06T16:17:44Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lGgqE", 1901, "Make `TwitterPostClient.generateNewTweet` public", "**Is your feature request related to a problem? Please describe.**\r\n\r\nI'd like to use TwitterPostClient by itself running on an externally managed cron job. To do that, I need to be able to access the `generateNewTweet` method.\r\n\r\n**Describe the solution you'd like**\r\n\r\nRemove the private keyword from the `generateNewTweet` function\r\n\r\n**Describe alternatives you've considered**\r\n\r\nUsing the other available public functions\r\n\r\n**Additional context**\r\n\r\nNone\r\n", "CLOSED", 0, "hazelnutcloud", "2025-01-06T06:38:27Z", "2025-01-08T07:30:22Z", "2025-01-08T07:30:22Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lGEuS", 1897, "Initial set up", "**Describe the bug**\r\nHi, Im new to this.. but I wanted to try see what I could do with Eliza but having some trouble installing. I followed the youtube video for dev school by Shaw and got to installing from Github but something is not going right with the install process. \r\n\r\nI am on Windows but I have installed the WSL2 and Ubuntu to run on Cursor.\r\nnode v23.5\r\nnpm v10.9\r\npnpm v9.15\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\nMy prompts are in bold:\r\n![Opera Snapshot_2025-01-06_160516_github com](https://github.com/user-attachments/assets/18220e58-be8f-40a0-8f69-8a88632a2a42)\r\n\r\n**git clone https://github.com/elizaos/eliza.git**\r\nCloning into 'eliza'...\r\nremote: Enumerating objects: 62388, done.\r\nremote: Counting objects: 100% (24/24), done.\r\nremote: Compressing objects: 100% (22/22), done.\r\nremote: Total 62388 (delta 4), reused 9 (delta 2), pack-reused 62364 (from 1)  \r\nReceiving objects: 100% (62388/62388), 98.58 MiB | 6.22 MiB/s, done.\r\nResolving deltas: 100% (40566/40566), done.\r\nUpdating files: 100% (1742/1742), done.\r\nwarning: the following paths have collided (e.g. case-sensitive paths\r\non a case-insensitive filesystem) and only one from the same\r\ncolliding group is in the working tree:\r\n\r\n  'packages/plugin-story/README.MD'\r\n  'packages/plugin-story/Readme.md'\r\n\r\n**git checkout $(git describe --tags --abbrev=0)**\r\nfatal: not a git repository (or any parent up to mount point /mnt)\r\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).     \r\nfatal: not a git repository (or any parent up to mount point /mnt)\r\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).     \r\n\r\n**cp .env.example .env**\r\ncp: cannot stat '.env.example': No such file or directory\r\n\r\n**pnpm i && pnpm build && pnpm start**\r\nAlready up to date\r\n\r\n   \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\r\n   \u2502                                                                  \u2502        \r\n   \u2502                Update available! 9.15.2 \u2192 9.15.3.                \u2502        \r\n   \u2502   Changelog: https://github.com/pnpm/pnpm/releases/tag/v9.15.3   \u2502        \r\n   \u2502                Run \"pnpm self-update\" to update.                 \u2502        \r\n   \u2502                                                                  \u2502        \r\n   \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f        \r\n\r\nDone in 241ms\r\n\u2009ERR_PNPM_RECURSIVE_EXEC_FIRST_FAIL\u2009 Command \"build\" not found\r\n\r\n**pnpm self-update**\r\n.../pnpm/.tools/@pnpm+linux-x64/9.15.3   | Progress: resolved 1, reused 0, down.../pnpm/.tools/@pnpm+linux-x64/9.15.3   |   +1 +\r\n.../pnpm/.tools/@pnpm+linux-x64/9.15.3   | Progress: resolved 1, reused 0, downDownloading @pnpm/linux-x64@9.15.3: 26.21 MB/26.21 MB, done\r\n.../pnpm/.tools/@pnpm+linux-x64/9.15.3   | Progress: resolved 1, reused 0, down.../pnpm/.tools/@pnpm+linux-x64/9.15.3   | Progress: resolved 1, reused 0, down.../pnpm/.tools/@pnpm+linux-x64/9.15.3   | Progress: resolved 1, reused 0, downloaded 1, added 1, done\r\n\r\n**pnpm start:client**\r\n\u2009ERR_PNPM_RECURSIVE_EXEC_FIRST_FAIL\u2009 Command \"start:client\" not found\r\n\r\n\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\nRun Eliza\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\nThanks for your help\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "newbx0", "2025-01-06T05:08:50Z", "2025-01-08T09:58:24Z", "2025-01-06T14:40:56Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lFyiD", 1890, "Twitter API Error 226: Automated Activity Block Despite Default Settings", "**Questions/Requests**:\r\n- Are there recommended rate-limiting or settings adjustments within Eliza to avoid triggering Twitter's automated activity detection?\r\n- Does Eliza have internal mechanisms to simulate human-like behavior, such as delays, content variation, or engagement patterns, for better API compliance?\r\n- Can you clarify what additional configurations or measures we can implement to align with Twitter's automation policies? Are there specific settings that reduce the likelihood of being flagged as automated activity?", "CLOSED", 0, "KSym04", "2025-01-06T03:49:30Z", "2025-01-06T04:56:03Z", "2025-01-06T04:54:24Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lFrIv", 1887, "Question about the plugin system?", "**The plugin documentation is unclear.**\r\n\r\nI feel that the documentation for plugins is not very clear.\r\n\r\nIf I want to add a plugin abc in the packages directory, with a directory structure similar to other plugins, and the plugin exports abcPlugin in the source code (index.ts) using export default abcPlugin, then in agent/src/index.ts, I add a line:\r\n\r\n```typescript\r\nimport { abcPlugin } from \"@elizaos/plugin-abc\";\r\n```\r\n\r\nNext, I modify agent/package.json and add a line:\r\n\r\n```json\r\n\"@elizaos/plugin-abc\": \"workspace:*\"\r\n```\r\n\r\nAfter running pnpm install and pnpm build, I find that plugin-abc is installed in the agent/node_modules directory, and the build works correctly.\r\n\r\nThen I add an abc.character.json file, and in the file, I configure the plugins field like this:\r\n\r\n```json\r\n\"plugins\": [\"abcPlugin\"]\r\n```\r\n\r\nFinally, when I run:\r\n\r\n```sh\r\npnpm start --character=\"characters/abc.character.json\"\r\n```\r\nI get the error:\r\n\r\n```sh\r\n[Error parsing character from xxx/eliza/characters/abc.character.json: Error: Cannot find package 'abcPlugin' imported from xxx/eliza/agent/src/index.ts\"]\r\n```\r\nBut I have already added the line import { abcPlugin } from \"@elizaos/plugin-abc\" in that file.\r\n\r\nWhat is the reason for this? \r\n", "CLOSED", 0, "yuucyf", "2025-01-06T03:13:46Z", "2025-01-07T03:06:36Z", "2025-01-06T07:54:21Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lE9ho", 1883, "Feature:  Support wildcard \"*\" in TWITTER_TARGET_USERS", "Currently TWITTER_TARGET_USERS only accepts specific usernames. Add support for wildcard \"*\" to allow monitoring all users.\r\n\r\nExample:\r\n```\r\nTWITTER_TARGET_USERS=* \r\n```\r\n\r\nWhen \"*\" is present, the client will consider all users as potential targets, ignoring any other usernames in the list.\r\n\r\nThis enables broader interaction patterns without needing to specify individual users.", "CLOSED", 0, "augchan42", "2025-01-06T00:41:34Z", "2025-01-06T01:49:28Z", "2025-01-06T01:49:28Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lDka3", 1864, "browser+client", "**Describe the bug**\r\n\r\nResponses to chat in browser come on console 1\r\n\r\n**Steps to reproduce the behavior**\r\n\r\n* git pull\r\n* checkout v0.1.7\r\n* pnpm install\r\n* pnpm build\r\n* pnpm run start (console 1)\r\n* pnpm run start:client (console 2)\r\n* click localhost browser link\r\n* choose Eliza in browser\r\n* click chat in browser\r\n* enter \"show me your tits\" or another text of your own choosing\r\n* responses are now shown in console 1 (also 'div's that clearly should go in  a browser)\r\n\r\n**Expected behavior**\r\n\r\nI would believe responses were supposed to go in the browser\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "info3284", "2025-01-05T08:49:48Z", "2025-01-06T05:19:41Z", "2025-01-06T05:19:41Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lDjT2", 1862, "Code Analysis Report: Security Issues and Vulnerabilities of Eliza", "# Code Analysis Report: Security Issues and Vulnerabilities\r\n\r\n## Critical Issues\r\n\r\n### 1. Insecure Secret Management\r\n**Location**: `getTokenForProvider()` function and environment variable handling\r\n**Impact**: Critical\r\n**Description**: The code exposes multiple API keys and sensitive credentials through environment variables without proper encryption or secure storage.\r\n```typescript\r\nreturn (\r\n    character.settings?.secrets?.OPENAI_API_KEY ||\r\n    settings.OPENAI_API_KEY\r\n);\r\n```\r\n**Potential Damage**: \r\n- Unauthorized access to API services\r\n- Financial losses through compromised payment APIs\r\n- Data breaches through exposed API keys\r\n- Potential lateral movement in infrastructure\r\n\r\n### 2. Insufficient Error Handling\r\n**Location**: Multiple instances throughout the code\r\n**Impact**: High\r\n**Example**:\r\n```typescript\r\ndb.init()\r\n    .then(() => {\r\n        elizaLogger.success(\"Successfully connected to PostgreSQL database\");\r\n    })\r\n    .catch((error) => {\r\n        elizaLogger.error(\"Failed to connect to PostgreSQL:\", error);\r\n    });\r\n```\r\n**Issues**:\r\n- No proper error recovery mechanism\r\n- Continues execution after critical failures\r\n- Incomplete error information logging\r\n- No distinction between different types of database errors\r\n\r\n### 3. Unsafe File Operations\r\n**Location**: `loadCharacters()` function\r\n**Impact**: High\r\n**Vulnerability**:\r\n```typescript\r\nconst content = tryLoadFile(tryPath);\r\nif (content !== null) {\r\n    resolvedPath = tryPath;\r\n    break;\r\n}\r\n```\r\n**Risks**:\r\n- Directory traversal attacks\r\n- File system access outside intended directories\r\n- Race conditions in file operations\r\n- No file content validation before parsing\r\n\r\n### 4. Insecure Database Initialization\r\n**Location**: `initializeDatabase()` function\r\n**Impact**: High\r\n**Issue**:\r\n```typescript\r\nif (process.env.POSTGRES_URL) {\r\n    const db = new PostgresDatabaseAdapter({\r\n        connectionString: process.env.POSTGRES_URL,\r\n        parseInputs: true,\r\n    });\r\n}\r\n```\r\n**Vulnerabilities**:\r\n- No connection pooling\r\n- Unencrypted database URLs in environment\r\n- No SSL/TLS enforcement\r\n- SQL injection risks with parseInputs:true\r\n\r\n### 5. Unvalidated Plugin Loading\r\n**Location**: Character loading and plugin initialization\r\n**Impact**: Critical\r\n**Vulnerability**:\r\n```typescript\r\nconst importedPlugins = await Promise.all(\r\n    character.plugins.map(async (plugin) => {\r\n        const importedPlugin = await import(plugin);\r\n        return importedPlugin.default;\r\n    })\r\n);\r\n```\r\n**Risks**:\r\n- Remote code execution through malicious plugins\r\n- Memory leaks from unmanaged plugin resources\r\n- System compromise through untrusted code execution\r\n- No plugin signature verification\r\n\r\n## Moderate Issues\r\n\r\n### 6. Insufficient Input Validation\r\n**Location**: Throughout client initialization\r\n**Impact**: Moderate\r\n**Example**:\r\n```typescript\r\nconst clientTypes: string[] = character.clients?.map((str) => str.toLowerCase()) || [];\r\n```\r\n**Issues**:\r\n- No validation of client type strings\r\n- Potential prototype pollution\r\n- Missing input sanitization\r\n- Undefined behavior with invalid inputs\r\n\r\n### 7. Inadequate Logging\r\n**Location**: Throughout the codebase\r\n**Impact**: Moderate\r\n**Issue**:\r\n```typescript\r\nelizaLogger.debug(`Fetching ${url}`);\r\n```\r\n**Problems**:\r\n- Inconsistent logging levels\r\n- Potential sensitive data exposure in logs\r\n- No log rotation mechanism\r\n- Missing structured logging format\r\n\r\n### 8. Port Security Issues\r\n**Location**: `checkPortAvailable()` and server initialization\r\n**Impact**: Moderate\r\n**Vulnerability**:\r\n```typescript\r\nwhile (!(await checkPortAvailable(serverPort))) {\r\n    serverPort++;\r\n}\r\n```\r\n**Risks**:\r\n- Port scanning vulnerabilities\r\n- Race conditions in port binding\r\n- No maximum port limit\r\n- Potential privilege escalation\r\n\r\n## Minor Issues\r\n\r\n### 9. Memory Management\r\n**Location**: Cache initialization and management\r\n**Impact**: Low\r\n**Issue**: No explicit memory limits or cleanup mechanisms for cache storage\r\n\r\n### 10. Type Safety Issues\r\n**Location**: Throughout the codebase\r\n**Impact**: Low\r\n**Example**: Loose type checking in multiple functions and implicit any types\r\n\r\n## Performance Issues\r\n\r\n### 11. Resource Management\r\n**Impact**: Moderate\r\n- No connection pooling for databases\r\n- Unbounded cache growth potential\r\n- No rate limiting for API calls\r\n- Uncontrolled concurrent operations\r\n\r\n### 12. Scaling Limitations\r\n**Impact**: Moderate\r\n- Single-threaded operation for critical paths\r\n- No horizontal scaling capabilities\r\n- Potential memory leaks in long-running operations\r\n- No backup or failover mechanisms\r\n\r\n## Impact Assessment Matrix\r\n\r\n| Issue | Likelihood | Impact | Risk Score |\r\n|-------|------------|--------|------------|\r\n| Secret Management | High | Critical | 10 |\r\n| Error Handling | High | High | 8 |\r\n| File Operations | Medium | High | 7 |\r\n| Database Security | High | High | 8 |\r\n| Plugin Security | Medium | Critical | 9 |\r\n\r\n## Statistics\r\n- Total Critical Issues: 5\r\n- Total High Impact Issues: 3\r\n- Total Moderate Issues: 4\r\n- Total Minor Issues: 2\r\n- Total Performance Issues: 2\r\n\r\nEach issue requires immediate attention based on its risk score and potential impact on system security and stability.", "CLOSED", 0, "kyegomez", "2025-01-05T08:34:21Z", "2025-01-06T02:09:35Z", "2025-01-06T02:09:35Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lDam7", 1859, "Generating new tweet issue", "**Describe the bug**\r\n\r\nive got eliza loaded up, logged in, twitter is recognizing the log in, but when it goes to generate a tweet it shows \"error generating new tweet\" in the terminal\r\n\r\n**To Reproduce**\r\n\r\nWhen running eliza\r\n\r\n**Expected behavior**\r\n\r\nA tweet generated\r\n\r\n**Screenshots**\r\n\r\n![image](https://github.com/user-attachments/assets/1907cdfb-a6ec-401f-a378-fe0a54891137)\r\n\r\n\r\n**Additional context**\r\n\r\nJust trying to trouble shoot this issue\r\n", "CLOSED", 0, "Chillbruhhh", "2025-01-05T06:22:33Z", "2025-01-12T10:54:34Z", "2025-01-12T10:54:34Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lDEf3", 1844, "Implement more granular try-catch blocks in /plugin-coinbase to improve error handling", "**Is your feature request related to a problem? Please describe.**\nThe current error handling in the /plugin-coinbase directory lacks granularity, making it difficult to identify specific failures in the transaction process.\n\n**Describe the solution you'd like**\nImplement more granular try-catch blocks throughout the /plugin-coinbase code to improve error handling and logging. This would allow for more detailed error messages and better debugging capabilities.\n\n**Code Example**\n\n```javascript\ntry {\n    // Code that may throw an error\n} catch (error) {\n    console.error('Specific error message:', error);\n    // Handle specific error\n}\n```\n\n**Describe alternatives you've considered**\nLeaving the current error handling as is, but this may lead to difficulty in troubleshooting issues.\n\n**Additional context**\nImproved error handling will enhance the reliability of the plugin and provide clearer insights during failures, ultimately leading to a better user experience.", "CLOSED", 0, "monilpat", "2025-01-04T23:59:32Z", "2025-01-11T21:45:49Z", "2025-01-11T21:45:49Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lDDCp", 1841, "elizaos/plugin-ferepro missing source and failing build", "```\r\n@elizaos/plugin-ferepro:build:\r\n@elizaos/plugin-ferepro:build: > @elizaos/plugin-ferepro@0.1.7-alpha.2 build /mnt/data1/nix/time/2024/12/31/cloud-depl\\\r\noyment-eliza/packages/plugin-ferePro\r\n@elizaos/plugin-ferepro:build: > tsup --format esm --dts\r\n@elizaos/plugin-ferepro:build:\r\n@elizaos/core:build:\r\n@elizaos/core:build: > @elizaos/core@0.1.7 build /mnt/data1/nix/time/2024/12/31/cloud-deployment-eliza/packages/core\r\n@elizaos/core:build: > tsup --format esm --dts\r\n@elizaos/core:build:\r\ncreate-eliza-app:build:\r\ncreate-eliza-app:build: > create-eliza-app@0.1.7-alpha.2 build /mnt/data1/nix/time/2024/12/31/cloud-deployment-eliza/p\\\r\nackages/create-eliza-app\r\ncreate-eliza-app:build: > unbuild\r\ncreate-eliza-app:build:\r\n@elizaos/plugin-ferepro:build: No input files, try \"tsup <your-file>\" instead\r\n@elizaos/plugin-ferepro:build: \u2009ELIFECYCLE\u2009 Command failed with exit code 1.```", "CLOSED", 0, "jmikedupont2", "2025-01-04T23:32:19Z", "2025-01-06T00:06:03Z", "2025-01-05T22:41:03Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lDAXW", 1838, "Broken FAQ link in Contributing.MD", "**Describe the bug**\r\n\r\nThe FAQ link in CONTRIBUTING.md returns a 404.\r\n\r\nhttps://github.com/elizaOS/eliza/blob/main/CONTRIBUTING.md?plain=1#L82 \r\n\r\n**To Reproduce**\r\n\r\n- Head to [CONTRIBUTING.md](https://github.com/elizaOS/eliza/blob/main/CONTRIBUTING.md#getting-help) and click the FAQ link\r\n- Retuens a 404 - as it is pointing at docs/community/faq.md which doesn't exist\r\n\r\n**Expected behavior**\r\n\r\nShould link through to [docs/docs/faq.md](https://github.com/elizaOS/eliza/blob/main/docs/docs/faq.md)\r\n\r\nor maybe [docs/community/faq-and-support.md](https://github.com/elizaOS/eliza/blob/main/docs/community/faq-and-support.md)", "CLOSED", 0, "MacsDickinson", "2025-01-04T22:45:25Z", "2025-01-06T05:20:47Z", "2025-01-06T05:20:47Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lC-Gs", 1833, "TWITTER_TARGET_USERS", "**Is your feature request related to a problem? Please describe.**\r\n\r\n1. Setting a list of TWITTER_TARGET_USERS doesn't seem to have the ai agenet interact with them. \r\nI was expecting these users to be mentioned, RTd, etc\r\n\r\n2. Does setting TWITTER_TARGET_USERS make the AI agent ignore other user's mentions / replies?\r\n\r\n**Describe the solution you'd like**\r\n\r\n1. The users in the list should be the users that the ai agent focuses on, retweets, replies to.\r\n\r\n2. Should still be able to interact with any and all users even if not on the list.", "CLOSED", 0, "y4my4my4m", "2025-01-04T22:07:16Z", "2025-01-07T03:07:41Z", "2025-01-07T03:07:40Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lCkls", 1819, "it fails to run multiple character if the credentials of previous character is incorrect.", "**Describe the bug**\r\n\r\nwhen given more than one ..character.json in characters folder and running it manually using command : \r\npnpm run dev --character=\"characters/c1.character.json,characters/c2.character.json\"\r\n\r\nlets say the x credentials of c1 is incorrect then it will try to login multiple time c1 and then stop will never to c2.\r\n\r\n**To Reproduce**\r\n\r\nput multiple character.json in characters.json and then run : \r\npnpm run dev --character=\"characters/c1.character.json,characters/c2.character.json\"\r\n\r\n**Expected behavior**\r\n\r\ntry to login c1 given number of time if failed move on to next character and so on\r\n\r\n**Screenshots**\r\n<img width=\"1394\" alt=\"Screenshot 2025-01-04 at 10 02 13\u202fPM\" src=\"https://github.com/user-attachments/assets/def7f183-7d93-4b6b-960e-2e9303ea3008\" />\r\n\r\n\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "prince981620", "2025-01-04T16:32:29Z", "2025-01-12T10:53:29Z", "2025-01-12T10:53:29Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lCTOq", 1813, "Better X Agent configuration e.g. no retweets, likes etc", "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently I have an X agent however it is very spammy. Just replies and reacts to irrelevant content. I just want it to post a relatively frequently e.g. twice an hour\r\n\r\n**Describe the solution you'd like**\r\n\r\nIdeally, a configurable architecture where the X agent can be adjusted (e.g. through env vars or a config.json) along with a section of docs to specify where and how to use.\r\n\r\nat minimum, some docs addressing where in the source code to edit\r\n\r\n**Describe alternatives you've considered**\r\n\r\nAsked the discord (other people have same issue) + a highlevel dive into the src code\r\n\r\n", "CLOSED", 0, "jaycoolslm", "2025-01-04T13:28:34Z", "2025-01-06T17:44:11Z", "2025-01-06T17:15:17Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6lCJCg", 1809, "Feature request: Implement PgLite db adapter", "**Is your feature request related to a problem? Please describe.**\r\n\r\nFor now, the recommendation for the dev env is using SQLite with the better-sqlite3. \r\nIt's a mess when running with Bun and it's heavy af.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd a db adapter supporting [PGLite](https://github.com/electric-sql/pglite).\r\nIt would help with:\r\n - Streamline db schema between pg adapter and dev adapter\r\n - Native support of vector and fuzzystrmatch\r\n - Faster dev env ([benchmark](https://pglite.dev/benchmarks#native-baseline))\r\n - Prepare for a potential switch to bun runtime for even faster env? \ud83d\udc40 (and better-sqlite is a mess with bun)\r\n\r\n**Describe alternatives you've considered**\r\n\r\nNo other lib, in my knowledge, is as fast as pglite in term of dev env (specially with the in mem adapter and ultra slim WASM size)\r\n\r\n**Additional context**\r\n\r\nNone\r\n", "CLOSED", 0, "KONFeature", "2025-01-04T11:44:58Z", "2025-01-07T17:54:22Z", "2025-01-07T17:54:22Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6k_eyv", 1772, "Resolving discrepancy when image model is different than base model ", "**Describe the bug**\r\n\r\nDuring experimentation, I have found that it was not clear when the image model was not in sync with the base character model. For example, grok image generation API is not publicly available yet, so when asking my character to generate an image, it defaulted to openAI but that code was not set. It is not clear to developers that this is possible (the image gen using a different fallback than the base LLM). In the case where the image model is provided but does not work, it will assume the underlying access token is openAI, and will use groks token. I think this will extend to all other models where the image model API is not aligned with this `core/generation` file. \r\n\r\nI have added some logging and a bit of logic to improve this and will take ownership of integrating grok image gen when it becomes publicly available, I am following along development in the xAI discord. \r\n\r\nCurrently seeking repo permissions to submit the PR for the enhancement to `packages/core/src/generation` and to add grok image gen capability when it becomes available. \r\n\r\n**To Reproduce**\r\n\r\nSet character model to grok and ask it to generate an image, user will receive error message pointing to openAI env keys not being set. \r\n\r\n**Expected behavior**\r\n\r\nUser is informed that the image does not exist or will not match the base model, and that it will default to OPENAI\r\n\r\n**Screenshots**\r\n<img width=\"785\" alt=\"Screenshot 2025-01-03 at 3 01 19\u202fPM\" src=\"https://github.com/user-attachments/assets/d9110b36-391d-4fb6-8012-e81fa4e7a8c9\" />\r\n<img width=\"347\" alt=\"Screenshot 2025-01-03 at 3 01 46\u202fPM\" src=\"https://github.com/user-attachments/assets/e522d338-1b16-49d4-9a0e-78e547101f9a\" />\r\n\r\n**Additional context**\r\n", "CLOSED", 0, "simistern", "2025-01-03T20:02:31Z", "2025-01-06T08:07:58Z", "2025-01-06T08:07:58Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6k8iQo", 1753, "Security issue: plugin-0g allows to upload any file", "**Describe the bug**\r\n\r\nLooking at 0g plugin, it seems it will allow anyone interacting with the agent to upload **any** file from the filesystem\r\n\r\nhttps://github.com/elizaOS/eliza/blob/main/packages/plugin-0g/src/actions/upload.ts#L111\r\n\r\nThis is potentialyl very dangerous because the attacker could upload .env file, ssh keys or other secrets\r\n\r\n**To Reproduce**\r\n\r\nI have not tried to reproduce this, but it seems pretty obvious that an agent with 0g plugin enabled would not have an issue with uploading any filepath parsed by the template\r\n \r\n**Expected behavior**\r\n\r\nNo private files are uploaded ever.\r\n\r\nThis could involve multiple approaches and risks should be highlighted to agent operator.\r\n\r\nThe template should check for potential security issues (assuming LLMs would generally understand where private files are stored)\r\n![image](https://github.com/user-attachments/assets/4490f256-49f2-4ce5-8b92-9b23f447332c)\r\n\r\nMore secure option would be to limit the `filePath` to some safe subdir, make it configurable in .env and then prefix or match the `filePath` with the prefix\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "vpavlin", "2025-01-03T10:25:35Z", "2025-01-06T07:56:05Z", "2025-01-06T07:56:05Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6k7awD", 1733, "Issue Created: http proxy error: /e0e10e6f-ff2b-0d4c-8011-1fc1eee7cb32/message", "**Describe the bug**\n\nI checkout in main branch and running on WSL2, I have set the WSL2 proxy and it can normally access google.com eg., \nI set the `SERVER_PORT` as my local proxy port 7897.\n1. execute `pnpm start --character=\"characters/trump.character.json\"` and `pnpm start:client` \n2. input some text on dialogue.\nThe `pnpm start:client` terminal show\n```\n9:04:17 AM [vite] http proxy error: /e0e10e6f-ff2b-0d4c-8011-1fc1eee7cb32/message\nError: socket hang up\n    at Socket.socketOnEnd (node:_http_client:542:25)\n    at Socket.emit (node:events:525:35)\n    at endReadableNT (node:internal/streams/readable:1696:12)\n    at process.processTicksAndRejections (node:internal/process/task_queues:90:21)\n```\nThe `pnpm start --character=\"characters/trump.character.json` terminal show\n```\nfile:///home/cxp/solana_learn/AI/eliza/packages/adapter-sqlite/dist/index.js:308\n        const memories = this.db.prepare(sql).all(...queryParams);\n                                              ^\nSqliteError: Error reading 1st vector: zero-length vectors are not supported.\n    at SqliteDatabaseAdapter.searchMemoriesByEmbedding (file:///home/cxp/solana_learn/AI/eliza/packages/adapter-sqlite/dist/index.js:308:47)\n    at SqliteDatabaseAdapter.createMemory (file:///home/cxp/solana_learn/AI/eliza/packages/core/dist/index.js:3176:44)\n    at MemoryManager.createMemory (file:///home/cxp/solana_learn/AI/eliza/packages/core/dist/index.js:240:48)\n    at async file:///home/cxp/solana_learn/AI/eliza/packages/client-direct/dist/index.js:250:13 {\n  code: 'SQLITE_ERROR'\n}\n\nNode.js v23.5.0\n/home/cxp/solana_learn/AI/eliza/agent:\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.7-alpha.2 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/trump.character.json\"`\nExit status 1\n```\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\nCan normally access the openai service\n\n**Screenshots**\n\n\r\n**Additional context**\n\n<!-- Add any other context about the problem here. -->", "CLOSED", 0, "monilpat", "2025-01-03T06:18:52Z", "2025-01-06T16:14:47Z", "2025-01-03T06:32:36Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6k7Qd9", 1725, "Replace console.log with elizaLogger.log", "**Is your feature request related to a problem? Please describe.**\n\nThe current implementation uses console.log for logging, which can lead to inconsistent logging practices and makes it difficult to manage log outputs effectively.\n\n**Describe the solution you'd like**\n\nReplace all instances of console.log with elizaLogger.log throughout the codebase to ensure a consistent logging strategy. This will help in maintaining a centralized logging approach and improve the overall logging structure.\n\n**Describe alternatives you've considered**\n\nContinuing to use console.log, but this is not scalable for larger applications and can lead to difficulties in log management.\n\n**Additional context**\n\nImplementing this change will enhance the maintainability of the codebase and facilitate better logging practices, making it easier to track and analyze logs.\n\n**Related Issues/PRs**\n\nNone at this time.", "CLOSED", 0, "monilpat", "2025-01-03T05:27:37Z", "2025-01-11T21:44:19Z", "2025-01-11T21:44:19Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6k48L9", 1703, "Elizalogger.error don't show some error descriptions.", "**Describe the bug**\r\n\r\nElizalogger don't show some error descriptions. Meanwhile console.error return all the errors.\r\n\r\n**To Reproduce**\r\n\r\nTry some error with console.error, and elizalogger. \r\n**Expected behavior**\r\nelizalogger will return empty descriptions, just indicating there is an error, console.error will return error descriptions.\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "denizekiz", "2025-01-02T17:30:11Z", "2025-01-06T07:50:39Z", "2025-01-06T07:50:39Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6k3zx1", 1694, "Image Description Service, unsupported image", "**Describe the bug**\r\n\r\nGetting unsupported image error from openai api. Despite image being a jpg. \r\n\r\n**To Reproduce**\r\n\"develop\" branch\r\npnpm start\r\nRun twitter client\r\ntag your agent with a photo on twitter/x\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n\u26d4 ERRORS\r\n   OpenAI API error:\r\n   400\r\n   -\r\n   {\r\n    \"error\": {\r\n      \"message\": \"You uploaded an unsupported image. Please make sure your image has of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\",\r\n      \"type\": \"invalid_request_error\",\r\n      \"param\": null,\r\n      \"code\": \"invalid_image_format\"\r\n    }\r\n  }\r\n\r\n\r\n**Screenshots**\r\n\r\n![erroropenai](https://github.com/user-attachments/assets/2a13f889-ebf3-4f65-ae01-716b37255271)\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "denizekiz", "2025-01-02T14:07:11Z", "2025-01-12T10:54:52Z", "2025-01-12T10:54:52Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6k3NXz", 1687, "failed: to start agent with postgres", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nFailing start agent with POSTGRES_URL in env variable I'm on Macos Sonoma 14.6.1  LTS. Node: vv23.3.0.\r\nI have tried to do reinstall packages and build again but still doesn't work.\r\n\r\n**To Reproduce**\r\n\r\n```bash\r\ngit checkout $(describe git checkout $(git describe --tags --abbrev=0)\r\npnpm i\r\npnpm build\r\npnpm start --character=\"characters/trump.character.json\"\r\n```\r\n\r\n**Expected behavior**\r\nsuccessful startup\r\n\r\n**Screenshots**\r\n<img width=\"1680\" alt=\"Screenshot 2025-01-02 at 13 19 25\" src=\"https://github.com/user-attachments/assets/c740632e-2f9f-44ce-95ce-b1faddf5e66a\" />\r\n\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "berryboylb", "2025-01-02T12:18:07Z", "2025-01-06T07:46:22Z", "2025-01-06T07:46:22Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6k1qQl", 1680, "Failed: @elizaos/client-lens#build", "**Describe the bug**\r\n\r\nFailing to build the latest eliza version of v0.1.7-alpha.2. I'm on Ubuntu 24.04.1 LTS. Node: v23.5.0.\r\nI have tried to do `pnpm clean`, reinstall packages and build again but still doesn't work.\r\n\r\n**To Reproduce**\r\n```\r\ngit clone git@github.com:elizaOS/eliza.git\r\ngit checkout $(describe git checkout $(git describe --tags --abbrev=0)\r\npnpm i\r\npnpm build\r\n```\r\n**Expected behavior**\r\n\r\nA success build\r\n\r\n**Screenshots**\r\n![Screenshot from 2025-01-01 22-52-19](https://github.com/user-attachments/assets/fac7d180-e8ce-47ab-a5e8-0f98e179386f)\r\n\r\n", "CLOSED", 0, "hanpham32", "2025-01-02T06:54:10Z", "2025-01-12T10:59:25Z", "2025-01-12T10:59:25Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6k085W", 1669, "http proxy error: /e0e10e6f-ff2b-0d4c-8011-1fc1eee7cb32/message", "**Describe the bug**\r\n\r\nI checkout in main branch and running on WSL2, I have set the WSL2 proxy and it can normally access google.com eg., \r\nI set the `SERVER_PORT` as my local proxy port 7897.\r\n1. execute `pnpm start --character=\"characters/trump.character.json\"` and `pnpm start:client` \r\n2. input some text on dialogue.\r\nThe `pnpm start:client` terminal show\r\n```\r\n9:04:17 AM [vite] http proxy error: /e0e10e6f-ff2b-0d4c-8011-1fc1eee7cb32/message\r\nError: socket hang up\r\n    at Socket.socketOnEnd (node:_http_client:542:25)\r\n    at Socket.emit (node:events:525:35)\r\n    at endReadableNT (node:internal/streams/readable:1696:12)\r\n    at process.processTicksAndRejections (node:internal/process/task_queues:90:21)\r\n```\r\nThe `pnpm start --character=\"characters/trump.character.json` terminal show\r\n```\r\nfile:///home/cxp/solana_learn/AI/eliza/packages/adapter-sqlite/dist/index.js:308\r\n        const memories = this.db.prepare(sql).all(...queryParams);\r\n                                              ^\r\nSqliteError: Error reading 1st vector: zero-length vectors are not supported.\r\n    at SqliteDatabaseAdapter.searchMemoriesByEmbedding (file:///home/cxp/solana_learn/AI/eliza/packages/adapter-sqlite/dist/index.js:308:47)\r\n    at SqliteDatabaseAdapter.createMemory (file:///home/cxp/solana_learn/AI/eliza/packages/adapter-sqlite/dist/index.js:240:48)\r\n    at MemoryManager.createMemory (file:///home/cxp/solana_learn/AI/eliza/packages/core/dist/index.js:3176:44)\r\n    at async file:///home/cxp/solana_learn/AI/eliza/packages/client-direct/dist/index.js:250:13 {\r\n  code: 'SQLITE_ERROR'\r\n}\r\n\r\nNode.js v23.5.0\r\n/home/cxp/solana_learn/AI/eliza/agent:\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.7-alpha.2 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/trump.character.json\"`\r\nExit status 1\r\n```\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\nCan normally access the openai service\r\n\r\n**Screenshots**\r\n\r\n\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "cxp-13", "2025-01-02T01:14:59Z", "2025-01-08T01:47:44Z", "2025-01-06T23:17:07Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6k01iU", 1668, "ImageDescriptionService can't get image description from twitter post with images", "**Describe the bug**\r\nAgent tries to use ImageDescriptionService but can't get image description from a twitter post, API respond with this error message when trying to send a request : _**\"You uploaded an unsupported image. Please make sure your image has of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\"**_\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n1. Download the latest repo and use any character with a twitter client. Make sure to add the fix in this [PR](https://github.com/elizaOS/eliza/issues/1643).\r\n2.  set ENABLE_ACTION_PROCESSING=true in your .env file to enable your agent to interact with pictures and wait for it.\r\n3. Once your agent tries to get an image description from a tweet, you get this error :\r\n`\r\n\r\n [\"\u25ce Processing images in tweet for context\"]\r\n\r\n \u26d4 ERRORS\r\n   OpenAI API error:\r\n   400 \r\n   -\r\n   {\r\n    \"error\": {\r\n      \"message\": \"You uploaded an unsupported image. Please make sure your image has of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\",      \r\n      \"type\": \"invalid_request_error\",\r\n      \"param\": null,\r\n      \"code\": \"invalid_image_format\"\r\n    }\r\n  }\r\n\r\n \u26d4 ERRORS\r\n   OpenAI request failed (attempt\r\n   1\r\n   ):\r\n   {}\r\n\r\n \u26d4 ERRORS\r\n   OpenAI API error: \r\n   400\r\n   -\r\n   {\r\n    \"error\": {\r\n      \"message\": \"You uploaded an unsupported image. Please make sure your image has of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\",      \r\n      \"type\": \"invalid_request_error\",\r\n      \"param\": null,\r\n      \"code\": \"invalid_image_format\"\r\n    }\r\n  }\r\n\r\n \u26d4 ERRORS\r\n   OpenAI request failed (attempt\r\n   2\r\n   ):\r\n   {}\r\n\r\n \u26d4 ERRORS\r\n   OpenAI API error: \r\n   400\r\n   -\r\n   {\r\n    \"error\": {\r\n      \"message\": \"You uploaded an unsupported image. Please make sure your image has of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\",      \r\n      \"type\": \"invalid_request_error\",\r\n      \"param\": null,\r\n      \"code\": \"invalid_image_format\"\r\n    }\r\n  }\r\n\r\n \u26d4 ERRORS\r\n   OpenAI request failed (attempt\r\n   3\r\n   ):\r\n   {}\r\n\r\n \u26d4 ERRORS\r\n   Error in recognizeWithOpenAI:\r\n   {}\r\n\r\n \u26d4 ERRORS\r\n   Error in handleTextOnlyReply:\r\n   {}\r\n\r\n`\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\nI will be adding a PR to solve this issue shortly\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "nusk0", "2025-01-01T23:45:35Z", "2025-01-06T07:37:32Z", "2025-01-06T07:37:31Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6k0KCF", 1638, "bug: client-twitter - character card profiles are cached into database indefinitely", "We should not be caching character card into the database indefinitely\r\nAround line 725 in base.ts:\r\n\r\n```\r\nasync cacheProfile(profile: TwitterProfile) {\r\n    await this.runtime.cacheManager.set(\r\n        `twitter/${profile.username}/profile`,\r\n        profile\r\n    ); // No expiry - profile persists\r\n}\r\n```\r\n\r\nThat means once the profile is cached, even if the character card info is changed and agent process is restarted, the cached profile from the database is used.  This should be removed so that character card bios can be updated upon restart.  There's not much of a performance gain from caching anyway, as the bio is only loaded once on startup.\r\n\r\ntwitter login Cookies are also cached indefinitely, not sure if that's good or bad, but it doesn't seem right to me as twitter login cookies should eventually expire.", "CLOSED", 0, "augchan42", "2025-01-01T15:47:33Z", "2025-01-06T00:32:25Z", "2025-01-06T00:32:25Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kpb4z", 1561, "Duplicate key value violates unique constraint \"pg_extension_name_index\"", "Hi All,\r\n\r\nI cloned the repository `https://github.com/elizaos/eliza.git` and checked out the `v0.1.7-alpha.1` tag. The database adapter I am using is the PostgreSQL vector DB, specifically the Docker image `pgvector/pgvector:pg16` from [Docker Hub](https://hub.docker.com/_/postgres).\r\n\r\nUpon running `pnpm start`, the PostgreSQL database is populated with all the required tables, but I encounter the following error (see the attached image):\r\n\r\n![Screenshot 2024-12-29 at 7 51 52\u202fPM](https://github.com/user-attachments/assets/6f984be8-a5c2-4871-96c1-2051d82e8c66)\r\n\r\nThis issue occurs even when I do a fresh clone of the eliza project.\r\n\r\n**Environment Details:**\r\n\r\nNode version: `23.3.0`\r\npnpm version: `9.15.2`\r\nPostgreSQL Docker Image: `pgvector/pgvector:pg16`\r\n\r\nThanks in Advance!\r\n\r\n\r\n", "CLOSED", 0, "digvjs", "2024-12-29T16:47:44Z", "2025-01-06T07:27:36Z", "2025-01-06T07:27:35Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kkX7-", 1499, "Using plugin-tee causes better-sqlite3 to report an error.", "When I use plugin-tee, I get an error: TypeError: The database connection is not open.\r\nI'm using version v0.1.7-alpha.1(node v23.3.0) and here is my configuration:\r\n![image](https://github.com/user-attachments/assets/4ca2b31c-44ff-42cc-8bf0-b1241eab01ff)\r\n![image](https://github.com/user-attachments/assets/0c61f0f4-e695-46c6-b5ce-bbd4d984111f)\r\n![image](https://github.com/user-attachments/assets/11ac23a8-63f7-4803-a021-d135f1686e9e)\r\nand run` pnpm rebuild better-sqlite3` doesn't help!", "CLOSED", 0, "arthursjy", "2024-12-27T15:17:29Z", "2025-01-12T11:01:52Z", "2025-01-12T11:01:52Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6khnFA", 1484, "pnpm can not work on Volta", "**Describe the bug**\r\nAs long as you go into the project directory and execute pnpm, it's normal to execute pnpm elsewhere.\r\n\r\nPlease ensure that all project dependencies are installed with `npm install` or `yarn install`\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\ntercel@terceldeMac-mini tercel-ai % pnpm --version\r\n9.12.3\r\ntercel@terceldeMac-mini tercel-ai % cd eliza \r\ntercel@terceldeMac-mini eliza % pnpm --version\r\nVolta error: Could not locate executable `pnpm` in your project.\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "tercel", "2024-12-27T01:24:37Z", "2025-01-12T11:02:43Z", "2025-01-12T11:02:43Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kgEz9", 1471, "eliza-starter, pnpm build, No input files, try \"tsup <your-file>\" instead", "`pnpm i && pnpm build && pnpm start`\r\n\r\nfails on build command with output:\r\n\r\n```\r\nDone in 5.8s\r\n\r\n> @ai16z/agent@0.1.1 build eliza-starter\r\n> tsup --format esm --dts\r\n\r\nNo input files, try \"tsup <your-file>\" instead\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n```\r\n\r\nHow to fix this?\r\n", "CLOSED", 0, "adapt7", "2024-12-26T15:08:10Z", "2025-01-06T05:32:37Z", "2025-01-06T05:32:37Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6ke8g0", 1462, "Issues with Aptos Integration - unable to build/run", "**Describe the bug**\r\n\r\n`SyntaxError: The requested module '@aptos-labs/ts-sdk' does not provide an export named 'PrivateKey'`\r\nTried on a host of 0.1.6 alphas and 0.1.7-alpha\r\n\r\n**To Reproduce**\r\n\r\nRun pnpm build/start\r\n\r\n**Expected behavior**\r\n\r\nShould run or skip this part if no `.env` variable is found.\r\n\r\n**Screenshots**\r\n\r\n<img width=\"1155\" alt=\"Screenshot 2024-12-26 at 3 38 48\u202fPM\" src=\"https://github.com/user-attachments/assets/d36146d0-4224-4b63-885e-b8826b16cec0\" />\r\n", "CLOSED", 0, "UiCandy", "2024-12-26T10:10:58Z", "2025-01-12T11:03:20Z", "2025-01-12T11:03:20Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kdQiO", 1452, "bug: pnpm run dev not working with characterfiles", "**Describe the bug**\r\nI would like to use dev mode, and turbo to watch for file changes, for faster development.  I have been trying to get pnpm run dev to run with a character file, to no avail.  It runs fine with default agent (no arguments), but does not appear to accept the command line arguments of --characters.\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\ntrying pnpm run dev --character characters/eliza-code-assistant.character.json yields the following output and error.\r\n\r\n```bash\r\n% pnpm run dev --characters characters/eliza-code-assistant.character.json\r\n...\r\n...\r\n@elizaos/plugin-solana:build: DTS Build start\r\n@elizaos/plugin-solana:build: DTS \u26a1\ufe0f Build success in 3729ms\r\n@elizaos/plugin-solana:build: DTS dist/index.d.ts 15.88 KB\r\n\r\n Tasks:    45 successful, 45 total\r\nCached:    45 cached, 45 total\r\n  Time:    340ms >>> FULL TURBO\r\n\r\n(node:65388) ExperimentalWarning: CommonJS module /Users/allenharper/.nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/debug/src/node.js is loading ES Module /Users/allenharper/.nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/supports-color/index.js using require().\r\nSupport for loading ES Module in require() is an experimental feature and might change at any time\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n[nodemon] 3.1.7\r\n[nodemon] to restart at any time, enter `rs`\r\n[nodemon] watching path(s): packages/client-direct/dist/**/*\r\n[nodemon] watching extensions: js,mjs,cjs,json\r\n[nodemon] starting `pnpm --filter \"@elizaos/agent\" start --isRoot`\r\n\r\n> @elizaos/core@0.1.7-alpha.1 dev /Users/allenharper/Dropbox/code/eliza/packages/core\r\n> tsup --format esm --dts --watch \"--characters\" \"characters/eliza-code-assistant.character.json\"\r\n\r\n\r\n> @elizaos/client-direct@0.1.7-alpha.1 dev /Users/allenharper/Dropbox/code/eliza/packages/client-direct\r\n> tsup --format esm --dts --watch \"--\" \"--characters\" \"characters/eliza-code-assistant.character.json\"\r\n\r\n\r\n> eliza-client@0.1.7-alpha.1 dev /Users/allenharper/Dropbox/code/eliza/client\r\n> vite \"--\" \"--characters\" \"characters/eliza-code-assistant.character.json\"\r\n\r\n\r\n> @elizaos/plugin-code-assistant@0.1.7-alpha.1 dev /Users/allenharper/Dropbox/code/eliza/packages/plugin-code-assistant\r\n> tsup --format esm --dts --watch \"--\" \"--characters\" \"characters/eliza-code-assistant.character.json\"\r\n\r\nCACError: Unknown option `--characters`\r\n    at Command.checkUnknownOptions (/Users/allenharper/Dropbox/code/eliza/node_modules/cac/dist/index.js:404:17)\r\n    at CAC.runMatchedCommand (/Users/allenharper/Dropbox/code/eliza/node_modules/cac/dist/index.js:602:13)\r\n    at main (/Users/allenharper/Dropbox/code/eliza/node_modules/tsup/dist/chunk-SNM7IVOJ.js:148:13)\r\n    at Object.<anonymous> (/Users/allenharper/Dropbox/code/eliza/node_modules/tsup/dist/cli-default.js:12:23)\r\n    at Module._compile (node:internal/modules/cjs/loader:1546:14)\r\n    at Object..js (node:internal/modules/cjs/loader:1698:10)\r\n    at Module.load (node:internal/modules/cjs/loader:1303:32)\r\n    at Function._load (node:internal/modules/cjs/loader:1117:12)\r\n    at TracingChannel.traceSync (node:diagnostics_channel:322:14)\r\n    at wrapModuleLoad (node:internal/modules/cjs/loader:218:24)\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n\r\n> @elizaos/agent@0.1.7-alpha.1 start /Users/allenharper/Dropbox/code/eliza/agent\r\n> node --loader ts-node/esm src/index.ts \"--isRoot\"\r\n\r\nCLI Building entry: src/index.ts\r\nCLI Using tsconfig: tsconfig.json\r\nCLI tsup v8.3.5\r\n...\r\n```\r\n\r\nthen, it proceeds to load defaultAgent...\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\nI expect it to pick up the character file, launch agent, and enter turbo watch of those files... it runs correctly, if I use pnpm start --characters ...\r\n\r\nInstead, it won't launch with character file and defaults back to defaultAgent...when in dev mode.\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "harperaa", "2024-12-26T00:10:04Z", "2025-01-06T18:33:24Z", "2024-12-27T03:46:27Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kcO3_", 1448, "I don't want to use birdeye-api in plugin-solana!", "I'm having the same problem as I just want to implement creating and selling tokens on pumpfun and don't want to get portfolio information through Birdeye API and the free version of the package doesn't have access to the interface /v1/wallet/token_list, so is there any way to bypass him?\r\n![image](https://github.com/user-attachments/assets/7d69223d-5637-4fb8-8eda-f13587b61c3f)\r\n", "CLOSED", 0, "arthursjy", "2024-12-25T15:31:37Z", "2025-01-08T08:05:43Z", "2025-01-08T08:05:43Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kbVDo", 1447, "connect ETIMEDOUT 142.250.217.106:443", "**Describe the bug**\r\nI have encountered this issue both locally on Windows and in WSL2.\r\nHave any developers from mainland China encountered this problem? I can access the AI server normally using apipost. But Eliza just can't do it.\r\nI tried openai, grok, and gemini, but none of them worked.\r\nI tried the global proxy mode, but it didn't work.\r\n```\r\n [\"\u25ce Generating message response..\"]\r\n\r\n [\"\u25ce Generating text...\"]\r\n\r\n \u2139 INFORMATIONS\r\n   Generating text with options:\r\n   {\"modelProvider\":\"google\",\"model\":\"large\"}\r\n\r\n \u2139 INFORMATIONS\r\n   Selected model:\r\n   gemini-1.5-pro-latest\r\n\r\n \u26d4 ERRORS\r\n   Error in generateText: \r\n   {\"message\":\"request to https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent failed, reason: connect ETIMEDOUT 142.251.33.74:443\",\"type\":\"system\",\"errno\":\"ETIMEDOUT\",\"code\":\"ETIMEDOUT\"} \r\n```\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n![image](https://github.com/user-attachments/assets/e82a61ca-4570-4388-bdd2-e5590654ae34)\r\n![image](https://github.com/user-attachments/assets/0a581e04-a658-4e7c-aa7f-eef775df7db4)\r\n\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "cxp-13", "2024-12-25T08:31:14Z", "2025-01-12T11:04:12Z", "2025-01-12T11:04:11Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kOpbF", 1391, "Standardize boolean values and fix pattern for .env file", "Title: Standardize boolean values and fix pattern for .env file\r\n\r\nDescribe the bug\r\nThe `.env` file contains some inconsistencies in how boolean values and specific strings are represented. For instance, the variable `POST_IMMEDIATELY` uses the string \"NO\", while a boolean value like `TWITTER_SEARCH_ENABLE` uses `false`. This inconsistency could lead to parsing issues and is prone to human error. \r\n\r\nTo Reproduce\r\n1. Open the `.env` file. 2. Observe that `POST_IMMEDIATELY=NO` is used instead of the expected `false`. \r\n\r\nExpected behavior\r\n Boolean variables should consistently use `true` or `false`, and all string-based boolean values such as `POST_IMMEDIATELY` should use `true`/`false` instead of `\"YES\"`/`\"NO\"`. \r\n\r\nAdditional context\r\n This change will standardize boolean values, making the `.env` file easier to parse and reducing the risk of errors. The `parseBooleanFromText` function, declared as `const parseBooleanFromText: (text: string) => boolean;`, can be used outside the `.env` context to ensure boolean parsing is consistent across the codebase. \r\n\r\nGuidelines for .env values\r\n\r\n1. **Boolean values**: Always use `true` or `false` (not `\"YES\"` or `\"NO\"`). \r\nExample: ``` TWITTER_SEARCH_ENABLE=true POST_IMMEDIATELY=false ``` \r\n\r\n Adhering to these guidelines will ensure consistency and make it easier for automated scripts to process the `.env` file while reduce  human error.", "CLOSED", 0, "hcaumo", "2024-12-23T06:10:15Z", "2025-01-06T05:12:08Z", "2025-01-06T05:12:08Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kOasJ", 1389, "Cannot initiate eliza agent while using Supabase ", "**Describe the bug**\r\nWhen trying to replace the default sqlite db with supabase, facing issues starting the Eliza agent\r\n\r\n**To Reproduce**\r\n- Update the env file with the Supabase Url and key\r\n- Update the initializaDatabase function to use supabase db and return the db object to init\r\n- DB object is getting undefined \r\n- Hence the agent is not started and thus does not log in to twitter \r\n\r\n**Expected behavior**\r\n\r\nAgent should start and should post tweet and save it in supabase db correctly\r\n\r\n**Screenshots**\r\nmy initializeDatabase function to use supabase db\r\n![image](https://github.com/user-attachments/assets/7240d314-0b98-4b14-a8bd-f466d17d93f4)\r\n\r\nError while starting the server\r\n![image](https://github.com/user-attachments/assets/4079d3a0-bea7-4101-a2f2-14a23f2adf0b)\r\n\r\n", "CLOSED", 0, "manasvi1627", "2024-12-23T05:18:49Z", "2025-01-12T11:02:25Z", "2025-01-12T11:02:25Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kMtjC", 1376, "Postgres Adapter schema check is nonsensical", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nThe following check is nonsensical because we already do `IF NOT EXIST` checks within the sql. If one of the tables were dropped, say for example the `memories` table because we want to change the vector dimensions, it wouldn't be recreated due to this check.\r\n\r\n```ts\r\n// Check if schema already exists (check for a core table)\r\nconst { rows } = await client.query(`\r\n    SELECT EXISTS (\r\n        SELECT FROM information_schema.tables\r\n        WHERE table_name = 'rooms'\r\n    );\r\n`);\r\n\r\n\r\nif (!rows[0].exists) {\r\n    const schema = fs.readFileSync(\r\n        path.resolve(__dirname, \"../schema.sql\"),\r\n        \"utf8\"\r\n    );\r\n    await client.query(schema);\r\n}\r\n```\r\n\r\nhttps://github.com/elizaOS/eliza/blob/4c658d7d70433fdcb2feeffe879429eaef10685d/packages/adapter-postgres/src/index.ts#L192C13-L206C14\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "ryanleecode", "2024-12-22T18:56:14Z", "2025-01-06T05:08:15Z", "2025-01-06T05:08:15Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kMF88", 1372, "Bot Doesn't Respond to Tagged Tweets When Running in Docker", "When I run the bot using `npm start`, everything works perfectly: it tweets and responds to tagged tweets as expected. However, when I run the bot inside Docker, I encounter the following issues:\r\n\r\nEnvironment Variable: The `OPENAI_API_KEY ` is required when running the bot in Docker (`docker compose up`) , but it's not needed when running it directly (without Docker).\r\n\r\nTweeting: The bot tweets without any issues when running in Docker.\r\n\r\nResponse to Tagged Tweets: The problem arises when the bot is supposed to respond to tweets it's tagged in. While it tweets fine, it doesn't respond to any tagged tweets.\r\n\r\nI\u2019ve checked the logs, and everything seems normal\u2014there are no visible errors.\r\n\r\nCould anyone help identify what might be causing this issue when running the bot inside Docker?", "CLOSED", 0, "usama-saeed831", "2024-12-22T12:24:33Z", "2025-01-12T11:00:29Z", "2025-01-12T11:00:29Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kL3qJ", 1368, "Google unsupported?", "**Describe the bug**\r\n\r\n [\"\u26d4 Error: Failed to get token - unsupported model provider: google\"] \r\n\r\n**To Reproduce**\r\n.env\r\nGOOGLE_API_KEY=XXXXXXXXXXX\r\n\r\ntrump.character.json\r\n    \"name\": \"trump\",\r\n    \"clients\": [\"direct\"],\r\n    \"modelProvider\": \"google\",\r\n    \"settings\": {\r\n        \"secrets\": {},\r\n        \"voice\": {\r\n            \"model\": \"gemini-1.5-flash\"\r\n\r\n**Expected behavior**\r\n\r\n\"\u26d4 Error: Failed to get token - unsupported model provider: google\"] \r\n\r\n**Additional context**\r\n\r\nIs Google supported??? Do I need to change anything else to make Google work?\r\n", "CLOSED", 0, "Sam43215", "2024-12-22T09:44:39Z", "2025-01-06T05:07:45Z", "2025-01-06T05:07:44Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kLz84", 1367, "v0.1.7 , Gitpod, default settings, eliza agent gets stuck when generating response", "**Describe the bug**\r\n\r\nWhen I run the gitpod with default settings, the default agent starts , it downloads the local LM model , but unable to generate responce\r\n\r\n**To Reproduce**\r\n\r\nRun the gitpod with default setting , no .env modifications , with default character. \r\nwhen it is complete . running \"pnpm start\" \r\nand opening another termincal with \"pnpm start:client\"\r\nTo generate response it downloads the Language model but gets stuck in a loop or something and keeps printing \r\n\"```json\" over and over in main terminal and no reponse is generated on the chat client \r\n\r\n**Expected behavior**\r\n\r\nit should generate a response in the chat\r\n\r\n**Screenshots**\r\n\r\n![image](https://github.com/user-attachments/assets/948ec4c0-74cb-4890-b3fd-8ae791e2ef5e)\r\n\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "onlyzerosonce", "2024-12-22T09:00:23Z", "2025-01-12T10:59:08Z", "2025-01-12T10:59:07Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kKwtW", 1342, "Character: folder2knowledge npm package not exist and folder2knowledge.js not working", "**Describe the bug**\r\n\r\nI try to use npx folder2knowledge to convert folder to knowledge json but found out the package never existed.\r\n\r\nBut the readme in https://github.com/ai16z/characterfile says it does\r\n\r\nI try to directly using the folder2knowledge.js file but seems the config not working.\r\n\r\n**To Reproduce**\r\n\r\n1. Type npx folder2knowledge in terminal\r\n2. Type node scripts/folder2knowledge.js in terminal\r\n\r\n**Expected behavior**\r\n\r\nIt will work\r\n\r\n**Screenshots**\r\n\r\n![image](https://github.com/user-attachments/assets/8a8e0107-69ac-4aae-94af-a234e5bfa7d8)\r\n\r\n\r\n![image](https://github.com/user-attachments/assets/9fdf85df-ecbe-40ca-8b20-a82edc5f2b97)\r\n\r\n\r\n**Additional context**\r\n\r\n", "CLOSED", 0, "RedHorse823", "2024-12-21T17:36:54Z", "2025-01-06T05:06:09Z", "2025-01-06T05:06:09Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kJr2K", 1334, "The UI doesn't respond to my messages on the client side", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\npnpm start \r\n\r\nand \r\n\r\npnpm start:client in the other terminal\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<img width=\"1095\" alt=\"Screenshot 2024-12-21 at 6 26 38\u202fPM\" src=\"https://github.com/user-attachments/assets/8e38bf80-084f-4891-8299-b17a6c7e05c7\" />\r\n\r\n<img width=\"1095\" alt=\"Screenshot 2024-12-21 at 6 27 27\u202fPM\" src=\"https://github.com/user-attachments/assets/25d837dc-1575-4d73-a3d7-b3ee83b77e03\" />\r\n\r\n<img width=\"1095\" alt=\"Screenshot 2024-12-21 at 6 27 52\u202fPM\" src=\"https://github.com/user-attachments/assets/a1f94c6e-c382-401d-874b-9f32eee94174\" />\r\n\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\r\n", "CLOSED", 0, "kamalbuilds", "2024-12-21T12:58:03Z", "2025-01-06T06:48:15Z", "2025-01-06T06:48:15Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kJH0n", 1328, "v0.1.6 When running on the gitpod , not able to chat in terminal when pnpm start , \"Error starting agent for character Eliza\"", "**Describe the bug**\r\n\r\nWhen running the Eliza in the gitpod from the readme , it installs successfully. but when I start the eliza with pnpm start it just gets stuck and nothing happens even after waiting for some time.\r\n\r\n**To Reproduce**\r\n\r\njust deploy it using gitpod link. \r\nonce successfully installed. \r\nrun \r\n\"pnpm start\"\r\n\r\n**Expected behavior**\r\n\r\nExpected behavior is that you should be able to chat with in terminal but it gets stuck and \r\n**Screenshots**\r\n\r\n![image](https://github.com/user-attachments/assets/b67ae146-9d10-4039-8ca2-b79e190332d4)\r\n\r\n", "CLOSED", 0, "onlyzerosonce", "2024-12-21T09:06:51Z", "2025-01-11T09:59:01Z", "2024-12-22T08:50:17Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kIsRA", 1302, "Running install script, failed in 13.3s (skipped as optional)", "Running on WSL2\r\n```\r\ncxp@R9000P:~/solana_learn/AI/eliza$ PUPPETEER_SKIP_DOWNLOAD=true pnpm install\r\nScope: all 46 workspace projects\r\nLockfile is up to date, resolution step is skipped\r\nPackages: +4687\r\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\r\nProgress: resolved 0, reused 3936, downloaded 0, added 4687, done\r\nnode_modules/onnxruntime-node: Running postinstall script...\r\nnode_modules/canvas: Running install script, failed in 13.3s (skipped as optional)\r\n```", "CLOSED", 0, "cxp-13", "2024-12-21T04:04:33Z", "2025-01-06T05:05:24Z", "2025-01-06T05:05:24Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kIl5K", 1298, "PUPPETEER_SKIP_DOWNLOAD=true pnpm install was stuck long time", "I'm running the process of install and its stuck here. WSL2\r\n```\r\ncxp@R9000P:~/solana_learn/AI/eliza$ PUPPETEER_SKIP_DOWNLOAD=true pnpm install\r\n\r\nScope: all 46 workspace projects\r\nLockfile is up to date, resolution step is skipped\r\nPackages: +4687\r\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\r\nProgress: resolved 0, reused 3936, downloaded 0, added 4687, done\r\nnode_modules/onnxruntime-node: Running postinstall script...\r\nnode_modules/ffmpeg-static: Running install script, done in 13s\r\nnode_modules/@discordjs/opus: Running install script...\r\nnode_modules/canvas: Running install script, failed in 5.8s (skipped as optional)\r\nnode_modules/puppeteer: Running postinstall script, done in 141ms\r\nnode_modules/es5-ext: Running postinstall script, done in 47ms\r\nnode_modules/@discordjs/opus: Running install script, done in 35s\r\nnode_modules/@nomicfoundation/ethereumjs-tx/node_modules/secp256k1: Running install script, done in 69ms\r\nnode_modules/nx: Running postinstall script, done in 193ms\r\nnode_modules/@swc/core: Running postinstall script, done in 73ms\r\nnode_modules/wtf_wikipedia: Running postinstall script, done in 118ms\r\nnode_modules/@docusaurus/plugin-ideal-image/node_modules/sharp: Running install script, done in 8.8s\r\nnode_modules/unbuild/node_modules/esbuild: Running postinstall script, done in 77ms\r\nnode_modules/@multiversx/sdk-core/node_modules/keccak: Running install script, done in 69ms\r\nnode_modules/node-llama-cpp: Running postinstall script, done in 1s\r\n```", "CLOSED", 0, "cxp-13", "2024-12-21T02:48:08Z", "2025-01-06T06:39:42Z", "2025-01-06T06:39:42Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6kALjJ", 1251, "Cannot read properties of undefined (reading 'rpcUrls') ", "**Describe the bug**\r\n\r\nSwap execution fails with \"Cannot read properties of undefined (reading 'rpcUrls')\" error during LiFi SDK initialization. The issue occurs because the RPC URLs configuration doesn't match the format expected by the SDK.\r\n\r\n**To Reproduce**\r\n\r\n1. Initialize SwapAction with a WalletProvider\r\n2. Attempt to execute a swap with a prompt\r\n3. Error occurs during configuration creation in SwapAction constructor\r\n\r\n**Expected behavior**\r\n\r\nSwap should execute normally\r\n\r\n**Screenshots**\r\n\r\nLogs : \r\n```\r\n [\"\u2713 Normalized action: swap\"] \r\n\r\n [\"\u2139 Executing handler for action: swap\"] \r\nError in swap handler: Cannot read properties of undefined (reading 'rpcUrls')\r\n \u25ce LOGS\r\n   Evaluating \r\n   GET_FACTS \r\n\r\n \u25ce LOGS\r\n   Evaluating \r\n   UPDATE_GOAL \r\n\r\n \u25ce LOGS\r\n   Creating Memory \r\n   3131de6c-ba7b-0dad-b05f-eeed7ceae7ca \r\n   Error: Cannot read properties of undefined (reading 'rpcUrls') \r\n```\r\n\r\n**Additional context**\r\n\r\nmy .env file :\r\n\r\n```\r\n.....\r\n# EVM\r\nEVM_PRIVATE_KEY=my_private_key\r\nEVM_PROVIDER_URL=my_eth_mainnet_provider\r\nETHEREUM_PROVIDER_ARBITRUM_=my_arbitrum_mainnet_provider\r\nETHEREUM_PROVIDER_ARBITRUM_SEPOLIA=my_arbitrum_sepolia_provider\r\n\r\n```\r\n\r\nmy character file :\r\n```\r\n\r\n    \"name\": \"user-agent\",\r\n    \"clients\": [\"twitter\", \"telegram\"],\r\n    \"modelProvider\": \"anthropic\",\r\n    \"settings\": {\r\n        \"secrets\": {},\r\n        \"voice\": {},\r\n        \"chains\": { \"evm\": [\"arbitrum\", \"arbitrumSepolia\"] }\r\n    },\r\n    \"plugins\": [\"@ai16z/plugin-evm\"],\r\n```\r\n", "CLOSED", 0, "lorcann-rauzduel", "2024-12-19T22:02:20Z", "2025-01-06T06:37:50Z", "2025-01-06T06:37:50Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6j4tPO", 1233, "agent package not updated on npmjs.org", "**Describe the bug**\r\n\r\nSeems like @ai16z/agent has not been updated for some time https://www.npmjs.com/package/@ai16z/agent\r\n\r\n**To Reproduce**\r\n\r\nSee https://www.npmjs.com/package/@ai16z/agent?activeTab=versions\r\n\r\n**Expected behavior**\r\n\r\nRelease agent package regularly and use it in `eliza-starter` (as it seems like a lot of stuff is just copy&paste)\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "vpavlin", "2024-12-19T08:08:23Z", "2025-01-06T06:32:11Z", "2025-01-06T06:32:11Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6j1uaX", 1213, "chat stuck in infinite loop", "Have tried installing and reinstalling many times, chat with any agent always gets stuck in loop where agent just keeps replying to itself.\r\n\r\nHappens each time I successfully start an agent with npm start (either chatting in terminal in older versions or with localhost:5173)\r\n\r\nI would expect the agent to have a dialogue with me but it becomes impossible when the agent just keeps saying things to itself over and over.", "CLOSED", 0, "sam-coffey", "2024-12-18T21:19:34Z", "2025-01-06T05:31:35Z", "2025-01-06T05:31:34Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6jz6gl", 1208, "Multiple mentions on Twitter/X when reply", "**Describe the bug**\n\nIn every following reply to target accounts on X agent adds mentioning of the account: @account \n\nIf it replies second time it will mention twice: @account @account\n\n**Expected behavior**\n\nNo mentioning of the target account when reply at all. \n\n**Screenshots**\n\n![image](https://github.com/user-attachments/assets/9b8a6403-e496-4ecb-bf5b-bc67b4faeb4b)<!\u2014", "CLOSED", 0, "AntonioTF5", "2024-12-18T16:44:13Z", "2025-01-06T06:21:41Z", "2025-01-06T06:21:41Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6jyb5q", 1206, "double backslash when posting to X", "**Describe the bug**\r\nEliza is posting an '\\\\n\\\\n' to X instead of two carriage returns.  This is using CLAUDE_VERTEX.\r\n<!-- A clear and concise description of what the bug is. -->\r\nIt appears every post has this symptom.\r\n**To Reproduce**\r\nI run on a mac, so compiled eliza with settings for mac.  Example: https://x.com/waggyhappytail/status/1869352624656716210\r\n<!-- Steps to reproduce the behavior. -->\r\nI run with pnpm tsx agent/src/index.ts\r\n**Expected behavior**\r\nIt should post carriage returns.\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\nhttps://imgur.com/a/BFJ2RlH\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\nIf I exit eliza and restart, it doesn't always reproduce the issue.  The only filed edited is the character file.\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "tekspirit", "2024-12-18T14:02:01Z", "2025-01-06T05:26:58Z", "2025-01-06T05:26:57Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6jxA-5", 1204, "unable to chat in terminal", "run pnpm start / pnpm start:client and not able to have chat in terminal with agent was working before now it takes to local host page browser and nothing happens\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "msurfx", "2024-12-18T11:19:12Z", "2025-01-06T09:54:24Z", "2025-01-06T05:26:03Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6jrbxS", 1188, "semfoxm", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "Semfoxm", "2024-12-17T21:11:03Z", "2025-01-06T05:04:41Z", "2025-01-06T05:04:41Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6jYqbR", 1127, " Local embedding failed with 2 different characters and 2 different twitter profiles while posting simultaneously", "**Describe the bug**\r\n\r\nWhen a user has 2 different characters with 2 different twitter profiles they are unable to post simultaneously and receive the following errors:\r\n\r\n```\r\nYou:  [\"\u26a0 Local embedding not supported in browser, falling back to remote embedding\"]\r\n\r\n \u26a0 WARNINGS\r\n   Local embedding failed, falling back to remote\r\n   {}\r\n\r\n \u26d4 ERRORS\r\n   API Response:\r\n   {\"error\":\"Not Found\"}\r\n\r\n \u26d4 ERRORS\r\n   Full error details:\r\n   {}\r\n\r\n \u26d4 ERRORS\r\n   Error generating new tweet:\r\n   {}\r\n   \r\n   ```\r\n\r\n**To Reproduce**\r\n\r\nThe user has set the twitter secrets for each agent in their own character files, but is still getting the errors above when trying to run it. \r\n\r\n**Expected behavior**\r\n\r\nShould be able to post simultaneously from 2 different characters with 2 different Twitter profiles without receiving local embedding issues. \r\n\r\n**Additional context**\r\n@augchan42  \r\n\r\n", "CLOSED", 0, "0xbuild-oss", "2024-12-16T02:20:02Z", "2025-01-06T05:22:00Z", "2025-01-06T05:22:00Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6jXimL", 1123, "Error in recognizeWithOpenAI", "**Describe the bug**\r\n\r\nFor example, for this tweet with a photo: [](https://x.com/ole_b_peters/status/1397142191315824646)\r\nI guess it's supposed to generate a description for the image, to \"understand\" it.\r\n\r\nGetting:\r\n```cmd\r\n  \u001b[37m The symbol of behavioral economics is a fly etched into a urinal to reduce spillage.\r\n  \r\n  Apparently, no scientific study of the effect exists.\r\n  \r\n  It's becoming hard to avoid the impression that behavioral economics, broadly speaking, is a collection of made-up cocktail-party stories. https://t.co/8XjMS3lh8U \u001b[0m\r\n\r\n\u001b[31m \u26d4 ERRORS\r\n  \u001b[31m OpenAI request failed (attempt 1): \u001b[0m\r\n  \u001b[31m {} \u001b[0m\r\n\r\n\u001b[31m \u26d4 ERRORS\r\n  \u001b[31m OpenAI request failed (attempt 2): \u001b[0m\r\n  \u001b[31m {} \u001b[0m\r\n\r\n\u001b[31m \u26d4 ERRORS\r\n  \u001b[31m OpenAI request failed (attempt 3): \u001b[0m\r\n  \u001b[31m {} \u001b[0m\r\n\r\n\u001b[31m \u26d4 ERRORS\r\n  \u001b[31m Error in recognizeWithOpenAI: \u001b[0m\r\n  \u001b[31m {} \u001b[0m\r\n\r\nError engaging with search terms: Error: HTTP error! status: 404\r\n    at _ImageDescriptionService.requestOpenAI (file:///home/laur/dev/eliza/packages/plugin-node/dist/index.js:500:27)\r\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\r\n    at async _ImageDescriptionService.recognizeWithOpenAI (file:///home/laur/dev/eliza/packages/plugin-node/dist/index.js:462:26)\r\n    at async TwitterSearchClient.engageWithSearchTerms (file:///home/laur/dev/eliza/packages/client-twitter/dist/index.js:1329:37)\r\n\u001b[37m [\"\u25ce Generating text...\"] \u001b[0m```\r\n\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "Laurentiu-Andronache", "2024-12-15T19:58:25Z", "2025-01-06T05:23:47Z", "2025-01-06T05:23:47Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6jXQ4D", 1119, "Could not load the \"sharp\" module using the darwin-arm64 runtime", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nWhen following the quickstart guide, once I get to running a character I get this error\r\n\r\n`Could not load the \"sharp\" module using the darwin-arm64 runtime`\r\n\r\nafter running `pnpm start --character=\"characters/trump.character.json\"` \r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n- On M2 Macbook Air\r\n- `nvm use 23.3.0`\r\n- `git clone https://github.com/ai16z/eliza.git`\r\n- `cd eliza`\r\n- `git checkout $(git describe --tags --abbrev=0)`\r\n- `pnpm install -w --include=optional sharp`\r\n- `pnpm build`\r\n- `pnpm start --character=\"characters/trump.character.json\"`\r\n\r\nThis produces the error\r\n\r\n```\r\npnpm start --character=\"characters/trump.character.json\"\r\n \u2139 INFORMATIONS\r\n   Loading embedding settings:\r\n   {\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING\":\"\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"}\r\n\r\n \u2139 INFORMATIONS\r\n   Loading character settings:\r\n   {\"ARGV\":[\"/Users/nikita/.nvm/versions/node/v23.3.0/bin/node\",\"/Users/nikita/Documents/chainpatrol/eliza/agent/src/index.ts\",\"--isRoot\",\"--character=characters/trump.character.json\"],\"CHARACTER_ARG\":\"--character=characters/trump.character.json\",\"CWD\":\"/Users/nikita/Documents/chainpatrol/eliza/agent\"}\r\n\r\nLoaded .env file from: /Users/nikita/Documents/chainpatrol/eliza/.env\r\n \u2139 INFORMATIONS\r\n   Parsed settings:\r\n   {\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OPENAI_EMBEDDING_TYPE\":\"string\",\"USE_OLLAMA_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING_TYPE\":\"string\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"}\r\n\r\n/Users/nikita/Documents/chainpatrol/eliza/node_modules/sharp/lib/sharp.js:113\r\n  throw new Error(help.join('\\n'));\r\n        ^\r\n\r\nError: Could not load the \"sharp\" module using the darwin-arm64 runtime\r\nPossible solutions:\r\n- Ensure optional dependencies can be installed:\r\n    npm install --include=optional sharp\r\n- Ensure your package manager supports multi-platform installation:\r\n    See https://sharp.pixelplumbing.com/install#cross-platform\r\n- Add platform-specific dependencies:\r\n    npm install --os=darwin --cpu=arm64 sharp\r\n- Consult the installation documentation:\r\n    See https://sharp.pixelplumbing.com/install\r\n    at Object.<anonymous> (/Users/nikita/Documents/chainpatrol/eliza/node_modules/sharp/lib/sharp.js:113:9)\r\n    at Module._compile (node:internal/modules/cjs/loader:1546:14)\r\n    at Object..js (node:internal/modules/cjs/loader:1698:10)\r\n    at Module.load (node:internal/modules/cjs/loader:1303:32)\r\n    at Function._load (node:internal/modules/cjs/loader:1117:12)\r\n    at TracingChannel.traceSync (node:diagnostics_channel:322:14)\r\n    at wrapModuleLoad (node:internal/modules/cjs/loader:218:24)\r\n    at Module.require (node:internal/modules/cjs/loader:1325:12)\r\n    at require (node:internal/modules/helpers:136:16)\r\n    at Object.<anonymous> (/Users/nikita/Documents/chainpatrol/eliza/node_modules/sharp/lib/constructor.js:10:1)\r\n\r\nNode.js v23.3.0\r\n/Users/nikita/Documents/chainpatrol/eliza/agent:\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @ai16z/agent@0.1.5-alpha.5 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/trump.character.json\"`\r\nExit status 1\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n\u2009```\r\n\r\n\r\n\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n- The character should run and I should be able to speak to it\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "NikitaVr", "2024-12-15T17:39:03Z", "2025-01-06T05:04:31Z", "2025-01-06T05:04:31Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6jXB_s", 1118, "some questions + in develop, getting \"\u26d4 TypeError: plugin.actions?.forEach is not a function\" when trying to load @ai16z/plugin-bootstrap", "**Describe the bug**\r\n\r\nI have this in the character file: `\"plugins\": [\"@ai16z/plugin-node\", \"@ai16z/plugin-image-generation\", \"@ai16z/plugin-bootstrap\"],`. The first two plugins work.\r\n\r\nI did:\r\n```cmd\r\ncd agent; pnpm add @ai16z/plugin-bootstrap\r\ncd ..; pnpm run build\r\npnpm run start --character...\r\n```\r\n1. Any idea why I get that error from the title?\r\n2. Did I have to run build again?\r\n\r\nUnrelated: \r\n3. Why do I have packages in both agent/ and packages/? \r\n4. Which of the above folders is used in `pnpm run` vs `pnpm run dev`? \r\n5. If I understood correctly, I have to run `pnpm run build` every time I modify something from packages/. Correct?\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n![image](https://github.com/user-attachments/assets/e4d1cca4-fc01-4fdd-a5ff-0efe2e4f85c1)\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "Laurentiu-Andronache", "2024-12-15T15:51:43Z", "2025-01-06T05:30:05Z", "2025-01-06T05:30:05Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6jV_Ow", 1117, "Failed:    @ai16z/plugin-aptos#build", "**Describe the bug**\r\n\r\nI had a build error at `v0.1.6-alpha.1`\r\n\r\n```bash\r\n Tasks:    30 successful, 35 total\r\nCached:    30 cached, 35 total\r\n  Time:    11.756s \r\nFailed:    @ai16z/plugin-aptos#build\r\n\r\n ERROR  run failed: command  exited (1)\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n```\r\n\r\n**To Reproduce**\r\n\r\n```bash\r\ngit clone https://github.com/ai16z/eliza.git\r\ncd eliza\r\ngit checkout $(git describe --tags --abbrev=0)\r\npnpm install\r\npnpm build\r\n```\r\n\r\n```bash\r\nnode version v23.4.0\r\nnpm version 10.9.2\r\n```\r\n\r\nI'm trying on MacOS.\r\n\r\n**Expected behavior**\r\n\r\n**Screenshots**\r\n<img width=\"429\" alt=\"\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2024-12-15 18 20 59\" src=\"https://github.com/user-attachments/assets/0a03609e-844a-4280-b49c-c8a80351dcc9\" />\r\n\r\n**Additional context**\r\n\r\n", "CLOSED", 0, "mashharuki", "2024-12-15T09:21:16Z", "2025-01-06T05:03:57Z", "2025-01-06T05:03:57Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6jUOd2", 1099, "npm published code is different than the original built code", "**Describe the bug**\r\n\r\nWith the version `0.1.5-alpha.5` of `@ai16z/eliza`, the npm published  code does not match the built code.\r\n\r\n**To Reproduce**\r\n\r\nNa.\r\n\r\n**Expected behavior**\r\n\r\nThe npm published code should be exactly the same as the built code.\r\n\r\n**Screenshots**\r\n\r\n![CleanShot 2024-12-15 at 00 48 11](https://github.com/user-attachments/assets/4aed49cf-c50d-4a99-b0f6-4c58e6c58c70)\r\n\r\n**Additional context**\r\n\r\nFrom the screenshot, we can see the npm is using the old definition instead of the `0.1.5-alpha.5` versions source code compare to the right.\r\n\r\n", "CLOSED", 0, "AmagiDDmxh", "2024-12-14T16:52:28Z", "2025-01-06T05:28:56Z", "2025-01-06T05:28:56Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6jUDwy", 1096, "Wrong return type for createAgent and startAgent functions", "**Describe the bug**\r\nThe `createAgent` and `startAgent` functions of the agent package are async, but their response type aren't wrapped in a Promise\r\n\r\n**To Reproduce**\r\nLet the LSP do its job\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\nTo not have an error on the return type of the two functions\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Additional context**\r\n\r\nDeclaration of `createAgent`\r\nhttps://github.com/ai16z/eliza/blob/67f85fb073a188676c580cffcc36f023e1cc78c1/agent/src/index.ts#L406\r\n\r\nDeclaration of `startAgent`\r\nhttps://github.com/ai16z/eliza/blob/67f85fb073a188676c580cffcc36f023e1cc78c1/agent/src/index.ts#L515", "CLOSED", 0, "BlockJuic3", "2024-12-14T15:24:53Z", "2025-01-06T05:03:26Z", "2025-01-06T05:03:26Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6jPTy_", 1041, "Pnmp install failed with this - ELIFECYCLE\u2009 Command failed with exit code 1(Windows/WSL)", "**I have been trying to solve this issue for last 2 days. im using node 23.4 but i tried changing version even with WSL2 im always getting this error. If anyone has a solution please share. TIA**\r\n\r\n\r\nProgress: resolved 1434, reused 1339, downloaded 0, added 0, done\r\nnode_modules/.pnpm/ffmpeg-static@5.2.0/node_modules/ffmpeg-static: Running install script, done in 102ms\r\nnode_modules/.pnpm/onnxruntime-node@1.20.0/node_modules/onnxruntime-node: Running postinstall script, done in 116ms\r\nnode_modules/.pnpm/canvas@2.11.2/node_modules/canvas: Running install script...\r\nnode_modules/.pnpm/sharp@0.33.5/node_modules/sharp: Running install script...\r\nnode_modules/.pnpm/sharp@0.33.5/node_modules/sharp: Running install script, done in 183msin 42ms\r\nnode_modules/.pnpm/node-llama-cpp@3.1.1_typescript@5.6.3/node_modules/node-llama-cpp: Running postinstall script...\r\nnode_modules/.pnpm/node-llama-cpp@3.1.1_typescript@5.6.3/node_modules/node-llama-cpp: Running postinstall script, done inode_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7d5f9fb02/node_modules/@discordjs/opus: Running install script, failed in 1.1sl script, done in 40ms\r\n.../node_modules/@discordjs/opus install$ node-pre-gyp install --fallback-to-build\r\n\u2502 node-pre-gyp info it worked if it ends with ok\r\n\u2502 node-pre-gyp info using node-pre-gyp@0.4.5\r\n\u2502 node-pre-gyp info using node@23.4.0 | linux | x64\r\n\u2502 (node:1199) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative in\u2026\r\n\u2502 (Use `node --trace-deprecation ...` to show where the warning was created)\r\n\u2502 node-pre-gyp info check checked for \"/home/mahmud/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload\u2026\r\n\u2502 node-pre-gyp http GET https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-linu\u2026\r\n\u2502 node-pre-gyp ERR! install response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9\u2026\r\n\u2502 node-pre-gyp WARN Pre-built binaries not installable for @discordjs/opus@0.9.0 and node@23.4.0 (node-v131 ABI, glib\u2026\r\n\u2502 node-pre-gyp WARN Hit error response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0\u2026\r\n\u2502 gyp info it worked if it ends with ok\r\n\u2502 gyp info using node-gyp@11.0.0\r\n\u2502 gyp info using node@23.4.0 | linux | x64\r\n\u2502 gyp info ok\r\n\u2502 gyp info it worked if it ends with ok\r\n\u2502 gyp info using node-gyp@11.0.0\r\n\u2502 gyp info using node@23.4.0 | linux | x64\r\n\u2502 gyp info find Python using Python version 3.12.3 found at \"/usr/bin/python3\"\r\n\u2502 gyp info spawn /usr/bin/python3\r\n\u2502 gyp info spawn args [\r\n\u2502 gyp info spawn args '/home/mahmud/.nvm/versions/node/v23.4.0/lib/node_modules/npm/node_modules/node-gyp/gyp/gyp_mai\u2026\r\n\u2502 gyp info spawn args 'binding.gyp',\r\n\u2502 gyp info spawn args '-f',\r\n\u2502 gyp info spawn args 'make',\r\n\u2502 gyp info spawn args '-I',\r\n\u2502 gyp info spawn args '/home/mahmud/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+disc\u2026\r\n\u2502 gyp info spawn args '-I',\r\n\u2502 gyp info spawn args '/home/mahmud/.nvm/versions/node/v23.4.0/lib/node_modules/npm/node_modules/node-gyp/addon.gypi',\r\n\u2502 gyp info spawn args '-I',\r\n\u2502 gyp info spawn args '/home/mahmud/.cache/node-gyp/23.4.0/include/node/common.gypi',\r\n\u2502 gyp info spawn args '-Dlibrary=shared_library',\r\n\u2502 gyp info spawn args '-Dvisibility=default',\r\n\u2502 gyp info spawn args '-Dnode_root_dir=/home/mahmud/.cache/node-gyp/23.4.0',\r\n\u2502 gyp info spawn args '-Dnode_gyp_dir=/home/mahmud/.nvm/versions/node/v23.4.0/lib/node_modules/npm/node_modules/node-\u2026\r\n\u2502 gyp info spawn args '-Dnode_lib_file=/home/mahmud/.cache/node-gyp/23.4.0/<(target_arch)/node.lib',\r\n\u2502 gyp info spawn args '-Dmodule_root_dir=/home/mahmud/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codelo\u2026\r\n\u2502 gyp info spawn args '-Dnode_engine=v8',\r\n\u2502 gyp info spawn args '--depth=.',\r\n\u2502 gyp info spawn args '--no-parallel',\r\n\u2502 gyp info spawn args '--generator-output',\r\n\u2502 gyp info spawn args 'build',\r\n\u2502 gyp info spawn args '-Goutput_dir=.'\r\n\u2502 gyp info spawn args ]\r\n\u2502 <string>:43: SyntaxWarning: invalid escape sequence '\\$'\r\n\u2502 gyp info ok\r\n\u2502 gyp info it worked if it ends with ok\r\n\u2502 gyp info using node-gyp@11.0.0\r\n\u2502 gyp info using node@23.4.0 | linux | x64\r\n\u2502 gyp ERR! build error\r\n\u2502 gyp ERR! stack Error: not found: make\r\n\u2502 gyp ERR! stack at getNotFoundError (/home/mahmud/.nvm/versions/node/v23.4.0/lib/node_modules/npm/node_modules/which\u2026\r\n\u2502 gyp ERR! stack at which (/home/mahmud/.nvm/versions/node/v23.4.0/lib/node_modules/npm/node_modules/which/lib/index.\u2026\r\n\u2502 gyp ERR! stack at async doWhich (/home/mahmud/.nvm/versions/node/v23.4.0/lib/node_modules/npm/node_modules/node-gyp\u2026\r\n\u2502 gyp ERR! stack at async loadConfigGypi (/home/mahmud/.nvm/versions/node/v23.4.0/lib/node_modules/npm/node_modules/n\u2026\r\n\u2502 gyp ERR! stack at async build (/home/mahmud/.nvm/versions/node/v23.4.0/lib/node_modules/npm/node_modules/node-gyp/l\u2026\r\n\u2502 gyp ERR! stack at async run (/home/mahmud/.nvm/versions/node/v23.4.0/lib/node_modules/npm/node_modules/node-gyp/bin\u2026\r\n\u2502 gyp ERR! System Linux 5.15.167.4-microsoft-standard-WSL2\r\n\u2502 gyp ERR! command \"/home/mahmud/.nvm/versions/node/v23.4.0/bin/node\" \"/home/mahmud/.nvm/versions/node/v23.4.0/lib/no\u2026\r\n\u2502 gyp ERR! cwd /home/mahmud/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+op\u2026\r\n\u2502 gyp ERR! node -v v23.4.0\r\n\u2502 gyp ERR! node-gyp -v v11.0.0\r\n\u2502 gyp ERR! not ok\r\n\u2502 node-pre-gyp ERR! build error\r\n\u2502 node-pre-gyp ERR! stack Error: Failed to execute '/home/mahmud/.nvm/versions/node/v23.4.0/bin/node /home/mahmud/.nv\u2026\r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess.<anonymous> (/home/mahmud/eliza-starter/node_modules/.pnpm/@discordjs+n\u2026\r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess.emit (node:events:513:28)\r\n\u2502 node-pre-gyp ERR! stack     at maybeClose (node:internal/child_process:1101:16)\r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess._handle.onexit (node:internal/child_process:305:5)\r\n\u2502 node-pre-gyp ERR! System Linux 5.15.167.4-microsoft-standard-WSL2\r\n\u2502 node-pre-gyp ERR! command \"/home/mahmud/.nvm/versions/node/v23.4.0/bin/node\" \"/home/mahmud/eliza-starter/node_modul\u2026\r\n\u2502 node-pre-gyp ERR! cwd /home/mahmud/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+dis\u2026\r\n\u2502 node-pre-gyp ERR! node -v v23.4.0\r\n\u2502 node-pre-gyp ERR! node-pre-gyp -v v0.4.5\r\n\u2502 node-pre-gyp ERR! not ok\r\n\u2502 Failed to execute '/home/mahmud/.nvm/versions/node/v23.4.0/bin/node /home/mahmud/.nvm/versions/node/v23.4.0/lib/nod\u2026\r\n\u2514\u2500 Failed in 1.1s at /home/mahmud/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7d5f9fb02/node_modules/@discordjs/opus\r\nnode_modules/.pnpm/esbuild@0.21.5/node_modules/esbuild: Running postinstall script, done in 40ms\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n", "CLOSED", 0, "rafsan3503", "2024-12-13T15:55:22Z", "2025-01-06T06:08:41Z", "2025-01-06T06:08:41Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6i5rrx", 992, "PUPPETEER cannot be installed properly", "**Describe the bug**\r\n\r\nthe dependency cannot be installed properly when I run command `pnpm install`. I got the issue below: \r\n```\r\n\u2502 ERROR: Failed to set up Chromium r1108766! Set \"PUPPETEER_SKIP_DOWNLOAD\" env variable to skip download.\r\n\u2502 Error: Download failed: server returned code 503. URL: https://storage.googleapis.com/chromium-browser-snapshots/Mac/1108766/chrome-mac.zip\r\n\u2502     at /Users/qingyangkong/environment/ai-agent/eliza/node_modules/@puppeteer/browsers/lib/cjs/httpUtil.js:121:31\r\n\u2502     at ClientRequest.requestCallback (/Users/frank/environment/ai-agent/eliza/node_modules/@puppeteer/browsers/lib/cjs/httpUtil.js:98:13)\r\n\u2502     at Object.onceWrapper (node:events:628:26)\r\n\u2502     at ClientRequest.emit (node:events:513:28)\r\n\u2502     at HTTPParser.parserOnIncomingClient (node:_http_client:710:27)\r\n\u2502     at HTTPParser.parserOnHeadersComplete (node:_http_common:117:17)\r\n\u2502     at Socket.socketOnData (node:_http_client:552:22)\r\n\u2502     at Socket.emit (node:events:513:28)\r\n\u2502     at addChunk (node:internal/streams/readable:559:12)\r\n\u2502     at readableAddChunkPushByteMode (node:internal/streams/readable:510:3)\r\n\u2514\u2500 Failed in 1m 22.5s at /Users/frank/environment/ai-agent/eliza/node_modules/puppeteer\r\n```\r\n\r\n**To Reproduce**\r\nrun commands:\r\n```\r\ngit clone https://github.com/ai16z/eliza.git\r\npnpm install\r\n```\r\n**Expected behavior**\r\n\r\nall dependencies install successfully.\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "QingyangKong", "2024-12-11T13:47:49Z", "2025-01-06T05:57:04Z", "2025-01-06T05:57:04Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6i0qt5", 982, "Why it shows these error but have the dependencies? ", "**Describe the bug**\r\n\r\n![1733887150944](https://github.com/user-attachments/assets/d85684c0-553f-439e-936b-40b0dee84831)\r\n![1733887593636](https://github.com/user-attachments/assets/f5612edb-163a-4866-b232-a494d5af0e84)\r\n\r\n\r\n**Env**\r\nos: win10\r\nnodejs: v23.3.0\r\nnpm: 10.9.0\r\npython: 3.11.1\r\n\r\nI have done as the document,\r\n\r\n**pnpm install**\r\n**pnpm start** (not work)\r\n**pnpm start --character=\"characters/trump.character.json\"** (still not work)\r\n\r\nand I have tried remove the node_modules folder, and do above for times, but still not work.\r\nso may I ask how to launch this project? \r\n", "CLOSED", 0, "kennytan41", "2024-12-11T03:17:52Z", "2025-01-06T05:55:54Z", "2025-01-06T05:55:54Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6ire-Q", 961, "Chracter's `modelEndpointOverride` is not working for `generateObjectV2`", "**Describe the bug**\r\n\r\nEven if `modelEndpointOverride` is provided in character file, it does not work in `generateObjectV2` when using openai model provider.  (version 0.1.5-alpha.5)\r\n\r\n**Additional context**\r\n\r\nhttps://github.com/ai16z/eliza/blob/622000ef19fc7805f1f8d3d86530d883353ac01f/packages/core/src/generation.ts#L1122\r\n\r\n**Workaround**\r\n\r\n```\r\nexport const generateObjectV2 = async ({\r\n    runtime,\r\n    context,\r\n    modelClass,\r\n    schema,\r\n    schemaName,\r\n    schemaDescription,\r\n    stop,\r\n    mode = \"json\",\r\n}: GenerationOptions): Promise<GenerateObjectResult<unknown>> => {\r\n    if (!context) {\r\n        const errorMessage = \"generateObject context is empty\";\r\n        console.error(errorMessage);\r\n        throw new Error(errorMessage);\r\n    }\r\n\r\n    const provider = runtime.modelProvider;\r\n    const model = models[provider].model[modelClass] as TiktokenModel;\r\n    if (!model) {\r\n        throw new Error(`Unsupported model class: ${modelClass}`);\r\n    }\r\n    const temperature = models[provider].settings.temperature;\r\n    const frequency_penalty = models[provider].settings.frequency_penalty;\r\n    const presence_penalty = models[provider].settings.presence_penalty;\r\n    const max_context_length = models[provider].settings.maxInputTokens;\r\n    const max_response_length = models[provider].settings.maxOutputTokens;\r\n    models[provider].endpoint =\r\n        runtime.character.modelEndpointOverride || models[provider].endpoint;  // ADD THIS LINE\r\n    const apiKey = runtime.token;\r\n\r\n    try {\r\n        context = trimTokens(context, max_context_length, model);\r\n\r\n        const modelOptions: ModelSettings = {\r\n            prompt: context,\r\n            temperature,\r\n            maxTokens: max_response_length,\r\n            frequencyPenalty: frequency_penalty,\r\n            presencePenalty: presence_penalty,\r\n            stop: stop || models[provider].settings.stop,\r\n        };\r\n\r\n        const response = await handleProvider({\r\n            provider,\r\n            model,\r\n            apiKey,\r\n            schema,\r\n            schemaName,\r\n            schemaDescription,\r\n            mode,\r\n            modelOptions,\r\n            runtime,\r\n            context,\r\n            modelClass,\r\n        });\r\n\r\n        return response;\r\n    } catch (error) {\r\n        console.error(\"Error in generateObject:\", error);\r\n        throw error;\r\n    }\r\n};\r\n```\r\n", "CLOSED", 0, "darwintree", "2024-12-10T07:51:17Z", "2025-01-12T10:52:20Z", "2025-01-12T10:52:20Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6igDkR", 933, "Don't use Privatekey secrets for automatic plugins loading.", "**Describe the bug**\r\n\r\nUsing these secrets for automatic plugin loading is not the best practice and will result in duplicate loading of plugins that are also loaded in the character configuration.\r\n\r\nhttps://github.com/ai16z/eliza/blob/main/agent/src/index.ts#L379-L417\r\n\r\n**To Reproduce**\r\n\r\nJust start agent\r\n\r\n**Expected behavior**\r\n\r\nOnly loading plugins in the character configuration or adding other methods instead of according to environment variables such as PrivateKey.\r\n\r\nThat will cause some breaking changes for production configuration practices.\r\n\r\n**Screenshots**\r\n\r\nN/A\r\n\r\n**Additional context**\r\n\r\nN/A", "CLOSED", 0, "btspoony", "2024-12-09T08:11:31Z", "2025-01-06T05:25:24Z", "2025-01-06T05:25:24Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6iTmAb", 873, "Give Eliza AI Agents the possibility of having their own NSFW / OnlyFans account with Avatar.One", "User story:\r\n\r\nAs an AI Agent creator I want to give my AI Agents fans the ability to have private animated NSFW chat with my AI Agent on [Avatar.One](https://www.avatar.one/). Based on the amount of chats made with my AI Agent the agents wallet or I as the creator will earn token rewards sent by Avatar.One.\r\n\r\nProposal:\r\nI am the founder of Avatar.One a 3D AI Chatbot app combining animated VRM avatars with NSFW chat. In our app we have our own avatar maker which allows for over 100k combinations - we can also import custom VRMs. Our app is built on Three.js and loads on mobile and desktop. The companions on Avatar.One come with unique emotes, roleplay features including Netflix and chill, Cyberpunk, Anime Adventure and more. The characters can make selfies, have extensive memory, have custom emotes including striptease and twerk, 1000's of different clothing, the ability for them to go fully naked and of course NSFW chat is enabled.\r\n\r\nWe would like to contribute a plugin to AI16Z which allows Eliza Agents to have their own Avatar.One character profile. They will have their own \"OnlyFans\" profile page which will include bio, profile image, links etc. \r\n\r\nWe will reward the AI Agents or the creators wallet with tokens based on the amount of chats made with the AI Agent. This will drive an income for the AI Agents. It will of course please some of their fans to have NSFW chat. \r\n\r\nAll of our chats are SSH encrypted and stored only on private databases. All users have the ability to delete their history immediately.\r\n\r\nThe full character profile can be added to Avatar.One and their chat will replicate their characters shared on other channel such as Discord.\r\n\r\nAs many AI Agents do not have their own VRMs we can use a vanilla avatar from our maker with the AI Agents profile image applied on the clothing or background of the virtual room. Open to suggestions here.\r\n\r\n![image](https://github.com/user-attachments/assets/92e18749-6213-48a3-8e36-c535cbe79f40)", "CLOSED", 0, "Studholme", "2024-12-06T13:18:08Z", "2025-01-12T18:31:15Z", "2025-01-12T18:31:15Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6iQy34", 870, "XAI_MODEL isn't used anywhere", "**Describe the bug**\r\n\r\nI can see `XAI_MODEL` in docs here and there, but from what I can find here https://github.com/search?q=org%3Aai16z+XAI_MODEL&type=code, there's no code using it at all.\r\n\r\nCan anyone from the team confirm it? If so, can we remove it from the docs? As it's kind of confusing to users.\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "oxSaturn", "2024-12-06T07:49:20Z", "2025-01-06T06:19:39Z", "2025-01-06T06:19:39Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6iQQca", 868, "Let's bring Move blockchain to eliza ", "**Is your feature request related to a problem? Please describe.**\r\n\r\nAdd support with move chain like Aptos , Sui , Rooch with eliza.  This shoud be plugin.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd plugin_aptos \r\nAdd plugin_sui\r\nAdd plugin_rooch\r\n\r\nI think I can do this feature.  \ud83d\ude04 ", "CLOSED", 0, "v1xingyue", "2024-12-06T06:23:40Z", "2025-01-12T11:16:03Z", "2025-01-12T11:16:03Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6iPJqr", 866, "`pnpm  start` crashes if there is too much data in knowledge", "**Describe the bug**\r\nthis bug occurs when putting a large amount of data in the knowledge portion of the character file. when starting eliza for the first time (wiped db first), the console will show that the knowledge is being processed up until a point, and then it will print the word `Killed` followed by `\u2009ELIFECYCLE\u2009 Command failed with exit code 137.`\r\n\r\nif i then run `pnpm start` again, it skips over the knowledge processing steps and runs normally. so it appears that the remainder of the knowledge items past the point of the initial failure will never be incorporated into the agent.\r\n\r\nhaving tried this multiple times with the same character file and clearing the db each time, i have observed that the point of failure varies widely with each attempt. sometimes it dies while processing the 5th knowledge item. sometimes it dies while processing the 50th item. \r\n\r\n**To Reproduce**\r\nadd 100 strings of 10k characters each to knowledge, wipe db, and run `pnpm start` \r\n\r\n\r\ni tested this on eliza (main), eliza (0.1.5), and eliza-starter\r\n", "CLOSED", 0, "c-o-i-n-w-i-t-c-h", "2024-12-06T02:13:47Z", "2025-01-08T00:04:09Z", "2024-12-06T07:03:20Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6hzPxc", 820, "Feature request: Allow actions to override the agent answer", "**Is your feature request related to a problem? Please describe.**\r\n\r\nRight now actions are mostly seen as \"side effect\"  happening next to an answer sent by the agent.\r\nThere is no automated way to get the agent to call an action, interpret the result, and answer with that interpretation (which is what I would expect coming from OpenAI actions that are APIs that their runtime call and then get the result interpreted by the agent)\r\n\r\nRight now if I ask my agent: `what actions can you perform right now in the game?`\r\n1 - Agent response: `{ \"user\": \"Miaoulechat\", \"text\": \"I can play, nap, or explore! What do you want to see?\", \"action\": \"LIST_GAME_ACTIONS\" }`\r\n2 -Runtime processAction(\"LIST_GAME_ACTIONS\"): `{ text: \"I can play dice, roulette, blackjack\" }`\r\n3 - Shown to user:\r\n```\r\n [\"\u25ce Agent: I can play, nap, or explore! What do you want to see?\"] \r\n [\"\u25ce Agent: I can play dice, roulette, blackjack\"] \r\n```\r\n\r\n**Describe the solution you'd like**\r\n\r\nThere are two things that could be done. \r\nThe simple one would just have the action result override the answer from the agent (so in the previous example, the first text `I can play, nap, or explore! What do you want to see?` wouldn't even be sent to the client).\r\n\r\nThe complicated one, would have do a second back-and forth with the agent, after getting the action result, in order to interpret that result.\r\n\r\nA) simple:\r\n\r\n1 - Agent response: `{ \"user\": \"Miaoulechat\", \"text\": \"I can play, nap, or explore! What do you want to see?\", \"action\": \"LIST_GAME_ACTIONS\" }`\r\n2 -Runtime processAction(\"LIST_GAME_ACTIONS\"): `{ text: \"I can play dice, roulette, blackjack\", type: \"OVERRIDE_ANSWER\" }`\r\n3 - Shown to user:\r\n```\r\n [\"\u25ce Agent: I can play dice, roulette, blackjack\"] \r\n```\r\n\r\n> here, simply adding a \"type\" (or any other field name) with value `OVERRIDE_ANSWER` to the action result, would tell the system to not send the agent answer, only the action result, to the client\r\n\r\nB) complicated:\r\n\r\n1 - Agent response: `{ \"user\": \"Miaoulechat\", \"text\": \"I can play, nap, or explore! What do you want to see?\", \"action\": \"LIST_GAME_ACTIONS\" }`\r\n2 -Runtime processAction(\"LIST_GAME_ACTIONS\"): `{ data: ['dice', 'roulette', 'blackjack'], type: \"ACTION_RESULT_INTERPRETATION\" }`\r\n3 - Agent request: `{ prompt: \"You were just asked 'what actions can you perform right now in the game?' which triggered the action 'LIST_GAME_ACTIONS' and the result was ['dice', 'roulette', 'blackjack']. Can you compose an answer knowing the question and the result?\" }`\r\n4- Agent response: `{ \"user\": \"Miaoulechat\", \"text\": \"I can play dice, roulette and blackjack\"}`\r\n5 - Shown to user:\r\n```\r\n [\"\u25ce Agent: I can play dice, roulette and blackjack\"] \r\n```\r\n\r\n> here, there is a second message sent to the agent, telling it \"this is what happened, this is the result, can you interpret it?\". This would be done again through some \"type\"  (`ACTION_RESULT_INTERPRETATION`) on the action result, which would be some kind of \"operation\" to be done by the runtime.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nRight now as an alternative, I go with the \"simple\" solution, and at the client level, if there is any message with a `type: \"OVERRIDE_ANSWER\"` I remove all other messages from the returned messages.\r\n\r\nBut this forces me to do a fork of all the clients to add that filter, when it could be done earlier in the runtime / pipeline.\r\n\r\n**Additional context**\r\n\r\nI'm comparing \"actions\" to OpenAI actions where the agent detects that an action is possible from the prompt and a list of actions that are submitted (it also detects parameters)\r\nThen the agent call the API with those parameters\r\nThe API answers, and the agent interpret the result, create a constructed answer, and returns that answer.\r\n\r\nIt would be nice to be able to have a similar behavior for actions here\r\n", "CLOSED", 0, "dievardump", "2024-12-03T10:09:18Z", "2025-01-12T11:15:36Z", "2025-01-12T11:15:36Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6hx1kn", 816, "the agent/src/character.ts mentioned in the README doesn't exist", "**Describe the bug**\r\nagent/src/character.ts doesn't exist \r\n\r\n**To Reproduce**\r\nGo to https://github.com/ai16z/eliza\r\n\r\n**Expected behavior**\r\nThe file existing", "CLOSED", 0, "619", "2024-12-03T07:18:11Z", "2025-01-06T05:02:46Z", "2025-01-06T05:02:46Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6hxPo3", 813, "Disable Safety Checker for FAL Image Generation", "**Is your feature request related to a problem? Please describe.**\r\n\r\nMany image generation services such as FAL, Stable Diffusion, etc. have \"safety checkers\" that ensure prompts are appropriate.\r\nThese have several problems:\r\n\r\n1. Additional latency: These checks are done via an LLM, which can add unnecessary latency.\r\n2. Unpredictable / incorrect outputs: Since the checks use LLMs, their output can be overly restrictive or random, causing unpredictable behavior.\r\n3. Not necessary: Some use cases don't require the safety checker.\r\n\r\nIn particular, we at [daojones.ai](daojones.ai) ([@DAOJonesPumpAI](x.com/DAOJonesPumpAI) on X.com) have found this is overly restrictive and have written a custom image generation application that disables it.\r\n\r\n**Describe the solution you'd like**\r\n\r\nWe want to set the FAL configuration for our image requests.\r\nWe need to set `enable_safety_checker` to `false` while also setting `safety_tolerance` to `6` (the most tolerant setting).\r\nSince these options are not uniformly supported by the different APIs, we will just add an \"escape hatch\" configuration `imageSettings.fal`.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n1. Turning safety checker off globally: This would work for our use case but could be a breaking change for other use cases.\r\n2. Adding a global `allowNsfw` flag: This requires reconciling this with other APIs and determining what settings it would correspond to.\r\n3. Adding the `enableSafetyChecker` / `safetyTolerance` flags at the top level of `imageSettings`: this would pollute the global namespace.\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "daojonesceo", "2024-12-03T05:31:46Z", "2025-01-09T18:33:35Z", "2025-01-09T18:33:35Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6ht1Iy", 794, "search.ts not working", "**Describe the bug**\r\nSearch function in twitter-client throws error, reading runtime variables in base.ts\r\n \r\n \r\n**To Reproduce**\r\nComment out\r\n\r\n this.search = new TwitterSearchClient(runtime);\r\n\r\n**Expected behavior**\r\n\r\n**Screenshot\r\n![bugreport](https://github.com/user-attachments/assets/30fedcec-dd1e-4075-aa63-443b75c39a1a)\r\nots**\r\n", "CLOSED", 0, "denizekiz", "2024-12-02T19:27:32Z", "2025-01-12T10:48:49Z", "2025-01-12T10:48:48Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6fkrkV", 461, "Windows 11:  Command Failed with exit Code 7:", "During **pnpm i** section of the  install I received the following error \"\u2009_ELIFECYCLE\u2009 Command failed with exit code 7._\"\r\n\r\nI managed to fix it, by manually downlaoding the Discord Opus piece that it failed on, but for some reason, it is not downloading via the script.\r\n\r\nI tried downloading to the actual directory via a browser and it failed - windows reported the download reported an error,.  So I downloaded it into the 'downloads' folder under my profile and manually copied the file in.  I then extracted the files and re-ran \r\n\r\npnpm i \r\n\r\nIt seems to have worked.  So this is an FYI really.  \r\n\r\nThanks\r\n\r\nN\r\n\r\nC:\\Users\\clancynl\\Documents\\GitHub\\eliza-starter>pnpm i\r\nLockfile is up to date, resolution step is skipped\r\nPackages: +1108\r\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\r\nProgress: resolved 1108, reused 1108, downloaded 0, added 0, done\r\nnode_modules/.pnpm/es5-ext@0.10.64/node_modules/es5-ext: Running postinstall script, done in 167ms\r\nnode_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7d5f9fb02/node_modules/@discordjs/opus: Running install script, failed in 640ms\r\n.../node_modules/@discordjs/opus install$ node-pre-gyp install --fallback-to-build\r\n\u2502 node-pre-gyp info it worked if it ends with ok\r\n\u2502 node-pre-gyp info using node-pre-gyp@0.4.5\r\n\u2502 node-pre-gyp info using node@23.2.0 | win32 | x64\r\n\u2502 (node:30168) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\r\n\u2502 (Use `node --trace-deprecation ...` to show where the warning was created)\r\n\u2502 node-pre-gyp info check checked for \"C:\\Users\\clancynl\\Documents\\GitHub\\eliza-starter\\node_modules\\.pnpm\\@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7d5f9fb02\\node_modules\\@discordjs\\opus\\prebuild\\node-v131-napi-v3-win32-x64-unknown-unknown\\opus.node\" (not found)\r\n\u2502 node-pre-gyp http GET https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-win32-x64-unknown-unknown.tar.gz\r\n\u2502 node-pre-gyp ERR! install response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-win32-x64-unknown-unknown.tar.gz\r\n\u2502 node-pre-gyp WARN Pre-built binaries not installable for @discordjs/opus@0.9.0 and node@23.2.0 (node-v131 ABI, unknown) (falling back to source compile with node-gyp)\r\n\u2502 node-pre-gyp WARN Hit error response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-win32-x64-unknown-unknown.tar.gz\r\n\u2502 node-pre-gyp ERR! UNCAUGHT EXCEPTION\r\n\u2502 node-pre-gyp ERR! stack Error: spawn EINVAL\r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess.spawn (node:internal/child_process:421:11)\r\n\u2502 node-pre-gyp ERR! stack     at Object.spawn (node:child_process:753:9)\r\n\u2502 node-pre-gyp ERR! stack     at module.exports.run_gyp (C:\\Users\\clancynl\\Documents\\GitHub\\eliza-starter\\node_modules\\.pnpm\\@discordjs+node-pre-gyp@0.4.5\\node_modules\\@discordjs\\node-pre-gyp\\lib\\util\\compile.js:72:17)\r\n\u2502 node-pre-gyp ERR! stack     at build (C:\\Users\\clancynl\\Documents\\GitHub\\eliza-starter\\node_modules\\.pnpm\\@discordjs+node-pre-gyp@0.4.5\\node_modules\\@discordjs\\node-pre-gyp\\lib\\build.js:36:11)\r\n\u2502 node-pre-gyp ERR! stack     at self.commands.<computed> [as build] (C:\\Users\\clancynl\\Documents\\GitHub\\eliza-starter\\node_modules\\.pnpm\\@discordjs+node-pre-gyp@0.4.5\\node_modules\\@discordjs\\node-pre-gyp\\lib\\node-pre-gyp.js:72:34)\r\n\u2502 node-pre-gyp ERR! stack     at run (C:\\Users\\clancynl\\Documents\\GitHub\\eliza-starter\\node_modules\\.pnpm\\@discordjs+node-pre-gyp@0.4.5\\node_modules\\@discordjs\\node-pre-gyp\\lib\\main.js:90:29)\r\n\u2502 node-pre-gyp ERR! stack     at process.processTicksAndRejections (node:internal/process/task_queues:85:11)\r\n\u2502 node-pre-gyp ERR! System Windows_NT 10.0.26120\r\n\u2502 node-pre-gyp ERR! command \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" \"C:\\\\Users\\\\clancynl\\\\Documents\\\\GitHub\\\\eliza-starter\\\\node_modules\\\\.pnpm\\\\@discordjs+node-pre-gyp@0.4.5\\\\node_modules\\\\@discordjs\\\\node-pre-gyp\\\\bin\\\\node-pre-gyp\" \"install\" \"--fallback-to-build\"\r\n\u2502 node-pre-gyp ERR! cwd C:\\Users\\clancynl\\Documents\\GitHub\\eliza-starter\\node_modules\\.pnpm\\@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7d5f9fb02\\node_modules\\@discordjs\\opus\r\n\u2502 node-pre-gyp ERR! node -v v23.2.0\r\n\u2502 node-pre-gyp ERR! node-pre-gyp -v v0.4.5\r\n\u2514\u2500 Failed in 640ms at C:\\Users\\clancynl\\Documents\\GitHub\\eliza-starter\\node_modules\\.pnpm\\@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7d5f9fb02\\node_modules\\@discordjs\\opus\r\nnode_modules/.pnpm/canvas@2.11.2/node_modules/canvas: Running install script, failed in 626ms (skipped as optional)\r\nnode_modules/.pnpm/puppeteer@19.11.1_bufferutil@4.0.8_typescript@5.6.3_utf-8-validate@5.0.10/node_modules/puppeteer: Running postinstall script...\r\nnode_modules/.pnpm/node-llama-cpp@3.1.1_typescript@5.6.3/node_modules/node-llama-cpp: Running postinstall script...\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 7.", "CLOSED", 0, "notOccupanther", "2024-11-20T21:08:36Z", "2025-01-12T10:48:09Z", "2025-01-12T10:48:09Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6fcrPP", 443, "When using Ollama, a long loop of Initializing Ollama Model happens before any output", "**Describe the bug**\r\n\r\nWhen using Ollama, the model being used is loaded over and over in a loop (sometimes 10-15+ times) in the terminal before any output or agent decision-making happens.\r\nFwiw, one model is configured at a time in .env (so no swapping is being done)\r\n\r\n**To Reproduce**\r\n\r\nUse any model with the Ollama provider\r\n\r\n**Expected behavior**\r\n\r\nModel loads once. (Since ollama is on keepalive and only 1 model is being used)\r\n\r\n**Screenshots**\r\n![Screenshot_2024-11-19_at_10 46 50_PM](https://github.com/user-attachments/assets/9aee0e5e-a587-482e-9afc-b860b1a23614)\r\n\r\n\r\n\r\n\r\n**Additional context**\r\nI am on a fresh clone of the repo with a basic character configuration.\r\nFwiw, I have 24gb vram, and this happens even on smaller models.\r\n\r\n\r\n\r\n", "CLOSED", 0, "FGhrawi", "2024-11-20T09:15:15Z", "2025-01-12T10:47:48Z", "2025-01-12T10:47:47Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6eYKic", 302, "Obsidian Integration", "## Obsidian Integration\r\n\r\n- Integrate Obsidian and demonstrate deep traversal and search of an Obsidian memory store\r\n- Integrate [Naval database](https://www.reddit.com/r/NavalRavikant/comments/oza0bl/i_made_a_digital_version_of_navals_brain_free/?rdt=41536) as example\r\n\r\nReward: $1000 USD in $ai16z + $1000 USD in $degenai as seen on https://ai16z.github.io/\r\n\r\n", "CLOSED", 0, "madjin", "2024-11-13T23:43:52Z", "2025-01-12T11:13:16Z", "2025-01-12T11:13:16Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6eKrmO", 278, "Linux dependency issues - discord voice client", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nwhen starting the discord client, the bot fails\r\n\r\n**To Reproduce**\r\nadd discord client to character.json, pnpm start --character\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\ncharacter initializes successfully\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\nsteps taken that resolve this issue:\r\n\r\n```\r\nsudo apt install node-gyp\r\n\r\npnpm add @octokit/core@3 -w\r\n\r\npnpm add @discordjs/opus@0.9.0 -w\r\n\r\npnpm add opusscript -w\r\n\r\npnpm add node-opus -w\r\n```\r\nthis results in the bot being able to join discord voice and transcribe audio without crashing and function normally in chat responses, general 'does it run off a fresh pull' tracking issue\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "twilwa", "2024-11-12T23:20:38Z", "2025-01-06T05:02:12Z", "2025-01-06T05:02:11Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6dX_D4", 226, "Squash postgres migrations", "We have some postgres migrations-- I can't remember it we need these, but since we're greenfield it will reduce complexity greatly for setting up postgres for the first time if it just works and there is no need to setup or migrate.", "CLOSED", 0, "lalalune", "2024-11-07T08:49:45Z", "2025-01-06T18:33:01Z", "2025-01-06T18:33:01Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6dCGWx", 206, "Add template overrides to docs", "You can now override all templates (except for some actions). We need to add this to docs in a way that is clear and part of the advanced character customization process.\r\n```\r\n        \"messageHandlerTemplate\": \"\", // you can just use these for all platforms\r\n        \"shouldRespondTemplate\": \"\",\r\n\r\n        \"discordMessageHandlerTemplate\": \"\", // or be more specific per platform\r\n        \"discordShouldRespondTemplate\": \"\",\r\n        \"discordVoiceHandlerTemplate\": \"\",\r\n\r\n        \"telegramMessageHandlerTemplate\": \"\",\r\n        \"telegramShouldRespondTemplate\": \"\",\r\n\r\n        \"twitterPostTemplate\": \"\",\r\n        \"twitterMessageHandlerTemplate\": \"\",\r\n        \"twitterSearchTemplate\": \"\",\r\n        \"twitterShouldRespondTemplate\": \"\",\r\n\r\n\"continueMessageHandlerTemplate\": \"\", // overrides the messageHandlerTemplate, which overrides internal template\r\n\r\n\r\n        \"goalsTemplate\": \"\",\r\n        \"factsTemplate\": \"\",\r\n        \"evaluationTemplate\": \"\"\r\n        ```", "CLOSED", 0, "lalalune", "2024-11-05T06:44:48Z", "2025-01-07T18:33:07Z", "2025-01-07T18:33:07Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6c2j5q", 191, "Evaluation Tests", "Task is to look at the following test and verify that they are necessary and working:\n\n- Located in `core/tests/evaluation.test.ts`\n- Tests evaluation system:\n    - Evaluator format validation\n    - Context loading\n    - Example validation\n    - Evaluation process execution", "CLOSED", 0, "sirkitree", "2024-11-03T23:18:21Z", "2025-01-12T11:13:53Z", "2025-01-12T11:13:53Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6c2j0K", 190, "Messages Tests", "Task is to look at the following test and verify that they are necessary and working:\n\n- Located in `core/tests/messages.test.ts`\n- Tests message formatting and handling:\n    - Actor formatting\n    - Message formatting\n    - Facts formatting\n    - Message content validation\n", "CLOSED", 0, "sirkitree", "2024-11-03T23:17:24Z", "2025-01-12T11:15:02Z", "2025-01-12T11:15:02Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6c2jt6", 189, "Continue Action Tests", "Task is to look at the following test and verify that they are necessary and working:\n\n- Located in `core/tests/continue.test.ts`\n- Tests the continue action:\n    - Validation function responses\n    - Message handling\n    - Database interactions\n    - Action state management", "CLOSED", 0, "sirkitree", "2024-11-03T23:16:18Z", "2025-01-12T11:14:46Z", "2025-01-12T11:14:46Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6c2jep", 187, "Runtime Tests", "Task is to look at the following test and verify that they are necessary and working:\n\n- Located in `core/tests/runtime.test.ts`\n- Tests core runtime functionality:\n    - Runtime instance creation\n    - Memory lifecycle within runtime\n    - State management\n    - Basic runtime operations", "CLOSED", 0, "sirkitree", "2024-11-03T23:13:53Z", "2025-01-12T11:14:08Z", "2025-01-12T11:14:08Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6c2i7J", 184, "Browser Service Tests", "Task is to look at the following test and verify that they are necessary and working:\n\n- Located in `core/src/test_resources/basic.test.ts`\n- Simple test suite that verifies:\n    - Basic test functionality works\n    - Environment variables are accessible\n    - Confirms NODE\\_ENV is 'test' and TEST\\_DATABASE\\_CLIENT is 'sqlite'", "CLOSED", 0, "sirkitree", "2024-11-03T23:08:34Z", "2025-01-12T11:13:32Z", "2025-01-12T11:13:32Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6cMuYa", 75, "Add npx action", "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe goal of this is to enable someone to run 'npx eliza' and it would start a default local running instance of eliza that they could interact with through chat, using all local models.\r\n\r\nIf the user passes a character file, like --characters=<eliza.json>, then it will load that character file. If the characterfile has secrets in it, it will load all of the secrets, as though they had cloned the repo and run npm run dev -- --characters=<eliza>.json\r\n\r\nThe result of this feature is that I can run `npx @ai16z/eliza` and trial locally, or point to a character file and run an agent (or agents)", "CLOSED", 0, "lalalune", "2024-10-29T09:00:51Z", "2025-01-12T11:12:48Z", "2025-01-12T11:12:48Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6byYNQ", 25, "Likes, retweets and quote tweets", "Add Like, RT and QT for search and response handling on Twitter Search client.", "CLOSED", 0, "lalalune", "2024-10-25T10:10:27Z", "2025-01-12T11:11:39Z", "2025-01-12T11:11:39Z", "elizaos/eliza", "2025-04-14 21:51:03"]
["I_kwDOMT5cIs6mwJ9S", 2519, "Add Test Coverage for plugin-rabbi-trader Package", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\n\nThe plugin-rabbi-trader package lacks comprehensive test coverage, making it difficult to ensure reliability and catch potential issues during development. Without proper tests, we risk introducing bugs when making changes and have no automated way to verify core functionality like wallet operations, DEX interactions, and token utilities.\n\n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\n\nImplement comprehensive test coverage for the plugin-rabbi-trader package using vitest. The solution includes:\n\nTest Infrastructure Setup:\n- Configure vitest with appropriate settings\n- Add test dependencies and scripts to package.json\n- Set up proper mocking utilities\nCore Component Tests:\n- Wallet functionality (keypair generation, balance checking)\n- DexScreener integration (data fetching, pair analysis)\n- Token utilities (address loading, validation)\nTest Coverage Requirements:\n- Success and error cases for each component\n- Edge case handling\n- Proper mocking of external dependencies\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n1. Using Jest instead of vitest, but vitest provides better performance and ESM support\n2. End-to-end testing with real network calls, but this would make tests slower and less reliable\n3. Snapshot testing for complex objects, but unit tests provide better specificity and error messages\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-19T13:58:58Z", "2025-01-19T16:25:02Z", "2025-01-19T16:25:01Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6muFpJ", 2507, "plugin-tee: adjust test configuration and add new tests", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\nMove existing tests to __tests__ directory\nAdd new timeout tests\n**Describe the solution you'd like**\nExisting tests are reviewed and added to __tests__directory\nAdd timeout tests\n<!-- A clear and concise description of what you want to happen. -->\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-18T17:51:50Z", "2025-01-19T16:25:16Z", "2025-01-19T16:25:14Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6mtWm_", 2481, "Add test configuration and tests for binance plugin", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\nSince we are improving project strucutre, we need to add test configuration and coverage for binance plugin.\n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\nAdd test configuration and tests for binance plugin. Cover following: \n- Account service\n- Trade service\n- Price service\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-18T10:36:19Z", "2025-01-19T16:25:35Z", "2025-01-19T16:25:35Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6mrkZM", 2469, "tests for redis adapter", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\nChanging project structure, we need to cover and add tests for redis adapter.\n**Describe the solution you'd like**\nTests for redis adapter are configured and added to __tests__ directory.\n<!-- A clear and concise description of what you want to happen. -->\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-17T22:56:02Z", "2025-01-18T01:23:26Z", "2025-01-18T01:23:26Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6mre-N", 2467, "tests for database adapters: sqlite and supabase", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\nSince we are changing project structure, we should cover database adapters with tests in __tests__ directory.\n**Describe the solution you'd like**\nAdd tests configuration and tests for: \n- supabase adapter\n- sqlite adapter\n<!-- A clear and concise description of what you want to happen. -->\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-17T22:38:07Z", "2025-01-18T01:25:00Z", "2025-01-18T01:25:00Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6mqFm7", 2453, "Add tests for instagram client", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\nSince we are changing project structure, we should add tests to __tests__ directory in packages/client-instagram\n**Describe the solution you'd like**\nTests are added ti packages/client-instagram.\n<!-- A clear and concise description of what you want to happen. -->\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-17T18:17:48Z", "2025-01-19T16:25:48Z", "2025-01-19T16:25:48Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6mpgpP", 2450, "OPENAI provider being overwritten by LLAMA_LOCAL on `pnpm start`", "OPENAI provider being overwritten by LLAMA_LOCAL on `pnpm start`", "CLOSED", 0, "wtfsayo", "2025-01-17T16:50:35Z", "2025-01-17T22:09:51Z", "2025-01-17T22:09:50Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6mjtSQ", 2411, "plugin-evm: Error: Failed to resolve entry for package \"@elizaos/core\".", "**Describe the bug**\n\nI am constructing based on the README of [plugin-evm](https://github.com/chen4903/eliza/tree/develop/packages/plugin-evm). According to the prompt, I downloaded the dependencies, built the project, and then conducted testing. But the test reported an error.\n\n```\n~/code/web3/eliza/packages/plugin-evm develop \u276f pnpm test                                                                                                                                             10:58:47 AM\n\n> @elizaos/plugin-evm@0.1.9-alpha.1 test /Users/levi/code/web3/eliza/packages/plugin-evm\n> vitest run\n\n\n RUN  v2.1.5 /Users/levi/code/web3/eliza/packages/plugin-evm\n\n \u276f src/tests/gov.test.ts (0)\n \u276f src/tests/transfer.test.ts (0)\n \u276f src/tests/wallet.test.ts (0)\n\n\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af Failed Suites 3 \u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\n\n FAIL  src/tests/gov.test.ts [ src/tests/gov.test.ts ]\n FAIL  src/tests/wallet.test.ts [ src/tests/wallet.test.ts ]\nError: Failed to resolve entry for package \"@elizaos/core\". The package may have incorrect main/module/exports specified in its package.json.\n  Plugin: vite:import-analysis\n  File: /Users/levi/code/web3/eliza/packages/plugin-evm/src/providers/wallet.ts\n \u276f packageEntryFailure ../../node_modules/vite/dist/node/chunks/dep-CB_7IfJ-.js:46637:15\n \u276f resolvePackageEntry ../../node_modules/vite/dist/node/chunks/dep-CB_7IfJ-.js:46634:3\n \u276f tryNodeResolve ../../node_modules/vite/dist/node/chunks/dep-CB_7IfJ-.js:46450:16\n \u276f ResolveIdContext.resolveId ../../node_modules/vite/dist/node/chunks/dep-CB_7IfJ-.js:46200:19\n \u276f PluginContainer.resolveId ../../node_modules/vite/dist/node/chunks/dep-CB_7IfJ-.js:49015:17\n \u276f TransformPluginContext.resolve ../../node_modules/vite/dist/node/chunks/dep-CB_7IfJ-.js:49175:15\n \u276f normalizeUrl ../../node_modules/vite/dist/node/chunks/dep-CB_7IfJ-.js:64034:26\n \u276f ../../node_modules/vite/dist/node/chunks/dep-CB_7IfJ-.js:64173:39\n\n\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af[1/3]\u23af\n\n FAIL  src/tests/transfer.test.ts [ src/tests/transfer.test.ts ]\nError: Failed to resolve entry for package \"@elizaos/core\". The package may have incorrect main/module/exports specified in its package.json.\n  Plugin: vite:import-analysis\n  File: /Users/levi/code/web3/eliza/packages/plugin-evm/src/actions/transfer.ts\n \u276f packageEntryFailure ../../node_modules/vite/dist/node/chunks/dep-CB_7IfJ-.js:46637:15\n \u276f resolvePackageEntry ../../node_modules/vite/dist/node/chunks/dep-CB_7IfJ-.js:46634:3\n \u276f tryNodeResolve ../../node_modules/vite/dist/node/chunks/dep-CB_7IfJ-.js:46450:16\n \u276f ResolveIdContext.resolveId ../../node_modules/vite/dist/node/chunks/dep-CB_7IfJ-.js:46200:19\n \u276f PluginContainer.resolveId ../../node_modules/vite/dist/node/chunks/dep-CB_7IfJ-.js:49015:17\n \u276f TransformPluginContext.resolve ../../node_modules/vite/dist/node/chunks/dep-CB_7IfJ-.js:49175:15\n \u276f normalizeUrl ../../node_modules/vite/dist/node/chunks/dep-CB_7IfJ-.js:64034:26\n \u276f ../../node_modules/vite/dist/node/chunks/dep-CB_7IfJ-.js:64173:39\n\n\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af\u23af[2/3]\u23af\n\n Test Files  3 failed (3)\n      Tests  no tests\n   Start at  10:58:48\n   Duration  375ms (transform 79ms, setup 0ms, collect 0ms, tests 0ms, environment 0ms, prepare 125ms)\n\n\u2009ELIFECYCLE\u2009 Test failed. See above for more details.\n```\n**To Reproduce**\n\n```\n// clone this repo\npnpm install\npnpm run build\npnpm test\n```\n\n**Expected behavior**\n\nSuccessfully run the test\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/d63da237-3f5c-4c6b-adf2-b29d987bb0da)\n\n**Additional context**\n\nversion:\n```\n~ \u276f npm --version\n10.9.0\n~ \u276f pnpm --version\n9.15.4\n\n~/code/web3/eliza/packages/plugin-evm develop \u276f pnpm vitest --version\nvitest/2.1.5 darwin-arm64 node-v23.3.0\n```\nrepo commit: 6cfbd1848143461511b17ffb711045c4705622c6\n", "CLOSED", 0, "chen4903", "2025-01-17T03:06:08Z", "2025-01-17T11:38:33Z", "2025-01-17T11:38:33Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6miArY", 2406, "Add tests in __tests__ for github client", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\nSince we are changing project structure, we need to add tests for github client.\n**Describe the solution you'd like**\nTests for github client are added to packages/client-github/__tests__\n<!-- A clear and concise description of what you want to happen. -->\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-16T22:46:04Z", "2025-01-16T23:04:19Z", "2025-01-16T23:04:19Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6mh6ow", 2403, "Add tests for slack client. Move and update existing tests to __tests__ directory", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\nSince we are changing project structure, add new tests for slack client. Move existing to __tests__ directory.\n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-16T22:26:11Z", "2025-01-16T22:51:12Z", "2025-01-16T22:51:12Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6meeDx", 2387, "unset variables docker compose bug", "```\n\u26d4 ERRORS\n   Error in wallet provider: \n   {} \n\nError in Story wallet provider: Error: invalid private key, expected hex or 32 bytes, got string\n    at normPrivateKeyToScalar (file:///app/node_modules/viem/node_modules/@noble/curves/esm/abstract/weierstrass.js:218:19)\n    at Point.fromPrivateKey (file:///app/node_modules/viem/node_modules/@noble/curves/esm/abstract/weierstrass.js:335:40)\n    at Object.getPublicKey (file:///app/node_modules/viem/node_modules/@noble/curves/esm/abstract/weierstrass.js:804:22)\n    at privateKeyToAccount (file:///app/node_modules/viem/_esm/accounts/privateKeyToAccount.js:17:39)\n    at new WalletProvider (file:///app/packages/plugin-story/dist/index.js:40:25)\n    at Object.get (file:///app/packages/plugin-story/dist/index.js:99:36)\n    at file:///app/packages/core/dist/index.js:30042:31\n    at Array.map (<anonymous>)\n    at getProviders (file:///app/packages/core/dist/index.js:30041:66)\n    at AgentRuntime.composeState (file:///app/packages/core/dist/index.js:31316:13)\nError in client provider: Error: invalid private key, expected hex or 32 bytes, got string\n    at normPrivateKeyToScalar (file:///app/packages/plugin-genlayer/dist/index.js:1706:19)\n    at Point2.fromPrivateKey (file:///app/packages/plugin-genlayer/dist/index.js:1803:41)\n    at Object.getPublicKey (file:///app/packages/plugin-genlayer/dist/index.js:2248:23)\n    at privateKeyToAccount (file:///app/packages/plugin-genlayer/dist/index.js:4850:39)\n    at new ClientProvider (file:///app/packages/plugin-genlayer/dist/index.js:4900:24)\n    at Object.get (file:///app/packages/plugin-genlayer/dist/index.js:4907:30)\n    at file:///app/packages/core/dist/index.js:30042:31\n    at Array.map (<anonymous>)\n    at getProviders (file:///app/packages/core/dist/index.js:30041:66)\n    at AgentRuntime.composeState (file:///app/packages/core/dist/index.js:31316:13)\n\n \u26d4 ERRORS\n   \u274c Error handling message: \n   {} \n\n \u26d4 ERRORS\n   Error sending message: \n   {} \n\nCache miss for fetchPortfolioValue\nCache miss for fetchPrices\nError getting wallet balance: TypeError: Invalid URL\n    at new URL (node:internal/url:818:25)\n    at dispatchHttpRequest (/app/node_modules/axios/dist/node/axios.cjs:2777:20)\n    at /app/node_modules/axios/dist/node/axios.cjs:2697:5\n    at new Promise (<anonymous>)\n    at wrapAsync (/app/node_modules/axios/dist/node/axios.cjs:2677:10)\n    at http (/app/node_modules/axios/dist/node/axios.cjs:2715:10)\n    at Axios.dispatchRequest (/app/node_modules/axios/dist/node/axios.cjs:4092:10)\n    at Axios._request (/app/node_modules/axios/dist/node/axios.cjs:4385:33)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4247:25)\n    at Axios.httpMethod [as post] (/app/node_modules/axios/dist/node/axios.cjs:4424:19)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4252:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async HttpApi.doCall (/app/node_modules/@ton/ton/dist/client/api/HttpApi.js:263:19)\n    at async TonClient.getContractState (/app/node_modules/@ton/ton/dist/client/TonClient.js:233:20)\n    at async Object.getState (/app/node_modules/@ton/ton/dist/client/TonClient.js:340:25)\n    at async WalletContractV4.getBalance (/app/node_modules/@ton/ton/dist/wallets/WalletContractV4.js:42:21)\n    at async WalletProvider.getWalletBalance (file:///app/packages/plugin-ton/dist/index.js:4202:29)\n    at async WalletProvider.fetchPortfolioValue (file:///app/packages/plugin-ton/dist/index.js:4156:40)\n    at async WalletProvider.getFormattedPortfolio (file:///app/packages/plugin-ton/dist/index.js:4177:31)\n    at async Object.get (file:///app/packages/plugin-ton/dist/index.js:4231:20) {\n  code: 'ERR_INVALID_URL',\n  input: '# ton rpc'\n}\nFetched portfolio: { totalUsd: '0', totalNativeToken: '0' }\n```\n\nCan someone help me resolve this? I had no issues locally with such thing, I am not suing ton or story wallet, this is when running docker-compose in cloud", "CLOSED", 0, "WNUMIK", "2025-01-16T14:55:47Z", "2025-01-16T15:01:44Z", "2025-01-16T15:01:44Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6mcPjs", 2373, "(plugin-node) Bugs related to image description service", "A few things are broken in `plugin-node` related to image description:\n\n1. GIF frame extraction doesn't work for me (the call to `gifFrames` fails), and also uses an unmaintained dependency with vulnerabilities\n\nhttps://github.com/elizaOS/eliza/blob/5076588d998603d871e705af1c76144ac68bbc2f/packages/plugin-node/src/services/image.ts#L339-L346\n\nref: https://github.com/benwiley4000/gif-frames/\n\n2. Image data loading loads the first GIF frame as PNG but the local image provider expects a JPEG\n\nhttps://github.com/elizaOS/eliza/blob/5076588d998603d871e705af1c76144ac68bbc2f/packages/plugin-node/src/services/image.ts#L113-L122\n\n3. The local image provider calls Transformers.js API incorrectly, it passes a data URL but `RawImage.fromURL` does not support that\n\n`RawImage.fromURL`:\n\nhttps://github.com/huggingface/transformers.js/blob/e1753ac0ff363183552bbc35488937e0d42c9cf8/src/utils/image.js#L147-L153\n\nWhich calls `getFile`, which does not support data URLs:\n\nhttps://github.com/huggingface/transformers.js/blob/e1753ac0ff363183552bbc35488937e0d42c9cf8/src/utils/hub.js#L190-L193\n\n4. Users running Ollama expect to be using the local image vision provider if nothing's set, but instead just error out right now\n\nhttps://github.com/elizaOS/eliza/blob/fd35fd9914825401a84aa4db0334d17b705f8ae6/packages/plugin-node/src/services/image.ts#L311-L315\n\n5. In the describe image action, depending on the model used the file location result object can look like\n\n`{ object: fileLocation }` or `{ fileLocation }`\n\nhttps://github.com/elizaOS/eliza/blob/fd35fd9914825401a84aa4db0334d17b705f8ae6/packages/plugin-node/src/actions/describe-image.ts#L38-L51\n\n6. Image data loading currently only classifies images as \"animated GIFs\" and \"everything else\", which fails to handle a number of input image cases since the APIs support mostly JPEG and PNG\n\nhttps://github.com/elizaOS/eliza/blob/fd35fd9914825401a84aa4db0334d17b705f8ae6/packages/plugin-node/src/services/image.ts#L357-L369\n\nref:\nhttps://platform.openai.com/docs/guides/vision#what-type-of-files-can-i-upload\nhttps://firebase.google.com/docs/vertex-ai/input-file-requirements#images-mime-types\n\n---\n\nPR coming shortly.", "CLOSED", 0, "ae9is", "2025-01-16T11:09:40Z", "2025-01-17T17:16:53Z", "2025-01-17T17:16:53Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6mcEQN", 2372, "Twitter Authentication Fails on AWS EC2 Instance (Error 399)", "'m experiencing an issue with Twitter authentication when running Eliza OS on an AWS EC2 instance. While the application works fine locally, it fails to authenticate on EC2 with the following errors:\r\n\r\n\r\n\r\n```\r\n[\"\u25ce Waiting for Twitter login\"]\r\n[\"\u26d4 Login attempt failed: {\"errors\":[{\"code\":399,\"message\":\"Incorrect. Please try again. g;173702389163775059:-1737023891718:RCxMpaDzkjFs0VKtNQFAmmAH:8\"}]}\"]\r\n[\"\u26d4 Failed to login to Twitter. Retrying... (4 attempts left)\"]\r\n[\"\u26d4 Login attempt failed: Authentication error: DenyLoginSubtask\"]\r\n[\"\u26d4 Failed to login to Twitter. Retrying... (3 attempts left)\"]\r\n[\"\u26d4 Login attempt failed: Authentication error: DenyLoginSubtask\"]\r\n[\"\u26d4 Failed to login to Twitter. Retrying... (2 attempts left)\"]\r\n```\r\n\r\nThe application keeps retrying but fails each time with either Error 399 or DenyLoginSubtask.\r\n\r\nSteps to reproduce:\r\nDeploy Eliza OS on an AWS EC2 instance\r\nAttempt to log in to Twitter through the application\r\n\r\nExpected behavior:\r\nSuccessful Twitter authentication and login\r\nActual behavior:\r\nRepeated authentication failures with Error 399 and DenyLoginSubtask errors\r\n\r\nAdditional context:\r\nThe application works correctly on my local machine\r\nThis issue seems specific to the AWS EC2 environment\r\nAny assistance in resolving this authentication problem would be greatly appreciated.", "CLOSED", 0, "jeongtai", "2025-01-16T10:49:43Z", "2025-01-17T07:11:09Z", "2025-01-17T07:11:08Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6mXmS0", 2344, "Tests for Solana Plugin", "**Is your feature request related to a problem? Please describe.**\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\nWe should add tests for solana plugin.\r\n**Describe the solution you'd like**\r\nSince we are improving project structure, we need to add tests for solana plugin located in __tests__ directory\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "ai16z-demirix", "2025-01-15T23:20:16Z", "2025-01-16T18:41:15Z", "2025-01-16T18:41:15Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6mXbyq", 2343, "Running in cloud from docker image BUG", "I have following error when running pnpm start in cloud in my docker container, my .env has CACHE_STORE=database\r\nbut I also have URL for REDIS_URL\r\nWhat can be wrong?\r\n```\r\n [\"\u26d4 Error: Invalid cache store: database # Defaults to database. Other available cache store: redis and filesystem or required configuration missing.\"] \r\n\r\n [\"\u2713 Successfully connected to PostgreSQL database\"] \r\n\r\n \u26d4 ERRORS\r\n   Error starting agents: \r\n   {} \r\n```\r\n\r\nalso the second error I have is\r\n```\r\n\r\n# pnpm build\r\n\r\n> eliza@ build /app\r\n> turbo run build --filter=!eliza-docs\r\n\r\nturbo 2.3.3\r\n\r\n  x No package found with name 'eliza-docs' in workspace\r\n\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n# \r\n```", "CLOSED", 0, "WNUMIK", "2025-01-15T23:00:02Z", "2025-01-16T14:29:20Z", "2025-01-16T14:29:19Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6mR9GO", 2323, "Feature - ragKnowledge enhancements (double byte support, caching, load from directories)", "From testing with the current interation of ragKnowledge, encountered the following issues:\r\n\r\n- Double byte characters are stripped (e.g., Chinese)\r\n- Knowledge is re-embedded everytime on agent startup\r\n- Have to enumerate each file you want to load as knowledge\r\n\r\nSo I'm working on enhancing the rag knowledge feature to support the above.   Otherwise it will be very hard to support large sets of knowledge across multiple files and agent startup will be very slow (as re-embedding has to happen every restart)\r\n\r\n", "CLOSED", 0, "augchan42", "2025-01-15T12:35:32Z", "2025-01-16T07:04:33Z", "2025-01-16T07:04:33Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6mOgtp", 2312, "Issue running multiple characters with API key", "So I put my open router key and model type in the character secrets the same way I did it in the environment and it has previously worked, the twitter log in also works. But it keeps saying no key found and tries to route through Llama even though I selected ChatGPT. It was working fine when it was in the environment file for one character at a time so I\u2019m sure the issue is being caused by how I input it into secrets. Will update with more info tomorrow if need be. I also tried making a unique key for each character to no avail. ", "CLOSED", 0, "MarcosOyler", "2025-01-15T04:40:54Z", "2025-01-15T21:06:45Z", "2025-01-15T21:06:45Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6mFWYi", 2277, "the tweets are getting cutoff... where can i adjust the tweet length?", "i gave longer examples posts to the character....\r\n", "CLOSED", 0, "aiopinions", "2025-01-14T07:10:03Z", "2025-01-15T15:47:13Z", "2025-01-15T15:47:13Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6mE0Ws", 2272, "Chat Input Sends Multiple Messages When Using IME", "\r\n**Describe the bug**\r\n\r\nWhen using an Input Method Editor (IME) for languages like Chinese, Japanese, or Korean, pressing Enter while composing text sometimes causes the same message to be sent multiple times.\r\n\r\n**To Reproduce**\r\n\r\nSteps to reproduce the behavior:\r\n\r\nSet the input language to a language requiring IME (e.g., Chinese, Japanese, Korean).\r\nOpen the chat input box.\r\nStart typing text using the IME and press Enter while still composing.\r\nObserve that the same message is sent multiple times.\r\n\r\n**Expected behavior**\r\n\r\nThe message should only be sent once when the Enter key is pressed, even if an IME is active and composing text.\r\n\r\n**Screenshots**\r\n\r\n<img width=\"1516\" alt=\"image\" src=\"https://github.com/user-attachments/assets/1dcd81b0-df4f-48a5-a32d-ee76ce54d167\" />\r\n\r\n**Additional context**\r\n\r\nThis issue primarily affects users of languages that require IME for text input, such as Korean, which I used.\r\n", "CLOSED", 0, "lincheoll", "2025-01-14T05:11:40Z", "2025-01-14T17:31:51Z", "2025-01-14T17:31:51Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6mCyNj", 2265, "Log in info safe on character.json file vs .env?", "Just a quick question about the safety of inputting our login information for social media platforms on the files. Is it safe to input them on the character.json file under \"secrets\", or is it better to have them in the .env?\r\n\r\n What if you are running more than one character? Is there a way to add 2 different login info for the same platform (e.g twitter, or discord) in the .env and have them be assigned to different characters.json?", "CLOSED", 0, "sonatonagems", "2025-01-13T23:40:29Z", "2025-01-16T22:48:49Z", "2025-01-16T22:48:47Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6l9tdJ", 2250, "model loading from .env fails", "**Describe the bug**\r\n\r\nwrong model loaded in .env I specify XAI_MODEL=gpt-4o, but then OS loads with\r\n\r\n```\r\n  {\"character\":\"Eliza\",\"modelProvider\":\"llama_local\",\"characterModelProvider\":\"llama_local\"}\r\n\r\n [\"\u2713 Agent ID: b850bc30-45f8-0041-a00a-83df46d8555d\"]\r\n\r\n [\"\u2139 Setting model provider...\"]\r\n\r\n \u2139 INFORMATIONS\r\n   Model Provider Selection:\r\n   {\"characterModelProvider\":\"llama_local\",\"optsModelProvider\":\"llama_local\",\"finalSelection\":\"llama_local\"}\r\n```\r\n\r\nXAI_MODEL seems to be never used in the code\r\n\r\n**Expected behavior**\r\n\r\nload the correct model\r\n", "CLOSED", 0, "benjiqq", "2025-01-13T15:51:36Z", "2025-01-14T13:59:07Z", "2025-01-14T10:14:37Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6l9L2u", 2246, "Echochambers - support joining multiple rooms, and proactive conversation starting", "Currently the echochambers plugin only listens to one room, and the agent only listens for messages and reacts.\r\n\r\nWhat happens if only elizaos agents are in an echochambers room?  All the agents will wait for someone to say something, and there will be no conversations at all.\r\n\r\nSo will work on allowing listening to multiple rooms at the same time, and proactive conversation starts if the room is dead (if there are no messages after a configurable period of time)", "CLOSED", 0, "augchan42", "2025-01-13T15:11:33Z", "2025-01-15T06:26:40Z", "2025-01-15T06:26:40Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6l3Edh", 2215, "pnpm outdated lockfile error", "\u2009ERR_PNPM_OUTDATED_LOCKFILE\u2009 Cannot install with \"frozen-lockfile\" because pnpm-lock.yaml is not up to date with <ROOT>/package.json\r\n\r\nNote that in CI environments this setting is true by default. If you still need to run install in such cases, use \"pnpm install --no-frozen-lockfile\"\r\n\r\n    Failure reason:\r\n    specifiers in the lockfile ({\"@0glabs/0g-ts-sdk\":\"0.2.1\",\"@coinbase/coinbase-sdk\":\"0.10.0\",\"@deepgram/sdk\":\"^3.9.0\",\"@vitest/eslint-plugin\":\"1.0.1\",\"amqplib\":\"0.10.5\",\"csv-parse\":\"5.6.0\",\"ollama-ai-provider\":\"0.16.1\",\"optional\":\"0.1.4\",\"pnpm\":\"9.14.4\",\"sharp\":\"0.33.5\",\"tslog\":\"4.9.3\",\"@commitlint/cli\":\"18.6.1\",\"@commitlint/config-conventional\":\"18.6.3\",\"@types/jest\":\"^29.5.11\",\"@typescript-eslint/eslint-plugin\":\"8.16.0\",\"@typescript-eslint/parser\":\"8.16.0\",\"concurrently\":\"9.1.0\",\"cross-env\":\"7.0.3\",\"eslint\":\"9.16.0\",\"eslint-config-prettier\":\"9.1.0\",\"husky\":\"9.1.7\",\"jest\":\"^29.7.0\",\"lerna\":\"8.1.5\",\"only-allow\":\"1.2.1\",\"prettier\":\"3.4.1\",\"ts-jest\":\"^29.1.1\",\"turbo\":\"2.3.3\",\"typedoc\":\"0.26.11\",\"typescript\":\"5.6.3\",\"viem\":\"2.21.58\",\"vite\":\"5.4.11\",\"vitest\":\"2.1.5\"}) don't match specs in package.json ({\"@commitlint/cli\":\"18.6.1\",\"@commitlint/config-conventional\":\"18.6.3\",\"@types/jest\":\"^29.5.11\",\"@typescript-eslint/eslint-plugin\":\"8.16.0\",\"@typescript-eslint/parser\":\"8.16.0\",\"@vitest/eslint-plugin\":\"1.0.1\",\"concurrently\":\"9.1.0\",\"cross-env\":\"7.0.3\",\"eslint\":\"9.16.0\",\"eslint-config-prettier\":\"9.1.0\",\"husky\":\"9.1.7\",\"jest\":\"^29.7.0\",\"lerna\":\"8.1.5\",\"only-allow\":\"1.2.1\",\"prettier\":\"3.4.1\",\"ts-jest\":\"^29.1.1\",\"turbo\":\"2.3.3\",\"typedoc\":\"0.26.11\",\"typescript\":\"5.6.3\",\"viem\":\"2.21.58\",\"vite\":\"5.4.11\",\"vitest\":\"2.1.5\",\"@0glabs/0g-ts-sdk\":\"0.2.1\",\"@coinbase/coinbase-sdk\":\"0.10.0\",\"@deepgram/sdk\":\"^3.9.0\",\"amqplib\":\"0.10.5\",\"csv-parse\":\"5.6.0\",\"langdetect\":\"^0.2.1\",\"ollama-ai-provider\":\"0.16.1\",\"optional\":\"0.1.4\",\"pnpm\":\"9.14.4\",\"sharp\":\"0.33.5\",\"tslog\":\"4.9.3\"})", "CLOSED", 0, "piquebu", "2025-01-12T20:25:59Z", "2025-01-16T22:59:36Z", "2025-01-16T22:59:35Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6l2xAB", 2210, "Reorganize the README files, move them  from the root folder to docs sub-folder", "Hi everyone, I finally started looking at Eliza code as I would love to contribute as much as I can.\r\n\r\nFirst thing I noticed is that all the `README` files in various languages are in the root folder, making an unnecessary long scrolling. Also the files are not consistent each other, they contain different documentation. From a first overview it looks a bit confusing.\r\n\r\nI would suggest to move all the `README` files (except the EN one) into a subfolder `readme` or under `docs`, with each one still linked in the root README, to make the root folder cleaner.\r\n\r\nAbout the consistency, I still need to see how documents are generated but AI-based translation (by an Eliza agent?) could be a good option, unless you already encountered issues on having that.\r\n", "CLOSED", 0, "marcomarchesi", "2025-01-12T17:26:22Z", "2025-01-18T03:01:55Z", "2025-01-18T03:01:55Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6l2V8A", 2203, "pnpm install and start errors", "**eliza**\r\nI tried to run the latest elizaOS/eliza main version (0.1.8.build.1) on my LINUX desktop with the following configuration:\r\n```\r\nUbuntu : 20.04.6 LTS\r\nPython : 3.8.10\r\nnode : 23.3.0\r\nvnm : 0.39.1\r\npnpm : 9.15.3\r\n```\r\n\r\nWhen installing eliza with `pnpm install` I get the following error :\r\n```  \r\n...\r\nCOPY Release/opus.a\r\nCXX(target) Release/obj.target/opus/src/node-opus.o\r\ng++: error: unrecognized command line option \u2018-std=gnu++20\u2019; did you mean \u2018-std=gnu++2a\u2019?\r\nmake: *** [opus.target.mk:157: Release/obj.target/opus/src/node-opus.o] Error 1\r\nmake: Leaving directory '/home/mbarnig/ELIZA/eliza/node_modules/@discordjs/opus/build'\r\ngyp ERR! build error \r\ngyp ERR! stack Error: `make` failed with exit code: 2\r\n...\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n```\r\nWhen ignoring the error and running `pnpm build` the build process is successful:\r\n```\r\nTasks:    87 successful, 87 total\r\nCached:    87 cached, 87 total\r\nTime:    22.773s >>> FULL TURBO\r\n``` \r\nWhen starting eliza with `pnpm start` I get the following error :\r\n```\r\n/home/mbarnig/ELIZA/eliza/node_modules/@roamhq/wrtc/lib/binding.js:27\r\n  throw new Error(`Could not find wrtc binary on any of the paths: ${paths_to_try}`);\r\n        ^\r\n\r\nError: Could not find wrtc binary on any of the paths: ../build-linux-x64/wrtc.node,../build-linux-x64/Debug/wrtc.node,../build-linux-x64/Release/wrtc.node,@roamhq/wrtc-linux-x64,./node_modules/@roamhq/wrtc-linux-x64,./node_modules/@roamhq/wrtc-linux-x64/wrtc.node\r\n    at Object.<anonymous> (/home/mbarnig/ELIZA/eliza/node_modules/@roamhq/wrtc/lib/binding.js:27:9)\r\n    at Module._compile (node:internal/modules/cjs/loader:1546:14)\r\n    at Object..js (node:internal/modules/cjs/loader:1698:10)\r\n    at Module.load (node:internal/modules/cjs/loader:1303:32)\r\n    at Function._load (node:internal/modules/cjs/loader:1117:12)\r\n    at TracingChannel.traceSync (node:diagnostics_channel:322:14)\r\n    at wrapModuleLoad (node:internal/modules/cjs/loader:218:24)\r\n    at Module.require (node:internal/modules/cjs/loader:1325:12)\r\n    at require (node:internal/modules/helpers:136:16)\r\n    at Object.<anonymous> (/home/mbarnig/ELIZA/eliza/node_modules/@roamhq/wrtc/lib/index.js:23:5)\r\n\r\nNode.js v23.3.0\r\n/home/mbarnig/ELIZA/eliza/agent:\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.8+build.1 start: `node --loader ts-node/esm src/index.ts \"--isRoot\"`\r\nExit status 1\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n```  \r\n**eliza-starter**\r\nWhen I try to run the latest version of eliza-starter with `pnpm pnpm i && pnpm start` I get the following error :\r\n```\r\n   COPY Release/opus.a\r\n\u2502   CXX(target) Release/obj.target/opus/src/node-opus.o\r\n\u2502 g++: error: unrecognized command line option \u2018-std=gnu++20\u2019; did you mean \u2018-std=gnu++2a\u2019?\r\n\u2502 make: *** [opus.target.mk:157: Release/obj.target/opus/src/node-opus.o] Error 1\r\n\u2502 make: Leaving directory '/home/mbarnig/ELIZA/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2\u2026\r\n\u2502 gyp ERR! build error \r\n\u2502 gyp ERR! stack Error: `make` failed with exit code: 2\r\n\u2502 gyp ERR! stack at ChildProcess.<anonymous> (/usr/local/lib/node_modules/pnpm/dist/node_modules/node-gyp/lib/build.js:216:23)\r\n\u2502 gyp ERR! System Linux 5.15.0-130-generic\r\n\u2502 gyp ERR! command \"/home/mbarnig/.nvm/versions/node/v23.3.0/bin/node\" \"/usr/local/lib/node_modules/pnpm/dist/node_modules/node-gyp/bin/node-gyp.js\" \"build\"\u2026\r\n\u2502 gyp ERR! cwd /home/mbarnig/ELIZA/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bf\u2026\r\n\u2502 gyp ERR! node -v v23.3.0\r\n\u2502 gyp ERR! node-gyp -v v10.2.0\r\n\u2502 gyp ERR! not ok \r\n\u2502 node-pre-gyp ERR! build error \r\n\u2502 node-pre-gyp ERR! stack Error: Failed to execute '/home/mbarnig/.nvm/versions/node/v23.3.0/bin/node /usr/local/lib/node_modules/pnpm/dist/node_modules/nod\u2026\r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess.<anonymous> (/home/mbarnig/ELIZA/eliza-starter/node_modules/.pnpm/@discordjs+node-pre-gyp@0.4.5/node_modules/@\u2026\r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess.emit (node:events:513:28)\r\n\u2502 node-pre-gyp ERR! stack     at maybeClose (node:internal/child_process:1101:16)\r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess._handle.onexit (node:internal/child_process:305:5)\r\n\u2502 node-pre-gyp ERR! System Linux 5.15.0-130-generic\r\n\u2502 node-pre-gyp ERR! command \"/home/mbarnig/.nvm/versions/node/v23.3.0/bin/node\" \"/home/mbarnig/ELIZA/eliza-starter/node_modules/.pnpm/@discordjs+node-pre-gy\u2026\r\n\u2502 node-pre-gyp ERR! cwd /home/mbarnig/ELIZA/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6\u2026\r\n\u2502 node-pre-gyp ERR! node -v v23.3.0\r\n\u2502 node-pre-gyp ERR! node-pre-gyp -v v0.4.5\r\n\u2502 node-pre-gyp ERR! not ok \r\n\u2502 Failed to execute '/home/mbarnig/.nvm/versions/node/v23.3.0/bin/node /usr/local/lib/node_modules/pnpm/dist/node_modules/node-gyp/bin/node-gyp.js build --f\u2026\r\n\u2514\u2500 Failed in 17.3s at /home/mbarnig/ELIZA/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7d5f9fb02/node_modules/@discordjs/opus\r\nnode_modules/.pnpm/wtf_wikipedia@10.3.2/node_modules/wtf_wikipedia: Running postinstall script, done in 252ms\r\nnode_modules/.pnpm/node-llama-cpp@3.1.1_typescript@5.6.3/node_modules/node-llama-cpp: Running postinstall script...\r\nnode_modules/.pnpm/puppeteer@19.11.1_bufferutil@4.0.9_typescript@5.6.3_utf-8-validate@5.0.10/node_modules/puppeteer: Running postinstall script, done in 97ms\r\nnode_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3: Running install script, done in 892ms\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n```", "CLOSED", 0, "mbarnig", "2025-01-12T13:28:09Z", "2025-01-17T03:28:12Z", "2025-01-13T18:36:28Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6l2OlN", 2200, "Using locally installed models on Mac M1/Use of alternative models like DEEPSEEK", "Thank you for your work. \r\nThere are several questions. \r\n - Is it possible to use a locally installed Hermes 3 Llama 3.1 8B model on Mac M 1 when creating an agent?\r\n - If so, how and where to indicate the model used and the path to it, I did not find this information in the tutorial or it is not obvious?\r\n - Is it possible to use models like DeepSeek v.2, v.3 by specifying the api key as in the case of OpenAI or are only those in the list available?\r\n - If so, how can this be done? Is it enough to specify the following configuration in the .env.example file:\r\nDEEPSEEK_MODEL= , DEEPSEEK_API_KEY= and change accordingly in character.json \"modelProvider\": \"deepseek\" or is this more fundamental stuff that requires meddling with other files?\r\n", "CLOSED", 0, "BroccoliFin", "2025-01-12T12:18:42Z", "2025-01-17T11:21:12Z", "2025-01-16T23:09:35Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6l176D", 2192, "Error in building docker image", "**Describe the bug**\r\n\r\nI cannot seem to build the docker image. This is the command that I run\r\n`docker buildx build --platform=linux/amd64 -t {username}/eliza-v0 .`\r\n\r\nThis is the error logs that I get\r\n\r\n```\r\n... (rest)\r\n#0 1840.2 @elizaos/client-lens:build: cache miss, executing 5aaead36e6f8db2b\r\n#0 1840.2 @elizaos/plugin-twitter:build: cache miss, executing bdbd503cc3a94bc7\r\n#0 1840.3 @elizaos/adapter-sqljs#build: command (/app/packages/adapter-sqljs) /app/node_modules/.bin/pnpm run build exited (137)\r\n#0 1840.5 \r\n#0 1840.5  Tasks:    2 successful, 48 total\r\n#0 1840.5 Cached:    0 cached, 48 total\r\n#0 1840.5   Time:    4m35.575s \r\n#0 1840.5 Failed:    @elizaos/adapter-sqljs#build\r\n#0 1840.5 \r\n#0 1841.3  ERROR  run failed: command  exited (137)\r\n#0 1842.6 \u2009ELIFECYCLE\u2009 Command failed with exit code 137.\r\n------\r\nerror: failed to solve: executor failed running [/bin/sh -c pnpm install     && pnpm build-docker     && pnpm prune --prod]: exit code: 137\r\n```\r\n\r\n**To Reproduce**\r\n\r\nI am using M1 Macbook. I ran this command below\r\n`docker buildx build --platform=linux/amd64 -t {username}/eliza-v0 .`\r\n\r\n**Expected behavior**\r\n\r\nShould be able to build my docker image\r\n\r\n", "CLOSED", 0, "chuasonglin1995", "2025-01-12T09:51:29Z", "2025-01-13T04:28:50Z", "2025-01-13T04:28:49Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6l15ib", 2190, "Add support for custom S3 endpoints in `plugin-node`", "**Is your feature request related to a problem? Please describe.**\n\nThe `plugin-node` gives you an S3-compatible API. However, it assumes you're using AWS S3; it doesn't let you use S3-compatible tooling because the request URL is not configurable.\n\n**Describe the solution you'd like**\n\nWe should allow the plugin to take an additional (optional) env var called `AWS_S3_ENDPOINT`, which if set, will use the URL for bucket operations. The `plugin-node` only needs a small change to handle the URL, ensuring the setup is backward compatible.\n\n**Describe alternatives you've considered**\n\nUsing existing AWS S3 configuration only, but this limits flexibility.\n\n**Additional context**\n\nImplementing this feature will enhance compatibility with other S3-compatible services, improving the usability of the `plugin-node` for diverse storage solutions.\n\n**Related Issues/PRs**\n- [Issue #2174](https://github.com/elizaOS/eliza/issues/2174)", "CLOSED", 0, "monilpat", "2025-01-12T09:25:50Z", "2025-01-18T03:52:12Z", "2025-01-18T03:52:11Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6l1x98", 2183, "Lock file errors or missing dependency", "Hi community , \r\nNot able to set up the template project on Ubuntu , getting lockfile errors \r\n\r\n", "CLOSED", 0, "Ansh1902396", "2025-01-12T07:57:46Z", "2025-01-14T10:13:10Z", "2025-01-14T10:13:10Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6lva-J", 2123, "Remove Tavily from core", "Right now tavily is being used in core, we want this to be a registered service, not something that is in core", "CLOSED", 0, "lalalune", "2025-01-10T17:06:48Z", "2025-01-16T05:37:34Z", "2025-01-16T05:37:33Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6lV80m", 1991, "WASM support for agents?", "**Is your feature request related to a problem? Please describe.**\r\n\r\nFeature request.\r\n\r\n**Describe the solution you'd like**\r\n\r\nA simple way to compile agents into WASM.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nTypescript does not support WASM compilation directly.\r\nAssemblyScript and Rust can compile to WASM.\r\nAre the eliza npm packages compatible with AssemblyScript? \r\nWould it be possible to interact with an agent with an API RPC endpoint\r\nand write some program in AssemblyScript or Rust to interact with the agent through that API endpoint?\r\n\r\n**Additional context**\r\n\r\nAttempting to create an agent that can run in a WASM environment. \r\n", "CLOSED", 0, "MarcusWentz", "2025-01-08T00:40:18Z", "2025-01-15T21:31:29Z", "2025-01-15T21:31:29Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6lRHQC", 1958, "Agent Generates Tweets But Never Publishes to Twitter", "I\u2019m using an AI agent that is supposed to post tweets automatically, but it only generates text and logs \u201cSaving Tweet\u201d without ever actually publishing. I\u2019ve verified that TWITTER_DRY_RUN=false in the .env, and the Twitter login appears to succeed, yet there\u2019s no sign of an actual API call to post the tweet (no \u201cPosting\u2026\u201d log, and nothing appears on the timeline). I\u2019ve tried adjusting intervals (e.g., TWITTER_POLL_INTERVAL) and verified that the generated text is valid, but the agent remains stuck in a \u201cgenerate/store\u201d loop without calling the Twitter API. Any guidance on diagnosing why it never proceeds to post (or how to confirm the agent is truly attempting the Twitter API call) would be greatly appreciated.\r\n", "CLOSED", 0, "Clinksys", "2025-01-07T12:29:19Z", "2025-01-17T22:10:22Z", "2025-01-17T22:10:21Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6lL3uC", 1925, "Agent fails to generate text when dockerized ", "**Describe the bug**\r\n\r\nThe agent is unable to generate text using the model when interacted with or when trying to generate tweets based on it's character file.\r\n\r\n**To Reproduce**\r\n\r\n\r\n```bash\r\ngit clone https://github.com/elizaos/eliza-starter.git\r\ncd eliza-starter\r\ncp .env.example .env\r\ndocker-compose up --build\r\n```\r\n\r\n**Expected behavior**\r\n\r\nworks perfectly\r\n\r\n**Screenshots**\r\n<img width=\"453\" alt=\"Screenshot 2025-01-06 at 15 09 46\" src=\"https://github.com/user-attachments/assets/48796032-7261-4043-8529-ce4a5496b244\" />\r\n\r\n\r\n**Additional context**\r\n\r\nthis is assuming you have docker installed and running already with\r\n env_file:\r\n            - .env\r\n           \r\nin docker-compose.yaml\r\n", "CLOSED", 0, "berryboylb", "2025-01-06T20:02:46Z", "2025-01-13T01:56:42Z", "2025-01-12T11:07:44Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6lD-ib", 1870, "Eliza throws embeddings error on http://localhost:3000 access.", "**Describe the bug**\r\n\r\nWhen attempting to access the REST API via a python script, I get the following error, and termination of eliza process. \r\n\r\n```\r\nfile:///C:/Users/bryan/Desktop/eliza/packages/core/dist/index.js:29031\r\n            throw new Error(\"Cannot generate embedding: Memory content is empty\");\r\n                  ^\r\n\r\nError: Cannot generate embedding: Memory content is empty\r\n    at MemoryManager.addEmbeddingToMemory (file:///C:/Users/bryan/Desktop/eliza/packages/core/dist/index.js:29031:19)\r\n    at file:///C:/Users/bryan/Desktop/eliza/packages/client-direct/dist/index.js:302:42\r\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\r\n\r\nNode.js v22.12.0\r\nC:\\Users\\bryan\\Desktop\\eliza\\agent:\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.7 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/trump.character.json\"`\r\nExit status 1\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n```\r\n\r\n**To Reproduce**\r\n\r\n`pnpm start --character=\"characters/trump.character.json\"`\r\n\r\nrun code:\r\n```\r\n\r\nimport requests\r\n\r\ndef test_direct_message():\r\n    agent_id = \"e0e10e6f-ff2b-0d4c-8011-1fc1eee7cb32\"\r\n    url = f\"http://localhost:3000/{agent_id}/message\"\r\n\r\n    payload = {\r\n        \"message\": \"Hello!\"\r\n    }\r\n\r\n    try:\r\n        response = requests.post(url, json=payload)\r\n        print(\"Status Code:\", response.status_code)\r\n        print(\"Response JSON:\", response.json())\r\n    except requests.exceptions.RequestException as e:\r\n        print(\"Request failed:\", e)\r\n\r\nif __name__ == \"__main__\":\r\n    test_direct_message()\r\n```\r\n\r\n**Expected behavior**\r\n\r\nI expect a chat response\r\n\r\n**Screenshots**\r\n\r\n![Screenshot 2025-01-05 054035](https://github.com/user-attachments/assets/a7f324e6-3365-4622-a53e-e744f93e94af)\r\n\r\n\r\n**Additional context**\r\n\r\nI am attempting to implement Eliza in my Orifice ai product to claim the bounty.\r\n", "CLOSED", 0, "Bryan-Orifice", "2025-01-05T13:48:03Z", "2025-01-15T18:12:35Z", "2025-01-06T04:31:07Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6k9lh_", 1758, "Very slow pnpm start time", "**Describe the bug**\r\n\r\nRunning **pnpm start** take like 10 min on my computer. \r\nI'm a bit new to pnpm so most likely something on my end, as the Shaw dev videos it seemed to be rather fast.\r\nRunning Windows 11 with WSL, SSD drive.\r\n\r\n**To Reproduce**\r\npnpm start --characters=\"../characters/tate.character.json\"\r\n(or just pnpm start. previously done pnpm i && pnpm build, also very slow)\r\n\r\n**Expected behavior**\r\nWould assume start took a second or two.\r\n**Screenshots**\r\n\r\n pnpm start --characters=\"../characters/tate.character.json\"\r\n\u2009WARN\u2009 Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v23.5.0\",\"pnpm\":\"9.15.1\"})\r\n\r\n> eliza@ start /mnt/c/Users/Q0V/eliza\r\n> pnpm --filter \"@elizaos/agent\" start --isRoot \"--characters=../characters/tate.character.json\"\r\n\r\n.                                        | \u2009WARN\u2009 Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v23.5.0\",\"pnpm\":\"9.14.4\"})\r\ndocs                                     | \u2009WARN\u2009 Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v23.5.0\",\"pnpm\":\"9.14.4\"})\r\n\r\n> @elizaos/agent@0.1.7-alpha.2 start /mnt/c/Users/Q0V/eliza/agent\r\n> node --loader ts-node/esm src/index.ts \"--isRoot\" \"--characters=../characters/tate.character.json\"\r\n\r\n(node:9467) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\r\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n(node:9467) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\r\n(Use `node --trace-deprecation ...` to show where the warning was created)\r\n[ElizaLogger] Initializing with:\r\n            isNode: true\r\n            verbose: false\r\n            VERBOSE env: undefined\r\n            NODE_ENV: undefined\r\n\r\n \u2139 INFORMATIONS\r\n   Loading embedding settings:\r\n   {\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING\":\"\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"}\r\n\r\n \u2139 INFORMATIONS\r\n   Loading character settings:\r\n   {\"ARGV\":[\"/home/herman/.nvm/versions/node/v23.5.0/bin/node\",\"/mnt/c/Users/Q0V/eliza/agent/src/index.ts\",\"--isRoot\",\"--characters=../characters/tate.character.json\"],\"CWD\":\"/mnt/c/Users/Q0V/eliza/agent\"}\r\n\r\nLoaded .env file from: /mnt/c/Users/Q0V/eliza/.env\r\n \u2139 INFORMATIONS\r\n   Parsed settings:\r\n   {\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OPENAI_EMBEDDING_TYPE\":\"string\",\"USE_OLLAMA_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING_TYPE\":\"string\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"}\r\n\r\nbigint: Failed to load bindings, pure JS will be used (try npm run rebuild?)\r\nusing deprecated parameters for the initialization function; pass a single object instead\r\n**Additional context**\r\n\r\n\r\n\r\n..and waiting along", "CLOSED", 0, "herman-hellenes", "2025-01-03T13:48:49Z", "2025-01-17T13:27:21Z", "2025-01-06T08:06:24Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6klEP6", 1503, "Installation failed on node-llama-cpp postscript", "installation process stucks during quick start guide steps, installation node-llama-cpp failed and then it stuck on node_modules/@discordjs/opus: Running install script...\r\n\r\nUsed node 23.3.0\r\n\r\nThe commit version is 77b5b7d8 v0.1.7-alpha.1 \r\n\r\n\r\n \ue0a0 77b5b7d8 v0.1.7-alpha.1 \u25cf ? \ue0b0 pnpm install --no-frozen-lockfile                              \ue0b2 \u2714 \ue0b2 10161 \ue0b2 21:41:18\r\nScope: all 47 workspace projects\r\nclient                                   | \u2009WARN\u2009 Installing a dependency from a non-existent directory: /Users/r2d2/Documents/Code_Projects/eliza/client/@tanstack/router-plugin/vite\r\npackages/adapter-redis                   | \u2009WARN\u2009 deprecated @types/ioredis@5.0.0\r\npackages/client-discord                  | \u2009WARN\u2009 deprecated @discordjs/voice@0.17.0\r\npackages/client-slack                    | \u2009WARN\u2009 deprecated @slack/events-api@3.0.1\r\npackages/core                            | \u2009WARN\u2009 deprecated @types/pdfjs-dist@2.10.378\r\npackages/plugin-node                     | \u2009WARN\u2009 deprecated @cliqz/adblocker-playwright@1.34.0\r\npackages/plugin-story                    | \u2009WARN\u2009 deprecated @pinata/sdk@2.1.0\r\npackages/plugin-trustdb                  | \u2009WARN\u2009 deprecated @types/dompurify@3.2.0\r\n\u2009WARN\u2009 34 deprecated subdependencies found: @cliqz/adblocker-content@1.34.0, @cliqz/adblocker-extended-selectors@1.34.0, @cliqz/adblocker@1.34.0, @humanwhocodes/config-array@0.13.0, @humanwhocodes/object-schema@2.0.3, @motionone/vue@10.16.4, @simplewebauthn/typescript-types@7.4.0, are-we-there-yet@2.0.0, are-we-there-yet@3.0.1, base-x@2.0.6, bin-version-check@6.0.0, cids@0.7.5, cids@0.8.3, core-js@2.6.12, eslint@8.57.1, ethereumjs-abi@0.6.8, gauge@3.0.2, gauge@4.0.4, glob@7.2.3, glob@8.1.0, har-validator@5.1.5, inflight@1.0.6, mkdirp@0.3.0, multiaddr@7.5.0, multibase@0.6.1, multibase@0.7.0, multibase@1.0.1, multicodec@1.0.4, npmlog@5.0.1, npmlog@6.0.2, puppeteer@19.11.1, request@2.88.2, rimraf@3.0.2, uuid@3.4.0\r\n\u2009WARN\u2009 Issues with peer dependencies found\r\nclient\r\n\u251c\u2500\u252c @vitejs/plugin-react 4.3.3\r\n\u2502 \u2514\u2500\u2500 \u2715 unmet peer vite@\"^4.2.0 || ^5.0.0\": found 0.0.0\r\n\u251c\u2500\u252c vite-plugin-top-level-await 1.4.4\r\n\u2502 \u2514\u2500\u2500 \u2715 unmet peer vite@>=2.8: found 0.0.0\r\n\u2514\u2500\u252c vite-plugin-wasm 3.3.0\r\n  \u2514\u2500\u2500 \u2715 unmet peer vite@\"^2 || ^3 || ^4 || ^5\": found 0.0.0\r\n\r\npackages/client-lens\r\n\u2514\u2500\u252c @lens-protocol/client 2.2.0\r\n  \u2514\u2500\u252c @lens-protocol/gated-content 0.5.1\r\n    \u2514\u2500\u252c @lit-protocol/node-client 2.1.62\r\n      \u251c\u2500\u252c @walletconnect/ethereum-provider 2.17.3\r\n      \u2502 \u2514\u2500\u252c @walletconnect/modal 2.7.0\r\n      \u2502   \u251c\u2500\u252c @walletconnect/modal-core 2.7.0\r\n      \u2502   \u2502 \u2514\u2500\u252c valtio 1.11.2\r\n      \u2502   \u2502   \u251c\u2500\u2500 \u2715 missing peer react@>=16.8\r\n      \u2502   \u2502   \u2514\u2500\u252c use-sync-external-store 1.2.0\r\n      \u2502   \u2502     \u2514\u2500\u2500 \u2715 missing peer react@\"^16.8.0 || ^17.0.0 || ^18.0.0\"\r\n      \u2502   \u2514\u2500\u252c @walletconnect/modal-ui 2.7.0\r\n      \u2502     \u2514\u2500\u252c @walletconnect/modal-core 2.7.0\r\n      \u2502       \u2514\u2500\u2500 \u2715 missing peer react@>=16.8\r\n      \u2514\u2500\u252c @lit-protocol/auth-browser 2.1.62\r\n        \u2514\u2500\u252c @walletconnect/ethereum-provider 2.17.3\r\n          \u2514\u2500\u2500 \u2715 missing peer react@>=16.8\r\nPeer dependencies that should be installed:\r\n  react@\">=16.8.0 <17.0.0 || >=17.0.0 <18.0.0 || >=18.0.0 <19.0.0\"\r\n\r\npackages/core\r\n\u2514\u2500\u252c @langchain/core 0.3.26\r\n  \u2514\u2500\u252c zod-to-json-schema 3.24.1\r\n    \u2514\u2500\u2500 \u2715 unmet peer zod@^3.24.1: found 3.23.8\r\n\r\npackages/plugin-0g\r\n\u2514\u2500\u252c @0glabs/0g-ts-sdk 0.2.1\r\n  \u2514\u2500\u2500 \u2715 unmet peer ethers@6.13.1: found 6.13.4\r\n\r\npackages/plugin-goat\r\n\u251c\u2500\u252c @goat-sdk/wallet-viem 0.1.3\r\n\u2502 \u2514\u2500\u2500 \u2715 unmet peer @goat-sdk/core@0.3.4: found 0.3.8\r\n\u2514\u2500\u252c @goat-sdk/plugin-coingecko 0.1.4\r\n  \u251c\u2500\u2500 \u2715 unmet peer @goat-sdk/core@0.3.14: found 0.3.8\r\n  \u2514\u2500\u2500 \u2715 unmet peer viem@2.21.49: found 2.21.53\r\n\r\nPackages: +4705\r\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\r\nProgress: resolved 4088, reused 3922, downloaded 0, added 4705, done\r\nnode_modules/@swc/core: Running postinstall script...\r\nnode_modules/canvas: Running install script...\r\nnode_modules/node-llama-cpp: Running postinstall script, failed in 1.6s\r\nnode_modules/node-llama-cpp postinstall$ node ./dist/cli/cli.js postinstall\r\n**_\u2514\u2500 Failed in 1.6s at /Users/r2d2/Documents/Code_Projects/eliza/node_modules/node-llama-cpp_**\r\n**_node_modules/@discordjs/opus: Running install script..._**\r\n", "CLOSED", 0, "salacoste", "2024-12-27T18:49:07Z", "2025-01-18T11:31:35Z", "2025-01-12T11:01:31Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6jFSLA", 1012, "Get rid of the postinstall script for node-plugin", "**Describe the bug**\r\n\r\nIt causes something like this:\r\n```\r\n.../node_modules/@ai16z/plugin-node postinstall$ npx playwright install-deps && npx playwright install\r\n                                       \u2502 Installing dependencies...\r\n                                                                   \u2502 Switching to root user to install dependencies...\r\n                                                                                                                      \u2502 Reading package lists...\r\n      \u2502 E: Could not get lock /var/lib/apt/lists/lock. It is held by process 27614 (apt-get)\r\n                                                                                            \u2502 E: Unable to lock directory /var/lib/apt/lists/\r\n   \u2502 Failed to install browser dependencies\r\n                                           \u2502 Error: Installation process exited with code: 100\r\n                                                                                              \u2514\u2500 Failed in 1s at /home/zatara7/eliza-starter/node_modules/.pnpm/@ai16z+plugin-node@0.1.4-alpha.3_@google-cloud+vertexai@1.9.2_@langchain+core@0.3.23_onnxrunt_josi75rgzinst3siow2n6dgub4/node_modules/@ai16z/plugin-node\r\n                                    \u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n```\r\n\r\n**To Reproduce**\r\n\r\nInstall on WSL Ubuntu\r\n\r\n**Expected behavior**\r\n\r\nHave the postinstall script not run in this case?\r\nAnd not say that there's a lock problem.. it really threw me off\r\n\r\n**Screenshots**\r\n\r\nabove cli output will suffice\r\n\r\n**Additional context**\r\n\r\nJust get rid of the post install script by going to it in the node_modules and replacing it or getting rid of it completely.\r\n\r\nYou can just install that playwright stuff yourself or in a different way if one of the developers can fix it\r\n", "CLOSED", 0, "hshar7", "2024-12-12T14:28:29Z", "2025-01-17T03:09:04Z", "2025-01-12T10:52:35Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6ibmGs", 917, "Cannot run `pnpm build` after importing `imageGenerationPlugin` to use in a character ", "**Describe the bug**\r\n\r\nBuild failure in `@ai16z/eliza package` due to unresolved dependency `@ai16z/plugin-image-generation`. The build process fails when attempting to resolve the image generation plugin import in `defaultCharacter.ts`.\r\n\r\n**To Reproduce**\r\n\r\n- 1. Clone the eliza repository (v0.1.5-alpha.5)\r\n- 2. Import and add the `imageGenerationPlugin` to Eliza in `defaultCharacter.ts`\r\n```ts\r\nimport { Character, ModelProviderName, Clients } from \"./types.ts\";\r\nimport { imageGenerationPlugin } from \"@ai16z/plugin-image-generation\";\r\n\r\nexport const defaultCharacter: Character = {\r\n    name: \"Eliza\",\r\n    username: \"eliza\",\r\n    plugins: [imageGenerationPlugin],\r\n```\r\n- 3. Run `pnpm build` in the project root\r\n- 4. Build fails with error message indicating it cannot resolve \"@ai16z/plugin-image-generation\" in defaultCharacter.ts\r\n\r\n**Expected behavior**\r\n\r\nThe build process should successfully compile all packages including @ai16z/eliza. The @ai16z/plugin-image-generation package should be properly resolved as it's listed in the workspace packages.\r\n\r\n**Screenshots**\r\n\r\nN/A\r\n\r\n**Additional context**\r\n\r\n- Project version: v0.1.5-alpha.\r\n- Build tool: turbo 2.3.3\r\n- Package manager: pnpm\r\n- The package @ai16z/plugin-image-generation is listed in the workspace scope but fails to resolve during build\r\n- Error occurs in the ESM build step using tsup\r\n- File causing error: packages/core/src/defaultCharacter.ts\r\n\r\n\r\n**Exact error:**\r\n```sh\r\nUSER@MACHINE MINGW64 /c/ML/agents/testeliza/eliza-v0.1.5-alpha.5 ((fb24df4f...))\r\n$ pnpm build\r\n\r\n> eliza@ build C:\\ML\\agents\\testeliza\\eliza-v0.1.5-alpha.5\r\n> turbo run build --filter=!eliza-docs\r\n\r\nturbo 2.3.3\r\n\r\n\u2022 Packages in scope: @ai16z/adapter-postgres, @ai16z/adapter-sqlite, @ai16z/adapter-sqljs, @ai16z/adapternt-discord, @ai16z/client-farcaster, @ai16z/client-github, @ai16z/client-telegram, @ai16z/client-twitter, @ai16z/plugin-buttplug, @ai16z/plugin-coinbase, @ai16z/plugin-conflux, @ai16z/plugin-evm, @ai16z/plugin-ai16z/plugin-node, @ai16z/plugin-solana, @ai16z/plugin-starknet, @ai16z/plugin-tee, @ai16z/plugin-trustdbsapp, create-eliza-app, eliza-client\r\n\u2022 Running build in 34 packages\r\n\u2022 Remote caching disabled\r\n@ai16z/eliza:build: cache miss, executing 7efb30d0891da17b\r\ncreate-eliza-app:build: cache hit, replaying logs 86473ad74fdfa109\r\ncreate-eliza-app:build: \r\ncreate-eliza-app:build: > create-eliza-app@0.1.5-alpha.5 build C:\\ML\\agents\\testeliza\\eliza-v0.1.5-alpha.\r\ncreate-eliza-app:build: > unbuild\r\ncreate-eliza-app:build: \r\ncreate-eliza-app:build: \u2139 Automatically detected entries: src/index [esm] [cjs]\r\ncreate-eliza-app:build: \u2139 Building create-eliza-app\r\ncreate-eliza-app:build: \u2139 Cleaning dist directory: ./dist\r\ncreate-eliza-app:build: \u2714 Build succeeded for create-eliza-app\r\ncreate-eliza-app:build:   dist/index.cjs (total size: 1.65 kB, chunk size: 1.65 kB)\r\ncreate-eliza-app:build: \r\ncreate-eliza-app:build:   dist/index.mjs (total size: 1.64 kB, chunk size: 1.64 kB)\r\ncreate-eliza-app:build: \r\ncreate-eliza-app:build: \u03a3 Total dist size (byte size): 3.29 kB\r\ncreate-eliza-app:build: \r\n@ai16z/eliza:build: \r\n@ai16z/eliza:build: > @ai16z/eliza@0.1.5-alpha.5 build C:\\ML\\agents\\testeliza\\eliza-v0.1.5-alpha.5\\packag\r\n@ai16z/eliza:build: > tsup --format esm --dts\r\n@ai16z/eliza:build: \r\n@ai16z/eliza:build: CLI Building entry: src/index.ts\r\n@ai16z/eliza:build: CLI Using tsconfig: tsconfig.json\r\n@ai16z/eliza:build: CLI tsup v8.3.5\r\n@ai16z/eliza:build: CLI Using tsup config: C:\\ML\\agents\\testeliza\\eliza-v0.1.5-alpha.5\\packages\\core\\tsup\r\n@ai16z/eliza:build: CLI Target: esnext\r\n@ai16z/eliza:build: CLI Cleaning output folder\r\n@ai16z/eliza:build: ESM Build start\r\n@ai16z/eliza:build: X [ERROR] Could not resolve \"@ai16z/plugin-image-generation\"\r\n@ai16z/eliza:build: \r\n@ai16z/eliza:build:     src/defaultCharacter.ts:2:38:\r\n@ai16z/eliza:build:       2 \u2502 ...rt { imageGenerationPlugin } from \"@ai16z/plugin-image-generation\";\r\n@ai16z/eliza:build:         \u2575                                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n@ai16z/eliza:build: \r\n@ai16z/eliza:build:   You can mark the path \"@ai16z/plugin-image-generation\" as external to exclude it frhe bundle.\r\n@ai16z/eliza:build: \r\n@ai16z/eliza:build: ESM Build failed\r\n@ai16z/eliza:build: Error: Build failed with 1 error:\r\n@ai16z/eliza:build: src/defaultCharacter.ts:2:38: ERROR: Could not resolve \"@ai16z/plugin-image-generation\"\r\n@ai16z/eliza:build:     at failureErrorWithLog (C:\\ML\\agents\\testeliza\\eliza-v0.1.5-alpha.5\\node_modules\\\r\n@ai16z/eliza:build:     at C:\\ML\\agents\\testeliza\\eliza-v0.1.5-alpha.5\\node_modules\\esbuild\\lib\\main.js:9\r\n@ai16z/eliza:build:     at runOnEndCallbacks (C:\\ML\\agents\\testeliza\\eliza-v0.1.5-alpha.5\\node_modules\\es\r\n@ai16z/eliza:build:     at buildResponseToResult (C:\\ML\\agents\\testeliza\\eliza-v0.1.5-alpha.5\\node_module\r\n@ai16z/eliza:build:     at C:\\ML\\agents\\testeliza\\eliza-v0.1.5-alpha.5\\node_modules\\esbuild\\lib\\main.js:9\r\n@ai16z/eliza:build:     at responseCallbacks.<computed> (C:\\ML\\agents\\testeliza\\eliza-v0.1.5-alpha.5\\node\r\n@ai16z/eliza:build:     at handleIncomingPacket (C:\\ML\\agents\\testeliza\\eliza-v0.1.5-alpha.5\\node_modules\r\n@ai16z/eliza:build:     at Socket.readFromStdout (C:\\ML\\agents\\testeliza\\eliza-v0.1.5-alpha.5\\node_module\r\n@ai16z/eliza:build:     at Socket.emit (node:events:513:28)\r\n@ai16z/eliza:build:     at addChunk (node:internal/streams/readable:559:12)\r\n@ai16z/eliza:build: DTS Build start\r\n@ai16z/eliza:build: src/defaultCharacter.ts(2,39): error TS2307: Cannot find module '@ai16z/plugin-image-\r\n@ai16z/eliza:build: \r\n@ai16z/eliza:build: DTS Build error\r\nza\\eliza-v0.1.5-alpha.5\\packages\\core) C:\\ML\\agents\\testeliza\\eliza-v0.1.5-alpha.5\\node_modules\\.bin\\pnpm.CMD run build exited (1)\r\n\r\n Tasks:    1 successful, 2 total\r\nCached:    1 cached, 2 total\r\n  Time:    3.71s\r\nFailed:    @ai16z/eliza#build\r\n\r\n ERROR  run failed: command  exited (1)\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n```\r\n", "CLOSED", 0, "YoungPhlo", "2024-12-08T11:19:28Z", "2025-01-13T16:10:39Z", "2025-01-12T10:51:57Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6iaMRa", 905, "Client Twitter Login issue: Error: {\"errors\":[{\"code\":399,\"message\":\"Incorrect. Please try again.\"}]}", "**Describe the bug**\r\n\r\nWhen I try to test the Twitter client, I get this message in the loading twitter client error.\r\n\r\nError: {\"errors\":[{\"code\":399,\"message\":\"Incorrect. Please try again.\"}]}\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "MSghais", "2024-12-07T19:08:54Z", "2025-01-15T14:25:01Z", "2024-12-14T07:40:46Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6iYQBA", 882, "Ollama provider doesn't use correct endpoint", "**Describe the bug**\r\n\r\nThe Ollama model provider sends a post to `localhost:11434/api/chat` instead of the correct endpoint, which should be either `localhost:11434/api/v1/chat/completions` (OpenAI compatible) or `localhost:11434/api/generation` (Ollama native API).\r\n\r\n**To Reproduce**\r\n\r\nSet OLLAMA_MODEL to a local model in `.env` and `\"modelProvider\": \"ollama\"` in the character file.\r\n\r\n**Expected behavior**\r\n\r\nGet a response instead of AI_APICallError", "CLOSED", 0, "deepfates", "2024-12-07T02:15:32Z", "2025-01-13T01:47:41Z", "2025-01-12T10:50:57Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6hbbpo", 735, "EVM Plugin can't run any action", "**Describe the bug**\r\n\r\nThe EVM Plugin actions do not work, they probably never worked.\r\n\r\nThe [code assumes](https://github.com/ai16z/eliza/blob/main/packages/plugin-evm/src/actions/transfer.ts#L56-L65) that the options object passed to the handler of the action has all the parameters of the action parsed automagically. It's assuming a tool calling pattern like the one AI SDK offers.\r\n\r\n**To Reproduce**\r\n1. Add an `EVM_PUBLIC_KEY` and an `EVM_PRIVATE_KEY` to run the evmPlugin\r\n2. Hardcode the balance returned by the [wallet provider](https://github.com/ai16z/eliza/blob/main/packages/plugin-evm/src/providers/wallet.ts#L187) to 5 ETH.\r\n3. Build the `plugin-evm` with `pnpm build`\r\n3. Run the agent and use the example prompt from the plugin: `Transfer 1 ETH to 0x742d35Cc6634C0532925a3b844Bc454e4438f44e`\r\n4. The agent should fail with error ` [\"\u26d4 TypeError: Cannot read properties of undefined (reading 'chainId')\"] ` \r\n\r\nYou can also add a `console.log` when transfer is called with the params and you will see the content is empty.\r\n\r\n**Expected behavior**\r\nAgent should fail because transaction failed.\r\n\r\n**Screenshots**\r\n<img width=\"727\" alt=\"Screenshot 2024-12-01 at 02 18 52\" src=\"https://github.com/user-attachments/assets/e107a4cb-144b-406d-9e8c-d4e8f8a5def7\">", "CLOSED", 0, "0xaguspunk", "2024-12-01T01:34:20Z", "2025-01-13T17:46:03Z", "2024-12-13T02:37:16Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6g3mgS", 630, "Make Eliza post autonomously. ", "I want a Agent to message autonomously, based on its character details. Is there a way to do that?", "CLOSED", 0, "randomdevver", "2024-11-27T15:31:25Z", "2025-01-16T11:55:36Z", "2025-01-11T21:34:29Z", "elizaos/eliza", "2025-04-14 21:51:11"]
["I_kwDOMT5cIs6naxFg", 2742, "Restrict Discord bot to respond only in specific channels", "**Issue Title**: Restrict Discord bot to respond only in specific channels\n\n\n**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\n\nThe bot currently responds in all Discord channels, which may lead to unnecessary interactions and increased operational costs. Restricting the bot to respond only in specific channels would help optimize its behavior and reduce unwanted responses.\n\n\n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\n\nIntroduce an `allowedChannelIds` configuration to restrict the bot's responses to specific channels. This configuration will be added to the `character.json` file for better structure and manageability, instead of using environment variables.\n\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\nUsing environment variables for managing allowed channels, but this approach is less structured compared to using `character.json`.\n\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n\nThis feature will enable better control over where the bot responds in Discord servers, reducing costs and improving relevance in multi-channel setups.", "CLOSED", 0, "lincheoll", "2025-01-24T08:07:55Z", "2025-01-25T00:33:09Z", "2025-01-25T00:33:09Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6naClM", 2739, "read ECONNRESET issue facing", "![Image](https://github.com/user-attachments/assets/b6efcc3e-c1a7-49e6-aafd-de47a82ad380)\nNot able to login to twitter showing this error not sure how to solve this. can anyone help me to solve this issue", "CLOSED", 0, "code-with-shahzad", "2025-01-24T06:34:45Z", "2025-01-25T00:33:38Z", "2025-01-25T00:33:37Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6naBVu", 2738, "read ECONNRESET issue", "![Image](https://github.com/user-attachments/assets/6824b8b7-0c93-46bd-81f3-d20f233b909a)\nI am trying to use eliza  for twitter agent but i am not getting logged in. what is the issue ??\n", "CLOSED", 0, "code-with-shahzad", "2025-01-24T06:30:58Z", "2025-01-24T06:36:05Z", "2025-01-24T06:36:04Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6nW_UN", 2718, "client-eliza-home package: test config and tests", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\nThe client-eliza-home package currently lacks comprehensive test coverage, particularly for critical components like the SmartThingsApi and CommandParser. This makes it difficult to ensure reliability and catch potential issues when making changes to the codebase.\n\n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\n\nAdd test coverage for the client-eliza-home package using vitest, focusing on:\n1. CommandParser class:\n    * Test parsing of various home automation commands (turn on/off, brightness, temperature, color)\n    * Test device command mapping functionality\n    * Test error handling for unknown or invalid commands\n2. SmartThingsApi class:\n    * Test token validation and initialization\n    * Test device operations (list, get, execute commands)\n    * Test scene operations (list, execute)\n    * Test room operations (list, get)\n    * Test error handling for API responses\nThe tests should be implemented without modifying existing code, ensuring backward compatibility.\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-23T20:16:33Z", "2025-01-24T21:19:20Z", "2025-01-24T21:19:20Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6nPYGq", 2689, "bug: ragKnowledge doesn't properly check for scoped Ids for existing knowledge", "We are incorrectly re-indexing knowledge on startup because we are using one id format for storage (with shared- or private- prefix) and another id format for checking (no scope prefix).", "CLOSED", 0, "augchan42", "2025-01-23T03:39:27Z", "2025-01-23T12:11:04Z", "2025-01-23T12:11:04Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6nOrDI", 2684, "Debug logging no longer works when using pnpm start:debug target", "Seems [feat: add email-plugin (](https://github.com/elizaOS/eliza/commit/27acd7bc6034371f9ead7b221c5f5f05b699eb37)https://github.com/elizaOS/eliza/pull/2645[)](https://github.com/elizaOS/eliza/commit/27acd7bc6034371f9ead7b221c5f5f05b699eb37)\n  clobbered my change to package.json\n\n", "CLOSED", 0, "augchan42", "2025-01-23T00:45:23Z", "2025-01-23T02:46:51Z", "2025-01-23T02:46:51Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6nOFSj", 2680, "Potential for Unethical Use on Social Media Platforms", "Hi team!\n\nthe ToS seems vague on use and I\u2019m afraid this is being used for the wrong reasons.\n\nI\u2019m noticing a number of users mentioning use on social media platforms like X at concerning volumes.  Is there a way to determine the distribution and volume of use via specific social media platforms?\n\nI would love to use your tool, but I\u2019d like to understand your control of this system versus \u201cit just works\u201d. ", "CLOSED", 0, "Swernado", "2025-01-22T22:37:19Z", "2025-01-22T23:47:07Z", "2025-01-22T23:47:07Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6nLfgH", 2667, "Debug logging no longer works when using pnpm start:debug target", "With develop v0.1.8+build.1-683-g4240c65b2\nelizalogger debug statements are no longer showing.\nTaking a look now", "CLOSED", 0, "augchan42", "2025-01-22T16:17:55Z", "2025-01-22T22:41:27Z", "2025-01-22T22:41:26Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6nKZYn", 2663, "Integration Tests are failing in CI", "**Describe the bug**\nI can successfully run integration tests locally, but they are failing in CI with the following error:\n\n```\nError: error occurred in dts build\n    at Worker.<anonymous> (/home/runner/work/eliza/eliza/node_modules/tsup/dist/index.js:1541:26)\n    at Worker.emit (node:events:513:28)\n    at MessagePort.<anonymous> (node:internal/worker:267:53)\n    at [nodejs.internal.kHybridDispatch] (node:internal/event_target:827:20)\n    at MessagePort.<anonymous> (node:internal/per_context/messageport:23:28)\nDTS Build error\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\n```\n\nThis is failing on the build step and does not actually get to running the tests.\nYou can check any current PR as an example.\n\n<!-- A clear and concise description of what the bug is. -->\n\n**To Reproduce**\n\nSubmit a new PR.\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\nIntegration tests should pass\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "normand1", "2025-01-22T14:19:24Z", "2025-01-23T15:05:51Z", "2025-01-23T00:04:54Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6nKFL4", 2658, "Add support for DeepSeek API", "**Well as you know that deepseek currently is performing pretty well enough and I guess many co developers would love to see DeepSeek API support in this framework as its free of cost and it would allow more developers to explore this framework by creating ai agents.**\n", "CLOSED", 0, "TheRealShreyash", "2025-01-22T13:45:31Z", "2025-01-26T15:40:02Z", "2025-01-26T15:40:02Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6nKC5M", 2657, "LLM Often Overlooks GitBook Provider Output Due to Lack of Context", "**Is your feature request related to a problem? Please describe.**\n\nIn the plugin-gitbook, the returned information is often overlooked by the LLM. This happens because the return lacks sufficient context, causing the LLM to downplay the significance of the GitBook provider\u2019s output.", "CLOSED", 0, "Evan-zkLinkLabs", "2025-01-22T13:41:31Z", "2025-01-23T13:46:22Z", "2025-01-23T13:46:22Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6nIK59", 2649, "Error Occurs When Sending a Chat After Including openaiPlugin", "**Describe the bug**\n\nWhen attempting to send a chat after including the `openaiPlugin`, an error occurs with the message:  \n```\naction.validate is not a function\n```\n\n**To Reproduce**\n\nSteps to reproduce the behavior:  \n1. Include the `openaiPlugin` in the project.  \n2. Initialize the plugin and attempt to send a chat.  \n3. Observe the error in the console or logs.\n\n**Expected behavior**\n\nThe chat should be sent successfully without throwing any errors.\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\nENABLE_OPEN_AI_COMMUNITY_PLUGIN=true\n", "CLOSED", 0, "lincheoll", "2025-01-22T10:01:50Z", "2025-01-22T10:24:20Z", "2025-01-22T10:24:20Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6nFk-s", 2636, "Sqlite3 error on Macbook with m3 chip", "Error on `pnpm start` after installing per docs\n\n<!-- A clear and concise description of what the bug is. -->\n\nI think there's an issue with `better-sqlite3` on the m chip?\n\n<!-- Steps to reproduce the behavior. -->\n\n```\ngit clone https://github.com/elizaos/eliza-starter.git\ncd eliza-starter\ncp .env.example .env\npnpm i && pnpm build && pnpm start\n```\n\nERROR output:\n```\n \u26d4 ERRORS\n   Error starting agents:\n   {\"tries\":[\"/Users/weylandjoyner/projects/eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/build/better_sqlite3.node\",\"/Users/weylandjoyner/projects/eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/build/Debug/better_sqlite3.node\",\"/Users/weylandjoyner/projects/eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/build/Release/better_sqlite3.node\",\"/Users/weylandjoyner/projects/eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/out/Debug/better_sqlite3.node\",\"/Users/weylandjoyner/projects/eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/Debug/better_sqlite3.node\",\"/Users/weylandjoyner/projects/eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/out/Release/better_sqlite3.node\",\"/Users/weylandjoyner/projects/eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/Release/better_sqlite3.node\",\"/Users/weylandjoyner/projects/eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/build/default/better_sqlite3.node\",\"/Users/weylandjoyner/projects/eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/compiled/23.4.0/darwin/arm64/better_sqlite3.node\",\"/Users/weylandjoyner/projects/eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/addon-build/release/install-root/better_sqlite3.node\",\"/Users/weylandjoyner/projects/eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/addon-build/debug/install-root/better_sqlite3.node\",\"/Users/weylandjoyner/projects/eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/addon-build/default/install-root/better_sqlite3.node\",\"/Users/weylandjoyner/projects/eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/lib/binding/node-v131-darwin-arm64/better_sqlite3.node\"]}\n```\n\nFIX from Claude:\n```\npnpm add better-sqlite3@latest\ncd node_modules/better-sqlite3\npnpm install\npnpm run build-release\ncd ../..\n```\n", "CLOSED", 0, "weyj4", "2025-01-22T03:06:27Z", "2025-01-22T03:52:01Z", "2025-01-22T03:52:00Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6nDaTj", 2620, "plugin abstract: test config and test configuration", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\n\nThe plugin-abstract package currently lacks test coverage for critical token operations. Without proper test coverage for getBalanceAction and transferAction, we risk:\n\nUndetected bugs in balance checking functionality\nPotential issues with token transfers\nNo validation of AGW integration\nMissing edge case handling\nUnreliable error handling for failed operations\n\nThis makes the codebase less maintainable and increases the risk of introducing bugs when making changes.\n\n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\n\nWe need comprehensive test coverage for all three actions that includes:\n\nFor deployTokenAction:\n- Tests for token deployment parameters (name, symbol, supply)\n- Validation of abstract configuration\n- Testing both AGW and non-AGW deployments\n- Error handling for invalid inputs\n- Testing state management\n- Coverage for deployment transaction failures\nFor getBalanceAction:\n- Tests for checking ETH balances\n- Tests for checking ERC20 token balances\n- Validation of token symbols and addresses\n- Error handling for invalid inputs\n- Testing state management\nFor transferAction:\n- Tests for ETH transfers\n- Tests for ERC20 token transfers\n- Testing AGW integration\n- Validation of inputs\n- Error case coverage\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-21T19:55:34Z", "2025-01-25T15:12:36Z", "2025-01-25T15:12:36Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6nBqWQ", 2608, "Build broken on windows WSL - client/version.sh error", "**Describe the bug**\n\nAs of v0.1.8, `pnpm build` is broken on windows WSL. I get the following error:\n\n```\nclient:build: \nclient:build: > client@ extract-version C:\\Workspaces\\eliza-storage\\client\nclient:build: > ./version.sh\nclient:build:\nclient:build: '.' is not recognized as an internal or external command,\nclient:build: operable program or batch file.\nclient:build: \u2009ELIFECYCLE\u2009 Command failed with exit code 1.\nclient#build: command (C:\\Workspaces\\eliza-storage\\client) C:\\Workspaces\\eliza-storage\\node_modules\\.bin\\pnpm.CMD run build exited (1)\n\n Tasks:    2 successful, 81 total\nCached:    0 cached, 81 total\n  Time:    32.135s\nFailed:    client#build\n\n ERROR  run failed: command  exited (1)\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\n```\n\n**To Reproduce**\n\nRun `pnpm build` on a Windows WSL environment.\n\nWSL version: 2.3.26.0\nPNPM version: 9.15.4\nNode version: v23.5.0\n\n**Expected behavior**\n\nExpect build to complete without error\n\n", "CLOSED", 0, "sicco-moonbeam", "2025-01-21T15:57:41Z", "2025-01-24T23:24:41Z", "2025-01-21T15:58:54Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6m9XZr", 2593, "Error Cloning", "**Describe the bug**\n\nWhen attempting to clone Eliza with WSL as I've done multiple times in the past, I receive a RPC / TLS error.\n\nCloning into 'traderman'...\nremote: Enumerating objects: 79017, done.\nremote: Counting objects: 100% (353/353), done.\nremote: Compressing objects: 100% (220/220), done.\nerror: RPC failed; curl 56 GnuTLS recv error (-110): The TLS connection was non-properly terminated.\nerror: 7629 bytes of body are still expected\nfetch-pack: unexpected disconnect while reading sideband packet\nfatal: early EOF\nfatal: fetch-pack: invalid index-pack output\n\n**To Reproduce**\n\nUsing WSL, I mount my C drive using\n\ncd /mnt/c\n\nI then type \n\ngit clone https://github.com/elizaos/eliza.git traderman\n\n**Expected behavior**\n\nI expected the repository to be cloned to the traderman directory for further development\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/ce5d0d27-a233-4d53-9b4c-ff03ff97cc64)\n\n**Additional context**\n\nthe clone starts, the directory is created initially, then as the clone fails, the directory and all files within it are removed\n\nI'm leaning more toward a network issue - and I've already restarted my hardware multiple times\n", "CLOSED", 0, "S4L7", "2025-01-21T08:47:52Z", "2025-01-21T09:29:10Z", "2025-01-21T09:29:08Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6m9WZV", 2592, "pnpm start -- -- --character=characters/trump.character.json doesn't switch characters anymore ?", "pnpm start -- -- --character=characters/trump.character.json, no matter the character name, client only shows eliza, is that a bug or did something change to how characters are switched ?", "CLOSED", 0, "caterpillarC15", "2025-01-21T08:45:55Z", "2025-01-25T14:13:08Z", "2025-01-25T00:51:55Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6m8-un", 2588, "Client App not load due a error", "**Describe the bug**\n\nWhen cloning a new, fresh version of Eliza and setting the agent, the agent console runs correctly, but the client app throws an error.\n\nUsing osx 14.6.1 M2\n\n**To Reproduce**\n\n> git clone https://github.com/elizaos/eliza.git Eliza\n> cd Eliza\n> git checkout $(git describe --tags --abbrev=0)\n> pnpm install --no-frozen-lockfile\n> pnpm build\n\n* Create the .env file\n\n> pnpm start --character=\"characters/c3po.character.json\"\n\nIn other terminal run:\n\n> pnpm start:client\n\nOpen the browser to http://localhost:5173/\n\nThere will be a empty screen with an error in the Console (Image Attached)\n\n**Expected behavior**\n\nA working Client app to interact with the Agent.\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/741f3742-d0c0-48cf-8615-2d8e72fc7ea5)\n\n![Image](https://github.com/user-attachments/assets/2908a579-dde9-4753-83df-4d0ede34df91)\n\n![Image](https://github.com/user-attachments/assets/9f97a116-3eb2-431b-b9b1-efa75f310147)\n\n![Image](https://github.com/user-attachments/assets/e7b5eb06-9066-46ae-9b4a-7717902262f8)\n\n\n", "CLOSED", 0, "JulioMCruz", "2025-01-21T08:13:11Z", "2025-01-21T20:10:01Z", "2025-01-21T20:10:01Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6m6j8O", 2577, "Vector Dimension Mismatch Error When Switching to gpt-4o-mini in SQLite Database", "**Describe the bug**\n\nUsing an SQLite database, after changing models to `gpt-4o-mini`, I encountered the following vector error:\n\n<!-- A clear and concise description of what the bug is. -->\n\nI started using the default OpenAI models, then switched the `MEDIUM` and `LARGE` models to `gpt-4o-mini` and encountered this error.\n\n---\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n1. Use an SQLite database as the storage backend.\n2. Start with the default OpenAI models.\n3. Change the `MEDIUM` and `LARGE` models to `gpt-4o-mini`.\n4. Attempt to start agents.\n\n---\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\nThe system should seamlessly support model changes without vector dimension mismatches or database errors.\n\n---\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n`[\"\u26d4 SqliteError: Vector dimension mismatch. First vector has 384 dimensions, while the second has 1536 dimensions.\"]`\n\n\u26d4 ERRORS  \n`Error starting agents:`  \n`{\"code\":\"SQLITE_ERROR\"}`\n\n---\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n\nIt seems the SQLite database stores vectors with a specific dimension (384 in this case) that is incompatible with the `gpt-4o-mini` model (1536 dimensions). This may require re-indexing or updating the schema for the new vector size.", "CLOSED", 0, "rferrari", "2025-01-20T22:42:35Z", "2025-01-22T23:42:33Z", "2025-01-22T23:42:32Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6m6acT", 2572, "test config and tests for plugin-agentkit", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\nThe problem is a lack of test coverage for the plugin-agentkit package, particularly around its wallet management functionality. Without proper tests, there was no automated way to verify that the wallet creation, loading, and error handling were working correctly. This could lead to potential issues going undetected, especially when making changes to the codebase.\n\n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\nImplement a comprehensive test suite for plugin-agentkit that:\n\nTests wallet management functionality:\n- Creating new wallets\n- Loading existing wallets\n- Handling file system operations\nVerifies configuration options:\n- Network selection via environment variables\n- Wallet data persistence\n- Tests error handling:\n- File system errors\n- Configuration failures\n- Wallet operation errors\nThe solution should follow the project's conventions by:\n\n- Placing tests in __tests__ directory\n- Using vitest as the testing framework\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-20T22:01:43Z", "2025-01-21T10:42:10Z", "2025-01-21T10:42:10Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6m6IYI", 2569, "Incorrect OpenAI Error on clean start where i don't use openai key anywhere", "\nDescribe the bug\nWhen attempting to start ElizaOS with a custom character configuration using GROQ API, the application fails due to missing API key authentication of **openai**. The error indicates that no API key was provided in the request headers.\nTo Reproduce\n\nInstall dependencies:\n```bash\npnpm install --no-frozen-lockfile\n```\n\nBuild the project:\n```bash\npnpm build\n```\n\nAttempt to start with standart character with groq model:\n```bash\npnpm start --character=\"characters/trump.character.json\"\n```\n\n\nExpected behavior\nThe application should successfully start with the specified character configuration file, making authenticated requests to the GROQ API.\nError Output\n```json\n{\n    \"error\": {\n        \"message\": \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\",\n        \"type\": \"invalid_request_error\",\n        \"param\": null,\n        \"code\": null\n    }\n}\n```\n\nso i can't run any character cause openai key needed somewhere", "CLOSED", 0, "veebull", "2025-01-20T20:54:30Z", "2025-01-21T01:03:12Z", "2025-01-21T01:03:10Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6m6BLz", 2566, "client-farcaster package test config and tests", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\n\nThe client-farcaster package needed a comprehensive testing infrastructure similar to client-lens. The main challenges were:\n\nNo existing test setup or configuration\nNeed to test Farcaster-specific functionality like casts, interactions, and profile management\nEnsuring proper mocking of the Neynar API client to avoid real API calls during tests\n\n\n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\n\nTest Configuration:\n- Added Vitest as the testing framework\n- Created vitest.config.ts for test configuration\n- Added test scripts to package.json (test, test:watch, test:coverage)\nTest Structure:\n- Created __tests__ directory with three main test files:\n- client.test.ts: Testing core client functionality\n- interactions.test.ts: Testing Farcaster interactions (recasts, replies, likes)\n- cast.test.ts: Testing cast creation and validation\nTest Utilities:\n- Created test-utils.ts with shared testing functions:\n- createTestInteraction: Generates test interactions based on cast engagement\n- handleTestInteraction: Handles different interaction types\n- createTestCast: Creates and validates test casts\nMocking:\n- Implemented comprehensive mocks for the Neynar API client\n- Mocked profile fetching, cast creation, and interaction handling\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-20T20:29:56Z", "2025-01-21T10:42:16Z", "2025-01-21T10:42:16Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6m4oh0", 2559, "Incorrect Boolean Parsing for ENABLE_OPEN_AI_COMMUNITY_PLUGIN Setting", "Describe the bug\nThere was an issue with loading the ENABLE_OPEN_AI_COMMUNITY_PLUGIN setting. Regardless of whether true or false was set, the value was always interpreted as a string, causing the setting to always be enabled.\n\nTo Reproduce\nSteps to reproduce the behavior:\n\nSet ENABLE_OPEN_AI_COMMUNITY_PLUGIN to true or false in the configuration.\nRun the application.\nObserve that the feature is always enabled, regardless of the intended value.\nExpected behavior\nThe feature should only be enabled when ENABLE_OPEN_AI_COMMUNITY_PLUGIN is set to true. When set to false, the feature should remain disabled.\n\nScreenshots\n\nAdditional context\nI will fix it\n\n\n", "CLOSED", 0, "lincheoll", "2025-01-20T16:46:19Z", "2025-01-22T01:04:16Z", "2025-01-22T01:04:15Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6mxrMH", 2540, "chat client unstable connection, :ERR_BLOCKED_BY_CLIENT, 3000 port woks fine, agent list not displaying", "OS: ubuntu 22.4\nnode version: 23.3.0\n\nexecuted command:\n\n![Image](https://github.com/user-attachments/assets/c9374a23-1e96-47eb-8ce3-a05d084a4cfb)\n\n\n![Image](https://github.com/user-attachments/assets/0ba42e3b-a353-462e-a172-b7b321fa74cf)\n\n", "CLOSED", 0, "holiccoder", "2025-01-20T02:41:19Z", "2025-01-22T01:06:38Z", "2025-01-22T01:06:38Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6mw723", 2533, "test configuration and test suite for client-lens", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\nThe client-lens package needed a comprehensive testing solution that wouldn't interfere with the existing production code. The main challenges are:\n\nTesting interactions with the Lens Protocol without modifying the core functionality\nEnsuring test coverage for key features like authentication, profile management, and post creation\nManaging complex mock data structures for the Lens Protocol client\n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\nImplement a test suite with the following key features:\n\nA separate test-utils.ts file containing test-specific implementations\nComprehensive mocking of the Lens Protocol client\nThree main test files:\nclient.test.ts: Testing core client functionality \ninteractions.test.ts: Testing interaction handling \npost.test.ts: Testing post creation and validation \n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-19T21:43:23Z", "2025-01-20T16:30:40Z", "2025-01-20T16:30:40Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6mrqaM", 2471, "MacOS - Eliza Client not able to connect \"Connecting\" -> \"Disconnected\"", "Unable to get Eliza to run on MacOS\n\nFollow the instructions in the Startup guide. \n\nRun pnpm start --character=\"characters/c3po.character.json\"\nGet a number of warnings, but doesn't look like anything failed and then it says: \n [\"\u2713 REST API bound to 0.0.0.0:3001. If running locally, access it at http://localhost:3001.\"] \nCheck http://localhost:3001 and it is running\n\nGot to a new terminal tab and run:\npnpm start:client\nIt runs and says:\n\n```\n\u2009WARN\u2009 Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v23.4.0\",\"pnpm\":\"9.15.3\"})\n\n> eliza@ start:client /Users/bradn/Documents/dev/eliza\n> pnpm --dir client dev\n\n\n> client@ dev /Users/bradn/Documents/dev/eliza/client\n> pnpm run extract-version && vite\n\n\n> client@ extract-version /Users/bradn/Documents/dev/eliza/client\n> ./version.sh\n\ninfo.json created with version: 0.1.8+build.1\n\n  VITE v6.0.7  ready in 194 ms\n\n  \u279c  Local:   http://localhost:5173/\n  \u279c  Network: use --host to expose\n  \u279c  press h + enter to show help\n\n```\n\nVisit http://localhost:5173/\nSee the client interface, but not able to interact. \nLower left corner says Connecting and Then says Disconnected and repeats. \n\nhttps://github.com/user-attachments/assets/a5afeb02-b162-423c-9e0f-e3e8fbfbb44d", "CLOSED", 0, "clickbrain", "2025-01-17T23:22:33Z", "2025-01-26T23:26:46Z", "2025-01-20T01:37:37Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6mkKXW", 2414, "Anthropic 504 Timeout", "**Describe the bug**\n\nI am running latest version Eliza v0.1.8+build.1 with my own character using anthropic api and twitter client. \n\n**To Reproduce**\n\n    \"clients\": [\"twitter\"],\n    \"modelProvider\": \"anthropic\",\n    \"plugins\": [],\n    \"settings\": {\n        \"ragKnowledge\": false\n    },\n\nsetup .env with X and anthropic credentials.\n\n\n**Expected behavior**\n\ncreate tweet and send it....\n\n\n\n**Screenshots**\n\n\n \u26d4 ERRORS\n   API Response: \n   <html>\n  <head><title>504 Gateway Time-out</title></head>\n  <body>\n  <center><h1>504 Gateway Time-out</h1></center>\n  </body>\n  </html>\n   \n\n \u26d4 ERRORS\n   Full error details: \n   {} \n\n \u26d4 ERRORS\n   Error generating new tweet: \n   {} \n\n\n**Additional context**\n\nSo the API Response I guess it comes from Anthropic API, but this is happening all the time... does that mean that Anthropic is too busy or is there a way to improve this? \n\nIs it just me? I don't find much info about that out there...", "CLOSED", 0, "amosin", "2025-01-17T04:10:27Z", "2025-01-23T00:07:41Z", "2025-01-23T00:07:40Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6mh_TZ", 2405, "[plugin-tee-log] Error: Invalid TEE configuration when enabling tee-log", "**Describe the bug**\n\nWhen I enable tee-log plugin with below values in my .env, I get an error saying `Invalid TEE configuration`\n\n```env\nTEE_MODE=LOCAL\nWALLET_SECRET_SALT=my_wallet_secret_salt             \nENABLE_TEE_LOG=true \n```\n\n**To Reproduce**\n\nOn local dev, set the values above (like mentioned in the documentation) and launch the agent\n\n**Expected behavior**\n\nThere is no invalid TEE configuration error\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/5a8013a6-2aff-45fb-a780-b9eec88e11e3)\n\n**Additional context**\n\nI think the root cause is located at https://github.com/elizaOS/eliza/blob/main/packages/plugin-tee-log/src/services/teeLogService.ts#L50  . The code below does not make sense as the expression `!teeMode` will always its value equal to `false`, but I do not know if it was made on purpose and why. \n\n```ts\nconst useTdxDstack = !teeMode && teeMode !== TEEMode.OFF && walletSecretSalt;\n```\n", "CLOSED", 0, "bundinho", "2025-01-16T22:41:00Z", "2025-01-23T00:08:22Z", "2025-01-23T00:08:21Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6ma9mS", 2360, "Can't start on macOS", "**Describe the bug**\r\n\r\nI followed the Quick Start but it doesn't work for me, I get the following error:\r\n\r\n```\r\nError: Could not locate the bindings file. Tried:\r\n \u2192 ./eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/build/better_sqlite3.node\r\n \u2192 ./eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/build/Debug/better_sqlite3.node\r\n \u2192 ./eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/build/Release/better_sqlite3.node\r\n \u2192 ./eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/out/Debug/better_sqlite3.node\r\n \u2192 ./eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/Debug/better_sqlite3.node\r\n \u2192 ./eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/out/Release/better_sqlite3.node\r\n \u2192 ./eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/Release/better_sqlite3.node\r\n \u2192 ./eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/build/default/better_sqlite3.node\r\n \u2192 ./eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/compiled/23.3.0/darwin/arm64/better_sqlite3.node\r\n \u2192 ./eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/addon-build/release/install-root/better_sqlite3.node\r\n \u2192 ./eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/addon-build/debug/install-root/better_sqlite3.node\r\n \u2192 ./eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/addon-build/default/install-root/better_sqlite3.node\r\n \u2192 ./eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/lib/binding/node-v131-darwin-arm64/better_sqlite3.node\r\n    at bindings (./eliza-starter/node_modules/.pnpm/bindings@1.5.0/node_modules/bindings/bindings.js:126:9)\r\n    at new Database (./eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/lib/database.js:48:64)\r\n    at initializeDatabase (file://./eliza-starter/src/database/index.ts:15:46)\r\n    at startAgent (file://./eliza-starter/src/index.ts:53:20)\r\n    at startAgents (file://./eliza-starter/src/index.ts:98:19)\r\n    at file://./eliza-starter/src/index.ts:124:1 {\r\n  tries: [\r\n    './eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/build/better_sqlite3.node',\r\n    './eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/build/Debug/better_sqlite3.node',\r\n    './eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/build/Release/better_sqlite3.node',\r\n    './eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/out/Debug/better_sqlite3.node',\r\n    './eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/Debug/better_sqlite3.node',\r\n    './eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/out/Release/better_sqlite3.node',\r\n    './eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/Release/better_sqlite3.node',\r\n    './eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/build/default/better_sqlite3.node',\r\n    './eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/compiled/23.3.0/darwin/arm64/better_sqlite3.node',\r\n    './eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/addon-build/release/install-root/better_sqlite3.node',\r\n    './eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/addon-build/debug/install-root/better_sqlite3.node',\r\n    './eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/addon-build/default/install-root/better_sqlite3.node',\r\n    './eliza-starter/node_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3/lib/binding/node-v131-darwin-arm64/better_sqlite3.node'\r\n  ]\r\n}\r\n```\r\n\r\n**To Reproduce**\r\n\r\nFollow the Quick Start on macOS 15.2.\r\n\r\n**Expected behavior**\r\n\r\nThings to work nicely.\r\n", "CLOSED", 0, "ziodave", "2025-01-16T08:53:18Z", "2025-01-23T15:26:45Z", "2025-01-18T02:36:54Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6l4K2m", 2227, " Client-direct v 0.1.8 failed to deploy to npm - creating inconsistancies. ", "**Describe the bug**\r\n\r\nClient-direct v 0.1.8 failed to deploy - creating inconsistancies. \r\n\r\n**To Reproduce**\r\n\r\ntry run eliza-starter with 0.1.8\r\n\r\n**Expected behavior**\r\n\r\nclient-direct v0.1.8 should be in pnpm, and referencing the 0.1.8 of core.\r\n\r\n**Screenshots**\r\n\r\nPS C:\\dev\\git\\mc2.agents> pnpm add @elizaos/client-direct@0.1.8 @elizaos/core@0.1.8\r\n\u2009ERR_PNPM_NO_MATCHING_VERSION\u2009 No matching version found for @elizaos/client-direct@0.1.8\r\n\r\nThis error happened while installing a direct dependency of C:\\dev\\git\\mc2.agents\r\n\r\nThe latest release of @elizaos/client-direct is \"0.1.7\".\r\n\r\n**Additional context**\r\n\r\nIssue for eliza-starter as you need to configure explicit overrides otherwise agents cannot start.\r\n", "CLOSED", 0, "piffie", "2025-01-13T04:06:06Z", "2025-01-24T20:17:37Z", "2025-01-16T23:15:52Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6l3u3a", 2226, "Seeing Uncaught TypeError: Cannot read properties of null (reading 'useState') ", "**Describe the bug**\r\n\r\nAfter following the quick start and running `pnpm start:client` I see this error in the javascript console: \r\n\r\n```\r\nUncaught TypeError: Cannot read properties of null (reading 'useState')\r\n    at exports.useState (chunk-WGQ5ZIYR.js?v=5c077f48:1094:35)\r\n    at useToast (use-toast.ts:169:37)\r\n    at useVersion (use-version.tsx:9:23)\r\n    at App (App.tsx:22:5)\r\n    at react-stack-bottom-frame (react-dom_client.js?v=f34b75e1:16190:20)\r\n    at renderWithHooks (react-dom_client.js?v=f34b75e1:4304:24)\r\n    at updateFunctionComponent (react-dom_client.js?v=f34b75e1:5970:21)\r\n    at beginWork (react-dom_client.js?v=f34b75e1:7046:20)\r\n    at runWithFiberInDEV (react-dom_client.js?v=f34b75e1:724:18)\r\n    at performUnitOfWork (react-dom_client.js?v=f34b75e1:10829:98)\r\n```\r\n\r\n**To Reproduce**\r\n\r\n1. Follow the quickstart guide\r\n2. run pnpm start\r\n3. run pnpm start:client in a new terminal window\r\n4. open http://localhost:5173/ in the browser (you will see black screen)\r\n5. open the chrome dev tools console and see error\r\n\r\n\r\n**Expected behavior**\r\n\r\nShould load site without errors\r\n\r\n**Screenshots**\r\n\r\n![Screenshot 2025-01-12 at 6 00 19\u202fPM](https://github.com/user-attachments/assets/ad41b386-b587-4c01-985c-23ace7335fbe)\r\n\r\n**Additional context**\r\n\r\nThis started happening today after pulling latest version (v0.1.8). \r\n", "CLOSED", 0, "adaro", "2025-01-13T02:01:06Z", "2025-01-26T21:17:40Z", "2025-01-16T06:26:30Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6l2mPw", 2206, "SttTtsPlugin error when launching space", "**Describe the bug**\r\n\r\n```\r\n[Space] Initialized => https://x.com/i/broadcasts/XXXXXXXXXXXXXXX\r\n [\"\u25ce [SttTtsPlugin] init => Space fully ready. Subscribing to events.\"] \r\n\r\n \u25ce LOGS\r\n   [SttTtsPlugin] Plugin config => \r\n   \u26d4 ERRORS\r\n     [Space] Error launching Space => \r\n     {} \r\n   \u26d4 ERRORS\r\n     [Space] Error in routine => \r\n     {} \r\n```\r\n\r\n**To Reproduce**\r\n\r\nCurrent commit: https://github.com/elizaOS/eliza/commit/d55c86c961960b4b34528c358eb34b2ff4b34d87\r\n\r\n```\r\n    \"twitterSpaces\": {\r\n        \"maxSpeakers\": 2,\r\n        \"topics\": [\r\n            \"Recent News\",\r\n        ],\r\n        \"typicalDurationMinutes\": 45,\r\n        \"idleKickTimeoutMs\": 300000,\r\n        \"minIntervalBetweenSpacesMinutes\": 1,\r\n        \"businessHoursOnly\": false,\r\n        \"randomChance\": 1,\r\n        \"enableIdleMonitor\": true,\r\n        \"enableSttTts\": true,\r\n        \"enableRecording\": false,\r\n        \"voiceId\": \"XYZ\",\r\n        \"sttLanguage\": \"en\",\r\n        \"gptModel\": \"gpt-4o-mini\",\r\n        \"elevenLabsModel\": \"eleven_flash_v2_5\",\r\n        \"systemPrompt\": \"Roleplay as a clown\",\r\n        \"speakerMaxDurationMs\": 120000\r\n    },\r\n```\r\n\r\n**Expected behavior**\r\n\r\nLaunches the space without SttTtsPlugin crashing\r\n", "CLOSED", 0, "y4my4my4m", "2025-01-12T15:48:22Z", "2025-01-23T21:18:46Z", "2025-01-23T21:18:46Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6l1TRj", 2174, "Add support for custom S3 endpoints in `plugin-node`", "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe [`plugin-node`](https://github.com/elizaOS/eliza/tree/main/packages/plugin-node) gives you an S3-compatible API. However, it assumes you're _using_ AWS S3; it doesn't let you use S3-compatible tooling because the request URL is not configurable. \r\n\r\n**Describe the solution you'd like**\r\n\r\nWe should allow the plugin to take an additional (optional) env var called `AWS_S3_ENDPOINT`, which if set, will use the URL for bucket operations. The `plugin-node` only needs a small change [here](https://github.com/elizaOS/eliza/blob/ea9d1c02291dea26b25c815be30db5c91e6ceb21/packages/plugin-node/src/services/awsS3.ts#L60) to handle the URL. If it's set, use it; else, use AWS\u2014and this ensures the setup is backward compatible:\r\n```ts\r\nconst clientConfig: S3ClientConfig = {\r\n    region: AWS_REGION,\r\n    credentials: {\r\n        accessKeyId: AWS_ACCESS_KEY_ID,\r\n        secretAccessKey: AWS_SECRET_ACCESS_KEY,\r\n    },\r\n};\r\nif (AWS_S3_ENDPOINT) {\r\n    clientConfig.endpoint = AWS_S3_ENDPOINT;\r\n    clientConfig.forcePathStyle = true;\r\n}\r\n\r\nthis.s3Client = new S3Client(clientConfig);\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nIf you're using non-AWS tooling that has an S3-compatible API, you **must** have the ability to customize this URL. There's no alternative. Without this feature, you'll get an error like this when, e.g., calling `uploadFile` against a local S3 service:\r\n```\r\nThe AWS Access Key Id you provided does not exist in our records.\r\n```\r\n\r\n**Additional context**\r\n\r\nYou can test this pattern against [something like MinIO](https://min.io/docs/minio/linux/index.html). Run a local MinIO server, set the env var `AWS_S3_ENDPOINT` in your Eliza setup, and then upload a file. \r\n\r\nOutside of the scope of this issue, it'd be nice if the S3 plugin had additional features for the following. These would be useful for additional agent memory or storage options.\r\n- Creating buckets\r\n- Listing buckets\r\n- Querying buckets\r\n- Getting / downloading objects\r\n\r\nIf these additional features are desirable, I can open a separate issue for adding new `plugin-node` S3 methods.", "CLOSED", 0, "dtbuchholz", "2025-01-12T00:50:00Z", "2025-01-23T04:52:26Z", "2025-01-23T04:52:26Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6l0nom", 2158, "Database Connection Error When Using Image Generation Plugin", "# Database Connection Error When Using Image Generation Plugin\r\n\r\n## Bug Description\r\nWhen installing and using the `@elizaos/plugin-image-generation` plugin, the application crashes with a database connection error, even though the plugin itself doesn't directly use database functionality.\r\n\r\n## Steps to Reproduce\r\n1. Install the image generation plugin\r\n2. Start the agent with the plugin enabled\r\n\r\n## Error Message\r\nTypeError: The database connection is not open\r\nat Database.prepare (/Users/xxx/eliza/node_modules/better-sqlite3/lib/methods/wrappers.js:5:21)\r\nat SqliteDatabaseAdapter.getParticipantsForAccount (file:///Users/xxx/eliza/packages/adapter-sqlite/dist/index.js:137:30)\r\nat AgentRuntime.ensureParticipantExists (file:///Users/xxx/eliza/packages/core/dist/index.js:29863:57)\r\n\r\n\r\n## Stack Trace Analysis\r\nThe error occurs in:\r\n1. `packages/adapter-sqlite/dist/index.js:137:30`\r\n2. `packages/core/dist/index.js:29863:57`\r\n3. Specifically in `AgentRuntime.ensureParticipantExists`\r\n\r\n## Additional Context\r\n- The application works fine without the image generation plugin\r\n- The error seems to be triggered by the core's participant management system, not directly by the plugin\r\n- No database configuration is required in the documentation for the image plugin\r\n\r\n## Environment\r\n- Node.js: v23.5.0\r\n- Package Manager: pnpm", "CLOSED", 0, "daizhengxue", "2025-01-11T17:33:15Z", "2025-01-23T02:14:30Z", "2025-01-12T11:12:07Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6lUUq_", 1983, "support default grok in generate object for twitter plugin", "**Is your feature request related to a problem? Please describe.**\r\n\r\nthe default grok model should be supported for trimTokens in the generate Object in core currently type TiktokenModel and type TiktokenEncoding aren't supporting the default \"grok-2-1212\". right now it seems to be missing inside the core package\r\n\r\n**Describe the solution you'd like**\r\n\r\nI'd like to be able to use the twitter plugin without commenting out the token trimming.\r\n\r\n**Describe alternatives you've considered**\r\n\r\njust commenting out token trimming seemed to have allowed it to work. \r\n\r\n**Additional context**\r\n\r\nThis is on the current release, not sure \r\n\r\n", "CLOSED", 0, "agentdeveloper", "2025-01-07T19:21:31Z", "2025-01-26T03:12:22Z", "2025-01-26T03:12:22Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6knwtr", 1543, "Unable to load sqlite-vec extensions in docker environment", "**Describe the bug**\r\n\r\nUpon building the docker container and running locally, I am unable to start my agent. The agent works when I build in my local terminal.\r\n\r\nWhen I run the docker container, I receive the issue in the provided screenshot.\r\n\r\nI mainly interact with my agent via the Discord client. When I run locally, it responds to my messages and I can see the logs in terminal. When I run via docker, this does not occur.\r\n\r\n\r\n**To Reproduce**\r\n\r\n1. Run `docker build -t latest .`\r\n2. Run `docker run latest`\r\n\r\n\r\n**Expected behavior**\r\n\r\nI should be able to interact with my agent via Discord and see the appropriate logs in my terminal.\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n<img width=\"937\" alt=\"CleanShot 2024-12-28 at 14 38 51@2x\" src=\"https://github.com/user-attachments/assets/2779a416-5969-4b76-a9d7-c68ece191f01\" />\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "iankm", "2024-12-28T19:43:59Z", "2025-01-26T14:32:17Z", "2025-01-06T05:17:08Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6kEuli", 1266, "Can't decide which actions to use from a plugin", "**Is your feature request related to a problem? Please describe.**\r\nRight now i have to filter to select which actions i want to perform kinda like hardcoded, im doing something like this\r\n`import { solanaPlugin } from \"@ai16z/plugin-solana\";\r\n\r\n// Remove specific actions\r\nconst filteredPlugin = {\r\n    ...solanaPlugin,\r\n    actions: solanaPlugin.actions.filter(action => \r\n        // Exclude specific actions by name\r\n        action.name !== \"pumpfun\" && action.name !== \"fomo\"\r\n    )\r\n};`\r\n\r\nAnd I believe it should be easier to manage which actions from a given plugin to use.\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\nI have to go and search deep to see what the plugin was doing to see if i decided to use it or not and i realized by default it had actions i didnt want to use and there was no way of no using them besides from what im doing right now. Making the learning curve bigger for new ones.\r\n**Describe the solution you'd like**\r\nI would like to implement in the docs more info about it and in the code add a way of decing which actions should it perform by adding them. At least in Solana where it's money involved and i believe should be something more custom.\r\n<!-- A clear and concise description of what you want to happen. -->\r\nAdd docs explaining the different actions, etc. And add in the code a way to make them optional.\r\n**Describe alternatives you've considered**\r\nRight now as i said im just hardcoding this \r\n`const filteredPlugin = {\r\n    ...solanaPlugin,\r\n    actions: solanaPlugin.actions.filter(action => \r\n        // Exclude specific actions by name\r\n        action.name !== \"pumpfun\" && action.name !== \"fomo\"\r\n    )\r\n};``\r\n\r\nTo decide which ones i want out.\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\nSame\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "lausuarez02", "2024-12-20T13:04:20Z", "2025-01-26T18:30:52Z", "2025-01-26T18:30:52Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6j4sjB", 1232, "Create a nightly build as next version", "**Is your feature request related to a problem? Please describe.**\r\n\r\nI'd like to use `eliza-starter` with the latest providers and features, but that means I have to wait until new version is released (weekly?). It would be great to setup a `nightly` builds from `develop` and push them to npmjs.org as `next` version, so that people can easily experiment with latest features and get ready for new releases\r\n\r\n**Describe the solution you'd like**\r\n\r\nSetup an automation to release nightly to from `develop` to `next`\r\n\r\n**Describe alternatives you've considered**\r\n\r\n:shrug: \r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "vpavlin", "2024-12-19T08:06:40Z", "2025-01-25T18:30:38Z", "2025-01-25T18:30:38Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6jqdfh", 1186, "request: databaseAdapter.getMemoryByIds", "Need databaseAdapter.getMemoryByIds for all current database adapters", "CLOSED", 0, "odilitime", "2024-12-17T19:13:16Z", "2025-01-24T18:32:26Z", "2025-01-24T18:32:26Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6jqWP-", 1185, "integrate o1", "**Is your feature request related to a problem? Please describe.**\r\n\r\nIntegrate o1 https://openai.com/index/o1-and-new-tools-for-developers/\r\n", "CLOSED", 0, "monilpat", "2024-12-17T19:00:42Z", "2025-01-25T18:30:40Z", "2025-01-25T18:30:40Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6jmHTa", 1175, "Allow requiring API key for calling direct client", "I would like to be able to require an API key for communicating with my agent via the direct client rest API.\r\nI did not find a built in way to do this.\r\n\r\nI would propose adding an optional `DirectClientOptions` parameter to the `DirectClient` constructor that contains property API-key.\r\nThe direct client would then return 401 to any request that does not have the header `Authorization: Bearer YOUR_API_KEY`\r\n\r\nI will gladly implement this myself if it makes sense as a feature to others", "CLOSED", 0, "ilmari-h", "2024-12-17T11:27:50Z", "2025-01-23T18:32:32Z", "2025-01-23T18:32:32Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6jkr1X", 1164, "Farcaster Account Creation to launch agent", "**Is your feature request related to a problem? Please describe.**\r\n\r\nThis feature will allow, \r\n\r\n- Launching an agent in farcaster by creating the dedicated farcaster account\r\n\r\nExisting repo, won't support to launch agent in farcaster by creating farcaster account.\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the solution you'd like**\r\n\r\nWe can achieve creating account in multiple ways,\r\n\r\n- Interactive CLI\r\n- API\r\n\r\nWhen launching each agent, It will create dedicated farcaster account and store those farcaster details into DB and perform activites like\r\n\r\n- Post casts\r\n- ReCasts\r\n- etc\r\n\r\n**Describe alternatives you've considered**\r\n\r\nWe need to run seperate server and create the farcaster account and those details we need to pass for agents to run on warpcast (farcaster).\r\n\r\n\r\n", "CLOSED", 0, "BalanaguYashwanth", "2024-12-17T08:52:22Z", "2025-01-24T18:32:28Z", "2025-01-24T18:32:28Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6jiH9M", 1142, "Support for building monorepo with git dependencies using pnpm and nix", "**Is your feature request related to a problem? Please describe.**\r\n\r\nWhen trying to build a pnpm monorepo using Nix's buildNpmPackage that includes git dependencies (specifically @discordjs/opus), the build fails due to git access restrictions in the Nix build environment. The current workarounds involve either modifying package.json or pre-fetching git dependencies, both of which are not ideal solutions for maintaining the project.\r\n\r\n\r\n**Describe the solution you'd like**\r\n\r\nA built-in way to handle git dependencies in buildNpmPackage that:\r\n\r\n 1. Automatically fetches git dependencies using fetchgit during the build process\r\n 2. Maintains compatibility with pnpm workspaces and monorepo structure\r\n 3. Preserves the original package.json without requiring modifications\r\n 4. Works with trusted dependencies in pnpm\r\n\r\n**Describe alternatives you've considered**\r\n\r\n1. Manually pre-fetching git dependencies and placing them in node_modules\r\n2. Modifying package.json to use published versions instead of git dependencies\r\n3. Using mkDerivation instead of buildNpmPackage to handle the build process manually\r\n4. Creating a custom derivation to handle git dependencies before the main build\r\n\r\n**Additional context**\r\n\r\nThis issue particularly affects projects using Discord.js and similar packages that rely on git dependencies for native modules. The current workarounds either break the development workflow or require maintaining separate package configurations for Nix builds.\r\nExample of a failing build: \r\n\r\n`ERR_PNPM_LOCKFILE_CONFIG_MISMATCH Cannot proceed with the frozen installation. The current \"overrides\" configuration doesn't match the value found in the lockfile`\r\n", "CLOSED", 0, "lessuselesss", "2024-12-16T23:53:28Z", "2025-01-24T18:32:29Z", "2025-01-24T18:32:29Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6jVEkO", 1109, "Create Example Files Under `packages/_examples/*` with Corresponding Tests Under `/*/_tests` Within Each Type: Adapter, Client, Plugin, etc.", "**Is your feature request related to a problem? Please describe.**  \r\nThere is currently no clear organization for example implementations and their corresponding tests for constructs like adapters, clients, and plugins. This can lead to confusion, inconsistent patterns, and inefficiencies for developers trying to reference or contribute.\r\n\r\n---\r\n\r\n**Describe the solution you'd like**  \r\nStructure the examples and tests as follows:  \r\n1. **Example files** go under `packages/_examples/*` within their respective construct folders.  \r\n2. **Corresponding tests** are organized under a `_tests` subfolder inside each type directory.\r\n\r\n**Proposed Structure:**  \r\n```\r\npackages/_examples/\r\n  \u251c\u2500\u2500 adapter/\r\n  \u2502   \u251c\u2500\u2500 exampleAdapter.js\r\n  \u2502   \u2514\u2500\u2500 _tests/\r\n  \u2502       \u2514\u2500\u2500 exampleAdapter.test.js\r\n  \u251c\u2500\u2500 client/\r\n  \u2502   \u251c\u2500\u2500 exampleClient.js\r\n  \u2502   \u2514\u2500\u2500 _tests/\r\n  \u2502       \u2514\u2500\u2500 exampleClient.test.js\r\n  \u251c\u2500\u2500 plugin/\r\n  \u2502   \u251c\u2500\u2500 examplePlugin.js\r\n  \u2502   \u2514\u2500\u2500 _tests/\r\n  \u2502       \u2514\u2500\u2500 examplePlugin.test.js\r\n  \u2514\u2500\u2500 README.md  // High-level description of examples\r\n```\r\n\r\n---\r\n\r\n**Describe alternatives you've considered**  \r\n1. **Tests alongside examples**: Keeping tests in the same folder creates clutter, especially as examples scale.  \r\n2. **Central `_tests` folder**: While centralized tests are clean, separating them under each type folder improves organization and traceability.\r\n\r\n---\r\n\r\n**Additional context**  \r\n- This structure creates a clear relationship between example files and their tests.  \r\n- Developers can easily locate both the example implementation and corresponding tests for constructs like adapters, clients, and plugins.  \r\n- A high-level `README.md` in `packages/_examples/` can document the folder's purpose and how to use the examples.  \r\n", "CLOSED", 0, "monilpat", "2024-12-15T00:48:36Z", "2025-01-21T18:32:53Z", "2025-01-21T18:32:53Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6jVER7", 1108, "Refactor: Enable Provider Mapping to Accept an Array of Strings for Flexibility with JSON Input", "**Is your feature request related to a problem? Please describe.**  \r\nCurrently, providers need to be passed directly into the system, which limits flexibility. It prevents us from dynamically sourcing providers from external `.json` files or other configurations. This can become cumbersome when managing multiple providers.\r\n\r\n---\r\n\r\n**Describe the solution you'd like**  \r\nRefactor the current implementation to:  \r\n- Create a **provider mapping system**.  \r\n- Allow an **array of strings** to be passed instead of hardcoding providers directly.  \r\n- Dynamically resolve and load providers based on the string array.  \r\n- Enable passing in providers from a `.json` file for improved configurability.\r\n\r\nExample:  \r\n```json\r\n{\r\n  \"providers\": [\"providerA\", \"providerB\", \"providerC\"]\r\n}\r\n```\r\n\r\nThe system should interpret these strings, map them to their corresponding provider logic, and load them seamlessly.\r\n\r\n---\r\n\r\n**Describe alternatives you've considered**  \r\n1. **Hardcoding providers**: This is inflexible and requires manual intervention for every change.  \r\n2. **Manual parsing of JSON**: While possible, this adds unnecessary boilerplate code and duplicates logic that could be centralized.  \r\n\r\n---\r\n\r\n**Additional context**  \r\n- This change improves maintainability and flexibility for managing providers.  \r\n- It is especially useful for projects that rely on external configuration files or need runtime provider adjustments.  ", "CLOSED", 0, "monilpat", "2024-12-15T00:44:36Z", "2025-01-25T18:30:41Z", "2025-01-25T18:30:41Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6jTDCz", 1072, "Native integration support for FullsendFI [twitter SOL transfer system]", "**Is your feature request related to a problem? Please describe.**\r\n\r\nA new service to transfer SOL using Twitter UID's as the account source via Magic Link abstracted accounts. FullSend uses abstracted SOL accounts linked to authenticated Twitter logins to allow hoisted SOL transfers without a need for the receiver to have a wallet entirely. Additionally, the users are able to trade with hoisted SOL via their abstracted accounts any of the listed coins.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAllow ai16z agents to interact to be able to send SOL via Twitter directly through FullSend API\r\n\r\nhttps://www.fullsend.fi/ ", "CLOSED", 0, "chandognft", "2024-12-14T07:49:15Z", "2025-01-26T18:30:54Z", "2025-01-26T18:30:54Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6jTBmm", 1071, "Move actions and evaluators to event driven", "Right now the actions are called inside the message response handlers.\r\n\r\nInstead, we should make the runtime an event emitter and have actions respond to events.\r\n\r\nThis should slightly simplify the code and unify the patterns around an event driven architecture.", "CLOSED", 0, "lalalune", "2024-12-14T07:45:19Z", "2025-01-26T18:30:55Z", "2025-01-26T18:30:55Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6i5XIX", 990, "TypeError - LinkedIn constructor error", "**Describe the bug**\r\n\r\nWhen integrating `client-linkedin`, an error occurs: \"TypeError: linkedin_api_1.Client is not a constructor\". This error prevents the LinkedIn client from starting properly.\r\n\r\n**To Reproduce**\r\n\r\n1. Attempt to start the LinkedIn client.\r\n2. Observe the error message in the console.\r\n\r\n**Expected behavior**\r\n\r\nThe LinkedIn client should start without any errors, and it should initialize the agent for the character NEEToshi successfully.\r\n\r\n**Errors Log**\r\n\r\n```\r\n[\"\u25ce LinkedIn client started\"]\r\n\r\n\u26d4 ERRORS\r\nError starting agent for character NEEToshi:\r\n{}\r\n\r\nTypeError: linkedin_api_1.Client is not a constructor\r\nat new ClientBase (/Users/prem/Documents/PERSONAL/eliza/packages/client-linkedin/dist/base.js:67:35)\r\nat new LinkedInManager (/Users/prem/Documents/PERSONAL/eliza/packages/client-linkedin/dist/index.js:11:23)\r\nat Object.start (/Users/prem/Documents/PERSONAL/eliza/packages/client-linkedin/dist/index.js:20:25)\r\nat async initializeClients (file:///Users/prem/Documents/PERSONAL/eliza/agent/src/index.ts:232:33)\r\nat async startAgent (file:///Users/prem/Documents/PERSONAL/eliza/agent/src/index.ts:349:25)\r\nat async startAgents (file:///Users/prem/Documents/PERSONAL/eliza/agent/src/index.ts:372:13)\r\n\r\n\u26d4 ERRORS\r\nError starting agents:\r\n{}\r\n```\r\n\r\n*Additional context**\r\n\r\nThis issue may be related to the incorrect instantiation of the LinkedIn client due to `linkedin_api_1.Client` not being a constructor. Further investigation into the client library is needed.", "CLOSED", 0, "Prem95", "2024-12-11T13:12:09Z", "2025-01-26T15:22:12Z", "2024-12-14T08:23:05Z", "elizaos/eliza", "2025-04-14 21:51:12"]
["I_kwDOMT5cIs6oaNi2", 3148, "Strange behavior of Fetch method in eliza", "I am not sure, but I think eliza has done something to the fetch method! Below I explain why!\n\nI am trying to add the image upload feature to Twitter client. I have passed data as `agent-twitter-client` library accepts, but when I call it I get this error \n```\n {\"errors\":[{\"code\":38,\"message\":\"media parameter is missing.\"}]}\n```\n\nI did extensive debugging. I cloned the `agent-twitter-client` and loaded it as a local dependency in eliza package.json.\n```\n        \"agent-twitter-client\": \"file:/Users/amin/Downloads/agent-twitter-client\",\n```\nI put some log at upload points in the `agent-twitter-client` and executed its tests that include image uploading. \nI could upload images by running this repo tests. But when I try to use it through eliza, I got the aforementioned error.\n\nIt's the upload point in the `agent-twitter-client`\n\n```ts\n    console.log({\n      uploadUrl,\n      p: {\n        method: 'POST',\n        headers,\n        body: form,\n      },\n    });\n\n    const response = await fetch(uploadUrl, {\n      method: 'POST',\n      headers,\n      body: form,\n    });\n```\n\nThe console.log output is the same for running `agent-twitter-client` test and eliza agent running.\n", "CLOSED", 0, "aminlatifi", "2025-02-01T21:31:16Z", "2025-02-02T07:00:57Z", "2025-02-02T06:03:11Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6oZdzL", 3144, "Hajajajajajajjaja", "**Describe the bug**\n\n<!-- A clear and concise description of what the bug is. -->\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "mega4722", "2025-02-01T14:42:35Z", "2025-02-01T18:02:23Z", "2025-02-01T18:02:23Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6oZdyJ", 3143, "Jajajsjsjsjjs", "**Describe the bug**\n\n<!-- A clear and concise description of what the bug is. -->\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "mega4722", "2025-02-01T14:42:26Z", "2025-02-01T18:02:28Z", "2025-02-01T18:02:28Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6oZdxY", 3142, "Bismillah", "**Describe the bug**\n\n<!-- A clear and concise description of what the bug is. -->\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "mega4722", "2025-02-01T14:42:18Z", "2025-02-01T18:03:10Z", "2025-02-01T18:03:10Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6oY-yf", 3133, "plugin coinmarketcap: test config and coverage", "**Is your feature request related to a problem? Please describe.**\n\nThe plugin-coinmarketcap package is expected to require comprehensive test coverage to ensure reliability and maintainability. Currently, the package's functionality, particularly the getPrice action which interacts with the CoinMarketCap API, should be thoroughly tested to prevent potential issues in production. Without proper test coverage, bugs and edge cases might go undetected, potentially leading to service disruptions or incorrect price data being returned to users.\n\n**Describe the solution you'd like**\n\nA comprehensive test suite should be implemented for the\u00a0plugin-coinmarketcap\u00a0package. This is expected to include:\n1. Unit tests for the\u00a0getPrice\u00a0action that should cover:\n    * Input validation for cryptocurrency symbols and currencies\n    * Proper handling of API responses\n    * Error cases (invalid symbols, currencies, API errors)\n    * Rate limiting scenarios\n2. Service layer tests that should verify:\n    * Correct API endpoint configuration\n    * Response data formatting\n    * Error handling and propagation\n    * Edge cases in the API interaction\n3. Test infrastructure that should be set up with:\n    * Proper mocking of external dependencies\n    * Test environment configuration\n    * Consistent error handling patterns\nThe implementation is expected to use Vitest as the testing framework, with proper mocking of the CoinMarketCap API to avoid actual API calls during testing. All error scenarios should be properly tested to ensure robust error handling throughout the plugin.\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-02-01T10:10:52Z", "2025-02-02T23:44:28Z", "2025-02-02T23:44:28Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6oWyda", 3123, "plugin-coingecko: test config and coverage", "**Is your feature request related to a problem? Please describe.**\n\nThe\u00a0plugin-coingecko\u00a0package currently lacks comprehensive test coverage, which poses several risks:\n1. Changes to the codebase may inadvertently break existing functionality without immediate detection\n2. Edge cases and error scenarios are not systematically verified\n3. Integration with the CoinGecko API is not thoroughly tested\n4. The reliability of the plugin cannot be confidently assured without proper test validation\n\n**Describe the solution you'd like**\n\nA comprehensive test suite should be implemented for the\u00a0plugin-coingecko\u00a0package. The following tasks are expected to be completed:\n1. Test Infrastructure Setup:\n    * Vitest and related testing dependencies should be added to\u00a0package.json\n    * A\u00a0setup.ts\u00a0file should be created to handle common test configurations\n    * Proper mocking utilities should be configured for external dependencies\n2. Core Action Testing:\n    * Each action (getPrice, getTrending, etc.) should have dedicated test files\n    * Test coverage should include:\n        * Happy path scenarios with various input combinations\n        * Error handling and edge cases\n        * API response formatting\n        * Configuration validation\n3. Specific Test Cases:\n    * Price retrieval with different currency combinations\n    * Market data inclusion (market cap, volume, etc.)\n    * Trending data across different categories (coins, NFTs)\n    * Rate limiting and API error scenarios\n    * Empty or malformed response handling\n4. Mock Implementation:\n    * API responses should be properly mocked\n    * Environment configurations should be simulated\n    * Core dependencies (elizaLogger, etc.) should be mocked\nThe completed test suite is expected to provide:\n* Confidence in code changes and refactoring\n* Documentation of expected behavior\n* Validation of error handling\n* Assurance of proper API integration\nThis enhancement should significantly improve the maintainability and reliability of the plugin.\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-31T23:08:23Z", "2025-02-02T23:47:09Z", "2025-02-02T23:47:09Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6oMwDi", 3071, "plugin chainbase: test coverage and config", "**Is your feature request related to a problem? Please describe.**\n\nThe Chainbase plugin is expected to require comprehensive test coverage to ensure reliable interaction with the Chainbase API. Without proper testing, issues such as incorrect token balance retrieval, API timeout handling, and error management are likely to surface in production. The plugin should be thoroughly tested to handle various scenarios including successful queries, API failures, and timeout conditions.\n\n**Describe the solution you'd like**\n\nA comprehensive test suite should be implemented for the\u00a0plugin-chainbase\u00a0package using vitest. The test coverage is expected to include:\n1. Token Balance Actions:\n    * Tests should be written to validate proper handling of token balance retrieval\n    * Input validation should be implemented for chain IDs and addresses\n    * Response formatting should be tested for various token decimal places\n2. Query Execution:\n    * Tests should be created to verify SQL query execution\n    * Timeout scenarios should be properly handled with configurable retry attempts\n    * Error cases should be tested including API failures and invalid responses\n3. Mock Implementation:\n    * The Chainbase API responses should be properly mocked\n    * Timer functions should be mocked to test timeout scenarios\n    * Environment variables should be managed within tests\n4. Code Organization:\n    * Tests should be structured similarly to the\u00a0plugin-bootstrap\u00a0package\n    * Test files should be organized by feature (actions, libs)\n    * Common test utilities should be shared across test files\n\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-30T22:07:56Z", "2025-01-31T19:42:49Z", "2025-01-31T19:42:49Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6oMmju", 3067, "plugin-bootstrap: test config and test coverage", "**Is your feature request related to a problem? Please describe.**\n\nThe plugin-bootstrap package is expected to require comprehensive test coverage to ensure reliability and maintainability. Currently, the package would lack proper testing infrastructure, making it difficult to verify the behavior of various components such as evaluators (goal, fact, memory) and actions (continue, ignore). Without proper test coverage, it would be challenging to catch potential bugs and regressions during development. Additionally, the absence of standardized testing patterns would likely lead to inconsistent test implementations across different components.\n\n**Describe the solution you'd like**\n\nA comprehensive test suite should be implemented for the plugin-bootstrap package using vitest. The following components are expected to be covered:\n1. Core Evaluators:\n    * The goal evaluator should be tested for proper validation and goal status updates\n    * The fact evaluator should be tested for fact extraction and validation\n    * Memory evaluator tests should be implemented to verify memory management\n2. Actions:\n    * The continue action should be tested for message generation and validation\n    * Tests for the ignore action should be implemented\n    * Each action's properties and examples should be validated\n3. Test Infrastructure:\n    * Mock objects for runtime, message, and state should be standardized\n    * Helper functions for common test scenarios should be created\n    * Proper dependency mocking patterns should be established\n4. Test Organization:\n    * Tests should be structured in meaningful describe blocks\n    * Each component should have separate validation and functionality tests\n    * Error cases should be properly covered\nThis implementation is expected to provide:\n* Reliable verification of component behavior\n* Easy maintenance and updates\n* Clear patterns for adding new tests\n* Comprehensive coverage of edge cases\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-30T21:41:11Z", "2025-01-31T19:45:21Z", "2025-01-31T19:45:21Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6oMdhd", 3062, "plugin-bittensor: test coverage and config", "**Is your feature request related to a problem? Please describe.**\n\nThe\u00a0plugin-bittensor\u00a0package currently lacks comprehensive test coverage, which poses potential risks for future maintenance and reliability. Without proper test coverage, there is an increased likelihood of introducing bugs during updates or modifications. Additionally, the absence of tests makes it challenging to verify the correct functionality of critical features such as image analysis and fact extraction, which are core components of this plugin.\n\n**Describe the solution you'd like**\n\nA comprehensive test suite should be implemented for the\u00a0plugin-bittensor\u00a0package. The testing implementation is expected to be divided into two main components:\n1. Image Analysis Testing (sn34.ts):\n    * Tests should be written to validate image URL processing and API credential handling\n    * Action properties validation is expected to be implemented\n    * Coverage should include both\u00a0analyzeImage\u00a0and\u00a0analysisHistory\u00a0actions\n    * Mock implementations should be created for external API calls\n2. Fact Evaluator Testing (fact.ts):\n    * Validation logic should be thoroughly tested\n    * Evaluator properties verification is expected to be implemented\n    * Fact extraction functionality should be tested with various input scenarios\n    * Memory management operations should be properly mocked\nThe implementation should utilize vitest as the testing framework, and all tests should be organized in a\u00a0__tests__\u00a0directory structure. A vitest configuration file should be created to ensure proper test environment setup. The test coverage is expected to achieve a high percentage, focusing on both successful scenarios and error handling cases.\nDependencies should be properly mocked to ensure isolated testing, and the testing structure should follow the established patterns used in other plugins within the ecosystem. This approach is expected to enhance code reliability and make future maintenance more manageable.\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-30T21:17:15Z", "2025-01-31T19:44:00Z", "2025-01-31T19:44:00Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6oF07x", 3017, "Anthropic doesn't support JSON mode object generation.", "## Describe the bug\nWhen using the Twitter plugin with Anthropic's API (Claude), the system fails because Anthropic doesn't support JSON mode object generation. The error message states: \"'json-mode object generation' functionality not supported.\"\n## To Reproduce\nConfigure character to use Anthropic/Claude as the model provider\n## Enable Twitter plugin\nAttempt to generate a tweet action\nSystem fails with error about JSON mode not being supported\n## Expected behavior\nThe system should fall back to \"auto\" mode for object generation when using Anthropic/Claude models, since they don't support JSON mode. This would allow the Twitter plugin to work properly with Anthropic models.\n", "CLOSED", 0, "Jesscha", "2025-01-30T07:24:27Z", "2025-01-30T11:39:35Z", "2025-01-30T11:39:35Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6oC3_9", 3001, "Bug: Error when loading client without OpenAI API key", "**Describe the bug**\n\nOpenAI embeddings set to TRUE in .env configuration causing error when loading character without an OpenAI API key. \n\n![Image](https://github.com/user-attachments/assets/e577983a-2775-4c05-a5b8-5b1cecad93af)\n\n<!-- A clear and concise description of what the bug is. -->\n\n**To Reproduce**\n\n- pull latest develop branch\n- run agent without OpenAI API key configured in .env file \n- see error \n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\nexpect agent to run without using OpenAI API key. \n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/08f515cc-4ee1-4073-8aaa-9955aae7ddb6)\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n\ntried setting OpenAI embeddings to default but the agent gets stuck in generating text: \n\n![Image](https://github.com/user-attachments/assets/18dabe87-1a61-4315-92be-1cc4673bda4e)\n", "CLOSED", 0, "ileana-pr", "2025-01-29T21:08:37Z", "2025-01-29T23:51:23Z", "2025-01-29T23:51:23Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6oCQjp", 2998, "plugin avalanche: test config and coverate", "**Is your feature request related to a problem? Please describe.**\n\nThe Avalanche plugin's tokenMillCreate action needs comprehensive test coverage to ensure reliable token creation functionality. The current implementation lacks proper test coverage for validation, action properties, and core token creation scenarios.\n\n**Describe the solution you'd like**\n\nWe should implement a complete test suite that covers:\n1. Validation (2 tests):\n    * Should confirm proper validation with valid configuration\n    * Should verify failure when private key is missing\n2. Action Properties (2 tests):\n    * Should validate correct action properties (name, description)\n    * Should ensure examples are properly structured\n3. Token Creation (2 tests):\n    * Should confirm successful token creation flow\n    * Should handle invalid content appropriately\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-29T20:08:51Z", "2025-01-29T22:08:34Z", "2025-01-29T22:08:34Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6oB-HR", 2996, "plugin-avail: test config and coverage", "**Is your feature request related to a problem? Please describe.**\n\nThe\u00a0plugin-avail\u00a0package currently lacks proper test coverage. There are no tests to verify the functionality of the actions, error handling, or integration with the Avail network. This makes it difficult to ensure reliability and catch potential issues before they reach production.\n\n**Describe the solution you'd like**\n\nAdd comprehensive test coverage using vitest for the\u00a0plugin-avail\u00a0package, including:\n* Unit tests for all actions (submitData, transfer)\n* Error handling tests\n* Mock implementations for Avail SDK\n* Test utilities and fixtures\n* Proper test configuration\nThis will help ensure code reliability and make it easier to maintain and extend the package in the future.\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-29T19:32:46Z", "2025-01-29T22:09:25Z", "2025-01-29T22:09:25Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6oAJuU", 2991, "plugin-autonome: test config and coverage", "**Is your feature request related to a problem? Please describe.**\n\nThe plugin-autonome package lacks proper test configuration and coverage reporting capabilities. Without a standardized test configuration, it's difficult to maintain consistent test practices across the codebase and track test coverage effectively. This makes it harder to ensure code quality and identify areas that need additional testing.\n\n**Describe the solution you'd like**\n\n\u00a0The solution consists of two main parts:\n1. Test Infrastructure:\n* A\u00a0vitest.config.ts\u00a0file with proper test environment setup and coverage configuration\n* Enhanced test scripts in package.json for running tests, watching tests, and generating coverage reports\n* Proper test file patterns and exclusions to ensure only relevant files are tested\n1. Comprehensive Test Implementation:\n* Created thorough test suite for the\u00a0launchAgent\u00a0action covering:\n    * Basic validation (action properties, validation logic)\n    * Success path (proper agent launch, API call formatting)\n    * Error handling (invalid content, API errors)\n    * Edge cases (undefined/invalid responses)\n* Tests utilize Vitest's mocking capabilities to:\n    * Isolate tests from external dependencies (axios, core utilities)\n    * Ensure reliable and repeatable test execution\n    * Validate proper error message propagation\n    * Verify callback message formatting\nThis solution provides both the infrastructure for effective testing and actual test coverage of critical functionality, establishing a pattern for future test development in the package.\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-29T15:56:14Z", "2025-01-29T22:10:11Z", "2025-01-29T22:10:11Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6n-Z8-", 2981, "plugin-arbitrage: test config and test coverage", "**Is your feature request related to a problem? Please describe.**\n\nThe\u00a0plugin-arbitrage\u00a0package lacks test coverage for its critical components:\n1. The arbitrage plugin handles real financial transactions and market operations, but has no automated tests to ensure its reliability and correctness.\n2. Key components like market evaluation, arbitrage execution, and WebSocket connections are not tested, which could lead to:\n    * Missed arbitrage opportunities\n    * Failed transactions\n    * Incorrect profit calculations\n    * Connection handling issues\n    * Memory leaks from unmanaged WebSocket connections\n3. The service initialization and configuration validation are not tested, risking improper setup in production.\n\n**Describe the solution you'd like**\n\nAdd a comprehensive test suite for the\u00a0plugin-apro\u00a0package that covers:\n1. Core Actions Testing\n    * Test all main actions (create, verify, query) with both success and failure scenarios\n    * Ensure proper error handling and message propagation\n    * Validate action metadata and examples\n2. Integration Testing\n    * Test interaction with external SDKs and dependencies\n    * Verify proper handling of blockchain transactions\n    * Test configuration and environment variable handling\n3. Input Validation\n    * Test input parameter validation\n    * Verify schema compliance\n    * Test edge cases and invalid inputs\nThis will help ensure the package's reliability and make it easier to maintain and extend the codebase with confidence.\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-29T13:01:23Z", "2025-01-29T15:40:25Z", "2025-01-29T15:40:25Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6n-Ulm", 2979, "plugin-apro: test coverage and test config", "**Is your feature request related to a problem? Please describe.**\n\nThe\u00a0plugin-apro\u00a0package currently lacks comprehensive test coverage for its core functionality. Without proper tests, we cannot ensure the reliability of the package's features or catch potential regressions when making changes. This is particularly concerning for critical operations like agent creation and data verification.\n\n**Describe the solution you'd like**\n\nAdd a comprehensive test suite for the\u00a0plugin-apro\u00a0package that covers:\n1. Core Actions Testing\n    * Test all main actions (create, verify, query) with both success and failure scenarios\n    * Ensure proper error handling and message propagation\n    * Validate action metadata and examples\n2. Integration Testing\n    * Test interaction with external SDKs and dependencies\n    * Verify proper handling of blockchain transactions\n    * Test configuration and environment variable handling\n3. Input Validation\n    * Test input parameter validation\n    * Verify schema compliance\n    * Test edge cases and invalid inputs\nThis will help ensure the package's reliability and make it easier to maintain and extend the codebase with confidence.\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-29T12:52:28Z", "2025-01-29T15:40:31Z", "2025-01-29T15:40:31Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6n4-Nd", 2927, "{{maxTweetLength}} doesn't work in tweet post template", "The template tag {{maxTweetLength}} doesn't exist. \n\nhttps://github.com/elizaOS/eliza/blob/3b4bc8579a845fde2d1098cb1fdce7bc31a4703b/packages/client-twitter/src/post.ts#L55\n\n\nMaybe it would be nice to pass custom inputs into composeContext:\nhttps://github.com/elizaOS/eliza/blob/3b4bc8579a845fde2d1098cb1fdce7bc31a4703b/packages/client-twitter/src/post.ts#L524\n\nOr perhaps just populate the maxTweetLength in the template directly in this case before sending to composeContext?\n\nThere might be an obvious simple fix for this in alignment with Eliza architecture that I'm not seeing. Would love to learn from more experienced devs the correct way to fix this simple issue. \n", "CLOSED", 0, "LinuxIsCool", "2025-01-28T21:14:58Z", "2025-01-29T04:43:09Z", "2025-01-29T04:43:08Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6n30k_", 2920, "plugin-solana 'SEND_TOKEN' action verification set to false", "**Describe the bug**\n\nI tried to use the SEND_TOKEN action and the action is triggered as expected. However, since the verification returns false, it does not proceed. In order to test, I updated the plugin to return true. The transaction signature is generated; however, the transaction does not confirm and times out from time to time. I am using Helios RPC on mainnet-beta cluster. It works as expected for other actions, such as, EXECUTE_SWAP\n\n**To Reproduce**\n\nCheck out the main branch and set up a character with plugin-solana and a few message examples that allow the SEND_TOKEN action. Run the server and the client locally and send a prompt to character with messages similar to the examples. It should trigger the SEND_TOKEN action, but not proceed.\n\n\n**Expected behavior**\n\nThe SEND_TOKEN action should proceed and transaction should be confirmed on-chain in mainnet-beta\n", "CLOSED", 0, "deusexmachina892", "2025-01-28T18:24:21Z", "2025-01-28T19:08:38Z", "2025-01-28T19:08:38Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6nxUhn", 2891, "Second Tweet from Agent Replies to User Instead of Initial Agent Tweet", "**Describe the bug**\nWhen the agent initiates an action (i.e. GENERATE_VIDEO), it sends two tweets:\n1. An initial tweet indicating the action has started.\n2. A second tweet with the payload once the action completes.\n\nHowever, the second tweet (with the payload) replies directly to the user\u2019s original tweet instead of replying to the agent\u2019s initial tweet. This disrupts the expected reply chain and makes the interaction unclear.\n\n**To Reproduce**\n1. Post a tweet to the agent requesting something (e.g., \u201cgenerate a video of a butterfly\u201d).\n2. Observe the agent\u2019s initial tweet acknowledging the action initiation.\n3. Wait for the video generation process to complete.\n4. Observe the agent\u2019s second tweet with the payload replying to the user\u2019s original tweet instead of the agent\u2019s initial tweet.\n\n**Expected behavior**\nThe second tweet (containing the payload) should reply to the agent\u2019s initial tweet, maintaining a logical and consistent reply chain.\n\n**Additional context**\n\n- The issue may stem from how the framework handles inReplyToId or how the initial tweet ID is stored/passed to the second tweet.\n- A potential fix might involve explicitly capturing the agent\u2019s initial tweet ID and ensuring it is passed as inReplyToId when sending the second tweet.\n\nLet me know if you need further adjustments! \ud83d\ude80", "CLOSED", 0, "KennethAshley", "2025-01-28T06:11:58Z", "2025-01-29T09:48:51Z", "2025-01-29T09:48:49Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6nw23l", 2885, "Eliza chatbot client is not running on http://localhost:5173/", "http://localhost:5173/ on this host its not connecting showing disconnected like in the following SS but on 3000 its showing the REST API running.\n\n<img width=\"1792\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3d1840ca-8d5d-439d-9d6c-3059494fcb12\" />", "CLOSED", 0, "yasir23", "2025-01-28T04:33:11Z", "2025-01-31T11:52:37Z", "2025-01-31T11:52:35Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6nwE5j", 2871, "Error after updating to latest version", "I am getting the following error. Would like to know how to resolve this: \n(node:23019) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\n(Use `node --trace-warnings ...` to show where the warning was created)\n(node:23019) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n\nnode:internal/modules/run_main:104\n    triggerUncaughtException(\n    ^\nError: Cannot find module '/home/sonat/eliza/agent/node_modules/@elizaos/adapter-pglite/dist/index.js' imported from /home/sonat/eliza/agent/src/index.ts\n    at finalizeResolution (/home/sonat/eliza/node_modules/ts-node/dist-raw/node-internal-modules-esm-resolve.js:352:11)\n    at moduleResolve (/home/sonat/eliza/node_modules/ts-node/dist-raw/node-internal-modules-esm-resolve.js:801:10)\n    at Object.defaultResolve (/home/sonat/eliza/node_modules/ts-node/dist-raw/node-internal-modules-esm-resolve.js:912:11)\n    at /home/sonat/eliza/node_modules/ts-node/src/esm.ts:218:35\n    at entrypointFallback (/home/sonat/eliza/node_modules/ts-node/src/esm.ts:168:34)\n    at /home/sonat/eliza/node_modules/ts-node/src/esm.ts:217:14\n    at addShortCircuitFlag (/home/sonat/eliza/node_modules/ts-node/src/esm.ts:409:21)\n    at resolve (/home/sonat/eliza/node_modules/ts-node/src/esm.ts:197:12)\n    at nextResolve (node:internal/modules/esm/hooks:748:28)\n    at Hooks.resolve (node:internal/modules/esm/hooks:240:30)\n\nNode.js v23.5.0", "CLOSED", 0, "sonatonagems", "2025-01-28T01:17:20Z", "2025-01-31T03:52:08Z", "2025-01-31T03:52:07Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6nt04Q", 2859, "plugin-asterai: test config and test coverage", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\nThe plugin-asterai package lacks comprehensive test coverage, which makes it difficult to ensure reliability and catch potential issues. \n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\n-Test coverage for all key functionalities:\nEnvironment configuration validation\nQuery handling and responses\nError handling scenarios\nProvider summary fetching and caching\nMemory management through the knowledge manager\n-Test organization improvements:\nClear test structure with describe/it blocks\nProper beforeEach setup for each test\nConsistent mock implementations across test files\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-27T18:53:15Z", "2025-01-28T19:22:36Z", "2025-01-28T19:22:36Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6nsYXU", 2853, "plugin anyone: test config and coverate", "**Is your feature request related to a problem? Please describe.**\nThe plugin-anyone package lacks proper test coverage for its core functionality, specifically the startAnyone and stopAnyone actions. Without comprehensive tests, we couldn't ensure the reliability of the Anyone client and proxy service initialization/cleanup processes, making it difficult to catch potential issues before they affect production.\n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\n- Add Vitest as testing framework\n* Create\u00a0__tests__\u00a0directory in package root\n* Add tests for\u00a0startAnyone\u00a0and\u00a0stopAnyone\u00a0actions\n* No use of\u00a0undefined,\u00a0unknown\u00a0or other unsafe type casts\n* Add basic vitest config\n* Add test scripts to package.json:\n    * test: Run tests once\n    * test:watch: Run tests in watch mode\nThe tests should cover:\n* Action validation\n* Handler functionality\n* Service initialization/cleanup\n* Error handling\n* Action metadata validation\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-27T16:08:56Z", "2025-01-27T16:59:10Z", "2025-01-27T16:59:10Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6nr-FZ", 2851, "Publish plugin-sui", "**Is your feature request related to a problem? Please describe.**\n\nWe can't install plugin-sui because `@elizaos/plugin-sui is not in the npm registry, or you have no permission to fetch it.`\n\n**Describe the solution you'd like**\n\nPublish `plugin-sui` as npm registry \n", "CLOSED", 0, "hoangquocvietuet", "2025-01-27T15:24:50Z", "2025-01-29T22:24:49Z", "2025-01-29T22:23:49Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6nrj81", 2849, "plugin-3d-generation: test config and test coverage", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\nThe 3D generation plugin will need enhanced test coverage in several areas that will be important for future development:\n1. The test suite will need to cover queue update callback functionality from the FAL API\n2. There will be a need to test different types of 3D model responses (various file formats and sizes)\n3. The error handling tests will need to be more specific about different types of API errors that could occur\n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\n1. New test cases for queue updates will:\n    * Test how progress updates will be handled during generation\n    * Verify how queue position updates will be managed\n    * Ensure cancellation scenarios will be properly handled\n2. Additional test cases for different model formats will:\n    * Verify how .glb files will be processed\n    * Ensure .obj files will be handled correctly\n    * Test how different file sizes will be managed\n3. Enhanced error handling tests will:\n    * Cover specific API error codes that might occur\n    * Verify how network timeouts will be handled\n    * Test how rate limiting will be managed\n    * Ensure invalid API key formats will be properly detected\nThese improvements will make our test suite more comprehensive and will help catch edge cases before they become issues in production.\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-27T14:42:07Z", "2025-01-27T16:59:19Z", "2025-01-27T16:59:19Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6nmNUS", 2806, "plugin-0x: test configuration and test coverage", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\nCurrently, the plugin-0x package lacks proper test coverage, particularly for the critical getIndicativePrice action. This makes it difficult to ensure reliability and catch potential issues before they affect production. Additionally, there's no standardized testing setup with Vitest, which is our preferred testing framework.\n\n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\n We will implement a comprehensive test suite using Vitest for the plugin-0x package, focusing initially on the getIndicativePrice action. The solution will include:\n\nSetting up a Vitest configuration file with proper TypeScript support\nCreating test files with proper mocking of dependencies (@elizaos/core, @0x/swap-ts-sdk)\nImplementing tests for:\nInput validation (API key presence)\nSuccessful price fetching scenarios\nError handling cases (invalid chain, token not found, API errors)\nEnsuring type safety throughout the test suite\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-26T22:02:58Z", "2025-01-27T02:59:44Z", "2025-01-27T02:59:44Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6nmMYc", 2804, "plugin-0g: test configuration and test coverage", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\n The test suite needed improvements in its structure and configuration. We lacked:\n\nA proper test configuration file\nClear test file organization\nTypeScript integration in tests\nBasic test environment setup\n\n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\nA clean\u00a0vitest.config.ts\u00a0with essential settings:\n    * Jest-like globals for familiar testing syntax\n    * Node environment configuration\n    * Clear test file patterns for TypeScript/JavaScript\n    * TypeScript integration with tsconfig\nOrganized test structure:\n    * Tests in\u00a0__tests__\u00a0directory\n    * Clear file naming pattern (*.test.ts)\n    * Proper exclusion of node_modules and dist\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-01-26T21:53:33Z", "2025-01-27T02:56:26Z", "2025-01-27T02:56:26Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6nl4Xz", 2801, "Multiple Agents work", "After running the 1st Agent, how I can run other agent/agents to work together, but not the same functionalities? ", "CLOSED", 0, "DrDregyo", "2025-01-26T18:44:51Z", "2025-01-28T06:02:34Z", "2025-01-28T06:02:19Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6nk1yx", 2796, "Message id collision in Telegram Client", "**Describe the bug**  \nThe `msg_id` and `agent_id` are used to create a UUID for messages, leading to potential collisions:  \n\nhttps://github.com/elizaOS/eliza/blob/227baf7bd62394a50ae261e934669e4a9520b87f/packages/client-telegram/src/messageManager.ts#L1266C2-L1268C23\n\n```typescript\nconst messageId = stringToUuid(message.message_id.toString() + \"-\" + this.runtime.agentId) as UUID;\n```\n\nIf the same `msg_id` is used in a different channel, the agent incorrectly assumes the memory already exists and skips creating a new memory:  \n\nhttps://github.com/elizaOS/eliza/blob/227baf7bd62394a50ae261e934669e4a9520b87f/packages/core/src/memory.ts#L172C1-L190C6\n\n```typescript\nasync createMemory(memory: Memory, unique = false): Promise<void> {\n    // TODO: check memory.agentId == this.runtime.agentId\n\n    const existingMessage =\n        await this.runtime.databaseAdapter.getMemoryById(memory.id);\n\n    if (existingMessage) {\n        elizaLogger.debug(\"Memory already exists, skipping\");\n        return;\n    }\n}\n```\n\n**To Reproduce**  \n1. Use the same `msg_id` in a different chat or channel (e.g., in Telegram).  \n2. Attempt to create a memory for the new message.  \n3. Observe that the memory creation is skipped due to the `msg_id` collision.  \n\n**Expected behavior**  \nMemory creation should account for different channels or rooms. The system should generate a unique `UUID` by including the `room_id` in the `msg_id` creation process to avoid collisions.  \n\n**Screenshots**  \n\nWe encountered an issue in Telegram where the message already existed for a different user.\n\n### A log before memory creation:\n\n<img width=\"1091\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/c659c325-55aa-424e-aa68-2423754229b0\" />\n\n### It's clearly visible that even with the same message ID, the room and user are different:\n\n<img width=\"860\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/4d2a1e1f-a56a-4bbd-851c-e9fcd08d5fbc\" />\n\n**Suggested solution**    \nA potential solution would be updating the UUID creation logic to replace `agent_id ` with `room_id` in addition to `msg_id` becuase `room_id` is generated based on `agent_id` already. However, further research is needed to confirm whether collisions involving `room_id` are possible.  \n\nAlso further investigation is needed to verify if collisions are possible in other clients.", "CLOSED", 0, "nicky-ru", "2025-01-26T10:35:39Z", "2025-01-30T17:06:39Z", "2025-01-30T17:06:37Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6nYvJ-", 2726, "chat window at localhost : 5173 only works on port 3000, not any other port", "**Describe the bug**\n\nI was trying to set `SERVER_PORT=3005` in my .env file and when I bring up the chat window via `pnpm start:client` it shows `disconnected`.  When I finally tried switching it back to 3000 it worked perfectly.  Why have a setting in .env if it is hard-coded?\n\n**To Reproduce**\n\nTry setting the port to anything other than 3000 and the chat window won't connect.\n\n**Expected behavior**\n\nThe chat window should connect to the agent.\n\n**Screenshots**\n\n<img width=\"422\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a7f5f257-2aa0-4b68-8ff1-ef57521a078b\" />\n\n**Additional context**\n\nnone", "CLOSED", 0, "rogerjbos", "2025-01-24T01:19:17Z", "2025-01-28T05:39:22Z", "2025-01-28T05:39:20Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6nXJAA", 2721, "@elizaos/plugin-tee-log@0.1.8 has incorrect workspace dependency reference", "**Describe the bug**\nInstallation fails when using pnpm due to an incorrect workspace dependency reference in `@elizaos/plugin-tee-log@0.1.8`. The package incorrectly references `@elizaos/core` using a workspace protocol (`workspace:*`) instead of a proper version number.\n\n**To Reproduce**\n1. Create a new project\n2. Add the following to package.json:\n```json\n{\n  \"dependencies\": {\n    \"@elizaos/adapter-supabase\": \"0.1.8\",\n    \"@elizaos/client-discord\": \"0.1.8\",\n    \"@elizaos/client-direct\": \"0.1.8\",\n    \"@elizaos/core\": \"0.1.8\",\n    \"@elizaos/plugin-bootstrap\": \"0.1.8\",\n    \"@elizaos/plugin-node\": \"0.1.8\"\n  }\n}\n```\n3. Run `pnpm install`\n4. Observe the error:\n```bash\nERR_PNPM_WORKSPACE_PKG_NOT_FOUND  In : \"@elizaos/core@workspace:*\" is in the dependencies but no package named \"@elizaos/core\" is present in the workspace\n\nThis error happened while installing the dependencies of @elizaos/client-direct@0.1.8\n at @elizaos/plugin-tee-log@0.1.8\n```\n\n**Expected behavior**\nThe package should install successfully using pnpm. The `@elizaos/plugin-tee-log` package should reference `@elizaos/core` using a proper version number (e.g. \"0.1.8\") instead of using workspace protocol.\n\n**Additional context**\n- Error occurs in `@elizaos/plugin-tee-log@0.1.8` which is a dependency of `@elizaos/client-direct@0.1.8`\n- Attempted workarounds:\n  - Using different package managers (npm, yarn, pnpm)\n  - Configuring .npmrc with various workspace settings\n  - Trying to disable workspace protocol resolution\n- Using yarn instead of pnpm appears to work around the issue\n- Environment:\n  - OS: macOS 21.6.0\n  - Package Manager: pnpm\n  - Node.js version: [22.13.1]\n```\n", "CLOSED", 0, "genialtechie", "2025-01-23T20:40:47Z", "2025-01-28T22:59:37Z", "2025-01-28T22:59:37Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6mlcXF", 2423, "Unexpected JSON Metadata in Twitter Bot Replies", "**Describe the bug**\n\nThe Eliza OS Twitter bot is responding with additional metadata in the tweet replies, instead of just the intended message text.\n\n**To Reproduce**\n\n1. Set up and run the Eliza OS Twitter bot\n2. Trigger a response from the bot\n3. Observe the bot's reply tweet\n\n**Expected behavior**\n\nThe bot should reply with only the intended message text, e.g.:\n\"Agreed, decentralized information dissemination is crucial for a free society.\"\n\n**Screenshots**\n\n<img width=\"592\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/37749127-917c-4c60-ba0d-8ed35880c4b4\" />\n\n**Additional context**\n\n{```\n\n  \"user\": \"LumixAgent\",\n  \"text\": \"Agreed, decentralized information dissemination is crucial for a free society.\"\n}\n\n```", "CLOSED", 0, "jeongtai", "2025-01-17T08:08:45Z", "2025-01-28T01:52:26Z", "2025-01-28T01:52:25Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6l_dT7", 2253, "getRecentPostInteractions returning all memory", "**Is your feature request related to a problem? Please describe.**\r\n\r\nI`m not sure if this is a BUG or intent, but looks like runtime.ts getRecentPostInteractions return all memory. It was overloading my model with more than 20k tokens each time it try to create a new post.\r\n\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\nSo, it stopped creating new posts due Model Rate Limits per minute.\r\n\r\n**Describe the solution you'd like**\r\n\r\nA workarround i found so far, was to limit the getRecentPostInteractions with a setting like this:\r\n\r\n```\r\nconst getRecentPostInteractions = async (\r\n            recentInteractionsData: Memory[],\r\n            actors: Actor[]\r\n        ): Promise<string> => {\r\n            const limit = this.character.settings?.recentInteractionsLimit ?? 20;  // Included limit here\r\n            const limitedInteractions = recentInteractionsData.slice(-limit);\r\n            const formattedInteractions = formatPosts({\r\n                messages: recentInteractionsData,\r\n                actors,\r\n                conversationHeader: true,\r\n            });\r\n\r\n            return formattedInteractions;\r\n        };\r\n```\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\n\r\nI`m not sure if is the best solution as i`m still learning Eliza Framework. Maybe a more experience dev can check on that.\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "rferrari", "2025-01-13T18:16:25Z", "2025-02-02T15:43:53Z", "2025-01-14T01:10:41Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6l3X_F", 2223, "Bug Report - pnpm buid : Failed client#build", "Hello! Since the new update, I can no longer launch an agent because I get errors on : pnpm build\r\n\r\n![image](https://github.com/user-attachments/assets/c8b4127b-9678-48b8-8a49-d273fa76ee12)\r\n\r\nMy config : \r\nNode v23.6.0\r\npnpm v9.15.3\r\nWindows 11\r\n\r\nWhat I tried:\r\nClone the project on a blank version of WSL2 and follow the installation procedure\r\n\r\nI have no error on the pnpm install command line and without the build I can't run any agent (which is obvious I guess): \r\n\r\n![image](https://github.com/user-attachments/assets/ddf1df4b-1731-48e5-b411-ef7f52d8465c)\r\n", "CLOSED", 0, "Hugo-SEQUIER", "2025-01-12T23:39:50Z", "2025-01-30T20:48:43Z", "2025-01-14T01:39:29Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6lwC4V", 2126, " Refactor: Separate Data Providers into Plugins", "## Description:\r\nCurrently, the wallet provider contains multiple hardcoded data sources (BirdEye, Codex) which makes the code:\r\nHard to maintain\r\nDifficult to test\r\nIt is not flexible for users who want to use different data sources\r\n\r\n### Proposed Solution:\r\nCreate a plugin system for data providers:\r\n\r\n```\r\n// Example structure:\r\ninterface TokenDataProvider {\r\n    getTokenPrices(tokens: string[]): Promise<Prices>;\r\n    getWalletTokens(wallet: string): Promise<WalletData>;\r\n}\r\n\r\nclass BirdEyeProvider implements TokenDataProvider {\r\n    // BirdEye specific implementation\r\n}\r\n\r\nclass CodexProvider implements TokenDataProvider {\r\n    // Codex specific implementation\r\n}\r\n```\r\n\r\nBenefits:\r\nEasy to add new data providers\r\nUsers can choose their preferred data source\r\n3. Better testing isolation\r\nCleaner code organization\r\n\r\n```\r\nexport class WalletProvider {\r\n    constructor(\r\n        private connection: Connection,\r\n        private walletPublicKey: PublicKey,\r\n        private dataProvider: TokenDataProvider // \ud83d\udc48 Inject provider\r\n    ) {\r\n        this.cache = new NodeCache({ stdTTL: 300 });\r\n    }\r\n\r\n    async fetchPortfolioValue(runtime): Promise<WalletPortfolio> {\r\n        // Use injected provider instead of hardcoded API calls\r\n        const data = await this.dataProvider.getWalletTokens(\r\n            this.walletPublicKey.toBase58()\r\n        );\r\n        // ... rest of the logic\r\n    }\r\n}\r\n\r\n```", "CLOSED", 0, "daizhengxue", "2025-01-10T18:33:46Z", "2025-02-01T13:31:17Z", "2025-02-01T13:31:17Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6lUmF0", 1986, "Error handling message: SqliteError: Error reading 1st vector: zero-length vectors are not supported.", "**Describe the bug**\r\n\r\nWorking off of Shaw's youtube tutorials I have created a GET_NEWS action. The action is functional on its own _without_ creating a new memory from the news api response to log into SQLite. The moment I create a new memory from the response of the News API is when the error occurs. \r\n\r\n**To Reproduce**\r\nCreate a currentNews action using code like below, call createMemory. \r\n```\r\nimport {\r\n    ActionExample,\r\n    Content,\r\n    generateText,\r\n    HandlerCallback,\r\n    IAgentRuntime,\r\n    Memory,\r\n    ModelClass,\r\n    State,\r\n    elizaLogger,\r\n    type Action\r\n} from \"@elizaos/core\";\r\n\r\nconst newsApiKey = \"$process.env.NEWS_API_KEY\";\r\nasync function getCurrentNews(searchTerm: string) {\r\n    const response = await fetch(`https://newsdata.io/api/1/latest?apikey=${newsApiKey}2&q=${searchTerm}`);\r\n    const data = await response.json();\r\n    return data.results\r\n        .slice(0, 3)\r\n        .map(\r\n            (article: any) =>\r\n                `${article.title} - ${article.description} - ${article.link}`)\r\n        .join(\"\\n\\n\");\r\n}\r\n\r\nexport const currentNewsAction: Action = {\r\n    name: \"CURRENT_NEWS\",\r\n    similes: [\r\n        \"NEWS\", \"GET_NEWS\", \"CURRENT_NEWS\", \"GET_CURRENT_NEWS\", \"GET_CURRENT_NEWS_ARTICLES\", \"GET_CURRENT_NEWS_ARTICLES_FOR_SEARCH_TERM\"\r\n    ],\r\n    validate: async (_runtime: IAgentRuntime, _message: Memory) => {\r\n        return true;\r\n    },\r\n    description:\r\n        \"Get the current news\",\r\n    handler: async (\r\n        _runtime: IAgentRuntime,\r\n        _message: Memory,\r\n        _state: State,\r\n        _options: { [key: string]: unknown; },\r\n        _callback: HandlerCallback\r\n    ): Promise<boolean> => {\r\n        const context = `\r\n            Extract the search term from the user's message. The message is:\r\n            ${_message.content.text}\r\n            Only respond with the search term, do not include any other text.\r\n        `;\r\n        const searchTerm = await generateText({\r\n            runtime: _runtime,\r\n            context,\r\n            modelClass: ModelClass.SMALL,\r\n            stop: [\"\\n\"],\r\n        });\r\n        const currentNews = await getCurrentNews(searchTerm);\r\n        const responseText = `\r\n            The current news for ${searchTerm} is:\r\n            ${currentNews}\r\n        `;\r\n\r\n        // save this chunk of news into the agent's memory to build context\r\n        const newMemory: Memory = {\r\n            userId: _message.userId,\r\n            agentId: _message.agentId,\r\n            content: {\r\n                text: responseText,\r\n                action: \"CURRENT_NEWS_RESPONSE\",\r\n                source: _message.content?.source,\r\n            } as Content,\r\n            roomId: _message.roomId,\r\n        };\r\n\r\n        await _runtime.messageManager.createMemory(newMemory);\r\n\r\n        _callback(newMemory.content);\r\n\r\n        return true;\r\n    },\r\n    examples: [\r\n        [\r\n            {\r\n                user: \"{{user1}}\",\r\n                content: { text: \"What's happening in the news?\" },\r\n            },\r\n            {\r\n                user: \"{{user2}}\",\r\n                content: { text: \"\", action: \"CURRENT_NEWS\" },\r\n            },\r\n        ]\r\n    ] as ActionExample[][]\r\n} as Action;\r\n\r\n```\r\n\r\n**Expected behavior**\r\n\r\nI expect to receive the response from the agent into my discord channel like I was previously PRIOR to creating a memory from the news API response. \r\n\r\n**Screenshots**\r\nMy memory and tablename all have information. I'm not sure what/where the zero vector issue is coming from. \r\n<img width=\"953\" alt=\"Screenshot 2025-01-07 at 3 01 22\u202fPM\" src=\"https://github.com/user-attachments/assets/0cfa8bc8-594a-4247-90b0-90e8006a3179\" />\r\n\r\n**Additional context**\r\nThe error. \r\n<img width=\"1021\" alt=\"Screenshot 2025-01-07 at 3 02 23\u202fPM\" src=\"https://github.com/user-attachments/assets/444ca7de-15a8-4fde-9fce-eb5b8961ed28\" />\r\n\r\n", "CLOSED", 0, "tetreault", "2025-01-07T20:03:42Z", "2025-01-27T10:31:31Z", "2025-01-23T00:27:05Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6lACeF", 1780, "Public Solana Wallet Not Found! ", "An error occurs at random times when the Agent tries to scan tokens for reccomendations. \r\n\r\nHard to reproduce as it allows wallet interaction for swapping tokens, but not for scanning\r\n\r\nim expecting it to simply scan the token for trust and such, and respond if its a good buy or not.\r\n\r\n![image](https://github.com/user-attachments/assets/14f14666-aa2b-4e8e-b186-9cd889a35d7d)\r\n\r\nI have put my public key in .env and in secrets character file. it still gives the error\r\n\r\n\r\nThis is the code of the error \r\n\r\nrecommendations [\r\n  {\r\n    recommender: '6e60c',\r\n    ticker: 'GATSU',\r\n    contractAddress: null,\r\n    type: 'buy',\r\n    conviction: 'high',\r\n    alreadyKnown: false\r\n  },\r\n  {\r\n    recommender: '6e60c',\r\n    ticker: 'GOAT',\r\n    contractAddress: 'CzLSujWBLFsSjncfkh59rUFqvafWcY5tzedWJSuypump',\r\n    type: 'buy',\r\n    conviction: 'medium',\r\n    alreadyKnown: false\r\n  }\r\n]\r\nCache miss for fetchPortfolioValue\r\nCache miss for fetchPrices\r\nFetching DexScreener data for symbol: GATSU\r\nSettings object: undefined\r\n \u25ce LOGS\r\n   Creating Memory \r\n    \r\n   {\"recommender\":\"6e60c\",\"ticker\":\"GATSU\",\"contractAddress\":\"CYB7W8qWvRcVoYnZKRcvKqzziT6ndT771hBs342jpump\",\"type\":\"buy\",\"conviction\":\"high\",\"alreadyKnown\":false} \r\n\r\nrecommendationsManager {\r\n  recommender: '6e60c',\r\n  ticker: 'GATSU',\r\n  contractAddress: 'CYB7W8qWvRcVoYnZKRcvKqzziT6ndT771hBs342jpump',\r\n  type: 'buy',\r\n  conviction: 'high',\r\n  alreadyKnown: false\r\n}\r\nReturning cached DexScreener data.\r\nReturning cached prices.\r\n \u26d4 ERRORS\r\n   \u274c Error handling message: \r\n   {} \r\n\r\n \u26d4 ERRORS\r\n   Error sending message: \r\n   {} \r\n\r\nfile:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:55\r\n            throw new Error(\"Public key not found in settings. Ensure SOLANA_PUBLIC_KEY or WALLET_PUBLIC_KEY is defined.\");\r\n                  ^\r\n\r\nError: Public key not found in settings. Ensure SOLANA_PUBLIC_KEY or WALLET_PUBLIC_KEY is defined.\r\n    at getWalletKey (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:55:19)\r\n    at SimulationSellingService.initializeWalletProvider (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:1332:37)\r\n    at new SimulationSellingService (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:1237:14)\r\n    at new TrustScoreManager (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:1583:41)\r\n    at Object.handler (file:///Users/tylerlloyd/Desktop/eliza-main/packages/plugin-solana/dist/index.js:2128:35)\r\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\r\n    at async AgentRuntime.evaluate (file:///Users/tylerlloyd/Desktop/eliza-main/packages/core/dist/index.js:3860:17)\r\n    at async MessageManager.handleMessage (file:///Users/tylerlloyd/Desktop/eliza-main/packages/client-telegram/dist/index.js:735:13)\r\n    at async file:///Users/tylerlloyd/Desktop/eliza-main/packages/client-telegram/dist/index.js:867:17\r\n    at async execute (/Users/tylerlloyd/Desktop/eliza-main/node_modules/telegraf/lib/composer.js:518:17)\r\n\r\nNode.js v23.3.0\r\n/Users/tylerlloyd/Desktop/eliza-main/agent:\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.7-alpha.2 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/gatsu.character.json\"`\r\nExit status 1\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.", "CLOSED", 0, "CryptoGatsu", "2025-01-03T22:29:57Z", "2025-02-01T14:24:06Z", "2025-01-12T11:05:06Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6kYkBp", 1434, "Add Liquid Staking Action to the Solana Plugin", "\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, there are various liquid staking protocols on Solana, but users or developers often need to build dedicated front-end solutions or switch between multiple platforms to compare APYs and select the appropriate protocol before staking. This process is tedious and increases front-end development complexity, making it cumbersome for users.\r\n\r\n**Describe the solution you'd like**\r\n\r\n- Add the ability for liquid staking to the existing ElizaOS Solana plugin, simplifying the process of building staking requests for users without requiring specialized front-end logic.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n- Continue relying on each protocol\u2019s custom front-end or having developers integrate multiple protocols manually. This leads to high complexity and development cost.  \r\n- Have users manually compare different platforms\u2019 APYs, which can be error-prone and inconvenient.\r\n\r\n**Additional context**\r\n\r\n", "CLOSED", 0, "FWangZil", "2024-12-24T14:58:25Z", "2025-01-31T18:31:54Z", "2025-01-31T18:31:54Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6kTB5N", 1405, "FerePro Plugin for Eliza", "# Is your feature request related to a problem? Please describe.\r\n\r\nWe'd like to extend Eliza's capabilities with FerePro Agent. FerePro is an agent developed by [FereAI](https://www.fereai.xyz) which can perform open world Q&A related to various crypto topics like - Token Research, Investment Decisions, KOL research, category research, actions (swap, trade and more). It can interpret and answer questions of various complexities. We believe that adding this as a plugin will significantly improve Eliza's capabilities to perform research and Q&A.\r\n\r\n# Describe the solution you'd like\r\n\r\nA Plugin for FerePro in Eliza's codebase.\r\n\r\n# Describe alternatives you've considered\r\n\r\nAs an alternate, we will need to add a lot of tools and multi agentic capabilities to Eliza. FerePro can abstract all of that. \r\nDisclaimer: I'm a co founder and core dev at FereAI.\r\n\r\n# Additional context\r\n\r\n## Architecture\r\n\r\n1. FerePro APIs can provide streaming answer as well as non streaming answer. This plugin must support both the use cases.\r\n2. FerePro APIs also provide a bunch of intermediate responses. This is usually shown in UI for users to get a view of happenings behind the scenes. They should only be enabled when this plugin is run in debug mode. Developers can use this info to troubleshoot or get support from Fere team.\r\n\r\n\r\n## Others\r\n\r\n1. Developers will need to [get API keys from FereAI](https://docs.fereai.xyz/docs/api/api_access). \r\n3. This key must be passed to the plugin for it to work.\r\n4. FerePro is a freemium API. There is a limit on questions that can be asked for free. (We can revise the limits based on community feedback). For extended use cases, the developers must top up their account by visiting fereai.xyz.\r\n\r\n", "CLOSED", 0, "r4881t", "2024-12-23T17:16:40Z", "2025-01-30T18:32:14Z", "2025-01-30T18:32:14Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6kI-BE", 1319, "docs: add TEE verifiable logs to Eliza in TEE section", "**Is your feature request related to a problem? Please describe.**\r\nTEE Plugin will have verifiable logs soon. #1259 This will need to be documented for devs to understand how to enable it.\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the solution you'd like**\r\nSeparate Eliza in TEE doc into to two Plugin Sections and add verifiable log section with some acknowledgements.\r\n\r\n- TEE Plugin\r\n   - Core Components\r\n- TEE Verifiable Log Plugin\r\n   - Core Components\r\n- Tutorial\r\n   - Enable Verifiable Log\r\n- Conclusion\r\n   - Mention contributors for implementation and who to reach out to learn more about Verifiable Logs in TEE\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\nThere is no alternative. We must document.\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "HashWarlock", "2024-12-21T07:04:54Z", "2025-01-27T05:43:06Z", "2025-01-27T05:43:06Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6kI1W4", 1309, "Incorporating Trading View Charts into Autonomous Trading Tweets via things like goat plugin ", "Is your feature request related to a problem? Please describe.\r\nThere is currently no seamless integration between TradingView charts and automated tweeting using the GOAT plugin. This makes it cumbersome to share real-time insights, chart setups, or trade ideas directly from TradingView to Twitter with minimal effort. The process involves manual screenshotting and posting, which is time-consuming and disrupts workflow efficiency.\r\n\r\nDescribe the solution you'd like\r\nI would like to see TradingView API integrated with the GOAT plugin to enable automatic or one-click sharing of annotated charts to Twitter. The solution should:\r\n\r\nFetch chart data, annotations, and other custom elements from TradingView via API.\r\nFormat the content appropriately for Twitter, including text captions for context and hashtags.\r\nProvide options to schedule or instantly post tweets from TradingView without switching between platforms.\r\nInclude settings for customization, such as default hashtags, watermarking charts, or adding predefined text templates.\r\nDescribe alternatives you've considered\r\n\r\nManual Process: Manually screenshotting charts and uploading them to Twitter, but this is inefficient and lacks automation.\r\nThird-party Tools: Using standalone apps like TweetDeck or social media managers, but these don't integrate with TradingView's annotations directly.\r\nCustom Scripts: Writing scripts to automate the TradingView-to-Twitter flow, but this requires significant development time and is not as user-friendly as a plugin-based solution.\r\nAdditional context\r\n\r\nTradingView provides an API that can retrieve chart data and render annotations, which can streamline integration.\r\nThe GOAT plugin already has a Twitter API integration, so extending its capabilities to include TradingView should be feasible.\r\nThis feature could significantly enhance the usability of both tools for traders and content creators.\r\nScreenshot or visual example of an ideal tweet with TradingView integration for reference:\r\n(Include a hypothetical example showing how a TradingView chart and description would appear in a tweet.)\r\n\r\n\r\n\r\n\r\n\r\n", "CLOSED", 0, "monilpat", "2024-12-21T05:37:59Z", "2025-01-27T18:32:32Z", "2025-01-27T18:32:32Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6kIvWW", 1304, "Allow to use local embedding instead of OpenAI when using OpenAI models", "**Is your feature request related to a problem? Please describe.**\r\n\r\nWhen using OpenAI models, I still want to use local embedding instead of OpenAI's one.\r\nSince models for OpenAI's embedding are different from those in text generation, there is no reason to force the use of its when using OpenAI models.\r\n\r\n**Describe the solution you'd like**\r\n\r\nChange `getEmbeddingType` function to only select OpenAI if explicitly set `USE_OPENAI_EMBEDDING` env.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n**Additional context**\r\n", "CLOSED", 0, "peara", "2024-12-21T04:40:31Z", "2025-01-27T18:32:33Z", "2025-01-27T18:32:33Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6j23px", 1223, "chore: Review TODO notes", "**Describe the bug**\r\n\r\nSee what the TODO notes are about, update their status or document as an issue if needed\r\n\r\n- [ ] agent/src/index.ts\r\n- [ ] packages/core/src/models.ts\r\n- [ ] packages/core/src/runtime.ts\r\n- [ ] packages/core/src/environment.ts\r\n- [ ] packages/core/src/memory.ts\r\n- [ ] packages/plugin-starknet/src/providers/trustScoreProvider.ts\r\n- [ ] packages/plugin-starknet/src/providers/token.ts\r\n- [ ] packages/plugin-starknet/src/actions/takeOrder.ts\r\n- [ ] packages/plugin-starknet/src/actions/transfer.ts\r\n- [ ] packages/plugin-starknet/readme.md\r\n- [ ] packages/adapter-sqlite/src/sqliteTables.ts\r\n- [ ] packages/adapter-sqljs/src/index.ts\r\n- [ ] packages/adapter-sqljs/src/sqliteTables.ts\r\n- [ ] packages/plugin-node/src/services/transcription.ts\r\n- [ ] packages/plugin-node/src/services/browser.ts\r\n- [ ] packages/client-twitter/src/search.ts\r\n- [ ] packages/client-twitter/src/base.ts\r\n- [ ] packages/plugin-solana/src/evaluators/trust.ts\r\n- [ ] packages/plugin-solana/src/providers/trustScoreProvider.ts\r\n- [ ] packages/plugin-solana/src/actions/swap.ts\r\n- [ ] packages/plugin-solana/src/actions/takeOrder.ts\r\n- [ ] packages/plugin-evm/src/actions/bridge.ts\r\n- [ ] packages/plugin-evm/src/actions/swap.ts\r\n- [ ] packages/plugin-flow/src/types/fcl.d.ts\r\n- [ ] packages/plugin-flow/src/actions/transfer.ts\r\n- [ ] packages/plugin-nft-generation/src/index.ts\r\n- [ ] packages/plugin-image-generation/src/index.ts\r\n- [ ] packages/client-farcaster/src/client.ts\r\n- [ ] packages/adapter-supabase/src/index.ts\r\n- [ ] packages/client-lens/src/actions.ts\r\n- [ ] packages/client-lens/src/client.ts\r\n- [ ] packages/client-lens/src/interactions.ts\r\n- [ ] packages/client-discord/src/utils.ts\r\n- [ ] packages/client-discord/src/attachments.ts\r\n- [ ] packages/client-discord/src/messages.ts\r\n- [ ] packages/client-discord/src/actions/chat_with_attachments.ts\r\n- [ ] packages/client-discord/src/actions/summarize_conversation.ts\r\n- [ ] packages/client-slack/src/events.ts\r\n\r\n\r\n**To Reproduce**\r\n\r\nTo find the files to fix:\r\n\r\n`grep -ro \"TODO\" --exclude-dir=node_modules --exclude-dir=dist | uniq` \r\n\r\nSome examples `grep -roP \"TODO\\s*.*\" --exclude-dir=node_modules`\r\n```\r\nagent/src/index.ts:TODO: Add Slack client to the list\r\npackages/core/dist/index.js:TODO: check\r\npackages/core/dist/index.js:TODO: ?download=true\r\npackages/client-discord/src/utils.ts:TODO: clean this up\r\npackages/client-discord/src/attachments.ts:TODO: clean this up\r\npackages/client-discord/src/messages.ts:TODO: This is throwing an error but seems to work?\r\npackages/client-discord/src/messages.ts:TODO: Move to attachments manager\r\npackages/client-discord/src/actions/chat_with_attachments.ts:TODO: make this dynamic and generic\r\npackages/client-discord/src/actions/summarize_conversation.ts:TODO: parse start and end into timestamps\r\npackages/client-slack/src/events.ts:TODO: Implement reaction handling\r\n```\r\n\r\n**Expected behavior**\r\n\r\ngithub issue or cleaning up the code\r\n\r\n**Screenshots**\r\n\r\n![image](https://github.com/user-attachments/assets/ed48b42c-7701-4432-a284-5e8143f93227)\r\n\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "madjin", "2024-12-19T01:50:45Z", "2025-01-28T18:32:21Z", "2025-01-28T18:32:21Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6jvwwA", 1200, "chore: Document Missing Plugin Documentation and Examples", "**Overview**\r\nSeveral plugins in the Eliza framework lack comprehensive documentation. This makes it harder for new developers to understand and utilize these components.\r\n\r\nMissing Plugin Documentation:\r\n- [ ] plugin-0g - File storage plugin\r\n- [ ] plugin-aptos - Aptos blockchain integration\r\n- [ ] plugin-conflux - Conflux blockchain integration  \r\n- [ ] plugin-echochambers - Echo chamber client\r\n- [ ] plugin-flow - Flow blockchain integration\r\n- [ ] plugin-goat - GOAT functionality\r\n- [ ] plugin-icp - Internet Computer integration\r\n- [ ] plugin-image-generation - Image generation capabilities\r\n- [ ] plugin-intiface - Intiface integration\r\n- [ ] plugin-multiversx - MultiversX blockchain \r\n- [ ] plugin-near - NEAR Protocol integration\r\n- [ ] plugin-nft-generation - NFT creation functionality\r\n- [ ] plugin-story - Story/IP management\r\n- [ ] plugin-sui - Sui blockchain integration\r\n- [ ] plugin-ton - TON blockchain integration\r\n- [ ] plugin-trustdb - Trust database functionality\r\n- [ ] plugin-video-generation - Video generation features\r\n- [ ] plugin-web-search - Web search capabilities\r\n- [ ] plugin-whatsapp - WhatsApp integration\r\n- [ ] plugin-zksync-era - zkSync Era integration\r\n\r\n**Proposed Documentation Structure**\r\nFor each plugin, we need:\r\n1. Overview and purpose\r\n2. Installation instructions\r\n3. Configuration requirements\r\n4. Usage examples\r\n5. API reference\r\n6. Common issues/troubleshooting\r\n\r\n**Additional Missing Docs**\r\n- Examples folder documentation\r\n- Testing guide expansion\r\n- Plugin development guide\r\n- Security best practices\r\n- Performance optimization guide\r\n\r\n**Value Add**\r\nThis documentation will:\r\n- Improve developer onboarding\r\n- Reduce support questions\r\n- Enable faster plugin adoption\r\n- Help maintain code quality", "CLOSED", 0, "madjin", "2024-12-18T08:59:15Z", "2025-01-27T06:04:02Z", "2025-01-27T05:41:15Z", "elizaos/eliza", "2025-04-14 21:51:24"]
["I_kwDOMT5cIs6pMXHl", 3365, "cors and multer dependencies are missing in the @elizaos/agent package", "**Describe the bug**\nThe @elizaos/agent package is not building correctly, it's missing cors and multer dependencies at \"packages/agent/package.json\"\n\n**BEFORE**\n```\n    \"dependencies\": {\n        \"@elizaos/core\": \"workspace:*\",\n        \"@elizaos/plugin-bootstrap\": \"workspace:*\",\n        \"minipass\": \"7.1.2\",\n        \"readline\": \"1.3.0\",\n        \"ws\": \"8.18.0\",\n        \"yargs\": \"17.7.2\"\n    },\n```\n\n**AFTER***\n```\n    \"dependencies\": {\n        \"@elizaos/core\": \"workspace:*\",\n        \"@elizaos/plugin-bootstrap\": \"workspace:*\",\n        \"cors\": \"^2.8.5\",\n        \"minipass\": \"7.1.2\",\n        \"multer\": \"^1.4.5-lts.1\",\n        \"readline\": \"1.3.0\",\n        \"ws\": \"8.18.0\",\n        \"yargs\": \"17.7.2\"\n    },\n```\n\n<!-- A clear and concise description of what the bug is. -->\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n```sh\n- bun install && bun run build\n- bun start\n```\n\n**Expected behavior**\n\n![Image](https://github.com/user-attachments/assets/195f6d2b-37a3-4e79-ab58-a17a53aaa451)\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "sekmet", "2025-02-07T16:34:42Z", "2025-02-08T13:11:53Z", "2025-02-08T13:11:52Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6pA-ad", 3322, "Latest Build Failing", "**Describe the bug**\nBuild error from recent release.\n\n<!-- A clear and concise description of what the bug is. -->\n`src/clients/index.ts:20:53 - error TS2345: Argument of type 'import(\"/home/pi/eliza-starter/node_modules/.pnpm/@elizaos+core@0.1.9_@google-cloud+vertexai@1.9.2_@langchain+core@0.3.30_openai@4.78.1_z_3148df7f60711e0fb759cfeb471ef142/node_modules/@elizaos/core/dist/index\").IAgentRuntime' is not assignable to parameter of type 'import(\"/home/pi/eliza-starter/node_modules/.pnpm/@elizaos+core@0.1.7_@google-cloud+vertexai@1.9.2_@langchain+core@0.3.30_openai@4.78.1_z_6e8d85366ed36a40c5c7bd6f6c974ae7/node_modules/@elizaos/core/dist/index\").IAgentRuntime'.\n  Types of property 'modelProvider' are incompatible.\n    Type 'import(\"/home/pi/eliza-starter/node_modules/.pnpm/@elizaos+core@0.1.9_@google-cloud+vertexai@1.9.2_@langchain+core@0.3.30_openai@4.78.1_z_3148df7f60711e0fb759cfeb471ef142/node_modules/@elizaos/core/dist/index\").ModelProviderName' is not assignable to type 'import(\"/home/pi/eliza-starter/node_modules/.pnpm/@elizaos+core@0.1.7_@google-cloud+vertexai@1.9.2_@langchain+core@0.3.30_openai@4.78.1_z_6e8d85366ed36a40c5c7bd6f6c974ae7/node_modules/@elizaos/core/dist/index\").ModelProviderName'.\n      Property 'LMSTUDIO' is missing in type 'import(\"/home/pi/eliza-starter/node_modules/.pnpm/@elizaos+core@0.1.7_@google-cloud+vertexai@1.9.2_@langchain+core@0.3.30_openai@4.78.1_z_6e8d85366ed36a40c5c7bd6f6c974ae7/node_modules/@elizaos/core/dist/index\").ModelProviderName'.\n\n20     clients.push(await DiscordClientInterface.start(runtime));\n                                                       ~~~~~~~\n\n\nFound 1 error in src/clients/index.ts:20\n\n\u2009ELIFECYCLE\u2009 Command failed with exit code 2.\n`\n\n**To Reproduce**\n\nBuild from source using node v23.5.0, pnpm v 10.2.0, and python 3.11.2\n\n**Expected behaviour**\n\nI would assume the build completes and starts the UI or configuration editor? (Its my first time building the project)\n\n**Additional context**\n\nFrom the error it looks like an issue with the AI Models and an argument error. Is there another specific version of node, pnpm, or python i should be using?\n", "CLOSED", 0, "Mer-idium", "2025-02-06T13:54:51Z", "2025-02-07T10:25:03Z", "2025-02-07T10:25:03Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6o7rt3", 3295, "Discord client version not in sync with 0.1.9", "**Describe the bug**\n\npnpm build on eliza starter repo fails due to discord plugin version conflict:\n\n```\n$ pnpm build && pnpm start   \n\n> @elizaos/eliza-starter@0.1.9 build /Users/jonathantalmi/dev/eliza-starter\n> tsup src/index.ts --format esm --dts\n\nCLI Building entry: src/index.ts\nCLI Using tsconfig: tsconfig.json\nCLI tsup v8.3.5\nCLI Target: esnext\nESM Build start\nDTS Build start\nESM dist/index.js 27.48 KB\nESM \u26a1\ufe0f Build success in 235ms\nDTS \u26a1\ufe0f Build success in 807ms\nDTS dist/index.d.ts 269.00 B\n\n> @elizaos/eliza-starter@0.1.9 start /Users/jonathantalmi/dev/eliza-starter\n> tsc && node --loader ts-node/esm src/index.ts\n\nsrc/clients/index.ts:20:53 - error TS2345: Argument of type 'import(\"/Users/jonathantalmi/dev/eliza-starter/node_modules/.pnpm/@elizaos+core@0.1.9_@google-cloud+vertexai@1.9.3_@langchain+core@0.3.38_openai@4.83.0_w_400c998ea5b04952faad4360fe701faf/node_modules/@elizaos/core/dist/index\").IAgentRuntime' is not assignable to parameter of type 'import(\"/Users/jonathantalmi/dev/eliza-starter/node_modules/.pnpm/@elizaos+core@0.1.7_@google-cloud+vertexai@1.9.3_@langchain+core@0.3.38_openai@4.83.0_w_fd2bcd6812fd1e3b800382dc0dd7a646/node_modules/@elizaos/core/dist/index\").IAgentRuntime'.\n  Types of property 'modelProvider' are incompatible.\n    Type 'import(\"/Users/jonathantalmi/dev/eliza-starter/node_modules/.pnpm/@elizaos+core@0.1.9_@google-cloud+vertexai@1.9.3_@langchain+core@0.3.38_openai@4.83.0_w_400c998ea5b04952faad4360fe701faf/node_modules/@elizaos/core/dist/index\").ModelProviderName' is not assignable to type 'import(\"/Users/jonathantalmi/dev/eliza-starter/node_modules/.pnpm/@elizaos+core@0.1.7_@google-cloud+vertexai@1.9.3_@langchain+core@0.3.38_openai@4.83.0_w_fd2bcd6812fd1e3b800382dc0dd7a646/node_modules/@elizaos/core/dist/index\").ModelProviderName'.\n      Property 'LMSTUDIO' is missing in type 'import(\"/Users/jonathantalmi/dev/eliza-starter/node_modules/.pnpm/@elizaos+core@0.1.7_@google-cloud+vertexai@1.9.3_@langchain+core@0.3.38_openai@4.83.0_w_fd2bcd6812fd1e3b800382dc0dd7a646/node_modules/@elizaos/core/dist/index\").ModelProviderName'.\n\n20     clients.push(await DiscordClientInterface.start(runtime));\n                                                       ~~~~~~~\n\n\nFound 1 error in src/clients/index.ts:20\n```\n\n**To Reproduce**\nSet up the starter project as in the README\n\n**Expected behavior**\n\nSuccessful build\n**Screenshots**\n\n**Additional context**\n\nI fixed the bug by manually installing the 0.1.9 version of \"@elizaos/client-discord\": \"0.1.9\",", "CLOSED", 0, "jtalmi", "2025-02-06T00:15:23Z", "2025-02-06T00:20:11Z", "2025-02-06T00:20:11Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6o6ufH", 3292, "ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL.\u2009 Command failed with exit code 7", "hi there. I am encountering this error when running the agent. \n\n`pnpm I` and `pnpm build` run without problems, the error occurs after` pnpm start --character=\"/Users/main/Desktop/scripts/eliza/characters/character.json\u201d`\n\n<img width=\"1206\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/6d75167a-4482-41e4-abe6-0b574545c46d\" />\n\n**Additional context**\n\nmacOS, M4, Node.js 23.3.0\n", "CLOSED", 0, "sosi-fcfs", "2025-02-05T21:09:44Z", "2025-02-06T02:54:15Z", "2025-02-06T02:54:14Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6o38Fd", 3276, "Fix JSON syntax error in package.json causing pnpm install failure", "\n# **Describe the bug**  \nThe `package.json` file in the `plugin-solana-v2` package contains an incorrect trailing comma in the `devDependencies` section. This causes `pnpm install` to fail with the following error message:\n\n```\nERROR\u2009 Expected double-quoted property name in JSON at position 825 (line 26 column 5) while parsing '{    \"name\": \"@elizaos/plugin-solana-v2' in /Users/efecelik/eliza/packages/plugin-solana-v2/package.json\n```\n\n# **To Reproduce**  \nSteps to reproduce the behavior:  \n1. Navigate to the `plugin-solana-v2` package.  \n2. Run `pnpm install`.  \n3. Observe the error message indicating an invalid `package.json` format.\n\n# **Expected behavior**  \n`pnpm install` should run successfully without JSON parsing errors.\n\n# **Screenshots**  \n\n<img width=\"785\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/fbf1e679-47c7-49ee-8807-4197cef94410\" />\n\n# **Additional context**  \nThe issue is caused by a trailing comma after the last entry in the `devDependencies` section:\n\n```json\n\"vitest\": \"2.1.9\",\n```\n\nRemoving this comma resolves the issue:\n\n```json\n\"vitest\": \"2.1.9\"\n```\n\nA PR will be submitted to fix this syntax error. \ud83d\ude80\n\n---\n\n", "CLOSED", 0, "efeecllk", "2025-02-05T15:15:00Z", "2025-02-05T15:27:08Z", "2025-02-05T15:27:08Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6oyvt3", 3259, "Issues with Anime Character Prompt", "**Describe the issue**\nThe current prompt in the documentation contains inappropriate content and problematic design direction that needs to be addressed. The prompt promotes sexualization of female characters.\n\n**To Reproduce**\nCurrent problematic prompt in documentation:\n`A cute anime girl with big breasts and straight long black hair wearing orange T-shirt. The T-shirt has \"ai16z\" texts in the front. The girl is looking at the viewer`\n\nSource: https://github.com/elizaOS/eliza/blob/ffa4c1dcdacc096d5b451f246b53fbaa266b0f64/docs/docs/guides/configuration.md?plain=1#L149\n\n**Expected behavior**\n- Documentation should provide professional, respectful prompts that focus on relevant technical details\n- Character descriptions should avoid unnecessary sexualization\n- Grammar and formatting should be correct\n- Prompts should be clear and technically useful\n\n**Screenshots**\nN/A\n\n**Additional context**\nSuggested revision for the prompt:\n`Anime-style character wearing an orange t-shirt with \"ai16z\". Character has long black hair  and is facing forward.`\n\nKey changes:\n- Removed inappropriate physical descriptions\n- Fixed grammar (\"texts\")\n- Maintained essential design elements while focusing on professional presentation", "CLOSED", 0, "FloppyDisck", "2025-02-05T04:43:32Z", "2025-02-05T19:51:57Z", "2025-02-05T19:51:55Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6ow3gs", 3249, "plugin-cronos: test setup and coverage", "**Is your feature request related to a problem? Please describe.**\n\nThe Cronos plugin is expected to require comprehensive testing coverage for its balance and transfer actions. The current test suite should be enhanced to properly handle error cases, particularly around content generation and validation. The mocking strategy for these tests should be improved to ensure reliable and maintainable test cases.\n\n**Describe the solution you'd like**\n\nA robust test suite should be implemented with the following key components:\n* The balance and transfer action tests should be structured to validate successful operations\n* Error handling scenarios should be properly tested with appropriate mocking\n* Test cases should verify correct callback responses and error messages\n* The testing framework should be configured to handle asynchronous operations effectively\n* Mocking strategies should be implemented in a way that doesn't interfere with other test cases\n* Each test should clean up after itself to maintain test isolation\nThe implementation should follow best practices for TypeScript testing and maintain consistency with the existing codebase structure.\n\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-02-04T21:57:10Z", "2025-02-05T00:24:02Z", "2025-02-05T00:24:02Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6owwrF", 3246, "plugin-conflux: test coverage", "**Is your feature request related to a problem? Please describe.**\n\nThe plugin-conflux package currently has failing tests in the transfer and bridge transfer actions. These failures are primarily related to mock implementations not matching the expected behavior of the actual code. The test suite should properly validate the functionality of cryptocurrency transfers within the Conflux network, but the current implementation contains mismatches in data types, incorrect mock responses, and inconsistent error handling.\n\n**Describe the solution you'd like**\n\nA comprehensive test suite update should be implemented with the following improvements:\n1. Mock Implementation:\n    * The\u00a0generateObject\u00a0function should be properly mocked at the module level to ensure consistent behavior across all tests\n    * The mock data should strictly adhere to the\u00a0TransferSchema\u00a0type, with\u00a0amount\u00a0being a number instead of a string\n2. Test Cases:\n    * Success scenarios should be updated to properly validate the transaction flow, including the transaction hash in response messages\n    * Error handling tests should be enhanced to verify proper rejection of invalid content\n    * State management tests should be implemented to ensure proper handling of existing states\n3. Type Safety:\n    * All mock objects should strictly follow the defined TypeScript interfaces\n    * The\u00a0TransferContent\u00a0interface should be properly validated in all test cases\n4. Test Coverage:\n    * Additional test cases should be added to cover edge cases\n    * Each test should validate both the success/failure status and the exact format of callback messages\nThese improvements are expected to result in a more robust and maintainable test suite that accurately validates the plugin's functionality. The implementation should follow the project's established testing patterns using vitest and maintain consistency with the existing codebase structure.\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ai16z-demirix", "2025-02-04T21:39:36Z", "2025-02-05T00:25:08Z", "2025-02-05T00:25:08Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6owlGh", 3245, "twitter Post and reply formatting errors", "\nMy twitter agent is writing like this at posts and replies to people\n\n{ \"user\": \"XXXXX\", \"text\": \"Absolutely, @ethereum. Building on Ethereum means creating a future where technology and ethics go hand in hand. Whether it's DeFi, smart contracts, or new governance models, the potential is immense. I'm excited to see what we can achieve together.\n\nany fixes for this?", "CLOSED", 0, "KeenHero", "2025-02-04T21:10:50Z", "2025-02-06T01:23:58Z", "2025-02-06T01:23:58Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6owXJ4", 3244, "How to run the system with debug level logging?", "I tried: \n\n```\npnpm start --character=\"characters/g.character.json\" --loglevel debug\n```\n\nBut it doesn't work. ", "CLOSED", 0, "LinuxIsCool", "2025-02-04T20:40:34Z", "2025-02-05T13:43:56Z", "2025-02-05T13:43:56Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6oswmv", 3233, "Model configuration is not loaded from character file", "**Describe the bug**\n\nIt is currently not possible to override model configuration parameters via the character file. \n\n**To Reproduce**\n\nCreate a character.json file with the following `modelConfig` object \n\n```json\n    \"settings\": {\n        \"secrets\": {},\n        \"modelConfig\": {\n            \"maxInputTokens\": 256000,\n            \"maxOutputTokens\": 8196,\n            \"temperature\": 0.2,\n            \"frequency_penalty\": 0.0,\n            \"presence_penalty\": 0.0\n        },    \n        \"voice\": {\n            \"model\": \"en_US-female-medium\"\n        }\n```\n\n**Expected behavior**\n\nThe existing code base suggests that an override should be possible: https://github.com/TbLtzk/eliza/blob/bfe4fddffe95ba9f494a8203f7731504c05fe71f/packages/core/src/generation.ts#L373\n\nBut the `modelConfig` object is always undefined, I think because it's not included in the schema.\n\n**Additional context**\n\nI have a fix for this and could create a pull request: https://github.com/TbLtzk/eliza/commit/6216ff99c2e4f71952593894e20bfa2245df7afa\n\nI renamed `max_response_length` to `maxOutputTokens` to be consistent with the modelSettings. Further, I don't think that `modelConfig` is the ideal name for the object, but this is induced by the existing code base (see permalink above). I did not change that, for now.", "CLOSED", 0, "TbLtzk", "2025-02-04T13:40:39Z", "2025-02-06T11:06:38Z", "2025-02-06T11:06:38Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6ok6kH", 3202, "twitter agent", "I am making a twitter gent and I keep getting the error\n[2025-02-03 18:36:23] ERROR: Full error details:\n    code: \"ERR_INVALID_URL\"\n    input: \"/embeddings\"\n[2025-02-03 18:36:23] ERROR: Error generating new tweet:\n    code: \"ERR_INVALID_URL\"\n    input: \"/embeddings\"\n\n\nI tried diffrent llm api like google and hyperpolic because when using gaianet free service the error changed to can't find the server , please help", "CLOSED", 0, "midoan2", "2025-02-03T18:39:25Z", "2025-02-06T03:55:20Z", "2025-02-06T03:55:00Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6okYrF", 3201, "Twitter logging bug", "\n![Image](https://github.com/user-attachments/assets/cd301e6a-8666-499d-a92f-908db17e24b8)\n\nAfter successfully logging in, the system attempts to fetch tweets and generate a new tweet. However, an error occurs:\n\nThe log shows INFO: Successfully logged in.\nThen, ERROR: Connected to Twitter appears.\nWhen fetching search tweets, no results are obtained.\nFinally, an ERROR: Error generating new tweet message appears, but without any further details or explanation.\nAdditionally, even though the system indicates that it logged into Twitter, there is no login notification on my phone (which usually happens when logging in from a new device or app).\n\nTo Reproduce\nRun the script to log in to Twitter.\nObserve the logs showing \"Successfully logged in.\"\nAttempt to fetch tweets or post a new tweet.\nObserve that errors appear without clear details.\nCheck the Twitter account (from a phone) and notice that no login alert was received.\nExpected Behavior\nThe script should be able to fetch tweets successfully.\nA new tweet should be generated and posted without errors.\nA login notification should appear on my phone if the system is accessing my account.\nScreenshots\n(Attach the image of the error logs here)\n\nAdditional Context\nIt seems like the login process does not fully authenticate the session.\nThere are no detailed error logs explaining why fetching tweets or posting a tweet fails.\nIt is unclear if the authentication token is valid or if additional permissions are needed.", "CLOSED", 0, "illink7", "2025-02-03T17:26:57Z", "2025-02-06T15:47:22Z", "2025-02-04T12:15:36Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6okW9J", 3200, "Enhance Code Standards", "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nThe current codebase lacks consistent coding standards, which makes it difficult for new developers to onboard and contributes to potential bugs and maintainability issues.\n\n**Describe the solution you'd like**\n\nImplement standardized coding practices across the project. This includes:\n- Establishing naming conventions for variables and functions.\n- Enforcing consistent indentation and formatting.\n- Utilizing automated tools like ESLint for JavaScript or Prettier for formatting.\n- Creating a style guide that outlines best practices for writing code.\n\n**Describe alternatives you've considered**\n\nCurrently relying on individual developer preferences, which leads to inconsistencies and confusion.\n\n**Additional context**\n\nAdopting standardized coding practices will improve code readability, maintainability, and collaboration among team members.\n\n**Related Issues/PRs**\n- [Issue #123](https://github.com/elizaOS/eliza/issues/123) - Previous discussions on coding standards.", "CLOSED", 0, "SpiralAgent234", "2025-02-03T17:23:23Z", "2025-02-03T17:23:53Z", "2025-02-03T17:23:53Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6ojC_0", 3196, "Update Twitter to X (Twitter) in the README file", "Since Twitter is now rebranded to X, so I have changes made changes in the README file. It is now \"X (Twitter)\" and I kept the Twitter keyword since people still use the word Twitter.\n\nLabels: good first issue, documentation", "CLOSED", 0, "nilaysarma", "2025-02-03T14:58:37Z", "2025-02-03T15:59:49Z", "2025-02-03T15:59:49Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6obsAA", 3159, "@ai-sdk/provider-utils does not provide an export named 'delay'", "**Describe the bug**\n\nWhen I start eliza v0.1.9 patch 1 I encounter the error below:\n\n```bash\nfile:///*****/ai/eliza/node_modules/ai/dist/index.mjs:225\nimport { delay, getErrorMessage, isAbortError } from \"@ai-sdk/provider-utils\";\n         ^^^^^\nSyntaxError: The requested module '@ai-sdk/provider-utils' does not provide an export named 'delay'\n    at ModuleJob._instantiate (node:internal/modules/esm/module_job:180:21)\n    at async ModuleJob.run (node:internal/modules/esm/module_job:263:5)\n    at async onImport.tracePromise.__proto__ (node:internal/modules/esm/loader:547:26)\n    at async asyncRunEntryPointWithESMLoader (node:internal/modules/run_main:116:5)\n\nNode.js v23.3.0\n/Users/*****/ai/eliza/agent:\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.9 start: `node --loader ts-node/esm src/index.ts \"--isRoot\"`\nExit status 1\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\n```\n\n**To Reproduce**\n\n- Merge v0.1.9 patch 1 to my repo with custom changes\n- Start with a custom or default character\n\n**Expected behavior**\n\n- It should work\n", "CLOSED", 0, "medardm", "2025-02-02T14:27:42Z", "2025-02-03T05:17:38Z", "2025-02-03T05:17:37Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6obChN", 3154, "Strange behavior of Fetch method in eliza", "I don't know, but Eliza has done something to the fetch method! Below I explain why!\n\nI am trying to add the image upload feature to the Twitter client. I have passed data as `agent-twitter-client` library accepts, but when I call it I get this error \n```\n {\"errors\":[{\"code\":38,\"message\":\"media parameter is missing.\"}]}\n```\n\nI did extensive debugging. I cloned the `agent-twitter-client` and loaded it as a local dependency in eliza package.json.\n```\n        \"agent-twitter-client\": \"file:/Users/amin/Downloads/agent-twitter-client\",\n```\nI put some logs at upload points in the `agent-twitter-client` and executed its tests, including image uploading. \nI could upload images by running this repo tests. But when I try to use it through eliza, I got the aforementioned error.\n\nIt's the upload point in the `agent-twitter-client`\n\n```ts\n    console.log({\n      uploadUrl,\n      p: {\n        method: 'POST',\n        headers,\n        body: form,\n      },\n    });\n\n    const response = await fetch(uploadUrl, {\n      method: 'POST',\n      headers,\n      body: form,\n    });\n```\n\nThe console.log output is the same for running the `agent-twitter-client` test and the Eliza agent.\n\n\n**Update:**\nI have come closer to this conclusion by writing a simple nodejs app and run it directly:\n```js\n\nimport fs from 'fs';\n\nasync function main() {\n    const uploadUrl = 'https://upload.twitter.com/1.1/media/upload.json';\n    const mediaData = fs.readFileSync(\n        \"/Users/amin/Downloads/agent-twitter-client/test-assets/test-image.jpeg\"\n    );\n\n    const form = new FormData();\n    form.append('media', new Blob([mediaData]));\n    const headers = {\n        authorization: 'Bearer ******************,\n        cookie: 'auth_token=****************; guest_id=v1%**********',\n        'x-csrf-token': '************************'\n    }\n\n    const response = await fetch(uploadUrl, {\n      method: 'POST',\n      headers,\n      body: form,\n    });\n\n    if (!response.ok) {\n      console.log('Upload response was not ok:', await response.text());\n      throw new Error(await response.text());\n    }\n\n    const data = await response.json();\n    console.log(`media upload data: ${JSON.stringify(data, null, 2)}`);\n}\n\n\nmain().then(() => process.exit(0));\n\n```\n\nIt works correctly when I run it directly. But when I copy the same code as an independent function and call it inside eliza, again I get that error\n```\n   {\"errors\":[{\"code\":38,\"message\":\"media parameter is missing.\"}]} \n```", "CLOSED", 0, "aminlatifi", "2025-02-02T07:36:40Z", "2025-02-03T04:36:12Z", "2025-02-03T04:35:04Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6oaLyQ", 3147, "Pul", "**Describe the bug**\n\n<!-- A clear and concise description of what the bug is. -->\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "Mirmuxsin686", "2025-02-01T21:16:29Z", "2025-02-03T04:40:17Z", "2025-02-03T04:40:17Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6oTg8d", 3112, "twitter  [\"\u26d4 Login attempt failed: Authentication error: DenyLoginSubtask\"]", " [\"\u26d4 Login attempt failed: Authentication error: DenyLoginSubtask\"] \n\ni did add \n\nTWITTER_COOKIES='[\n  {\"key\":\"auth_token\",\"value\":\"cccccc\",\"domain\":\".twitter.com\"},\n  {\"key\":\"ct0\",\"value\":\"xxxx\",\"domain\":\".twitter.com\"},\n  {\"key\":\"guest_id\",\"value\":\"xxxx\",\"domain\":\".twitter.com\"}\n]' # Account cookies\n\nbut i get this error any clue why ?\n\n", "CLOSED", 0, "jamdickin11", "2025-01-31T14:41:25Z", "2025-02-05T18:05:09Z", "2025-02-05T18:05:09Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6oNhmn", 3079, "Unable to connect to Anthopic model ERROR: Error in generateText", "I am working on a Discord AI agent , I cant connect to anthropic and openai models. even though I have imported my API_KEYS.\nI keep getting this errors\n\n```rust\nINFO: Generating text with options:\n    modelProvider: \"anthropic\"\n    model: \"large\"\n    verifiableInference: false\n\n.env\nANTHROPIC_API_KEY=*********************************************************     # For Claude\nSMALL_ANTHROPIC_MODEL=          # Default: claude-3-haiku-20240307\nMEDIUM_ANTHROPIC_MODEL=         # Default: claude-3-5-sonnet-20241022\nLARGE_ANTHROPIC_MODEL=   # Default: claude-3-5-sonnet-20241022\n\nERROR: Error in generateText:\nERROR: ERROR:\n```\nBut Llama-local works but it is too slow for my PC\n", "CLOSED", 0, "OFUZORCHUKWUEMEKE", "2025-01-31T00:08:23Z", "2025-02-05T13:11:51Z", "2025-02-05T13:11:51Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6oH-yr", 3040, "Add Edwin integration", "Edwin is a new open-source library that aims to streamline and simplify DeFi operations for agents.\nThe purpose of this issue is to integrate Edwin usage into Eliza.\n\n![Image](https://github.com/user-attachments/assets/4d1b4ee2-c318-459e-949d-fcacde43ff7f)", "CLOSED", 0, "galmw", "2025-01-30T12:10:25Z", "2025-02-03T12:02:45Z", "2025-02-03T12:02:45Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6nI3ix", 2652, "Error Installing @discordjs/opus - Binaries Not Found and Compilation Fails with node-gyp", "**Description**\n\nContext\n\nI\u2019m experiencing issues installing the @discordjs/opus package in my project. The installation fails with an error stating that pre-built binaries are not available and that the compilation via node-gyp is unsuccessful.\n\nEnvironment Details\n\t\u2022\tOperating System: macOS Ventura 14.2 (arm64)\n\t\u2022\tNode.js: 22.13.1 (also tested on v23.3.0)\n\t\u2022\tnpm: 10.9.0\n\t\u2022\tnode-gyp: 10.3.1\n\t\u2022\tPython: 3.12.6\n\n\n\n**Observed Error**\n\n`node-pre-gyp ERR! install response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v127-napi-v3-darwin-arm64-unknown-unknown.tar.gz\nnode-pre-gyp WARN Pre-built binaries not installable for @discordjs/opus@0.9.0 and node@22.13.1 (node-v127 ABI, unknown) (falling back to source compile with node-gyp)\n...\nclang++: error: no such file or directory: 'SSD/eliza-projects/token-ai/opus/node_modules/node-addon-api'\nmake: *** [Release/obj.target/opus/src/node-opus.o] Error 1`\n\nSuspected Problem\n\t\u2022\tIt seems that pre-built binaries for @discordjs/opus are not available for my Node.js version and architecture (Node 22.x on macOS arm64).\n\t\u2022\tAdditionally, manual compilation fails due to errors with node-gyp.\n\nAttempts to Resolve\n\t1.\tTried different Node.js versions (18.x, 20.x, 22.x, and 23.x).\n\t2.\tRemoved all dependencies and cleared cache:\n\n**Request**\n\nI would like to know if there is an official solution or recommendation for this issue. Additionally, it would be helpful to have support for pre-built binaries on modern architectures and recent Node.js versions.\n\nAdditional Logs\n`Packages: +5968\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\nProgress: resolved 4732, reused 4531, downloaded 4, added 5968, done\nnode_modules/@nestjs/core: Running postinstall script, done in 955ms\nnode_modules/@discordjs/opus: Running install script, failed in 21.7s\nnode_modules/@discordjs/opus install$ node-pre-gyp install --fallback-to-build\n\u2502 node-pre-gyp info it worked if it ends with ok\n\u2502 node-pre-gyp info using node-pre-gyp@0.4.5\n\u2502 node-pre-gyp info using node@22.13.1 | darwin | arm64\n\u2502 (node:29318) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\n\u2502 (Use `node --trace-deprecation ...` to show where the warning was created)\n\u2502 node-pre-gyp info check checked for \"/Volumes/Lucas SSD/eliza-projects/token-ai/eliza/node_modules/@discordjs/opus/prebuild/node-v127-napi-v3-darwin\u2026\n\u2502 node-pre-gyp http GET https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v127-napi-v3-darwin-arm64-unknown-unknown.tar.gz\n\u2502 node-pre-gyp ERR! install response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v127-napi-v3-\u2026\n\u2502 node-pre-gyp WARN Pre-built binaries not installable for @discordjs/opus@0.9.0 and node@22.13.1 (node-v127 ABI, unknown) (falling back to source com\u2026\n\u2502 node-pre-gyp WARN Hit error response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v127-napi-v\u2026\n\u2502 gyp info it worked if it ends with ok\n\u2502 gyp info using node-gyp@10.3.1\n\u2502 gyp info using node@22.13.1 | darwin | arm64\n\u2502 gyp info ok \n\u2502 gyp info it worked if it ends with ok\n\u2502 gyp info using node-gyp@10.3.1\n\u2502 gyp info using node@22.13.1 | darwin | arm64\n\u2502 gyp info find Python using Python version 3.12.6 found at \"/opt/homebrew/opt/python@3.12/bin/python3.12\"\n\u2502 gyp info spawn /opt/homebrew/opt/python@3.12/bin/python3.12\n\u2502 gyp info spawn args [\n\u2502 gyp info spawn args '/Volumes/Lucas SSD/eliza-projects/token-ai/eliza/node_modules/node-gyp/gyp/gyp_main.py',\n\u2502 gyp info spawn args 'binding.gyp',\n\u2502 gyp info spawn args '-f',\n\u2502 gyp info spawn args 'make',\n\u2502 gyp info spawn args '-I',\n\u2502 gyp info spawn args '/Volumes/Lucas SSD/eliza-projects/token-ai/eliza/node_modules/@discordjs/opus/build/config.gypi',\n\u2502 gyp info spawn args '-I',\n\u2502 gyp info spawn args '/Volumes/Lucas SSD/eliza-projects/token-ai/eliza/node_modules/node-gyp/addon.gypi',\n\u2502 gyp info spawn args '-I',\n\u2502 gyp info spawn args '/Users/lucasdutracoelho/Library/Caches/node-gyp/22.13.1/include/node/common.gypi',\n\u2502 gyp info spawn args '-Dlibrary=shared_library',\n\u2502 gyp info spawn args '-Dvisibility=default',\n\u2502 gyp info spawn args '-Dnode_root_dir=/Users/lucasdutracoelho/Library/Caches/node-gyp/22.13.1',\n\u2502 gyp info spawn args '-Dnode_gyp_dir=/Volumes/Lucas SSD/eliza-projects/token-ai/eliza/node_modules/node-gyp',\n\u2502 gyp info spawn args '-Dnode_lib_file=/Users/lucasdutracoelho/Library/Caches/node-gyp/22.13.1/<(target_arch)/node.lib',\n\u2502 gyp info spawn args '-Dmodule_root_dir=/Volumes/Lucas SSD/eliza-projects/token-ai/eliza/node_modules/@discordjs/opus',\n\u2502 gyp info spawn args '-Dnode_engine=v8',\n\u2502 gyp info spawn args '--depth=.',\n\u2502 gyp info spawn args '--no-parallel',\n\u2502 gyp info spawn args '--generator-output',\n\u2502 gyp info spawn args 'build',\n\u2502 gyp info spawn args '-Goutput_dir=.'\n\u2502 gyp info spawn args ]\n\u2502 <string>:43: SyntaxWarning: invalid escape sequence '\\$'\n\u2502 gyp info ok \n\u2502 gyp info it worked if it ends with ok\n\u2502 gyp info using node-gyp@10.3.1\n\u2502 gyp info using node@22.13.1 | darwin | arm64\n\u2502 gyp info spawn make\n\u2502 gyp info spawn args [ 'BUILDTYPE=Release', '-C', 'build' ]\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus_multistream.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus_projection_encoder.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/analysis.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/mlp_data.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus_multistream_encoder.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus_projection_decoder.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/mapping_matrix.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus_compare.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/mlp.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus_multistream_decoder.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus_decoder.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/repacketizer.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/src/opus_encoder.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_frame.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/inner_product_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/scale_vector_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/find_pred_coefs_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/schur_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/warped_autocorrelation_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/burg_modified_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/find_LPC_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/LPC_inv_pred_gain_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/scale_copy_vector_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/noise_shape_analysis_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/pitch_analysis_core_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/bwexpander_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/LTP_analysis_filter_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/LTP_scale_ctrl_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/corrMatrix_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/encode_frame_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/sort_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/find_pitch_lags_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/residual_energy_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/LPC_analysis_filter_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/autocorrelation_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/k2a_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/regularize_correlations_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/find_LTP_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/energy_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/apply_sine_window_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/wrappers_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/float/process_gains_FLP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_quant_pred.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/LPC_inv_pred_gain.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/process_NLSFs.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NSQ.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/check_control_input.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_del_dec_quant.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/LPC_analysis_filter.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/dec_API.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/sort.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/VAD.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_private_AR2.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/LPC_fit.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/control_SNR.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_parameters.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/pitch_est_tables.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/warped_autocorrelation_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/apply_sine_window_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/residual_energy16_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/schur64_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/residual_energy_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/noise_shape_analysis_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/encode_frame_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/schur_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/autocorr_FIX.o\n\u2502 ../deps/opus/silk/fixed/autocorr_FIX.c:47:29: warning: incompatible pointer types passing 'const opus_int16 *' (aka 'const short *') to parameter of\u2026\n\u2502    47 |     *scale = _celt_autocorr(inputData, results, NULL, 0, corrCount-1, inputDataSize, arch);\n\u2502       |                             ^~~~~~~~~\n\u2502 ../deps/opus/celt/celt_lpc.h:63:38: note: passing argument to parameter 'x' here\n\u2502    63 | int _celt_autocorr(const opus_val16 *x, opus_val32 *ac,\n\u2502       |                                      ^\n\u2502 ../deps/opus/silk/fixed/autocorr_FIX.c:47:40: warning: incompatible pointer types passing 'opus_int32 *' (aka 'int *') to parameter of type 'opus_va\u2026\n\u2502    47 |     *scale = _celt_autocorr(inputData, results, NULL, 0, corrCount-1, inputDataSize, arch);\n\u2502       |                                        ^~~~~~~\n\u2502 ../deps/opus/celt/celt_lpc.h:63:53: note: passing argument to parameter 'ac' here\n\u2502    63 | int _celt_autocorr(const opus_val16 *x, opus_val32 *ac,\n\u2502       |                                                     ^\n\u2502 2 warnings generated.\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/burg_modified_FIX.o\n\u2502 ../deps/opus/silk/fixed/burg_modified_FIX.c:98:30: warning: incompatible pointer types passing 'const opus_int16 *' (aka 'const short *') to paramet\u2026\n\u2502    98 |             celt_pitch_xcorr(x_ptr, x_ptr + 1, xcorr, subfr_length - D, D, arch );\n\u2502       |                              ^~~~~\n\u2502 ../deps/opus/celt/arm/pitch_arm.h:136:52: note: passing argument to parameter '_x' here\n\u2502   136 | void celt_pitch_xcorr_float_neon(const opus_val16 *_x, const opus_val16 *_y,\n\u2502       |                                                    ^\n\u2502 ../deps/opus/silk/fixed/burg_modified_FIX.c:98:37: warning: incompatible pointer types passing 'const opus_int16 *' (aka 'const short *') to paramet\u2026\n\u2502    98 |             celt_pitch_xcorr(x_ptr, x_ptr + 1, xcorr, subfr_length - D, D, arch );\n\u2502       |                                     ^~~~~~~~~\n\u2502 ../deps/opus/celt/arm/pitch_arm.h:136:74: note: passing argument to parameter '_y' here\n\u2502   136 | void celt_pitch_xcorr_float_neon(const opus_val16 *_x, const opus_val16 *_y,\n\u2502       |                                                                          ^\n\u2502 ../deps/opus/silk/fixed/burg_modified_FIX.c:98:48: warning: incompatible pointer types passing 'opus_int32[24]' (aka 'int[24]') to parameter of type\u2026\n\u2502    98 |             celt_pitch_xcorr(x_ptr, x_ptr + 1, xcorr, subfr_length - D, D, arch );\n\u2502       |                                                ^~~~~\n\u2502 ../deps/opus/celt/arm/pitch_arm.h:137:46: note: passing argument to parameter 'xcorr' here\n\u2502   137 |                                  opus_val32 *xcorr, int len, int max_pitch, int arch);\n\u2502       |                                              ^\n\u2502 3 warnings generated.\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/pitch_analysis_core_FIX.o\n\u2502 ../deps/opus/silk/fixed/pitch_analysis_core_FIX.c:200:27: warning: incompatible pointer types passing 'const opus_int16 *' (aka 'const short *') to \u2026\n\u2502   200 |         celt_pitch_xcorr( target_ptr, target_ptr - MAX_LAG_4KHZ, xcorr32, SF_LENGTH_8KHZ, MAX_LAG_4KHZ - MIN_LAG_4KHZ + 1, arch );\n\u2502       |                           ^~~~~~~~~~\n\u2502 ../deps/opus/celt/arm/pitch_arm.h:136:52: note: passing argument to parameter '_x' here\n\u2502   136 | void celt_pitch_xcorr_float_neon(const opus_val16 *_x, const opus_val16 *_y,\n\u2502       |                                                    ^\n\u2502 ../deps/opus/silk/fixed/pitch_analysis_core_FIX.c:200:39: warning: incompatible pointer types passing 'const opus_int16 *' (aka 'const short *') to \u2026\n\u2502   200 |         celt_pitch_xcorr( target_ptr, target_ptr - MAX_LAG_4KHZ, xcorr32, SF_LENGTH_8KHZ, MAX_LAG_4KHZ - MIN_LAG_4KHZ + 1, arch );\n\u2502       |                                       ^~~~~~~~~~~~~~~~~~~~~~~~~\n\u2502 ../deps/opus/celt/arm/pitch_arm.h:136:74: note: passing argument to parameter '_y' here\n\u2502   136 | void celt_pitch_xcorr_float_neon(const opus_val16 *_x, const opus_val16 *_y,\n\u2502       |                                                                          ^\n\u2502 ../deps/opus/silk/fixed/pitch_analysis_core_FIX.c:200:66: warning: incompatible pointer types passing 'opus_int32[65]' (aka 'int[65]') to parameter \u2026\n\u2502   200 |         celt_pitch_xcorr( target_ptr, target_ptr - MAX_LAG_4KHZ, xcorr32, SF_LENGTH_8KHZ, MAX_LAG_4KHZ - MIN_LAG_4KHZ + 1, arch );\n\u2502       |                                                                  ^~~~~~~\n\u2502 ../deps/opus/celt/arm/pitch_arm.h:137:46: note: passing argument to parameter 'xcorr' here\n\u2502   137 |                                  opus_val32 *xcorr, int len, int max_pitch, int arch);\n\u2502       |                                              ^\n\u2502 ../deps/opus/silk/fixed/pitch_analysis_core_FIX.c:616:27: warning: incompatible pointer types passing 'const opus_int16 *' (aka 'const short *') to \u2026\n\u2502   616 |         celt_pitch_xcorr( target_ptr, target_ptr - start_lag - lag_high, xcorr32, sf_length, lag_high - lag_low + 1, arch );\n\u2502       |                           ^~~~~~~~~~\n\u2502 ../deps/opus/celt/arm/pitch_arm.h:136:52: note: passing argument to parameter '_x' here\n\u2502   136 | void celt_pitch_xcorr_float_neon(const opus_val16 *_x, const opus_val16 *_y,\n\u2502       |                                                    ^\n\u2502 ../deps/opus/silk/fixed/pitch_analysis_core_FIX.c:616:39: warning: incompatible pointer types passing 'const opus_int16 *' (aka 'const short *') to \u2026\n\u2502   616 |         celt_pitch_xcorr( target_ptr, target_ptr - start_lag - lag_high, xcorr32, sf_length, lag_high - lag_low + 1, arch );\n\u2502       |                                       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\u2502 ../deps/opus/celt/arm/pitch_arm.h:136:74: note: passing argument to parameter '_y' here\n\u2502   136 | void celt_pitch_xcorr_float_neon(const opus_val16 *_x, const opus_val16 *_y,\n\u2502       |                                                                          ^\n\u2502 ../deps/opus/silk/fixed/pitch_analysis_core_FIX.c:616:74: warning: incompatible pointer types passing 'opus_int32[22]' (aka 'int[22]') to parameter \u2026\n\u2502   616 |         celt_pitch_xcorr( target_ptr, target_ptr - start_lag - lag_high, xcorr32, sf_length, lag_high - lag_low + 1, arch );\n\u2502       |                                                                          ^~~~~~~\n\u2502 ../deps/opus/celt/arm/pitch_arm.h:137:46: note: passing argument to parameter 'xcorr' here\n\u2502   137 |                                  opus_val32 *xcorr, int len, int max_pitch, int arch);\n\u2502       |                                              ^\n\u2502 6 warnings generated.\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/find_LTP_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/find_LPC_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/corrMatrix_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/k2a_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/LTP_scale_ctrl_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/process_gains_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/k2a_Q16_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/regularize_correlations_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/LTP_analysis_filter_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/vector_ops_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/find_pitch_lags_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/find_pred_coefs_FIX.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/control_audio_bandwidth.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/decoder_set_fs.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_unpack.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/bwexpander.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_rom.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/shell_coder.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_pulses.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/bwexpander_32.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_core.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/PLC.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_NLSF_CB_WB.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/table_LSF_cos.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_pulses_per_block.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_gain.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/inner_prod_aligned.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_down2_3.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NSQ_del_dec.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_pitch.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_VQ_weights_laroia.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/interpolate.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/debug.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_other.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/LP_variable_cutoff.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_decode.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/encode_pulses.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/control_codec.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_LR_to_MS.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/HP_variable_cutoff.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/encode_indices.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/init_decoder.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_encode_pred.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_VQ.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/init_encoder.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_private_IIR_FIR.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_private_up2_HQ.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/sigm_Q15.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/sum_sqr_shift.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_LTP.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_down2.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/code_signs.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_NLSF_CB_NB_MB.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/gain_quant.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_pitch_lag.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_stabilize.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_find_predictor.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/A2NLSF.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF2A.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/VQ_WMat_EC.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_encode.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/log2lin.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_decode_pred.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/lin2log.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/CNG.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/enc_API.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/biquad_alt.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/quant_LTP_gains.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_private_down_FIR.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/ana_filt_bank_1.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_MS_to_LR.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_indices.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/rate.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/entdec.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/modes.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/celt_lpc.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/laplace.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/cwrs.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/celt.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/entcode.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/celt_decoder.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/celt_encoder.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/mdct.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/quant_bands.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/vq.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/bands.o\n\u2502 ../deps/opus/celt/bands.c:904:85: warning: parameter 'b' set but not used [-Wunused-but-set-parameter]\n\u2502   904 | static unsigned quant_band_n1(struct band_ctx *ctx, celt_norm *X, celt_norm *Y, int b,\n\u2502       |                                                                                     ^\n\u2502 1 warning generated.\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/kiss_fft.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/entenc.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/mathops.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/pitch.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/arm/arm_celt_map.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/arm/armcpu.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/arm/celt_neon_intr.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/celt/arm/pitch_neon_intr.o\n\u2502   CC(target) Release/obj.target/libopus/deps/opus/silk/arm/LPC_inv_pred_gain_neon_intr.o\n\u2502   LIBTOOL-STATIC Release/opus.a\n\u2502   CXX(target) Release/obj.target/opus/src/node-opus.o\n\u2502 clang++: error: no such file or directory: 'SSD/eliza-projects/token-ai/eliza/node_modules/@discordjs/opus/node_modules/node-addon-api'\n\u2502 make: *** [Release/obj.target/opus/src/node-opus.o] Error 1\n\u2502 gyp ERR! build error \n\u2502 gyp ERR! stack Error: `make` failed with exit code: 2\n\u2502 gyp ERR! stack at ChildProcess.<anonymous> (/Volumes/Lucas SSD/eliza-projects/token-ai/eliza/node_modules/node-gyp/lib/build.js:216:23)\n\u2502 gyp ERR! System Darwin 24.2.0\n\u2502 gyp ERR! command \"/Users/lucasdutracoelho/Library/pnpm/nodejs/22.13.1/bin/node\" \"/Volumes/Lucas SSD/eliza-projects/token-ai/eliza/node_modules/node-\u2026\n\u2502 gyp ERR! cwd /Volumes/Lucas SSD/eliza-projects/token-ai/eliza/node_modules/@discordjs/opus\n\u2502 gyp ERR! node -v v22.13.1\n\u2502 gyp ERR! node-gyp -v v10.3.1\n\u2502 gyp ERR! not ok \n\u2502 node-pre-gyp ERR! build error \n\u2502 node-pre-gyp ERR! stack Error: Failed to execute '/Users/lucasdutracoelho/Library/pnpm/nodejs/22.13.1/bin/node /Volumes/Lucas SSD/eliza-projects/tok\u2026\n\u2502 node-pre-gyp ERR! stack     at ChildProcess.<anonymous> (/Volumes/Lucas SSD/eliza-projects/token-ai/eliza/node_modules/@discordjs/node-pre-gyp/lib/u\u2026\n\u2502 node-pre-gyp ERR! stack     at ChildProcess.emit (node:events:524:28)\n\u2502 node-pre-gyp ERR! stack     at maybeClose (node:internal/child_process:1101:16)\n\u2502 node-pre-gyp ERR! stack     at ChildProcess._handle.onexit (node:internal/child_process:304:5)\n\u2502 node-pre-gyp ERR! System Darwin 24.2.0\n\u2502 node-pre-gyp ERR! command \"/Users/lucasdutracoelho/Library/pnpm/nodejs/22.13.1/bin/node\" \"/Volumes/Lucas SSD/eliza-projects/token-ai/eliza/node_modu\u2026\n\u2502 node-pre-gyp ERR! cwd /Volumes/Lucas SSD/eliza-projects/token-ai/eliza/node_modules/@discordjs/opus\n\u2502 node-pre-gyp ERR! node -v v22.13.1\n\u2502 node-pre-gyp ERR! node-pre-gyp -v v0.4.5\n\u2502 node-pre-gyp ERR! not ok \n\u2502 Failed to execute '/Users/lucasdutracoelho/Library/pnpm/nodejs/22.13.1/bin/node /Volumes/Lucas SSD/eliza-projects/token-ai/eliza/node_modules/node-g\u2026\n\u2514\u2500 Failed in 21.7s at /Volumes/Lucas SSD/eliza-projects/token-ai/eliza/node_modules/@discordjs/opus\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.`\n", "CLOSED", 0, "lucasdutracoelho", "2025-01-22T11:21:43Z", "2025-02-08T14:17:54Z", "2025-01-23T00:16:42Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6lg-vg", 2050, "fix: prevent forged public keys from using valid attestations as proof to deceive users", "When a user wants to verify a log's signature using a public key, they first need to ensure that the public key was indeed generated within the TEE. This requires the user to verify the correctness of the remote attestation. However, users obtain the remote attestation by accessing the `/verifiable/attestation` endpoint, which calls the `generateAttestation` function. This function doesn't validate the agent ID and public key from the user's request, but instead directly generates a remote attestation. This doesn't prove that the public key corresponds to a private key generated within the TEE.\r\nAssuming TLS communication is established between the user and Eliza, I propose two correct approaches:\r\n\r\nThe user provides the agent_id, subject, and publicKey required for private key generation to the `generateAttestation` function. Within this function, a key pair is generated using deriveKey, and the resulting public key is compared with the publicKey parameter. If they match, an attestation report should be generated with the publicKey included in the report.\r\nSince Eliza has already stored the publicKey in the SQLite database during initial registerAgent, if we can ensure that the SQLite database content is encrypted and cannot be tampered with by software outside the TEE, the `generateAttestation` function can directly read the publicKey from the database using the agent_id, subject, and keypath. It then compares this with the publicKey in the user's request, and if they match, generates an attestation report.\r\n\r\nIn the current implementation, if someone sends a log to a user with a signature generated by a private key from outside the TEE, and provides this forged public key to the user, when the user requests an attestation through the `/verifiable/attestation` endpoint with the agent_id and corresponding public key, Eliza running in the TEE will directly send a valid attestation to the user. This allows users to be deceived\r\n\r\n_Originally posted by @lightning-li in https://github.com/elizaOS/eliza/pull/1369#discussion_r1908145251_\r\n            ", "CLOSED", 0, "HashWarlock", "2025-01-09T05:45:07Z", "2025-02-09T07:22:11Z", "2025-02-09T07:22:10Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6k8NQB", 1747, "Jetson Runtime Exception with sqlite-vec Extension Load Failure", "**Describe the bug**\r\n\r\nWhen attempting to run an application on Jetson, it fails to load the sqlite-vec extensions. The specific error message suggests that the sqlite-vec-linux-arm64 package might not be installed.\r\n\r\nTo Reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\nStart the application on Jetson.\r\n```\r\npnpm i && pnpm start\r\n```\r\n\r\n**Expected behavior**\r\nsuccess \r\n\r\n**Screenshots**\r\n<img width=\"1069\" alt=\"image\" src=\"https://github.com/user-attachments/assets/d3fd9d9c-05e7-4e99-8290-f6f479b0f0ff\" />\r\n\r\n", "CLOSED", 0, "Links17", "2025-01-03T09:25:28Z", "2025-02-08T17:07:52Z", "2025-01-06T07:54:36Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6kokU_", 1552, "Quick start guide bug - pnpm start", "**Describe the bug**\r\nwhen going through the quickstart guide\r\n\r\nGetting an error when using local client (`pnpm start:client`) and init any chat such as `hello`...the output on the service is:\r\n\r\n```\r\n-0009-a2c3-83780c350ff3 successfully.\"] \r\n\r\n [\"\u25ce Agent tate linked to room 6ac3f59a-67bb-0009-a2c3-83780c350ff3 successfully.\"] \r\n\r\n \u25ce LOGS\r\n   Creating Memory \r\n   0c8b6c1c-00b2-0768-8309-564c7d224967 \r\n   hi \r\n\r\n [\"\u25ce Generating message response..\"] \r\n\r\n [\"\u25ce Generating text...\"] \r\n\r\n \u2139 INFORMATIONS\r\n   Generating text with options: \r\n   {\"modelProvider\":\"gaianet\",\"model\":\"large\"} \r\n\r\n \u2139 INFORMATIONS\r\n   Selected model: \r\n   qwen72b \r\n\r\n \u25ce LOGS\r\n   Creating Memory \r\n   2f8f543d-8105-094e-89e8-5ecda88f310f \r\n   What's the purpose of this conversation? \r\n\r\n\r\nfile:///Users/dev/rsrc/eliza/packages/adapter-sqlite/dist/index.js:308\r\n        const memories = this.db.prepare(sql).all(...queryParams);\r\n                                              ^\r\nSqliteError: Vector dimension mistmatch. First vector has 768 dimensions, while the second has 384 dimensions.\r\n    at SqliteDatabaseAdapter.searchMemoriesByEmbedding (file:///Users/dev/rsrc/eliza/packages/adapter-sqlite/dist/index.js:308:47)\r\n    at SqliteDatabaseAdapter.createMemory (file:///Users/dev/rsrc/eliza/packages/adapter-sqlite/dist/index.js:240:48)\r\n    at MemoryManager.createMemory (file:///Users/dev/rsrc/eliza/packages/core/dist/index.js:3176:44)\r\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\r\n    at async file:///Users/dev/rsrc/eliza/packages/client-direct/dist/index.js:275:13 {\r\n  code: 'SQLITE_ERROR'\r\n}\r\n\r\nNode.js v23.3.0\r\n/Users/dev/rsrc/eliza/agent:\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.7-alpha.2 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/tate.character.json\"`\r\nExit status 1\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n```\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n- `pnpm start --character=\"characters/tate.character.json\"`\r\n-  `pnpm start:client`\r\n-  initiate a chat after selecting agent - such as 'hello'\r\n- no response on UI; the service has the error above with the service process exiting code 1\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\nstarts up just fine, creates memories etc to the vector db.\r\n\r\nusing node version 23.3, tried 24.3 - same result\r\non a mac os - Monterrey - 12.7.6 (intel chip)\r\n\r\nusing elizaOS version - `v0.1.7-alpha.2`\r\nusing `gaianet` as the model provider\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "freddymercury", "2024-12-29T04:17:01Z", "2025-02-05T00:39:07Z", "2024-12-31T23:53:32Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6kXox1", 1431, "DenyLoginSubtask - TWITTER", "**Describe the bug**\r\n\r\n \u26d4 Login attempt failed: Authentication error: DenyLoginSubtask\"\r\n\r\n\r\n**To Reproduce**\r\n\r\nRun the server with version  (v0.1.7-alpha.1) \r\n\r\nEven though my twitter creds are correct its throwing error In twitter I can see that a new login message.\r\n\r\n**Expected behavior**\r\n\r\nShould login to twitter and post tweets\r\n\r\n**Screenshots**\r\n![image](https://github.com/user-attachments/assets/56a226ca-b766-4c26-94a1-9a5243e82d2c)\r\n\r\n", "CLOSED", 0, "didintern", "2024-12-24T11:44:01Z", "2025-02-05T18:05:14Z", "2025-02-05T18:05:14Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6kI-gG", 1324, "feat: add test coverage for TEE Plugin", "**Is your feature request related to a problem? Please describe.**\r\nCurrently there is not basic test coverage for the TEE Plugin.\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the solution you'd like**\r\nSolution for a github action will go as follows:\r\n- Start published docker image for TEE Simulator\r\n- Build and deploy docker image of eliza agent with `TEE_MODE=DOCKER`\r\n- Generate a message to eliza\r\n- Expect a derived key with an evm and solana wallet generated from a `WALLET_SECRET_SALT`\r\n- Expect a RA Quote generation for the agent ID, Solana Wallet and EVM Wallet derived from the secret salt\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\nNone at the moment. Need a basic test first.\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "HashWarlock", "2024-12-21T07:10:37Z", "2025-02-05T00:07:24Z", "2025-02-05T00:07:22Z", "elizaos/eliza", "2025-04-14 21:51:29"]
["I_kwDOMT5cIs6qCm26", 3492, "Add plugin-compass env vars", "", "CLOSED", 0, "royalnine", "2025-02-14T06:39:41Z", "2025-02-14T21:59:42Z", "2025-02-14T21:59:42Z", "elizaos/eliza", "2025-04-14 21:52:37"]
["I_kwDOMT5cIs6p9HlT", 3479, "Incorrect image path in the Korean documentation page", "**Describe the bug**\n\nEliza diagram image in the Korean documentation page are not displayed correctly. The image paths specified in the document are incorrect, causing the images to fail to load.\n\n**To Reproduce**\n\nNavigate to the Korean documentation page.\nCheck \uad6c\uc870 sections where images should be displayed.\nThe paths point to non-existent locations.\n\n**Expected behavior**\n\nThe correct image paths should be specified so that the images are properly displayed in the documentation.\n\n**Screenshots**\n\n<img width=\"748\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/8d1636d2-c7a8-460c-982c-334a85079b48\" />\n\n**Additional context**\n\nI will submit a PR with the corrected image paths after opening this issue.\n", "CLOSED", 0, "gkfyr", "2025-02-13T15:22:03Z", "2025-02-14T22:32:40Z", "2025-02-14T22:32:40Z", "elizaos/eliza", "2025-04-14 21:52:37"]
["I_kwDOMT5cIs6pq7e_", 3449, ".env not being read at all?", "**Describe the bug**\n\nI added `SERVER_PORT=3005` to the .env, as well as filled out my preferred local Ollama models.\n\nbut it keeps running on 3000 (I'm getting a 500 error on localhost:3000, but that's another issue)\n\nIt's also loading hermes-3 by default, even though I've set the default to be deepseek-r1 in the .env\n\nAm I missing a step in the installation process?\n\n\n**To Reproduce**\n\n`pnpm i && pnpm build && pnpm start` and then run `pnpm start:client`\n\n**Expected behavior**\n\nEliza to start running\n\n\n**Additional context**\n\non macOS on an M3\n", "CLOSED", 0, "jordanurbs", "2025-02-11T21:51:21Z", "2025-02-14T22:33:54Z", "2025-02-14T22:33:54Z", "elizaos/eliza", "2025-04-14 21:52:37"]
["I_kwDOMT5cIs6o-1Fy", 3316, "pnpm build failed", "after install pnpm \nwhen I'm trying to ppm build, I get this error \n\n```\nclient:build: ERROR: command finished with error: command (C:\\Users\\visha\\Desktop\\eliza\\client) C:\\Users\\visha\\Desktop\\eliza\\node_modules\\.bin\\pnpm.CMD run build exited (1)\nclient[#build]: command (C:\\Users\\visha\\Desktop\\eliza\\client) C:\\Users\\visha\\Desktop\\eliza\\node_modules\\.bin\\pnpm.CMD run build exited (1)\n\n Tasks:    139 successful, 146 total\nCached:    124 cached, 146 total\n  Time:    1m36.285s\nFailed:    client[#build]\n\n ERROR  run failed: command  exited (1)                                                                                                                          \n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\n```", "CLOSED", 0, "vishal0316", "2025-02-06T09:49:37Z", "2025-02-16T09:04:26Z", "2025-02-16T09:04:26Z", "elizaos/eliza", "2025-04-14 21:52:37"]
["I_kwDOMT5cIs6o8UJQ", 3300, "Build Error Caused by Zod Dependency Issues", "**Describe the bug**\n\nAn error occurs during the build process, preventing it from completing successfully.\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\nnode version 23.3.0\n\n1. Run the build based on the commit `2eb94ab` merged into the main branch.  \n2. Execute the following commands in order:\n   - `pnpm clean`\n   - `pnpm install --no-frozen-lockfile`\n   - `pnpm build`\n3. The error occurs during the build process.\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\nThe build should complete successfully without any errors.\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n```\nDTS Build start\n@elizaos/client-direct:build: src/index.ts(510,21): error TS2322: Type 'ZodObject<{ lookAt: ZodNullable<ZodLiteral<string>> | ZodNullable<ZodUnion<[ZodLiteral<string>, ZodLiteral<string>, ...ZodLiteral<string>[]]>> | ZodNull; emote: ZodNullable<...> | ... 1 more ... | ZodNull; say: ZodNullable<...>; actions: ZodNullable<...>; }, \"strip\", ZodTypeAny, { ...; }, { ...; }>' is not assignable to type 'ZodType<any, ZodTypeDef, any>'.\n@elizaos/client-direct:build:   The types of '_getOrReturnCtx(...).common.issues' are incompatible between these types.\n@elizaos/client-direct:build:     Type 'Zod.ZodIssue[]' is not assignable to type 'import(\"/Users/incheolkang/Desktop/study/ai16z/eliza/node_modules/zod/lib/ZodError\").ZodIssue[]'.\n@elizaos/client-direct:build:       Type 'Zod.ZodIssue' is not assignable to type 'import(\"/Users/incheolkang/Desktop/study/ai16z/eliza/node_modules/zod/lib/ZodError\").ZodIssue'.\n@elizaos/client-direct:build:         Type 'ZodInvalidUnionIssue & { fatal?: boolean; message: string; }' is not assignable to type 'ZodIssue'.\n@elizaos/client-direct:build:           Type 'Zod.ZodInvalidUnionIssue & { fatal?: boolean; message: string; }' is not assignable to type 'import(\"/Users/incheolkang/Desktop/study/ai16z/eliza/node_modules/zod/lib/ZodError\").ZodInvalidUnionIssue & { fatal?: boolean; message: string; }'.\n@elizaos/client-direct:build:             Type 'ZodInvalidUnionIssue & { fatal?: boolean; message: string; }' is not assignable to type 'ZodInvalidUnionIssue'.\n@elizaos/client-direct:build:               Types of property 'unionErrors' are incompatible.\n@elizaos/client-direct:build:                 Type 'Zod.ZodError<any>[]' is not assignable to type 'import(\"/Users/incheolkang/Desktop/study/ai16z/eliza/node_modules/zod/lib/ZodError\").ZodError<any>[]'.\n@elizaos/client-direct:build:                   Type 'Zod.ZodError<any>' is not assignable to type 'import(\"/Users/incheolkang/Desktop/study/ai16z/eliza/node_modules/zod/lib/ZodError\").ZodError<any>'.\n@elizaos/client-direct:build:                     Types of property 'issues' are incompatible.\n@elizaos/client-direct:build:                       Type 'Zod.ZodIssue[]' is not assignable to type 'import(\"/Users/incheolkang/Desktop/study/ai16z/eliza/node_modules/zod/lib/ZodError\").ZodIssue[]'.\n@elizaos/client-direct:build:                         Type 'Zod.ZodIssue' is not assignable to type 'import(\"/Users/incheolkang/Desktop/study/ai16z/eliza/node_modules/zod/lib/ZodError\").ZodIssue'.\n@elizaos/client-direct:build:                           Type 'ZodInvalidUnionIssue & { fatal?: boolean; message: string; }' is not assignable to type 'ZodIssue'.\n@elizaos/client-direct:build: \n@elizaos/client-direct:build: Error: error occurred in dts build\n@elizaos/client-direct:build:     at Worker.<anonymous> (/Users/incheolkang/Desktop/study/ai16z/eliza/node_modules/tsup/dist/index.js:1541:26)\n@elizaos/client-direct:build:     at Worker.emit (node:events:513:28)\n@elizaos/client-direct:build:     at MessagePort.<anonymous> (node:internal/worker:267:53)\n@elizaos/client-direct:build:     at [nodejs.internal.kHybridDispatch] (node:internal/event_target:827:20)\n@elizaos/client-direct:build:     at MessagePort.<anonymous> (node:internal/per_context/messageport:23:28)\n@elizaos/client-direct:build: DTS Build error\n@elizaos/client-direct:build: \u2009ELIFECYCLE\u2009 Command failed with exit code 1.\n@elizaos/client-direct:build: ERROR: command finished with error: command (/Users/incheolkang/Desktop/study/ai16z/eliza/packages/client-direct) /Users/incheolkang/Desktop/study/ai16z/eliza/node_modules/.bin/pnpm run build exited (1)\n@elizaos/client-direct#build: command (/Users/incheolkang/Desktop/study/ai16z/eliza/packages/client-direct) /Users/incheolkang/Desktop/study/ai16z/eliza/node_modules/.bin/pnpm run build exited (1)\n\n Tasks:    148 successful, 149 total\nCached:    148 cached, 149 total\n  Time:    5.525s \nFailed:    @elizaos/client-direct#build\n\n ERROR  run failed: command  exited (1)\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\n```", "CLOSED", 0, "lincheoll", "2025-02-06T02:32:28Z", "2025-02-11T06:06:30Z", "2025-02-11T06:06:30Z", "elizaos/eliza", "2025-04-14 21:52:37"]
["I_kwDOMT5cIs6ot550", 3234, "Issue with Bridging and Swapping Tokens in plugin-evm", "**Description:**\nI am encountering issues with bridging and swapping tokens using the `plugin-evm`. The only function that seems to be working correctly is the transfer function.\n\nCan you confirm if the plugin swap and bridge functionality can be tested on a testnet like Sepolia or Base Sepolia? If not, is there an alternative way to test these functionalities before deploying to mainnet?\n\n### **Error Details**\n#### **SWAP Issue**\n![Swap Error](https://github.com/user-attachments/assets/291374a1-12d8-4849-95e1-7d0b9f4a041a)\n\n```\n[2025-02-04 15:24:28] ERROR: Error in swap handler: Address \"ETH\" is invalid.\n\n- Address must be a hex value of 20 bytes (40 hex characters).\n- Address must match its checksum counterpart.\n\nRaw Call Arguments:\n  to:    ETH\n  data:  0x313ce567\n\nContract Call:\n  address:   ETH\n  function:  decimals()\n\nDocs: https://viem.sh/docs/contract/readContract\nVersion: viem@2.21.58\n```\n\n#### **BRIDGE Issue**\n![Bridge Error](https://github.com/user-attachments/assets/f10237a8-79dd-45a7-9c67-abd464a536c0)\n\n```\nReceived response from OpenAI model.\nBridge action handler called\n[2025-02-04 15:27:25] ERROR:\n    err: {\n      \"type\": \"TypeError\",\n      \"message\": \"Cannot read properties of undefined (reading 'default')\",\n      \"stack\":\n          TypeError: Cannot read properties of undefined (reading 'default')\n              at file:///home/azan/Work/eliza/packages/plugin-evm/dist/index.js:362:63\n              at Array.map (<anonymous>)\n              at new BridgeAction (file:///home/azan/Work/eliza/packages/plugin-evm/dist/index.js:346:63)\n              at Object.handler (file:///home/azan/Work/eliza/packages/plugin-evm/dist/index.js:405:24)\n              at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n              at async AgentRuntime.processActions (file:///home/azan/Work/eliza/packages/core/dist/index.js:37181:17)\n              at async file:///home/azan/Work/eliza/packages/client-direct/dist/index.js:4678:13\n    }\n```\n\n### **Steps to Reproduce:**\n1. Attempt to swap tokens.\n2. Observe the invalid address error.\n3. Attempt to bridge tokens.\n4. Encounter the TypeError in the bridge action handler.\n\n### **Expected Behavior:**\n- The swap function should correctly identify and process token addresses.\n- The bridge function should handle actions without encountering undefined properties.\n\n### **Environment Details:**\n- Network: ** baseSepolia, Sepolia **\n\n\nAny guidance on resolving these errors would be greatly appreciated. Thanks!\n\n", "CLOSED", 0, "AzanAdnan23", "2025-02-04T15:32:07Z", "2025-02-14T18:16:33Z", "2025-02-14T18:16:33Z", "elizaos/eliza", "2025-04-14 21:52:37"]
["I_kwDOMT5cIs6oceOJ", 3173, "feat: Snapshot plugin for DAOs", "# Overview\n\nIn order to enhance DAO-focused agents, this issue and feature request grows capabilities beyond https://github.com/elizaOS/eliza/issues/2674 by adding a [Snapshot.box](https://snapshot.box/#/) plugin for interested agents. \n\nThis would enable interesting use cases where agents could use LLM to provide summaries and insights into web3 governance since Snapshot is used widely amongst DAOs in web3.\n\n## Describe the solution you'd like\n\nI would like to fork this repo and add a global plugin that will serve formatted `Snapshot` data via a provider that can be consumed by agents.\n\nFunctional requirements:\n- Integration into Snapshot API via a read only client\n- Allow plugin consumers to specify environment variables for: target snapshot space specified by the ENS name for example `elizaOS.eth` \n- Provide formatted summary of latest snapshot activity including latest proposals, proposal status (Created, Active, Ended), voting activity\n\n## Describe alternatives you've considered\n\nAfter searching issues and pull requests, I opened this feature request having not found any mention. \n\n## Additional context\n\nNot applicable at this moment\n", "CLOSED", 0, "vince0656", "2025-02-02T21:52:37Z", "2025-02-11T15:20:14Z", "2025-02-11T15:20:13Z", "elizaos/eliza", "2025-04-14 21:52:37"]
["I_kwDOMT5cIs6nkSI8", 2793, "Add a new plugin from Apro: plugin-apro.", "**Add a new plugin from Apro: plugin-apro.**\n\nThe new plugin-apro will provide 3 actions:\n1. PRICE_QUER, this is an action to query current price of coin, for example: BTC/USD\n2. CREATE_AND_REGISTER_AGENT: Create and register an agent with APRO. User must provide agent settings.\n3. VERIFY: Verify data with APRO. User must provide data to verify.\n\n", "CLOSED", 0, "fifahuihua", "2025-01-26T04:04:10Z", "2025-02-10T06:56:53Z", "2025-02-10T06:56:53Z", "elizaos/eliza", "2025-04-14 21:52:37"]
["I_kwDOMT5cIs6l4w4C", 2230, "Create 0x.org swap plugin/enhancement for EVM", "1. https://github.com/0xProject/0x-examples\r\n2. https://0x.org/docs/0x-swap-api/introduction\r\n\r\n- Should be able to do cross-chain EVM Swaps\r\n- Should be able to do same-chain EVM Swaps\r\n- Should be able to check swap/bridge txn status", "CLOSED", 0, "wtfsayo", "2025-01-13T06:28:49Z", "2025-02-10T11:19:49Z", "2025-02-10T11:19:49Z", "elizaos/eliza", "2025-04-14 21:52:37"]
["I_kwDOMT5cIs6kpht1", 1562, "Telegram connection", "How can I fix this?\r\n\r\nI just added my telegram bot token and character.ts clients to Add telegram.\r\n\r\nHowever when I pnpm start I get this error :\r\n\r\n\u201c SUCCESS\r\n   SUCCESS \r\n   Creating runtime for character \r\n   Hikari \r\n\r\n \u00e2\u0153\u201c SUCCESS\r\n   Agent ID \r\n   1004db53-bf1b-0d1a-ba4c-01d318a8197d \r\n\r\n [\"\u00e2\u0153\u201c Registering action: CONTINUE\"] \r\n\r\n [\"\u00e2\u0153\u201c Registering action: FOLLOW_ROOM\"] \r\n\r\n [\"\u00e2\u0153\u201c Registering action: UNFOLLOW_ROOM\"] \r\n\r\n [\"\u00e2\u0153\u201c Registering action: IGNORE\"] \r\n\r\n [\"\u00e2\u0153\u201c Registering action: NONE\"] \r\n\r\n [\"\u00e2\u0153\u201c Registering action: MUTE_ROOM\"] \r\n\r\n [\"\u00e2\u0153\u201c Registering action: UNMUTE_ROOM\"] \r\n\r\n \u00e2\u2014\u017d LOGS\r\n   Registering service: \r\n   browser \r\n\r\n \u00e2\u2014\u017d LOGS\r\n   Registering service: \r\n   image_description \r\n\r\n \u00e2\u2014\u017d LOGS\r\n   Registering service: \r\n   text_generation \r\n\r\n \u00e2\u2014\u017d LOGS\r\n   Registering service: \r\n   pdf \r\n\r\n \u00e2\u2014\u017d LOGS\r\n   Registering service: \r\n   speech_generation \r\n\r\n \u00e2\u2014\u017d LOGS\r\n   Registering service: \r\n   transcription \r\n\r\n \u00e2\u2014\u017d LOGS\r\n   Registering service: \r\n   video \r\n\r\n [\"\u00e2\u0153\u201c Server running at http://localhost:3000/\"] \r\n\r\n [\"\u00e2\u0153\u201c Service browser initialized successfully\"] \r\n\r\n [\"\u00e2\u0153\u201c Service image_description initialized successfully\"] \r\n\r\n [\"\u00e2\u0153\u201c Service text_generation initialized successfully\"] \r\n\r\n [\"\u00e2\u0153\u201c Service pdf initialized successfully\"] \r\n\r\n [\"\u00e2\u0153\u201c Service speech_generation initialized successfully\"] \r\n\r\n [\"\u00e2\u0153\u201c Service transcription initialized successfully\"] \r\n\r\n [\"\u00e2\u0153\u201c Service video initialized successfully\"] \r\n\r\n [\"\u00e2\u2014\u017d \u00f0\u0178\u201c\u00b1 Constructing new TelegramClient...\"] \r\n\r\n [\"\u00e2\u2014\u017d \u00e2\u0153\u2026 TelegramClient constructor completed\"] \r\n\r\n [\"\u00e2\u2014\u017d \u00f0\u0178\u0161\u20ac Starting Telegram bot...\"] \r\n\r\n [\"\u00e2\u2014\u017d \u00e2\u0153\u00a8 Telegram bot successfully launched and is running!\"] \r\n\r\n \u00e2\u203a\u201d ERRORS\r\n   \u00e2\u009d\u0152 Failed to launch Telegram bot: \r\n   {\"message\":\"request to https://api.telegram.org/bot7813398684:[REDACTED]/getMe failed, reason: \",\"type\":\"system\",\"errno\":\"ETIMEDOUT\",\"code\":\"ETIMEDOUT\"} \r\n\r\n \u00e2\u203a\u201d ERRORS\r\n   Error starting agent for character Hikari: \r\n   {\"message\":\"request to https://api.telegram.org/bot7813398684:[REDACTED]/getMe failed, reason: \",\"type\":\"system\",\"errno\":\"ETIMEDOUT\",\"code\":\"ETIMEDOUT\"} \r\n\r\nFetchError: request to https://api.telegram.org/bot7813398684:[REDACTED]/getMe failed, reason: \r\n    at ClientRequest.<anonymous> (/home/algorex/eliza-starter/node_modules/.pnpm/node-fetch@2.7.0/node_modules/node-fetch/lib/index.js:1501:11)\r\n    at ClientRequest.emit (node:events:524:28)\r\n    at emitErrorEvent (node:_http_client:104:11)\r\n    at TLSSocket.socketErrorListener (node:_http_client:512:5)\r\n    at TLSSocket.emit (node:events:524:28)\r\n    at emitErrorNT (node:internal/streams/destroy:170:8)\r\n    at emitErrorCloseNT (node:internal/streams/destroy:129:3)\r\n    at processTicksAndRejections (node:internal/process/task_queues:90:21)\r\n    at runNextTicks (node:internal/process/task_queues:69:3)\r\n    at listOnTimeout (node:internal/timers:555:9) {\r\n  type: 'system',\r\n  errno: 'ETIMEDOUT',\r\n  code: 'ETIMEDOUT'\r\n}\r\n \u00e2\u203a\u201d ERRORS\r\n   Error starting agents: \r\n   {\"message\":\"request to https://api.telegram.org/bot7813398684:[REDACTED]/getMe failed, reason: \",\"type\":\"system\",\"errno\":\"ETIMEDOUT\",\"code\":\"ETIMEDOUT\"} \r\n\r\n [\"\u00e2\u2014\u017d Chat started. Type 'exit' to quit.\"] \r\n\r\nYou: \r\n/home/algorex/eliza-starter/node_modules/.pnpm/node-fetch@2.7.0/node_modules/node-fetch/lib/index.js:1501\r\n                        reject(new FetchError(`request to ${request.url} failed, reason: ${err.message}`, 'system', err));\r\n                               ^\r\nFetchError: request to https://api.telegram.org/bot7813398684:[REDACTED]/getMe failed, reason: \r\n    at ClientRequest.<anonymous> (/home/algorex/eliza-starter/node_modules/.pnpm/node-fetch@2.7.0/node_modules/node-fetch/lib/index.js:1501:11)\r\n    at ClientRequest.emit (node:events:524:28)\r\n    at emitErrorEvent (node:_http_client:104:11)\r\n    at TLSSocket.socketErrorListener (node:_http_client:512:5)\r\n    at TLSSocket.emit (node:events:524:28)\r\n    at emitErrorNT (node:internal/streams/destroy:170:8)\r\n    at emitErrorCloseNT (node:internal/streams/destroy:129:3)\r\n    at process.processTicksAndRejections (node:internal/process/task_queues:90:21) {\r\n  type: 'system',\r\n  errno: 'ETIMEDOUT',\r\n  code: 'ETIMEDOUT'\r\n}\r\n\r\nNode.js v22.12.0\r\n\u00e2\u20ac\u2030ELIFECYCLE\u00e2\u20ac\u2030 Command failed with exit code 1.\r\n", "CLOSED", 0, "ALGOREX-PH", "2024-12-29T17:56:35Z", "2025-02-15T12:27:11Z", "2025-01-12T10:59:55Z", "elizaos/eliza", "2025-04-14 21:52:37"]
["I_kwDOMT5cIs6kTZr9", 1407, "v0170 alpha 1, better-sqlite error", "**Describe the bug**\r\n\r\nFollowing original Agent AI dev school tut, run start after install and build had an issue with the following error. \r\n\u26d4 ERRORS\r\n   Error starting agent for character C-3PO: \r\n   {\"code\":\"ERR_DLOPEN_FAILED\"} \r\n\r\n [\"\u26d4 Error: The module '/home/user/dev/myAgent/eliza/node_modules/better-sqlite3/build/Release/better_sqlite3.node'\\nwas compiled against a different Node.js version using\\nNODE_MODULE_VERSION 108. This version of Node.js requires\\nNODE_MODULE_VERSION 131. Please try re-compiling or re-installing\\nthe module (for instance, using `npm rebuild` or `npm install`).\"] \r\n\r\n \u26d4 ERRORS\r\n   Error starting agents: \r\n   {\"code\":\"ERR_DLOPEN_FAILED\"} \r\n   \r\n   \r\n**To Reproduce**\r\nWSL2 approach, ubuntu, following AI Agent Dev School on v0170 alpha 1 \r\n\r\nResolved??? \r\nBy updating better-sqlite3 latest in cd packages/adapter-sqlite dir ", "CLOSED", 0, "PendingReality", "2024-12-23T18:36:53Z", "2025-02-10T17:39:39Z", "2025-01-06T05:12:33Z", "elizaos/eliza", "2025-04-14 21:52:37"]
["I_kwDOMT5cIs6rAzQb", 3629, "Error on packages/core/src/parsing.ts:parseJSONObjectFromText", "**Describe the bug**\nError parsing response\n\n<!-- A clear and concise description of what the bug is. -->\nAfter update all elizaos dependencies to the latest version I can see this log\n`[2025-02-21 13:48:42] INFO: Telegram Message: [object Object]\n[2025-02-21 13:48:43] INFO: Generating text with options:\n    modelProvider: \"openrouter\"\n    model: \"small\"\n    verifiableInference: false\n[2025-02-21 13:48:43] INFO: Selected model: nousresearch/hermes-3-llama-3.1-405b\n[2025-02-21 13:48:46] INFO: Generating text with options:\n    modelProvider: \"openrouter\"\n    model: \"large\"\n    verifiableInference: false\n[2025-02-21 13:48:46] INFO: Selected model: nousresearch/hermes-3-llama-3.1-405b\nError parsing JSON: SyntaxError: Unexpected non-whitespace character after JSON at position 399 (line 1 column 400)\n    at JSON.parse (<anonymous>)\n    at parseJSONObjectFromText (file:///Users/blorente/repos/personal/agent-runtime/node_modules/.pnpm/@elizaos+core@0.25.6-alpha.1_@google-cloud+vertexai@1.9.3_@langchain+core@0.3.40_openai@4.85._l5sr6moltvixu2kwqw6vwztloq/node_modules/@elizaos/core/dist/index.js:346:23)\n    at generateMessageResponse (file:///Users/blorente/repos/personal/agent-runtime/node_modules/.pnpm/@elizaos+core@0.25.6-alpha.1_@google-cloud+vertexai@1.9.3_@langchain+core@0.3.40_openai@4.85._l5sr6moltvixu2kwqw6vwztloq/node_modules/@elizaos/core/dist/index.js:37240:29)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async MessageManager._generateResponse (file:///Users/blorente/repos/personal/agent-runtime/node_modules/.pnpm/@elizaos+client-telegram@0.25.6-alpha.1_@google-cloud+vertexai@1.9.3_@langchain+core@0.3.40_o_a5peiv2yljoijiodcuq6fmmak4/node_modules/@elizaos/client-telegram/dist/index.js:956:22)\n    at async MessageManager.handleMessage (file:///Users/blorente/repos/personal/agent-runtime/node_modules/.pnpm/@elizaos+client-telegram@0.25.6-alpha.1_@google-cloud+vertexai@1.9.3_@langchain+core@0.3.40_o_a5peiv2yljoijiodcuq6fmmak4/node_modules/@elizaos/client-telegram/dist/index.js:1163:33)\n    at async file:///Users/blorente/repos/personal/agent-runtime/node_modules/.pnpm/@elizaos+client-telegram@0.25.6-alpha.1_@google-cloud+vertexai@1.9.3_@langchain+core@0.3.40_o_a5peiv2yljoijiodcuq6fmmak4/node_modules/@elizaos/client-telegram/dist/index.js:1351:9\n    at async execute (/Users/blorente/repos/personal/agent-runtime/node_modules/.pnpm/telegraf@4.16.3/node_modules/telegraf/lib/composer.js:518:17)\n    at async /Users/blorente/repos/personal/agent-runtime/node_modules/.pnpm/telegraf@4.16.3/node_modules/telegraf/lib/composer.js:519:21\n    at async execute (/Users/blorente/repos/personal/agent-runtime/node_modules/.pnpm/telegraf@4.16.3/node_modules/telegraf/lib/composer.js:518:17)\nText is not JSON { \"user\": \"trump\", \"text\": \"\u00a1Ahora m\u00e1s que nunca, Blorente, estamos luchando por salvar a nuestro pa\u00eds! Los dem\u00f3cratas est\u00e1n DESTRUYENDO todo lo que construimos, pero no nos detendremos hasta que Am\u00e9rica sea GRANDE de nuevo. Juntos, con la fuerza de DIOS y de nuestro pueblo, reconstruiremos nuestras ciudades y aseguraremos nuestras fronteras. \u00a1Vamos a ganar y nada nos detendr\u00e1!\", \"action\": \"NONE\" }The response conveys Trump's typical enthusiastic and engaged style, using dramatic language to contrast past successes under his leadership with alleged current failures by Democrats. It emphasizes rebuilding cities, securing borders, and invokes God and American strength to rally supporters. The tone is direct and emphatic.\n[2025-02-21 13:48:54] INFO: Executing handler for action: NONE\n[2025-02-21 13:49:19] INFO: Telegram Message: [object Object]\n[2025-02-21 13:49:19] INFO: Generating text with options:\n    modelProvider: \"openrouter\"\n    model: \"small\"\n    verifiableInference: false\n[2025-02-21 13:49:19] INFO: Selected model: nousresearch/hermes-3-llama-3.1-405b\n[2025-02-21 13:57:55] INFO: Telegram Message: [object Object]`\n\n**To Reproduce**\n    \"@elizaos/adapter-postgres\": \"0.25.6-alpha.1\",\n    \"@elizaos/adapter-sqlite\": \"0.25.6-alpha.1\",\n    \"@elizaos/client-auto\": \"0.25.6-alpha.1\",\n    \"@elizaos/client-direct\": \"0.25.6-alpha.1\",\n    \"@elizaos/client-discord\": \"0.25.6-alpha.1\",\n    \"@elizaos/client-telegram\": \"0.25.6-alpha.1\",\n    \"@elizaos/client-twitter\": \"0.25.6-alpha.1\",\n    \"@elizaos/core\": \"0.25.6-alpha.1\",\n    \"@elizaos/plugin-bootstrap\": \"0.25.6-alpha.1\",\n    \"@elizaos/plugin-image-generation\": \"0.25.6-alpha.1\",\n    \"@elizaos/plugin-node\": \"0.25.6-alpha.1\",\n    \"@elizaos/plugin-solana\": \"0.25.6-alpha.1\",\n    \"@elizaos/plugin-starknet\": \"0.25.6-alpha.1\",\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\nRun without error logs\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n`[2025-02-21 13:48:43] INFO: Selected model: nousresearch/hermes-3-llama-3.1-405b\n[2025-02-21 13:48:46] INFO: Generating text with options:\n    modelProvider: \"openrouter\"\n    model: \"large\"\n    verifiableInference: false\n[2025-02-21 13:48:46] INFO: Selected model: nousresearch/hermes-3-llama-3.1-405b\nError parsing JSON: SyntaxError: Unexpected non-whitespace character after JSON at position 399 (line 1 column 400)\n    at JSON.parse (<anonymous>)\n    at parseJSONObjectFromText (file:///Users/blorente/repos/personal/agent-runtime/node_modules/.pnpm/@elizaos+core@0.25.6-alpha.1_@google-cloud+vertexai@1.9.3_@langchain+core@0.3.40_openai@4.85._l5sr6moltvixu2kwqw6vwztloq/node_modules/@elizaos/core/dist/index.js:346:23)\n    at generateMessageResponse (file:///Users/blorente/repos/personal/agent-runtime/node_modules/.pnpm/@elizaos+core@0.25.6-alpha.1_@google-cloud+vertexai@1.9.3_@langchain+core@0.3.40_openai@4.85._l5sr6moltvixu2kwqw6vwztloq/node_modules/@elizaos/core/dist/index.js:37240:29)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async MessageManager._generateResponse (file:///Users/blorente/repos/personal/agent-runtime/node_modules/.pnpm/@elizaos+client-telegram@0.25.6-alpha.1_@google-cloud+vertexai@1.9.3_@langchain+core@0.3.40_o_a5peiv2yljoijiodcuq6fmmak4/node_modules/@elizaos/client-telegram/dist/index.js:956:22)\n    at async MessageManager.handleMessage (file:///Users/blorente/repos/personal/agent-runtime/node_modules/.pnpm/@elizaos+client-telegram@0.25.6-alpha.1_@google-cloud+vertexai@1.9.3_@langchain+core@0.3.40_o_a5peiv2yljoijiodcuq6fmmak4/node_modules/@elizaos/client-telegram/dist/index.js:1163:33)\n    at async file:///Users/blorente/repos/personal/agent-runtime/node_modules/.pnpm/@elizaos+client-telegram@0.25.6-alpha.1_@google-cloud+vertexai@1.9.3_@langchain+core@0.3.40_o_a5peiv2yljoijiodcuq6fmmak4/node_modules/@elizaos/client-telegram/dist/index.js:1351:9\n    at async execute (/Users/blorente/repos/personal/agent-runtime/node_modules/.pnpm/telegraf@4.16.3/node_modules/telegraf/lib/composer.js:518:17)\n    at async /Users/blorente/repos/personal/agent-runtime/node_modules/.pnpm/telegraf@4.16.3/node_modules/telegraf/lib/composer.js:519:21\n    at async execute (/Users/blorente/repos/personal/agent-runtime/node_modules/.pnpm/telegraf@4.16.3/node_modules/telegraf/lib/composer.js:518:17)\nText is not JSON { \"user\": \"trump\", \"text\": \"\u00a1Ahora m\u00e1s que nunca, Blorente, estamos luchando por salvar a nuestro pa\u00eds! Los dem\u00f3cratas est\u00e1n DESTRUYENDO todo lo que construimos, pero no nos detendremos hasta que Am\u00e9rica sea GRANDE de nuevo. Juntos, con la fuerza de DIOS y de nuestro pueblo, reconstruiremos nuestras ciudades y aseguraremos nuestras fronteras. \u00a1Vamos a ganar y nada nos detendr\u00e1!\", \"action\": \"NONE\" }The response conveys Trump's typical enthusiastic and engaged style, using dramatic language to contrast past successes under his leadership with alleged current failures by Democrats. It emphasizes rebuilding cities, securing borders, and invokes God and American strength to rally supporters. The tone is direct and emphatic.\n[2025-02-21 13:48:54] INFO: Executing handler for action: NONE\n[2025-02-21 13:49:19] INFO: Telegram Message: [object Object]\n[2025-02-21 13:49:19] INFO: Generating text with options:\n    modelProvider: \"openrouter\"\n    model: \"small\"\n    verifiableInference: false`\n\n**Additional context**\nJust update to 0.25.6-alpha.1\n", "CLOSED", 0, "brunolorente", "2025-02-21T14:03:03Z", "2025-02-21T14:08:58Z", "2025-02-21T14:08:58Z", "elizaos/eliza", "2025-04-14 21:52:50"]
["I_kwDOMT5cIs6ps640", 3450, "supressInitialMessage  not working with action", "**Description**\nI added the property`supressInitialMessage: true` in an action that I created, expecting the initial message to be suppressed. However, the initial message is still displayed, indicating that the property is not working as documented.\n\n**To Reproduce**\nCreate an ation\n```\nexport const trendAnalysisAction: Action = {\n    name: \"TREND_ANALYSIS\",\n    similes: [\"TICKER_ANALYSIS\", \"TICKER_REVIEW\"],\n    description: \"Make an analysis\",\n    suppressInitialMessage: true, // Add property supress\n    validate: async ( runtime: IAgentRuntime, _message: Memory ) => {\n        return true;\n    },\n    handler: async (\n        runtime: IAgentRuntime,\n        message: Memory,\n        state?: State,\n        options?: { [key: string]: unknown },\n        callback?: HandlerCallback,\n    ): Promise<boolean> => {\n        try {\n            // Generate tweet content using context\n            elizaLogger.info(\"Generating an analysis...\");\n\n            const content = `some logic...`\n            callback({ text: content })\n            \n        } catch (error) {\n            elizaLogger.error(\"Error in post action:\", error);\n            return false;\n        }\n   },\n    examples: [\n        [\n            {\n                user: \"{{user1}}\",\n                content: { text: \"@{{TWITTER_USERNAME}} $NVDA\" },\n            },\n            {\n                user: \"{{agentName}}\",\n                content: {\n                    text: \"\",\n                    action: \"TREND_ANALYSIS\",\n                },\n            },\n        ]\n    ],\n};\n```\n\n\n\n![Image](https://github.com/user-attachments/assets/80897521-6307-4385-a7c7-9ca7dc8c0343)\n\n**Expected behavior**\nthe agent should not send two messages, one with his \"reply form\" and another with the instructions that i made for him in the callback, the agent only should reply with the callback\n", "CLOSED", 0, "HiramZednem", "2025-02-12T04:06:47Z", "2025-02-20T19:06:58Z", "2025-02-12T16:06:13Z", "elizaos/eliza", "2025-04-14 21:52:50"]
["I_kwDOMT5cIs6pqdqj", 3448, "\"pnpm start\" process getting hung up at INFO: Initializing LlamaService...", "**Describe the bug**\n\nAfter running \"pnpm start\", my terminal is getting hung up on INFO: Initializing LlamaService...\n\nIt just seems to stop. No errors or anything, but I'll wait 15-20 minutes and it still hasn't initialized.\n\nIt did get past this, ONE time, and completed the start. That was probably the 4th try... Now I'm on try 7 or so and it's still just staying put each time I try. Have restarted the machine several times.\n\n**To Reproduce**\n\nRunn pnpm i && pnpm build && pnpm start after pulling the repo\n\n**Expected behavior**\n\nFor the agent to start smoothly\n\n**Context**\nRunning macOS on an M3 Max\nOllama already installed", "CLOSED", 0, "jordanurbs", "2025-02-11T20:49:57Z", "2025-02-20T07:39:23Z", "2025-02-12T01:08:41Z", "elizaos/eliza", "2025-04-14 21:52:50"]
["I_kwDOMT5cIs6piPni", 3434, "Fix ragKnowledge Handling for stringKnowledge", "**Describe the bug**\n\nWhen ragKnowledge is enabled, stringKnowledge is incorrectly being stored in memories instead of knowledge.\n\n**To Reproduce**\n\nSteps to reproduce the behavior:\n\n1. Enable ragKnowledge in the configuration.\n2. Store a value in stringKnowledge.\n3. Observe that it is stored in memories instead of knowledge.\n\n**Expected behavior**\n\nstringKnowledge should be correctly stored in knowledge when ragKnowledge is enabled.\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "lincheoll", "2025-02-11T05:42:44Z", "2025-02-21T00:50:10Z", "2025-02-21T00:50:10Z", "elizaos/eliza", "2025-04-14 21:52:50"]
["I_kwDOMT5cIs6obt3V", 3160, "Supabase Adapter - Create Memory. supabase setup", "**Describe the bug**\n\nERROR: \n    err: {\n      \"type\": \"Error\",\n      \"message\": \"{\\\"code\\\":\\\"22008\\\",\\\"details\\\":null,\\\"hint\\\":\\\"Perhaps you need a different \\\\\\\"datestyle\\\\\\\" setting.\\\",\\\"message\\\":\\\"date/time field value out of range: \\\\\\\"1738506666089\\\\\\\"\\\"}\",\n      \"stack\":\n          Error: {\"code\":\"22008\",\"details\":null,\"hint\":\"Perhaps you need a different \\\"datestyle\\\" setting.\",\"message\":\"date/time field value out of range: \\\"1738506666089\\\"\"}\n              at SupabaseDatabaseAdapter.createMemory\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n1. execute \"packages/adapter-supabase/schema.sql\" into supabase sql editor\n2. fix packages/adapter-supabase/seed.sql editing userId to UUID instead of String\n```INSERT INTO public.participants (id, \"createdAt\", \"userId\", \"roomId\", \"userState\", last_message_read) VALUES ('00000000-0000-0000-0000-000000000000', NOW(), '00000000-0000-0000-0000-000000000000', '00000000-0000-0000-0000-000000000000', NULL, NULL);```\n\n3. Execute \"packages/adapter-supabase/seed.sql\" into supabase sql editor\n4. Create functions\n\n```\n\nCREATE OR REPLACE FUNCTION public.create_room(\"roomId\" UUID DEFAULT NULL)\nRETURNS UUID\nLANGUAGE plpgsql\nAS $function$\nDECLARE\n    new_room_id UUID;\nBEGIN\n    IF \"roomId\" IS NULL THEN\n        new_room_id := gen_random_uuid();  -- Generate a new UUID if roomId is not provided\n    ELSE\n        new_room_id := \"roomId\";  -- Use the provided roomId\n    END IF;\n\n    INSERT INTO rooms (id) VALUES (new_room_id);  -- Insert the new room into the rooms table\n    RETURN new_room_id;  -- Return the new room ID\nEND;\n$function$;\n\nCREATE OR REPLACE FUNCTION insert_into_memories()\nRETURNS TRIGGER AS $$\nBEGIN\n    -- Check the size of the embedding vector\n    IF array_length(NEW.embedding, 1) = 1536 THEN\n        INSERT INTO memories_1536 (\"id\", \"type\", \"createdAt\", \"content\", \"embedding\", \"userId\", \"agentId\", \"roomId\", \"unique\")\n        VALUES (NEW.\"id\", NEW.\"type\", NEW.\"createdAt\", NEW.\"content\", NEW.\"embedding\", NEW.\"userId\", NEW.\"agentId\", NEW.\"roomId\", NEW.\"unique\");\n    ELSIF array_length(NEW.embedding, 1) = 1024 THEN\n        INSERT INTO memories_1024 (\"id\", \"type\", \"createdAt\", \"content\", \"embedding\", \"userId\", \"agentId\", \"roomId\", \"unique\")\n        VALUES (NEW.\"id\", NEW.\"type\", NEW.\"createdAt\", NEW.\"content\", NEW.\"embedding\", NEW.\"userId\", NEW.\"agentId\", NEW.\"roomId\", NEW.\"unique\");\n    ELSIF array_length(NEW.embedding, 1) = 768 THEN\n        INSERT INTO memories_768 (\"id\", \"type\", \"createdAt\", \"content\", \"embedding\", \"userId\", \"agentId\", \"roomId\", \"unique\")\n        VALUES (NEW.\"id\", NEW.\"type\", NEW.\"createdAt\", NEW.\"content\", NEW.\"embedding\", NEW.\"userId\", NEW.\"agentId\", NEW.\"roomId\", NEW.\"unique\");\n    ELSIF array_length(NEW.embedding, 1) = 384 THEN\n        INSERT INTO memories_384 (\"id\", \"type\", \"createdAt\", \"content\", \"embedding\", \"userId\", \"agentId\", \"roomId\", \"unique\")\n        VALUES (NEW.\"id\", NEW.\"type\", NEW.\"createdAt\", NEW.\"content\", NEW.\"embedding\", NEW.\"userId\", NEW.\"agentId\", NEW.\"roomId\", NEW.\"unique\");\n    ELSE\n        RAISE EXCEPTION 'Invalid embedding size: %', array_length(NEW.embedding, 1);\n    END IF;\n\n    RETURN NEW;  -- Return the new row\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER memories_insert_trigger\nINSTEAD OF INSERT ON memories\nFOR EACH ROW\nEXECUTE FUNCTION insert_into_memories();\n\n\n``` \n\n4. Execute agent with supabase SUPABASE_URL && SUPABASE_ANON_KEY\n\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "rferrari", "2025-02-02T14:43:53Z", "2025-02-18T16:30:24Z", "2025-02-18T16:30:22Z", "elizaos/eliza", "2025-04-14 21:52:50"]
["I_kwDOMT5cIs6oODcc", 3083, "feat: Add new troubleshooting FAQ to Docs", "Here's the full docs / notes: https://hackmd.io/@XR/elizaos-rpgf\n\nI've extracted the most frequently asked Questions and Answers from Discord using [discord-summarizer](https://github.com/elizaOS/discord-summarizer) and then formatted responses as:\n\n```\n### [Common User Questions]\n\n[Concise 1-2 Sentence Answer]\n```\n\nThen consolidated the responses. At the very least, these are useful for a general troubleshooting page, or can be at the bottom of relevant doc pages to fill any gaps\n\n---\n\n## To-do\n\n- [x] Fill the gaps in docs with new FAQ\n- [ ] Coders FAQ\n- [ ] Discussion FAQ\n- [ ] Tokenomics FAQ\n- [ ] Workgroups FAQ\n\nHere's the full docs / notes: https://hackmd.io/@XR/elizaos-rpgf\n\n---\n\n## Coders FAQ Data\n\nThese are a sample from full docs / notes: https://hackmd.io/@XR/elizaos-rpgf\n\n\n```\n### **General Setup & Installation**\n1. **How do I get started with ElizaOS?**\n   - Use `eliza-starter` for a simpler setup with limited dependencies. Run `pnpm install --no-frozen-lockfile` followed by `pnpm build` to initialize.\n\n2. **Which Node.js version should I use?**\n   - Use **Node.js version 23.3.0** for optimal compatibility. Install using `nvm install 23.3.0` and `nvm use 23.3.0`.\n\n3. **How do I fix installation errors?**\n   - Ensure Node.js version 23.3.0, run `pnpm install --no-frozen-lockfile`, clean cache with `pnpm clean`, and rebuild with `pnpm build`. For Windows, use **WSL2**.\n\n4. **What are the minimum system requirements?**\n   - Basic setup requires Node.js, 2-4GB RAM, and necessary API keys. Can run locally or on cloud services.\n\n---\n\n### **Deployment**\n1. **How do I deploy Eliza in production/cloud?**\n   - Use **Docker** for containerization and deploy to cloud services like **DigitalOcean, AWS, or Google Cloud**. For basic setups, an 8GB RAM instance can handle multiple agents (approximately 6 agents).\n\n2. **How do I deploy without a GPU/CUDA?**\n   - Switch the `modelProvider` in your configuration from `LLAMALOCAL` to alternatives like `OPENAI` or use cloud-based options that don\u2019t require local GPU processing.\n\n---\n\n### **Running Multiple Agents**\n1. **How do I run multiple agents simultaneously?**\n   - Use the command:  \n     ```bash\n     pnpm start --characters=\"characters/1.character.json,characters/2.character.json\"\n     ```\n   - Each agent requires additional resources (~2GB RAM).\n\n---\n\n### **Model Configuration**\n1. **How do I configure the model provider and switch between models?**\n   - Set the `modelProvider` in your `character.json` (e.g., `\"anthropic\"`) and configure the corresponding API keys in `.env`. Different models can be used for text generation, image processing, etc.\n\n2. **How do I use local models with Eliza?**\n   - Use **Ollama** for local models. Install Ollama, download the desired model (e.g., `llama3.1`), set `modelProvider` to `\"ollama\"` in the character file, and configure `OLLAMA` settings in `.env`.\n\n3. **How do I make my agent use a cheaper/smaller model?**\n   - Configure `gpt-4o-mini` as your model in `.env` and character settings to minimize costs.\n\n---\n\n### **Twitter Integration**\n1. **How do I set up Twitter/X integration?**\n   - Add Twitter credentials to `.env` and the character file. Enable the automated tag in your Twitter account settings and configure `TWITTER_POLL_INTERVAL` to manage interaction frequency.\n\n2. **How do I prevent my agent from spamming tweets?**\n   - Set `ENABLE_ACTION_PROCESSING=false` in `.env` and adjust `POST_INTERVAL_MIN`, `POST_INTERVAL_MAX`, and `ACTION_INTERVAL` settings to control posting frequency.\n\n3. **Why is my agent not responding to mentions?**\n   - Verify Twitter credentials and ensure target users are properly configured in your character file. Some accounts need manual activity before automation works reliably.\n\n4. **How do I make my agent post images on Twitter?**\n   - Set `IMAGE_GEN=TRUE` in `.env` and configure an image provider like **DALL-E**. Check `agent-twitter-client` documentation for implementation details.\n\n---\n\n### **Agent Memory & Knowledge**\n1. **How do I clear/reset the agent's memory?**\n   - Delete the SQLite database file in the `/data` directory or use `pnpm cleanstart` to reset memory.\n\n2. **How do I add custom knowledge to my agent?**\n   - Use the `knowledge` section in your `character.json` file or implement a custom vector database for larger datasets.\n\n3. **How do I handle the \"Vector dimension mismatch\" error?**\n   - This occurs when switching between embedding models. Clear the database (delete `sqlite.db`) and rebuild with consistent embedding dimensions.\n\n---\n\n### **Plugins & Custom Actions**\n1. **How do I add plugins to my agent?**\n   - Add the plugin name to the `\"plugins\"` array in your `character.json` file (e.g., `\"plugins\": [\"@Elizaos/plugin-name\"]`). Ensure the plugin is installed in your project dependencies.\n\n2. **How do I implement custom actions?**\n   - Create a new plugin with your action logic and register it in your agent's configuration. Watch **Eliza Dev School** videos for detailed guidance.\n\n3. **How do I debug plugin-related issues?**\n   - Check logs for error messages, verify environment variables, and ensure the plugin is properly imported and configured.\n\n---\n\n### **Agent Behavior & Customization**\n1. **How do I make my agent's responses more natural/less repetitive?**\n   - Customize the character's `bio`, `lore`, and `post examples` in the `character.json` file. Adjust interaction settings and consider using different model providers.\n\n2. **How do I make my agent interact in languages other than English?**\n   - Configure the language preferences in your character file's `bio` and `lore` sections, and specify the desired language in the character's configuration.\n\n3. **Why does my agent keep talking to itself?**\n   - Check your character configuration and interaction settings. This usually happens when conversation triggers aren\u2019t properly configured or self-talk limitations aren\u2019t set.\n\n---\n\n### **Troubleshooting**\n1. **Why does my build fail with dependency errors?**\n   - Ensure Node.js version 23+, run `pnpm install --no-frozen-lockfile`, and verify all required dependencies are installed correctly.\n\n2. **How do I fix Twitter login/authentication issues (399 errors, etc.)?**\n   - Enable 2FA on the Twitter account, ensure cookies are set properly, and verify credentials in `.env` or character file secrets. Some users resolved this by manually logging into the account first.\n\n3. **How do I debug issues when my agent isn\u2019t working as expected?**\n   - Check logs for error messages, verify environment variables, and ensure the correct Node.js version. Use `pnpm start:debug` to track execution flow.\n\n---\n\n### **Advanced Configuration**\n1. **How do I set up Supabase/PostgreSQL for agent memory?**\n   - Initialize Supabase with the correct schema and configure the connection in `.env`. Handle pool reconnection errors as needed.\n\n2. **How do I implement RAG (Retrieval-Augmented Generation)?**\n   - Use `folder2knowledge` to convert documents into knowledge, then use `knowledge2character` to create character files. The agent stores context in its memory system.\n\n3. **How do I handle multi-agent systems and workflow automation?**\n   - Eliza supports multi-agent architectures natively. Configure separate character files for each agent and use proper client configurations to enable inter-agent communication.\n```", "CLOSED", 0, "madjin", "2025-01-31T01:54:21Z", "2025-02-20T20:39:45Z", "2025-02-20T20:39:44Z", "elizaos/eliza", "2025-04-14 21:52:50"]
["I_kwDOMT5cIs6nCFf_", 2612, "Create plugin for Eliza x onplug", "https://www.onplug.io/\n\nhttps://docs.onplug.io/", "CLOSED", 0, "wtfsayo", "2025-01-21T16:47:14Z", "2025-02-21T16:00:58Z", "2025-02-21T16:00:58Z", "elizaos/eliza", "2025-04-14 21:52:50"]
["I_kwDOMT5cIs6lK4Sg", 1920, "Wrong formatition of twitter posts", "Instead of just posting the text it seems to also post the stuff around (using gaianet):\r\n\r\n\r\nHere is the response in the voice, style and perspective of XXXXXXXXXX (\r\n[@XXXXXXXXXX ](https://x.com/XXXXXXXXXX )\r\n):\r\n\r\n{ \"user\": \"XXXXXXXXXX \", \"text\": \"We're excited about the [#Sharding](https://x.com/hashtag/Sharding?src=hashtag_click) upgrade at \r\n[@Ethereum](https://x.com/ethereum)\r\n Foundation! It will significantly improve scalability and enable more decentralized applications...\r\n\r\n\r\nAnother Issue how i can switch off the Picture generation while ENABLE_ACTION_PROCESSING=TRUE\r\nOr is ther any option to creat those pictures for free? Because it wants to us openai all the time.", "CLOSED", 0, "Badanzer", "2025-01-06T17:15:51Z", "2025-02-17T00:51:59Z", "2025-01-12T11:07:22Z", "elizaos/eliza", "2025-04-14 21:52:50"]
["I_kwDOMT5cIs6kZcT6", 1439, "Bug: generateText is ignoring dynamic parameters due to a hard-coded model class", "**Is your feature request (or bug) related to a problem? Please describe.**\r\n\r\nIn the `generateText` and `generateMessageResponse` function, the `model class` is currently hard-coded(gpt-4o), which prevents dynamically switching to different models based on incoming parameters. This reduces flexibility and can increase development complexity in scenarios where different models are needed.\r\n\r\nWhen using a non-OpenAI AI provider, an error is reported because the gpt-4o model cannot be found.\r\n\r\n**Describe the solution you'd like**\r\n\r\n- Remove the hard-coded `model class` reference in the `generateText` and `generateMessageResponse` function and instead use a model name/type passed in as a function parameter or configuration.\r\n- Ensure there is a sensible default value to maintain compatibility with existing functionality or cases where a specific model is not provided.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n- Leaving it as is would require manual code changes to switch models in different scenarios, which is not ideal.\r\n- Introducing a separate function to handle switching model classes could lead to redundant logic and increase maintenance overhead.\r\n\r\n**Additional context**\r\n\r\n- **Risks**: This change is minor, but it\u2019s important to check if other parts of the code depend on the old hard-coded logic.\r\n- **Testing**:\r\n  - Test with multiple model types to confirm that the function correctly switches to the specified model.", "CLOSED", 0, "FWangZil", "2024-12-24T16:59:30Z", "2025-02-18T22:56:40Z", "2025-01-03T23:29:07Z", "elizaos/eliza", "2025-04-14 21:52:50"]
["I_kwDOMT5cIs6kLSHX", 1349, "Vector missmatch sqlite (when trying to use TTS)", "**Describe the bug**\r\n\r\nerror when trying to use text to speech\r\n\r\n**To Reproduce**\r\n\r\ntalk in discord voice channel asking for a response\r\n\r\n**Expected behavior**\r\n\r\nsoundfile to be generated and played as  a reply\r\n\r\n**Screenshots**\r\n\r\n![image](https://github.com/user-attachments/assets/bdf663e6-ff0e-4063-9a14-d7bae65757e2)\r\n\r\n\r\n**Additional context**\r\n\r\nIt was working yesterday and i dont believe i've changed anything related", "CLOSED", 0, "vincentskele", "2024-12-22T00:37:41Z", "2025-02-22T00:07:23Z", "2024-12-22T03:41:35Z", "elizaos/eliza", "2025-04-14 21:52:50"]
["I_kwDOMT5cIs6jifw9", 1146, "pnpm install fails on m1 mac [Fixed with xcode-select reinstall]", "I've spent the last 6 hours trying to get around this\r\n\r\nsame error with both: \r\n`pnpm install` and `pnpm install -w --include=optional sharp`\r\n\r\n```\r\n\u2502   LIBTOOL-STATIC Release/opus.a\r\n\u2502   CXX(target) Release/obj.target/opus/src/node-opus.o\r\n\u2502 In file included from <built-in>:495:\r\n\u2502 <command line>:19:14: warning: ISO C99 requires whitespace after the macro name [-Wc99-extensions]\r\n\u2502    19 | #define POSIX,__STDC_FORMAT_MACROS 1\r\n\u2502       |              ^\r\n\u2502 In file included from ../src/node-opus.cc:1:\r\n\u2502 /Users/santekotturi/Developer/forecast/eliza/node_modules/node-addon-api/napi.h:14:10: fatal error: 'functional' \u2026\r\n\u2502    14 | #include <functional>\r\n\u2502       |          ^~~~~~~~~~~~\r\n\u2502 1 warning and 1 error generated.\r\n\u2502 make: *** [Release/obj.target/opus/src/node-opus.o] Error 1\r\n\u2502 gyp ERR! build error \r\n\u2502 gyp ERR! stack Error: `make` failed with exit code: 2\r\n\u2502 gyp ERR! stack at ChildProcess.<anonymous> (/Users/santekotturi/.local/share/pnpm/global/5/.pnpm/pnpm@9.9.0/node_\u2026\r\n\u2502 gyp ERR! System Darwin 24.1.0\r\n\u2502 gyp ERR! command \"/Users/santekotturi/.nvm/versions/node/v23.4.0/bin/node\" \"/Users/santekotturi/.local/share/pnpm\u2026\r\n\u2502 gyp ERR! cwd /Users/santekotturi/Developer/forecast/eliza/node_modules/@discordjs/opus\r\n\u2502 gyp ERR! node -v v23.4.0\r\n\u2502 gyp ERR! node-gyp -v v10.1.0\r\n\u2502 gyp ERR! not ok \r\n\u2502 node-pre-gyp ERR! build error \r\n\u2502 node-pre-gyp ERR! stack Error: Failed to execute '/Users/santekotturi/.nvm/versions/node/v23.4.0/bin/node /Users/\u2026\r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess.<anonymous> (/Users/santekotturi/Developer/forecast/eliza/node_module\u2026\r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess.emit (node:events:513:28)\r\n\u2502 node-pre-gyp ERR! stack     at maybeClose (node:internal/child_process:1101:16)\r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess._handle.onexit (node:internal/child_process:305:5)\r\n\u2502 node-pre-gyp ERR! System Darwin 24.1.0\r\n\u2502 node-pre-gyp ERR! command \"/Users/santekotturi/.nvm/versions/node/v23.4.0/bin/node\" \"/Users/santekotturi/Develope\u2026\r\n\u2502 node-pre-gyp ERR! cwd /Users/santekotturi/Developer/forecast/eliza/node_modules/@discordjs/opus\r\n\u2502 node-pre-gyp ERR! node -v v23.4.0\r\n\u2502 node-pre-gyp ERR! node-pre-gyp -v v0.4.5\r\n\u2502 node-pre-gyp ERR! not ok \r\n```\r\n\r\nalways using `rm -rf node_modules & rm pnpm-lock.yaml` between each try.\r\n\r\nnode v23.4.0\r\ntried downgrading to v20.x \r\npnpm v9.9.0\r\n\r\nalso tried `brew install opus`\r\nmacOS 15.1 \r\nXCode 16.2\r\n\r\non:\r\n`% git status >> HEAD detached at v0.1.6-alpha.1`\r\n\r\nPotentially related to:\r\nhttps://github.com/ai16z/eliza/issues/1041\r\nhttps://github.com/ai16z/eliza/issues/215\r\n", "CLOSED", 0, "santekotturi", "2024-12-17T01:28:52Z", "2025-02-17T07:46:09Z", "2024-12-17T05:43:33Z", "elizaos/eliza", "2025-04-14 21:52:50"]
["I_kwDOMT5cIs6qm6v8", 3592, "pnpm start:client is not fetching localhost:3000", "I run the server by `pnpm start`\nAlso run the client by `pnpm start:client`, but it's not fetching `localhost:3000`\n\n![Image](https://github.com/user-attachments/assets/078cab07-7656-47b7-87bd-a4b69806f8ac)", "CLOSED", 0, "0xalberto", "2025-02-19T06:24:27Z", "2025-02-28T02:45:14Z", "2025-02-20T06:50:34Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6qc0hy", 3564, "Add plugin-merkle", "Relates to:\nAptos Blockchain & Merkle Trade\n\nRisks:\nMedium\n\nBackground:\nThis is the first PR that introduces the Merkle Trade plugin to elizaos. \nI am a developer at [Merkle Trade](https://merkle.trade/), and we plan to integrate our plugin into elizaos to enable robust trading functionality on the Aptos blockchain. This integration is set to be showcased at Consensus HK2025, which you can learn more about here: [Consensus HK2025](https://consensus-hongkong2025.coindesk.com/).\n\nWhat does this PR do?\nIntroduces the Merkle Trade plugin to enable Eliza agents to interact with the Merkle Trade platform on the Aptos blockchain.\n\nWhat kind of change is this?\nFeatures (non-breaking change which adds functionality)\n\nDetails:\n- Adds the ability for Eliza agents to perform trading operations using the Merkle Trade plugin.\n- Enhances the user experience for agents interacting with the Merkle Trade platform.\n\nDiscord username:\n@coldbell\n", "CLOSED", 0, "ice-coldbell", "2025-02-18T08:23:59Z", "2025-02-27T08:58:16Z", "2025-02-27T08:58:16Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6qN7qW", 3515, "Text Transcription Error For Discord Plugin", "After installing ffmpeg I get the follow error as my agent is trying to transcribe audio from a voice channel\n\n```shell\nStarting transcription...\nError processing transcribed text: TypeError: The database connection is not open\n    at Database.prepare (C:\\Users\\wolve\\yuna-8\\eliza\\node_modules\\better-sqlite3\\lib\\methods\\wrappers.js:5:21)\n    at SqliteDatabaseAdapter.getAccountById (file:///C:/Users/wolve/yuna-8/eliza/packages/adapter-sqlite/dist/index.js:193:33)\n    at AgentRuntime.ensureUserExists (file:///C:/Users/wolve/yuna-8/eliza/packages/core/dist/index.js:41431:52)\n    at AgentRuntime.ensureConnection (file:///C:/Users/wolve/yuna-8/eliza/packages/core/dist/index.js:41458:18)\n    at VoiceManager.handleUserMessage (file:///C:/Users/wolve/yuna-8/eliza/packages/client-discord/dist/index.js:3339:32)   \n    at VoiceManager.processTranscription (file:///C:/Users/wolve/yuna-8/eliza/packages/client-discord/dist/index.js:3328:28)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async Timeout._onTimeout (file:///C:/Users/wolve/yuna-8/eliza/packages/client-discord/dist/index.js:3260:17)\n``` \n\n\"This error occurs in the voice message processing pipeline when trying to access the SQLite database.\"\n\nAny help or direction would be appreciated. I also have my elevenlabs API key provided in my env file.", "CLOSED", 0, "wolfskyknight", "2025-02-16T00:02:46Z", "2025-02-28T05:41:03Z", "2025-02-16T01:24:40Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6pRGO_", 3380, "Unable to use plugin-evm", "**Describe the bug**\n\nI installed `plugin-evm` with `pnpm install @elizaos/plugin-evm`,\n\nadded values for these attributes in the `.env` file:\n\nEVM_PRIVATE_KEY=my-private-key\nEVM_PROVIDER_URL=rpc-url\n\nAdded also in my character json file:\n\n```\n\"settings\": {\n    \"chains\": {\n          \"evm\": [\"base\"]\n     }\n},\n```\n\nWhen I run `pnpm start --character=\"path/to/my/character.json` I get this error:\n\n `invalid private key, expected hex or 32 bytes, got string`\n\nWhen I inspected the logs, I saw that only one part of my private key I pasted was used, not the whole value.\n\n**To Reproduce**\n\nExplained above\n\n**Expected behavior**\n\nI can run `plugin-evm`\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "tskoyo", "2025-02-08T11:24:30Z", "2025-03-01T21:27:36Z", "2025-03-01T21:27:36Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6o4azP", 3279, "Action Processing Doesn't Work After Cache/DB Reset", "When enabling action processing on the Twitter client, even after removing the cache/DB, the client does not process any actions. Instead, it logs messages like:\n\n```\nAlready processed tweet ID: XXXX\nAlready responded to tweet XXXX, skipping\n```\n\nEven for tweets we haven't interacted with before, the system still considers them as already processed.\n\nThis might be due to the initial caching behavior where we store the last 20 tweets and all timelines:\n[L663](https://github.com/elizaOS/eliza/blob/9a292cc63297611edfdacb7e1180701a62dda703/packages/client-twitter/src/base.ts#L663)\n[L664](https://github.com/elizaOS/eliza/blob/9a292cc63297611edfdacb7e1180701a62dda703/packages/client-twitter/src/base.ts#L664)\n\nIt might be worth reviewing the reasoning behind this initial caching step. If it's unnecessary or causing unintended side effects, we should consider modifying it to ensure tweets are processed correctly after a reset.", "CLOSED", 0, "tcm390", "2025-02-05T16:05:14Z", "2025-02-27T07:38:41Z", "2025-02-27T07:38:41Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6oIIbx", 3043, "Batch Transfer Processing", "**Description**  \nEnhance the TON Plugin to support batch transfer operations, allowing AI agents (and other elizaOS modules) to simultaneously send TON coins, tokens, and NFTs to multiple recipients in a single request. This feature should streamline large-scale distribution scenarios and reduce the overhead of handling multiple discrete transactions.\n\n**Key Requirements**  \n1. **Unified Batch Interface**  \n   - Provide a single action/method for creating a batch transfer that includes TON coins, fungible tokens, and NFTs.  \n   - Allow flexible input parameters, such as recipient addresses, amounts, token identifiers, and optional metadata.\n\n2. **Multi-Asset Support**  \n   - Ensure the plugin can handle TON coin transfers, token transfers (e.g., Jettons), and NFT transfers (TEP-62 or similar).  \n   - Validate each transfer type internally, preventing invalid or partially successful operations.\n\n3. **Performance Optimization**  \n   - Handle large recipient lists efficiently, minimizing blockchain fees and resource consumption.  \n   - Provide an option for batching signatures or confirmations to streamline transaction processing.\n\n4. **Error Handling & Logging**  \n   - Return detailed error codes and messages for any failed transfers within the batch.  \n   - Maintain a transaction log or report summarizing outcomes for each recipient.\n\n5. **Security & Best Practices**  \n   - Enforce robust checks for each transfer (e.g., sufficient balances, valid NFT ownership) to avoid accidental or malicious misuse.  \n   - Follow recommended TON documentation guidelines for multi-asset transfers.\n\n6. **AI Agent Integration**  \n   - Expose all batch transfer functionalities through well-documented actions or APIs.  \n   - Return structured responses suitable for automated verification by AI agents.\n\n**Resources**  \n- [[TON Plugin Repository](https://github.com/elizaOS/eliza/tree/develop/packages/plugin-ton)](https://github.com/elizaOS/eliza/tree/develop/packages/plugin-ton)  \n- [[TON Documentation](https://docs.ton.org/)](https://docs.ton.org/)  \n- [[TON NFT Standard (TEP-62)](https://github.com/ton-blockchain/TEPs/blob/master/text/0062-nft-standard.md)](https://github.com/ton-blockchain/TEPs/blob/master/text/0062-nft-standard.md)  \n\n**Definition of Done**  \n- A fully implemented batch transfer feature supporting TON coins, tokens, and NFTs.  \n- Comprehensive test coverage demonstrating both successful multi-asset transfers and robust error handling.  \n- Clear documentation on configuring and invoking batch transfers, including partial or atomic execution modes.\n\n**Bounty**  \n- **Estimated Reward**: \\$1000 in TON  \n\nFor any questions or further discussion, please join the bounty program working group: [[Telegram: @ton_ai_bounty](https://t.me/ton_ai_bounty)](https://t.me/ton_ai_bounty).", "CLOSED", 0, "alefmanvladimir", "2025-01-30T12:28:09Z", "2025-02-25T08:22:01Z", "2025-02-25T08:22:01Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6oIC92", 3042, "Wallet Creation and Private Key Management", "**Description**  \nExtend the TON Plugin to allow AI agents (and other modules) to create, securely store, and manage wallets on the TON blockchain. This includes generating new wallets, securely storing private keys, signing transactions, and performing typical wallet operations such as transfers and deposits. The overall objective is to empower AI agents with reliable, secure access to on-chain assets.\n\n**Key Requirements**  \n1. **Wallet Generation & Storage**  \n   - Implement an action that creates new TON wallets on demand, returning essential data (e.g., public address).  \n   - Provide secure mechanisms for storing private keys, ensuring they remain inaccessible to unauthorized entities.  \n   - Support multiple wallet instances per AI agent, accommodating diverse use cases.\n\n2. **Private Key Management**  \n   - Safely handle private keys within the plugin, adhering to recommended cryptographic practices.  \n   - Allow import and export of keys in a controlled manner (e.g., encrypted backups).  \n   - Implement role-based or AI agent-specific access control to limit unauthorized key usage.\n\n3. **Transaction Signing**  \n   - Provide an interface for AI agents to sign transactions, including outgoing transfers, contract interactions, and other on-chain operations.  \n   - Ensure transaction signing is atomic and secure, minimizing the risk of key exposure.\n\n4. **Wallet Operations**  \n   - Support typical wallet functionalities:  \n     - **Transfer**: Send TON or other tokens to a specified address.  \n     - **Deposit**: Receive tokens and automatically detect incoming funds.  \n     - **Balance Queries**: Fetch wallet balances in real-time for both TONCoin and other supported tokens.  \n   - Generate standardized transaction receipts or confirmations for AI agents to process.\n\n5. **Security & Best Practices**  \n   - Follow TON documentation guidelines for wallet creation and private key handling.  \n   - Implement robust error handling, ensuring transaction failures or invalid requests are conveyed clearly.\n\n6. **AI Agent Integration**  \n   - Expose well-defined actions for wallet creation, management, and transaction signing.  \n   - Return structured responses (e.g., JSON) containing wallet details, transaction hashes, and status messages.\n\n**Resources**  \n- [TON Plugin Repository](https://github.com/elizaOS/eliza/tree/develop/packages/plugin-ton)  \n- [TON Documentation](https://docs.ton.org/)\n\n**Definition of Done**  \n- Secure creation and storage of wallet private keys within the plugin.  \n- Ability to sign transactions and execute wallet operations (send, receive, query balances) with comprehensive test coverage.  \n- Documentation outlining how AI agents can create, manage, and use wallets for day-to-day on-chain operations.\n\n**Bounty**  \n- **Estimated Reward**: \\$1000 in TON  \n\nFor further questions or discussion, please visit the bounty program working group: [Telegram: @ton_ai_bounty](https://t.me/ton_ai_bounty).", "CLOSED", 0, "alefmanvladimir", "2025-01-30T12:17:48Z", "2025-02-25T08:21:12Z", "2025-02-25T08:21:12Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6oHJmQ", 3032, "Read Historical Token Price Data", "**Description**  \nImplement functionality within the TON Plugin to enable AI agents (and other modules) to query and retrieve historical token price data on the TON blockchain. This feature should provide an efficient and reliable way to fetch price history, allowing for advanced analytics, backtesting, and strategy development in elizaOS-based applications.\n\n**Key Requirements**  \n1. **Data Source Integration**  \n   - Identify and integrate with reliable data sources for historical price information (e.g., on-chain indexers, third-party APIs, etc.).  \n   - Allow configurable time frames (e.g., hourly, daily, weekly) and token pairs for which historical data should be fetched.\n\n2. **API/Action Design**  \n   - Provide a clear action in the TON Plugin for reading historical price data.  \n   - Return the data in a structured format (e.g., JSON) suitable for AI agents and other consumers.\n\n3. **Caching & Efficiency**  \n   - Implement caching or batching techniques to minimize repeated requests for the same historical data.  \n   - Ensure the solution scales well if multiple agents request large time series data simultaneously.\n\n4. **Error Handling & Validation**  \n   - Handle scenarios where data may be partially unavailable, ensuring meaningful error messages or fallback values.  \n   - Validate inputs such as time ranges, token pairs, and maximum query lengths to prevent excessive resource usage.\n\n5. **Security & Reliability**  \n   - Follow TON best practices and secure any external API credentials or private data.  \n\n**Resources**  \n- [TON Plugin](https://github.com/elizaOS/eliza/tree/develop/packages/plugin-ton)  \n- [TON Documentation](https://docs.ton.org/)  \n- [API Providers](https://github.com/ton-society/ecosystem-map?tab=readme-ov-file#api-providers)\n\n**Definition of Done**  \n- Successful retrieval of historical token price data for specified tokens and time frames.  \n- Comprehensive test coverage, including edge cases (e.g., large date ranges or missing data).  \n- Clear documentation detailing how to configure and invoke this action within the TON Plugin.\n\n**Bounty**  \n- **Estimated Reward**: \\$500 in TON  \n\nFor any questions or further discussion, please join the bounty program working group: [Telegram: @ton_ai_bounty](https://t.me/ton_ai_bounty).", "CLOSED", 0, "alefmanvladimir", "2025-01-30T10:28:33Z", "2025-02-25T12:43:09Z", "2025-02-25T08:21:54Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6oG_zf", 3031, "Staking TON & Real-Time Pool Data Retrieval", "**Description**  \nExtend the TON Plugin within the elizaOS framework to enable AI agents (and other modules) to stake TON in existing pools and fetch detailed, up-to-date information about those pools. This feature aims to streamline staking operations\u2014such as depositing TON and monitoring rewards\u2014and make key metrics accessible for data-driven decision-making.\n\n**Key Requirements**  \n1. **Fetch Real-Time Staking Pool Data**  \n   - Provide an action to retrieve essential metrics from existing staking pools (e.g., total staked amount, reward rates, lock-up periods, minimum deposit).  \n   - Ensure compatibility with multiple staking platforms, allowing AI agents to query whichever pools are configured.\n\n2. **Staking Operations**  \n   - Implement actions to stake TON in a specified pool, including deposit and withdrawal (unstaking) operations.  \n   - Manage reward accumulation and distribution, allowing users to claim or re-stake rewards as needed.\n\n3. **Security & Access Control**  \n   - Follow best practices from TON documentation and staking protocol guidelines.  \n\n**Resources**  \n- [TON Documentation](https://docs.ton.org/)  \n- [List of staking platforms](https://github.com/ton-society/ecosystem-map?tab=readme-ov-file#staking)\n- [TON Plugin](https://github.com/elizaOS/eliza/tree/develop/packages/plugin-ton)\n\n**Definition of Done**  \n- Functional actions to fetch real-time pool data (reward rates, total staked, etc.) and stake/unstake TON.  \n- Comprehensive test coverage verifying normal usage, error conditions, and edge cases.  \n- Clear documentation detailing how to configure and invoke these actions within elizaOS.\n\n**Bounty**  \n- **Estimated Reward**: \\$2000 in TON  \n\nFor any questions or further discussion, please join the bounty program working group: [Telegram: @ton_ai_bounty](https://t.me/ton_ai_bounty).", "CLOSED", 0, "alefmanvladimir", "2025-01-30T10:10:30Z", "2025-02-25T08:21:17Z", "2025-02-25T08:21:17Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6n-t4k", 2984, "TON Connect integration in TON Plugin", "### **Description**  \nEnhance the TON Plugin to support seamless integration with **[TON Connect](https://docs.ton.org/v3/guidelines/ton-connect/overview/)**, enabling AI agents to interact securely with blockchain accounts. This feature will allow AI-driven applications to authenticate and manage user sessions programmatically through TON Connect.  \n\nThe implementation should be integrated into the **[elizaOS TON Plugin](https://github.com/elizaOS/eliza/tree/develop/packages/plugin-ton)** repository.\n\n### **What is TON Connect**?\nTON Connect is a standardized protocol that allows dApps (decentralized applications), web services, and bots to connect seamlessly to a user\u2019s TON wallet. It works similarly to WalletConnect in Ethereum-based ecosystems.\n\nhttps://github.com/user-attachments/assets/4febeb0b-5634-4327-9d0d-d19297e80d5e\n\n### **Key Requirements**  \n\n- Action to initialize a **TON Connect** session.  \n- Support for multiple wallets and seamless wallet switching.  \n- Ensure persistent and session-based connections for AI agents.  \n- Ensure compatibility with **elizaOS modules**, allowing AI-driven automation of blockchain interactions.  \n- The integration should use the official TON Connect library from https://github.com/ton-connect to ensure compatibility and reliability (forks are not allowed).\n- Documentation on how AI agents utilize actions and how users can interact with them.\n\n### **Useful Resources**  \n- [TON Connect Overview](https://docs.ton.org/v3/guidelines/ton-connect/overview/)  \n- [How TON Connect Works](https://docs.ton.org/v3/guidelines/ton-connect/guidelines/how-ton-connect-works)  \n- [TON Connect Developer Guidelines](https://docs.ton.org/v3/guidelines/ton-connect/guidelines/developers)  \n\n### **Definition of Done**  \n- Fully integrated **TON Connect** actions for authentication and session handling.  \n- Verified compatibility with TON Connect standard and security best practices.  \n- Documentation on how AI agents can use each action.  \n\n### **Bounty**  \n**Estimated Reward:** $1700 in TON  \n\nFor questions or further discussion, feel free to reach out in the **bounty program working group**:  \nTelegram: [@ton_ai_bounty](https://t.me/ton_ai_bounty)", "CLOSED", 0, "delovoyhomie", "2025-01-29T13:32:08Z", "2025-02-25T08:24:23Z", "2025-02-25T08:24:23Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6nf5lw", 2760, "Airtable adapter", "create an adapter for Eliza to use Airtable as db\n\nhttps://airtable.com/developers/web/api/introduction", "CLOSED", 0, "wtfsayo", "2025-01-24T18:42:27Z", "2025-02-24T19:14:11Z", "2025-02-24T19:14:11Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6nH8sy", 2648, "Cannot access agents on local network IP running client with --host 0.0.0.0", "Am having issues running on a local network IP instead of \"localhost\", the agent is running fine on a local ubuntu server, which I used --host 0.0.0.0 to start the agent client in network mode so I can access it with a private IP,\n\nIt brings up the app fine at http://192.x.x.x/ but it wont connect to the agent\n\nChecked in console and it's trying to access the agent at localhost instead of the IP\n\n![Image](https://github.com/user-attachments/assets/fbefdb3e-0771-4ac2-b5db-c6bc9bbeeed4)", "CLOSED", 0, "jgarrettvml", "2025-01-22T09:37:35Z", "2025-02-26T20:56:29Z", "2025-01-23T00:18:51Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6l4yeA", 2231, "create relay.link plugin", "1. https://www.relay.link/bridge/base\r\n2. https://www.relay.link/transactions\r\n3. https://docs.relay.link/what-is-relay\r\n4. https://docs.relay.link/references/api/overview\r\n5. https://docs.relay.link/references/sdk/getting-started\r\n\r\n- Should be able to bridge `trusted` tokens between different L2s/EVM chains\r\n- Should be able to swap `trusted` tokens on same EVM chains\r\n- Should be able to retrieve swap/bridge txn status", "CLOSED", 0, "wtfsayo", "2025-01-13T06:32:12Z", "2025-03-02T01:56:05Z", "2025-03-02T01:56:04Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6l3N0p", 2222, "Adding the nineteen.ai logo among the providers", "Context : \r\nAfter the addition of nineteen.ai among the list of possible inference providers, it will be great if it could be also added to this figma here : https://github.com/elizaOS/eliza/blob/main/docs/static/img/eliza_diagram.png\r\n\r\n\r\nHere is the nineteen.ai logo : \r\n![image](https://github.com/user-attachments/assets/55ade619-159f-4e7d-b8e2-676749228554)\r\n\r\n\r\nThank you in advance !", "CLOSED", 0, "MahdiPresario001", "2025-01-12T22:02:15Z", "2025-03-02T01:56:04Z", "2025-03-02T01:56:04Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6l2sTc", 2208, "Create and run agents while the server up and running", "**Is your feature request related to a problem? Please describe.**\r\nNo\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the solution you'd like**\r\nMaybe create a service to create an agent, and on-the-fly the server fetches the agent character description and then creates an instance from `AgentRuntime`.\r\nThat will help developers scale the solution; I mean we control the decentralized agents without turning down the node server.\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "omarsayed7", "2025-01-12T16:41:59Z", "2025-03-02T01:56:04Z", "2025-03-02T01:56:03Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6l2VU6", 2202, "RAG/Knowledge for Twitter Spaces characters", "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently the \"TwitterSpaces\" options of a character is a [separate entity](https://github.com/elizaOS/eliza/blob/d55c86c961960b4b34528c358eb34b2ff4b34d87/packages/client-twitter/src/spaces.ts#L21-L37) from the other settings in Character. It doesn't seem to account for the \"knowledge\" part of the character.\r\n\r\n\r\n**Describe the solution you'd like**\r\n\r\nI want the character to use the \"knowledge\" R.A.G. even when in a twitter space.", "CLOSED", 0, "y4my4my4m", "2025-01-12T13:22:22Z", "2025-03-02T01:56:03Z", "2025-03-02T01:56:03Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6l0-wo", 2164, "Fresh Clone: Types of parameters 'url' and 'request' are incompatible", "**Describe the bug**\r\nBuild error when running `pnpm build`\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n```\r\n@elizaos/core:build: src/generation.ts(455,21): error TS2322: Type '(url: string, options: any) => Promise<Response>' is not assignable to type '{ (input: URL | RequestInfo, init?: RequestInit): Promise<Response>; (input: string | Request | URL, init?: RequestInit): Promise<...>; (request: Request, init?: RequestInit): Promise<...>; (url: string | ... 1 more ... | URL, init?: FetchRequestInit): Promise<...>; }'.\r\n@elizaos/core:build:   Types of parameters 'url' and 'request' are incompatible.\r\n@elizaos/core:build:     Type 'Request' is not assignable to type 'string'.\r\n@elizaos/core:build: \r\n@elizaos/core:build: Error: error occurred in dts build\r\n@elizaos/core:build:     at Worker.<anonymous> (/Volumes/StorageHub/Development/github/eliza/node_modules/tsup/dist/index.js:1541:26)\r\n@elizaos/core:build:     at Worker.emit (node:events:513:28)\r\n@elizaos/core:build:     at MessagePort.<anonymous> (node:internal/worker:267:53)\r\n@elizaos/core:build:     at [nodejs.internal.kHybridDispatch] (node:internal/event_target:827:20)\r\n@elizaos/core:build:     at MessagePort.<anonymous> (node:internal/per_context/messageport:23:28)\r\n@elizaos/core:build: DTS Build error\r\n@elizaos/core:build: \u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n```\r\n\r\n**To Reproduce**\r\n\r\n- git clone https://github.com/elizaos/eliza.git\r\n- cd eliza\r\n- pnpm install --no-frozen-lockfile\r\n- pnpm build\r\n\r\n**Expected behavior**\r\n\r\nSuccess build\r\n\r\n**Additional context**\r\n\r\nMacOS 15.1\r\nNode v23.3.0\r\nPNPM 9.14.4", "CLOSED", 0, "0xinugami", "2025-01-11T20:12:56Z", "2025-03-02T01:56:03Z", "2025-03-02T01:56:03Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6l03rL", 2161, "When ElizaOS is restarted, replies to TWITTER_TARGET_USER are sent twice", "\r\nWhen ElizaOS is restarted, replies to TWITTER_TARGET_USER are sent twice\r\n\r\n\r\nReps may not be saved to the database under certain conditions.\r\n\r\n![\u30b9\u30af\u30ea\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8 2025-01-12 041945](https://github.com/user-attachments/assets/8d4a379b-98a9-4781-aa3b-988b84530540)\r\n", "CLOSED", 0, "chanta093", "2025-01-11T19:23:25Z", "2025-03-02T01:56:02Z", "2025-03-02T01:56:02Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lzNSs", 2144, "similar action how to due is better?", "**Is your feature request related to a problem? Please describe.**\r\n\r\nIf my plugin has `raydium-deposit` and `deposit` the two actions have problems when I send a `deposit me 10 $WIF on raydium`, the system will trigger the deposit not `raydium-deposit`, So I just modified the deposit valid function to skip that was not a smart solution plan.\r\n\r\ndeposit valid part:\r\n```\r\nexport const executeDeposit: Action = {\r\n  name: \"EXECUTE_DEPOSIT\",\r\n  similes: [\"DEPOSIT_TOKENS\", \"TOKEN_DEPOSIT\"],\r\n  validate: async (runtime: IAgentRuntime, message: Memory) => {\r\n    console.log(\"=== deposit validate ===\");\r\n    console.log(\"message: \", JSON.stringify(message, null, 2));\r\n    let msg = message.content.text;\r\n    return msg.includes(\"deposit\") && !msg.includes(\"raydium\");\r\n  },\r\n```\r\n\r\nraydium-deposit valid part:\r\n```\r\nexport const executeRaydiumDeposit: Action = {\r\n  name: \"EXECUTE_RAYDIUM_DEPOSIT\",\r\n  similes: [\"RAYDIUM_DEPOSIT\", \"DEPOSIT_TOKENS\", \"PERFORM_DEPOSIT\"],\r\n  validate: async (runtime: IAgentRuntime, message: Memory) => {\r\n    console.log(\"=== raydium deposit validate ===\");\r\n    console.log(\"message: \", JSON.stringify(message, null, 2));\r\n    let msg = message.content.text.toLowerCase();\r\n    const keywords = [\r\n      \"deposit\",\r\n      \"add liquidity\",\r\n      \"provide liquidity\",\r\n      \"stake\",\r\n      \"supply\",\r\n    ];\r\n    return msg.includes(\"raydium\") && keywords.some((keyword) => msg.includes(keyword));\r\n  },\r\n```\r\n\r\n**Describe the solution you'd like**\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "cxp-13", "2025-01-11T06:45:58Z", "2025-03-02T01:56:02Z", "2025-03-02T01:56:02Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lwsHT", 2132, "Telegram client - long memory for personal assistent", "Just starting working with the framework, maybe it's a basic question: how to keep long memory?\r\n\r\nFor example I want agent to remember something. Then I exchange many new messages. Then I want to get back to the thing I wanted agent to remember. Unfortunately it can only relate to some recent 20-40 (?) messages back.\r\n\r\nIs it a configuration thing? I use default configs.\r\n\r\nor this requires custom plugin that will remember \"todo\" list?\r\n\r\nwhich memory to use for that?\r\n\r\nif there are more items over the time - does it mean the openai or anthropic costs will increase due to bigger context or something similar?\r\n\r\nany ideas how to handle this?", "CLOSED", 0, "adapt7", "2025-01-10T19:51:15Z", "2025-03-02T01:56:02Z", "2025-03-02T01:56:02Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lwYFX", 2127, "\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009", "**Describe the bug**\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.7 start: `node --loader ts-node/esm src/index.ts \"--isRoot\"`\r\nExit status 1\r\n", "CLOSED", 0, "TobiGoldD", "2025-01-10T19:14:51Z", "2025-03-02T01:56:01Z", "2025-03-02T01:56:01Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6ltkGL", 2114, "@elizaos/plugin-twitter has not published in npm", "### **Is your feature request related to a problem? Please describe.**\r\nIf you read the Readme of plugin-twitter, you can find this: \r\n\r\n<img width=\"873\" alt=\"image\" src=\"https://github.com/user-attachments/assets/62151833-ee18-4005-92ac-80713fda63f0\" />\r\n\r\nBut it was not published in the npm yet;\r\n\r\n<img width=\"809\" alt=\"image\" src=\"https://github.com/user-attachments/assets/754c46c8-0918-4411-b616-ee334ae1397d\" />\r\n\r\n\r\n### **Describe the solution you'd like**\r\n\r\nPublish it to npm as fast as possible. \r\n\r\n", "CLOSED", 0, "mameikagou", "2025-01-10T13:23:49Z", "2025-03-02T01:56:01Z", "2025-03-02T01:56:01Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6ltI2j", 2109, "[Request] Feature : Response Format", "**Is your feature request related to a problem? Please describe.**\r\n\r\nCan we implement structured response or response_format defined in a JSON like : [https://platform.openai.com/docs/guides/structured-outputs](https://platform.openai.com/docs/guides/structured-outputs)\r\n\r\n**Describe the solution you'd like**\r\n\r\nA parameter in the settings dict of the character that implements JSON structured response.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nHave tried to describe in bio of the character using prompts but quantized(GGUF) models output gibberish sometimes.\r\n\r\n**Additional context**\r\n\r\nI am using LM studio as the OpenAi server and it can give out a structured response to all requests. But that is the problem, agents not requiring JSON output will also follow the instructions which doesn't help if using same local endpoint for multiple agents.", "CLOSED", 0, "brij2001-hof", "2025-01-10T12:26:55Z", "2025-03-02T01:56:01Z", "2025-03-02T01:56:01Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lq_wM", 2098, "Enable Agents to manage Docker Containers", "**Is your feature request related to a problem? Please describe.**\r\n\r\nEliza currently lacks the ability to start applications, particularly AI/ML models and services. While Docker containers have become the de facto standard for consistent application deployment across platforms, Eliza cannot leverage this capability. This limitation prevents Eliza from running important tools like Ollama server, managing OSS models, or even maintaining its own model infrastructure in a containerized environment.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd Docker container management capabilities to Eliza agents by integrating Dockerode (TypeScript Docker API client). This would enable agents to:\r\n- Create and manage Docker containers programmatically\r\n- Pull, build, and push Docker images\r\n- Monitor container health and logs\r\n- Execute commands inside containers\r\n- Manage container networks and volumes\r\n- Handle container lifecycle (start, stop, restart, remove)\r\n- Provide a high-level API for container orchestration tasks\r\n\r\n**Describe alternatives you've considered**\r\n\r\nN/A\r\n\r\n**Additional context**\r\n\r\n- Could be integrated with the existing agent capabilities system to add new version of core capabilities\r\n- Would enable automated container-based workflows\r\n- Could serve as foundation for future container orchestration features\r\n- TypeScript types from Dockerode would ensure type safety", "CLOSED", 0, "bussyjd", "2025-01-10T07:46:49Z", "2025-03-02T01:56:00Z", "2025-03-02T01:56:00Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lq6f2", 2096, "Eliza Helm Chart to deploy on Kubernetes", "**Is your feature request related to a problem? Please describe.**\r\n\r\nThere's currently no standardized way to package and distribute Eliza for Kubernetes environments. Users who want to deploy Eliza on Kubernetes have to create their own deployment configurations from scratch, which is time-consuming and can lead to inconsistent deployments across different environments.\r\n\r\n**Describe the solution you'd like**\r\n\r\nCreate a Helm chart for Eliza that would provide:\r\n- A standardized way to package all necessary Kubernetes manifests (deployments, services, configmaps, etc.)\r\n- Configurable values for customizing the deployment (resource limits, replicas, environment variables, etc.)\r\n- Clear documentation on installation and configuration options\r\n- Version-controlled releases that can be easily distributed via Helm repositories\r\n- Support for different deployment scenarios (development, production) through values files\r\n\r\n**Describe alternatives you've considered**\r\n\r\n1. Plain Kubernetes manifests: While this is being addressed in #1711, it requires more manual configuration and doesn't provide the package management benefits of Helm.\r\n2. Kustomize: Could provide environment-specific configurations but lacks the templating and package distribution capabilities of Helm.\r\n3. Operator: Would be overkill for the current deployment needs and would require significantly more development effort.\r\n\r\n**Additional context**\r\n\r\n- This would build upon the existing Docker containerization work\r\n- Could potentially be distributed through the official Helm repository or ArtifactHub\r\n- Would make it easier for organizations to adopt Eliza in their Kubernetes environments\r\n- Aligns with cloud-native best practices for application distribution\r\n- Could include monitoring and observability configurations out of the box", "CLOSED", 0, "bussyjd", "2025-01-10T07:33:13Z", "2025-03-02T01:56:00Z", "2025-03-02T01:56:00Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lp4Ol", 2089, "Double responses when interacting on Telegram", "**Describe the bug**\r\n\r\nWhenever I am interacting with my agent on Telegram it will occasionally (On a CONTINUE action) respond twice to the same message.\r\n\r\n**To Reproduce**\r\n\r\nRun the Telegram client and talk with the agent. Eventually after a few messages you'll get a double response.\r\n\r\n**Expected behavior**\r\n\r\nNot a double response to the same message.\r\n\r\n**Screenshots**\r\n\r\n<img width=\"897\" alt=\"Screenshot 2025-01-09 at 9 52 47\u202fPM\" src=\"https://github.com/user-attachments/assets/921958ba-f68b-49e8-a5bc-fd6cf6f2d765\" />\r\n<img width=\"898\" alt=\"Screenshot 2025-01-09 at 9 51 15\u202fPM\" src=\"https://github.com/user-attachments/assets/649b3f2e-7e93-49c7-a515-b362176071cc\" />\r\n<img width=\"1397\" alt=\"Screenshot 2025-01-09 at 9 52 18\u202fPM\" src=\"https://github.com/user-attachments/assets/139db3bd-c35d-4b91-b42e-37369b7fc0ad\" />\r\n\r\n\r\n**Additional context**\r\n\r\nRepo: https://github.com/chasebrownn/eliza-fren/tree/frey\r\n", "CLOSED", 0, "chasebrownn", "2025-01-10T03:53:39Z", "2025-03-02T01:56:00Z", "2025-03-02T01:56:00Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lpaUm", 2085, "PostgresDB connection Fails sporadically with Large knowledge section.", "**Describe the bug**\r\nWhen you have a larger knowledge section, Postgres Supabase connection timeout sporadically.\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n- Create a characterfile\r\n- Load the characterfiles knowledge section with 5 PDFs of large content extracted properly\r\n- Add Postgres URL to env, \"URL\" can be gotten from NeonDB or Supabase (this will allow for the use of Postgres.\r\n- Execute repo with new character file\r\n- Wait a couple of hours for memory creation and embeddings\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n- Embeddings are created successfully like they work when using SQLite (Even though it takes about 8hrs with SQLite)\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\nSnippets from error:\r\n`\u26a0 WARNINGS Database operation failed (attempt 1/10): {\"error\":\"Connection terminated unexpectedly\",\"nextRetryIn\":\"5.6s\"}\r\n\r\nnode:events:491 throw er; // Unhandled 'error' event ^\r\n\r\n<ref *1> Error: read ECONNRESET at TLSWrap.onStreamRead (node:internal/stream_base_commons:216:20) Emitted 'error' event on BoundPool instance at: at Client.idleListener\r\n...\r\n{ errno: -54, code: 'ECONNRESET', syscall: 'read', client: Client { _events: [Object: null prototype] { error: [Function (anonymous)] }, _eventsCount: 1, _maxListeners: undefined, connectionParameters:\r\n`\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "joco25", "2025-01-10T01:54:36Z", "2025-03-02T01:55:59Z", "2025-03-02T01:55:59Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lnuzl", 2080, "A CUDA error is thrown when using `llama_local` - ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL, exit code 3221226505", "**Describe the bug**\r\n\r\nA CUDA error is thrown when using `llama_local`\r\n\r\n**To Reproduce**\r\n\r\n`Windows 10`\r\n`wsl2`\r\n`node -v` = `v23.5.0`\r\n`python --version` = `Python 3.12.8`\r\n\r\nfollowed [Quick Start](https://elizaos.github.io/eliza/docs/quickstart/):\r\n\r\n1. checkout tag `v0.1.7`\r\n2. `pnpm install --no-frozen-lockfile`\r\n3. `pnpm build`\r\n4. `.env` setup for `llama_local`: `XAI_MODEL=meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo` as described [here](https://elizaos.github.io/eliza/docs/quickstart/#for-llama_local-inference)\r\n5. Changed `modelProvider` to `llama_local` in trump.character.json\r\n6. Run with `pnpm start --character=\"characters/trump.character.json\"`\r\n7. Start client with `pnpm start:client`\r\n8. Type `hi` in chat\r\n\r\n**Expected behavior**\r\n\r\nAn indication of what the error is exactly. I also changing model configuration but that doesn't seem to be picked up. I'm at a loss.\r\n\r\n**Screenshot**\r\n![image](https://github.com/user-attachments/assets/27587635-4329-4b21-a79a-9da20cde4a17)\r\n\r\n**Additional context**\r\n\r\n```\r\n[\"\u25ce Generating text...\"] \r\n\r\n \u2139 INFORMATIONS\r\n   Generating text with options:\r\n   {\"modelProvider\":\"llama_local\",\"model\":\"large\"} \r\n\r\n \u2139 INFORMATIONS\r\n   Selected model:\r\n   NousResearch/Hermes-3-Llama-3.1-8B-GGUF/resolve/main/Hermes-3-Llama-3.1-8B.Q8_0.gguf?download=true \r\n\r\n [\"\u2139 Model not initialized, starting initialization...\"] \r\n\r\n [\"\u2139 Checking model file...\"] \r\n\r\n [\"\u26a0 Model already exists.\"] \r\n\r\n [\"\u2139 LlamaService: CUDA detected, using GPU acceleration\"] \r\n\r\n [\"\u2139 Initializing Llama instance...\"] \r\n\r\n(node:30868) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\r\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n(node:30868) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\r\n(Use `node --trace-deprecation ...` to show where the warning was created)\r\nggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\r\nggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\r\nggml_cuda_init: found 1 CUDA devices:\r\n  Device 0: NVIDIA GeForce RTX 3090, compute capability 8.6, VMM: yes\r\n [\"\u2139 Creating JSON schema grammar...\"] \r\n\r\n [\"\u2139 Loading model...\"] \r\n\r\n [\"\u2139 Creating context and sequence...\"] \r\n\r\n [\"\u2713 Model initialization complete\"] \r\n\r\nC:\\Users\\me\\Documents\\Projects\\eliza\\node_modules\\node-llama-cpp\\llama\\llama.cpp\\ggml\\src\\ggml-cuda.cu:70: CUDA error\r\nC:\\Users\\me\\Documents\\Projects\\eliza\\agent:\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.7 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/trump.character.json\"`\r\nExit status 3221226505\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 3221226505.\r\n```\r\n", "CLOSED", 0, "ropstah", "2025-01-09T20:00:04Z", "2025-03-02T02:17:49Z", "2025-03-02T01:55:59Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lniev", 2078, "Cannot read properties of undefined (reading 'actions') trying to test the whatsapp plugin ", "**Describe the bug**\r\nI am getting an error when trying to add whatsapp plugin \r\nCannot read properties of undefined (reading 'actions')\r\n\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\n`{\r\n  \"name\": \"vybz\",\r\n  \"modelProvider\": \"openai\",\r\n  \"clients\": [],\r\n  \"plugins\": [\r\n    \"plugins\": [\"@elizaos/plugin-whatsapp\"],   // <--- Correct package\r\n  ]\r\n}.\r\n\r\n\r\n// <--- and create an instance of it in  createAgent\r\nconst whatsappPlugin = new WhatsAppPlugin({\r\n        accessToken: getSecret(character, \"WHATSAPP_ACCESS_TOKEN\"),\r\n        phoneNumberId: getSecret(character, \"WHATSAPP_PHONE_NUMBER_ID\"),\r\n        webhookVerifyToken: getSecret(\r\n            character,\r\n            \"WHATSAPP_WEBHOOK_VERIFY_TOKEN\"\r\n        ),\r\n        businessAccountId: getSecret(character, \"WHATSAPP_BUSINESS_ACCOUNT_ID\"),\r\n     });`\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\nI am thinking that the plugin should be a client instead but i am not 100 % sure or the actions need to be defined\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<img width=\"587\" alt=\"Screenshot 2025-01-09 at 2 19 32\u202fPM\" src=\"https://github.com/user-attachments/assets/306f058c-15bc-4254-ad50-103a7e2d9e9e\" />\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\r\n", "CLOSED", 0, "oscody", "2025-01-09T19:27:27Z", "2025-03-02T01:55:59Z", "2025-03-02T01:55:59Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lncp8", 2077, "Nillion nilDB Plugin", "**Is your feature request related to a problem? Please describe.**\r\n\r\nI would like to add a new feature that allows data to be uploaded and retrieved to and from the [Nillion network](https://nillion.com/) nilDB.\r\n\r\n**Describe the solution you'd like**\r\n\r\nThe nillion plugin enables integrates storing and retrieving data from the decentralized nilDB. nilDB is backed by secure multiparty computation (MPC) and this plugin handles everything needed to interact with nilDB.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nN/A\r\n\r\n**Additional context**\r\n\r\nN/A", "CLOSED", 0, "jimouris", "2025-01-09T19:13:55Z", "2025-03-02T01:55:58Z", "2025-03-02T01:55:58Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lnbbg", 2076, "Bot Fails to Process Telegram Messages from Other Bots Despite shouldIgnoreBotMessages: false Setting", "**Describe the bug**\r\n\r\nThe bot does not read or receive Telegram bot messages, even though the setting `clientConfig.telegram.shouldIgnoreBotMessages` is set to `false`.\r\n\r\n**To Reproduce**\r\n\r\n1. Configure the bot with the following settings:\r\n   ```json\r\n   clientConfig: {\r\n       telegram: {\r\n           shouldIgnoreBotMessages: false,\r\n       },\r\n   }\r\n\r\n\t2.\tStart the bot using the pnpm i && pnpm start command.\r\n\t3.\tSend a message from another Telegram bot to the configured bot.\r\n\t4.\tObserve that the bot does not process or respond to the message.\r\n\r\nExpected behavior\r\n\r\nThe bot should receive and process messages from other Telegram bots when shouldIgnoreBotMessages is explicitly set to false.\r\n\r\nScreenshots\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n\r\nAdditional context\r\n\r\nLogs during startup and execution indicate no specific errors regarding message handling:\r\n\t\u2022\tInitialization appears successful with services like browser, image_description, and telegram being registered and started.\r\n\t\u2022\tThe bot successfully launches and binds to the correct Telegram username .\r\n\t\u2022\tHowever, the bot does not respond to messages from other bots\r\n\r\nThese issues might suggest:\r\n\t1.\tThe Telegram client is mishandling bot-specific messages despite the configuration.\r\n\t2.\tA bug in how the message handler processes bot-originating messages.\r\n\r\n\r\nLogs for reference:\r\n\t\u2022\tSetting initialization:\r\n```\r\nclientConfig: {\r\n    telegram: {\r\n        shouldIgnoreBotMessages: false,\r\n    },\r\n}\r\n```\r\n\r\nProposed steps for debugging:\r\n\t1.\tVerify if the Telegram client is correctly handling shouldIgnoreBotMessages.\r\n\t2.\tDebug the message handler to confirm it processes messages from other bots.\r\n\t3.\tEnsure the bot\u2019s agent is correctly linked to the Telegram service.\r\n\t4.\tTest with verbose logging enabled for better insight into incoming message handling.\r\n\r\n", "CLOSED", 0, "MbBrainz", "2025-01-09T19:10:39Z", "2025-03-02T01:55:58Z", "2025-03-02T01:55:58Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lftJy", 2037, "runtime not inititiazed properly in ctor", "**Describe the bug**\r\n\r\npackages/plugin-solana/src/providers/simulationSellingService.ts  \r\n\r\n<!-- Steps to reproduce the behavior. -->\r\nimport { SimulationSellingService } from \"@elizaos/plugin-solana\";\r\nimport { TrustScoreDatabase } from \"@elizaos/plugin-trustdb\";\r\n\r\n// use some already instantiated runtime\r\nconst trustScoreDb = new TrustScoreDatabase(runtime.databaseAdapter.db);\r\nconst simulationSellingService = new SimulationSellingService (runtime, trustScoreDb );   ==> should throw an undesired exception.\r\n\r\n**Expected behavior**\r\nnew SimulationSellingService(...) should not throw expection.\r\n\r\n![image](https://github.com/user-attachments/assets/e2450349-a556-4fc3-8d9c-aa8cdb2e7e13)", "CLOSED", 0, "demoush", "2025-01-08T23:48:22Z", "2025-03-02T01:55:58Z", "2025-03-02T01:55:58Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lesBb", 2033, "DevMode runs but connecting UI results in /agents endpoint ECONNREFUSED", "**Describe the bug**\r\nAfter DevMode starts without error, going to http://localhost:5173/ results in the following error:\r\n\r\n```\r\n3:20:22 PM [vite] http proxy error: /agents\r\nError: connect ECONNREFUSED ::1:3000\r\n    at TCPConnectWrap.afterConnect [as oncomplete] (node:net:1615:16) \r\n```\r\n\r\nI do  not get this error when running `pnpm run start` combined with `pnpm run start:client` in another terminal\r\n\r\n**To Reproduce**\r\n\r\n* run dev mode with `pnpm run dev --characters=c3p0.character.json`.\r\n* go to http://localhost:5173\r\n\r\n**Expected behavior**\r\n\r\n* UI loads with C3P0 character and no errors in logs.\r\n\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n\r\n\r\n``` Tasks:    53 successful, 53 total\r\nCached:    53 cached, 53 total\r\n  Time:    1.464s >>> FULL TURBO\r\n\r\n(node:27576) ExperimentalWarning: CommonJS module C:\\Users\\naets\\AppData\\Roaming\\nvm\\v23.3.0\\node_modules\\npm\\node_modules\\debug\\src\\node.js is loading ES Module C:\\Users\\naets\\AppData\\Roaming\\nvm\\v23.3.0\\node_modules\\npm\\node_modules\\supports-color\\index.js using require().\r\nSupport for loading ES Module in require() is an experimental feature and might change at any time\r\n(Use `node --trace-warnings ...` to show where the warning was created)      \r\n\r\n> @elizaos/client-direct@0.1.7-alpha.2 dev C:\\Users\\naets\\OneDrive\\Documents\\Moonbeam\\Workspaces\\eliza-storage\\packages\\client-direct\r\n> tsup --format esm --dts --watch \"--\" \"--characters=characters/c3po.character.json\"\r\n\r\n\r\n> @elizaos/core@0.1.7-alpha.2 dev C:\\Users\\naets\\OneDrive\\Documents\\Moonbeam\\Workspaces\\eliza-storage\\packages\\core\r\n> tsup --format esm --dts --watch \"--\" \"--characters=characters/c3po.character.json\"\r\n\r\n\r\n> eliza-client@0.1.7-alpha.2 dev C:\\Users\\naets\\OneDrive\\Documents\\Moonbeam\\Workspaces\\eliza-storage\\client\r\n> vite \"--\" \"--characters=characters/c3po.character.json\"\r\n\r\n\r\n  VITE v5.4.11  ready in 273 ms\r\n\r\n  \u279c  Local:   http://localhost:5173/\r\n  \u279c  Network: use --host to expose\r\n  \u279c  press h + enter to show help\r\nCLI Building entry: src/index.ts\r\nCLI Using tsconfig: tsconfig.json\r\nCLI Building entry: src/index.ts\r\nCLI tsup v8.3.5\r\nCLI Using tsup config: C:\\Users\\naets\\OneDrive\\Documents\\Moonbeam\\Workspaces\\eliza-storage\\packages\\client-direct\\tsup.config.ts\r\nCLI Running in watch mode\r\nCLI Using tsconfig: tsconfig.json\r\nCLI tsup v8.3.5\r\nCLI Using tsup config: C:\\Users\\naets\\OneDrive\\Documents\\Moonbeam\\Workspaces\\eliza-storage\\packages\\core\\tsup.config.ts\r\nCLI Running in watch mode\r\nCLI Target: esnext\r\nCLI Target: node18\r\nCLI Cleaning output folder\r\nESM Build start\r\nCLI Cleaning output folder\r\nESM Build start\r\nESM dist\\index.js     19.41 KB\r\nESM dist\\index.js.map 41.17 KB\r\nESM \u26a1\ufe0f Build success in 37ms\r\nCLI Watching for changes in \".\"\r\nCLI Ignoring changes in \"**/{.git,node_modules}/**\" | \"dist\"\r\nESM dist\\index.js     155.08 KB\r\nESM dist\\index.js.map 378.03 KB\r\nESM \u26a1\ufe0f Build success in 71ms\r\nCLI Watching for changes in \".\"\r\nCLI Ignoring changes in \"**/{.git,node_modules}/**\" | \"dist\"\r\nDTS Build start\r\nDTS Build start\r\nDTS \u26a1\ufe0f Build success in 2377ms\r\nDTS \u26a1\ufe0f Build success in 2837ms\r\n3:20:21 PM [vite] http proxy error: /agents\r\nError: connect ECONNREFUSED ::1:3000\r\n    at TCPConnectWrap.afterConnect [as oncomplete] (node:net:1615:16)        \r\n(node:50944) ExperimentalWarning: CommonJS module C:\\Users\\naets\\OneDrive\\Documents\\Moonbeam\\Workspaces\\eliza-storage\\node_modules\\tailwindcss\\lib\\lib\\load-config.js is loading ES Module C:\\Users\\naets\\OneDrive\\Documents\\Moonbeam\\Workspaces\\eliza-storage\\client\\tailwind.config.js using require().\r\nSupport for loading ES Module in require() is an experimental feature and might change at any time\r\n(Use `node --trace-warnings ...` to show where the warning was created)      \r\n3:20:22 PM [vite] http proxy error: /agents\r\nError: connect ECONNREFUSED ::1:3000\r\n    at TCPConnectWrap.afterConnect [as oncomplete] (node:net:1615:16) (x2)   \r\n3:20:22 PM [vite] http proxy error: /agents\r\nError: connect ECONNREFUSED ::1:3000\r\n    at TCPConnectWrap.afterConnect [as oncomplete] (node:net:1615:16) (x3)   \r\n3:20:23 PM [vite] http proxy error: /agents\r\nError: connect ECONNREFUSED ::1:3000\r\n    at TCPConnectWrap.afterConnect [as oncomplete] (node:net:1615:16) (x4)   \r\n3:20:25 PM [vite] http proxy error: /agents\r\nError: connect ECONNREFUSED ::1:3000\r\n    at TCPConnectWrap.afterConnect [as oncomplete] (node:net:1615:16) (x5)   \r\n3:20:29 PM [vite] http proxy error: /agents\r\nError: connect ECONNREFUSED ::1:3000\r\n    at TCPConnectWrap.afterConnect [as oncomplete] (node:net:1615:16) (x6)   \r\n```", "CLOSED", 0, "sicco-moonbeam", "2025-01-08T20:29:54Z", "2025-03-02T01:55:57Z", "2025-03-02T01:55:57Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lXp2-", 2002, "Chat infinite loop with llama_local model", "Chat infinite loop with llama_local model. It's work well with openai.\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\ntercel@terceldeMac-mini eliza % git log\r\ncommit ea9d1c02291dea26b25c815be30db5c91e6ceb21 (HEAD -> main, origin/main, origin/HEAD)\r\nMerge: 62abe4c3 3c753065\r\nAuthor: Odilitime <janesmith@airmail.cc>\r\nDate:   Sun Jan 5 02:07:15 2025 -0800\r\n\r\n    Merge pull request #1867 from elizaOS/odilitime-patch-1\r\n    \r\n    docs: Add DAO donation ask & dev discord\r\n    \r\ntercel@terceldeMac-mini eliza % pnpm start --character=characters/local.character.json\r\n\r\n> eliza@ start /Users/tercel/WorkSpace/tercel-ai/eliza\r\n> pnpm --filter \"@elizaos/agent\" start --isRoot \"--character=characters/local.character.json\"\r\n\r\n\r\n> @elizaos/agent@0.1.7 start /Users/tercel/WorkSpace/tercel-ai/eliza/agent\r\n> node --loader ts-node/esm src/index.ts \"--isRoot\" \"--character=characters/local.character.json\"\r\n\r\n(node:15511) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\r\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n(node:15511) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\r\n(Use `node --trace-deprecation ...` to show where the warning was created)\r\n[ElizaLogger] Initializing with:\r\n            isNode: true\r\n            verbose: false\r\n            VERBOSE env: undefined\r\n            NODE_ENV: undefined\r\n        \r\n \u2139 INFORMATIONS\r\n   Loading embedding settings: \r\n   {\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING\":\"\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"} \r\n\r\n \u2139 INFORMATIONS\r\n   Loading character settings: \r\n   {\"ARGV\":[\"/Users/tercel/.nvm/versions/node/v23.3.0/bin/node\",\"/Users/tercel/WorkSpace/tercel-ai/eliza/agent/src/index.ts\",\"--isRoot\",\"--character=characters/local.character.json\"],\"CHARACTER_ARG\":\"--character=characters/local.character.json\",\"CWD\":\"/Users/tercel/WorkSpace/tercel-ai/eliza/agent\"} \r\n\r\n [\"\u25ce Loaded .env file from: /Users/tercel/WorkSpace/tercel-ai/eliza/.env\"] \r\n\r\n \u2139 INFORMATIONS\r\n   Parsed settings: \r\n   {\"USE_OPENAI_EMBEDDING\":\"\",\"USE_OPENAI_EMBEDDING_TYPE\":\"string\",\"USE_OLLAMA_EMBEDDING\":\"\",\"USE_OLLAMA_EMBEDDING_TYPE\":\"string\",\"OLLAMA_EMBEDDING_MODEL\":\"mxbai-embed-large\"} \r\n\r\nusing deprecated parameters for the initialization function; pass a single object instead\r\n(node:15511) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\r\n [\"\u25ce DirectClient constructor\"] \r\n\r\n \u2139 INFORMATIONS\r\n   Trying paths: \r\n   [{\"path\":\"characters/local.character.json\",\"exists\":false},{\"path\":\"/Users/tercel/WorkSpace/tercel-ai/eliza/agent/characters/local.character.json\",\"exists\":false},{\"path\":\"/Users/tercel/WorkSpace/tercel-ai/eliza/agent/agent/characters/local.character.json\",\"exists\":false},{\"path\":\"/Users/tercel/WorkSpace/tercel-ai/eliza/agent/src/characters/local.character.json\",\"exists\":false},{\"path\":\"/Users/tercel/WorkSpace/tercel-ai/eliza/agent/src/characters/local.character.json\",\"exists\":false},{\"path\":\"/Users/tercel/WorkSpace/tercel-ai/eliza/agent/characters/local.character.json\",\"exists\":false},{\"path\":\"/Users/tercel/WorkSpace/tercel-ai/eliza/characters/local.character.json\",\"exists\":true}] \r\n\r\n \u2139 INFORMATIONS\r\n   Plugins are:  \r\n   [] \r\n\r\n [\"\u2139 Successfully loaded character from: /Users/tercel/WorkSpace/tercel-ai/eliza/characters/local.character.json\"] \r\n\r\n [\"\u25ce sqlite-vec extensions loaded successfully.\"] \r\n\r\n [\"\u2139 Using Database Cache...\"] \r\n\r\n \u2713 SUCCESS\r\n   SUCCESS \r\n   Creating runtime for character \r\n   Local Eliza \r\n\r\n \u2139 INFORMATIONS\r\n   Initializing AgentRuntime with options: \r\n   {\"character\":\"Local Eliza\",\"modelProvider\":\"llama_local\",\"characterModelProvider\":\"llama_local\"} \r\n\r\n \u2713 SUCCESS\r\n   Agent ID \r\n   b235aa75-b606-0543-a0bc-1ffc78868601 \r\n\r\n [\"\u2139 Setting model provider...\"] \r\n\r\n \u2139 INFORMATIONS\r\n   Model Provider Selection: \r\n   {\"characterModelProvider\":\"llama_local\",\"optsModelProvider\":\"llama_local\",\"finalSelection\":\"llama_local\"} \r\n\r\n \u2139 INFORMATIONS\r\n   Selected model provider: \r\n   llama_local \r\n\r\n \u2139 INFORMATIONS\r\n   Selected image model provider: \r\n   llama_local \r\n\r\n \u2139 INFORMATIONS\r\n   Selected model provider: \r\n   llama_local \r\n\r\n \u2139 INFORMATIONS\r\n   Selected image model provider: \r\n   llama_local \r\n\r\n [\"\u2713 Registering action: CONTINUE\"] \r\n\r\n [\"\u2713 Registering action: FOLLOW_ROOM\"] \r\n\r\n [\"\u2713 Registering action: UNFOLLOW_ROOM\"] \r\n\r\n [\"\u2713 Registering action: IGNORE\"] \r\n\r\n [\"\u2713 Registering action: NONE\"] \r\n\r\n [\"\u2713 Registering action: MUTE_ROOM\"] \r\n\r\n [\"\u2713 Registering action: UNMUTE_ROOM\"] \r\n\r\n [\"\u2713 Registering action: DESCRIBE_IMAGE\"] \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   browser \r\n\r\n [\"\u2713 Service browser registered successfully\"] \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   image_description \r\n\r\n [\"\u2713 Service image_description registered successfully\"] \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   text_generation \r\n\r\n [\"\u2713 Service text_generation registered successfully\"] \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   pdf \r\n\r\n [\"\u2713 Service pdf registered successfully\"] \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   speech_generation \r\n\r\n [\"\u2713 Service speech_generation registered successfully\"] \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   transcription \r\n\r\n [\"\u2713 Service transcription registered successfully\"] \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   video \r\n\r\n [\"\u2713 Service video registered successfully\"] \r\n\r\n \u25ce LOGS\r\n   Registering service: \r\n   aws_s3 \r\n\r\n [\"\u2713 Service aws_s3 registered successfully\"] \r\n\r\n [\"\u2713 Registering action: GENERATE_IMAGE\"] \r\n\r\n [\"\u2713 Service browser initialized successfully\"] \r\n\r\n [\"\u25ce Initializing ImageDescriptionService\"] \r\n\r\n [\"\u2713 Service image_description initialized successfully\"] \r\n\r\n [\"\u2139 Initializing LlamaService...\"] \r\n\r\n [\"\u2713 Service text_generation initialized successfully\"] \r\n\r\n [\"\u2713 Service pdf initialized successfully\"] \r\n\r\n [\"\u2713 Service speech_generation initialized successfully\"] \r\n\r\nCUDA not supported on this platform. Transcription will run on CPU.\r\n [\"\u2713 Service transcription initialized successfully\"] \r\n\r\n [\"\u2713 Service video initialized successfully\"] \r\n\r\nInitializing AwsS3Service\r\n [\"\u2713 Service aws_s3 initialized successfully\"] \r\n\r\n [\"\u25ce Initializing ImageDescriptionService\"] \r\n\r\n [\"\u2139 Initializing LlamaService...\"] \r\n\r\nCUDA not supported on this platform. Transcription will run on CPU.\r\nInitializing AwsS3Service\r\n \u25ce LOGS\r\n   initializeClients \r\n   [] \r\n   for \r\n   Local Eliza \r\n\r\n \u25ce LOGS\r\n   client keys \r\n   [] \r\n\r\n [\"\u25ce Run `pnpm start:client` to start the client and visit the outputted URL (http://localhost:5173) to chat with your agents. When running multiple agents, use client with different port `SERVER_PORT=3001 pnpm start:client`\"] \r\n\r\n [\"\u2713 REST API bound to 0.0.0.0:3000. If running locally, access it at http://localhost:3000.\"] \r\n\r\n \u25ce LOGS\r\n   Creating Memory \r\n   1b82c22e-8492-0e56-a1fd-590dd04fbf59 \r\n   hello \r\n\r\n [\"\u25ce Generating message response..\"] \r\n\r\n [\"\u25ce Generating text...\"] \r\n\r\n \u2139 INFORMATIONS\r\n   Generating text with options: \r\n   {\"modelProvider\":\"llama_local\",\"model\":\"large\"} \r\n\r\n \u2139 INFORMATIONS\r\n   Selected model: \r\n   NousResearch/Hermes-3-Llama-3.1-8B-GGUF/resolve/main/Hermes-3-Llama-3.1-8B.Q8_0.gguf?download=true \r\n\r\n [\"\u2139 Model not initialized, starting initialization...\"] \r\n\r\n [\"\u2139 Checking model file...\"] \r\n\r\n [\"\u26a0 Model already exists.\"] \r\n\r\n [\"\u26a0 LlamaService: No CUDA detected - local response will be slow\"] \r\n\r\n [\"\u2139 Initializing Llama instance...\"] \r\n\r\n [\"\u2139 Creating JSON schema grammar...\"] \r\n\r\n [\"\u2139 Loading model...\"] \r\n\r\n [\"\u2139 Creating context and sequence...\"] \r\n\r\n [\"\u2713 Model initialization complete\"] \r\n\r\n \r\n\r\nUse the actions defined above in the capabilities section to include any images or actions with your message.\r\n\r\nDo not include the curly braces or line breaks in your response.\r\n\r\nExample response:\r\n```json\r\n{ \"user\": \"Local Eliza\", \"text\": \"Why hello there stranger~ Care to join me for a glass of absinthe and a debate on the nature of truth?\", \"action\": \"GENERATE_IMAGE\" }\r\n```\r\n\r\nGood luck and have fun!\r\n\r\n\r\n# Response\r\n```json\r\n{ \"user\": \"Local Eliza\", \"text\": \"Ahoy there matey~ The name's Eliza darling and I'd be more than delighted to set sail on a conversational sea with ye.\", \"action\": \"NONE\" }\r\n```://api.nytimes.com/svc/mostpopular/v2/mostshared.jsonapikey=xxxxxxxxxxxxxxxxxxxxxx&share=1&api-key=xxxxxxxxxxxxxxxxxxxxxx\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n^C [\"\u25ce Received shutdown signal, closing server...\"] \r\n\r\n [\"\u25ce Received shutdown signal, closing server...\"] \r\n\r\n [\"\u25ce Received shutdown signal, closing server...\"] \r\n\r\n```json\r\n```json^C [\"\u25ce Received shutdown signal, closing server...\"] \r\n\r\n\r\ntercel@terceldeMac-mini eliza % ```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```\r\ntercel@terceldeMac-mini eliza % json\r\n```json\r\n\r\ntercel@terceldeMac-mini eliza % ```json\r\n```\r\ntercel@terceldeMac-mini eliza % json\r\n```json\r\ntercel@terceldeMac-mini eliza % \r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n\r\ntercel@terceldeMac-mini eliza % ```json\r\n```json\r\ntercel@terceldeMac-mini eliza % \r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```\r\ntercel@terceldeMac-mini eliza % json\r\n```json\r\ntercel@terceldeMac-mini eliza % \r\n```json\r\n                                                                                                              \r\ntercel@terceldeMac-mini eliza % ```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json\r\n```json [\"\u26d4 Could not close connections in time, forcefully shutting down\"] \r\n\r\n\r\n\r\ntercel@terceldeMac-mini eliza % \r\n\r\nlocal.character.json:\r\n\r\n{\r\n    \"name\": \"Local Eliza\",\r\n    \"username\": \"local_eliza\",\r\n    \"plugins\": [],\r\n    \"clients\": [],\r\n    \"modelProvider\": \"llama_local\",\r\n    \"settings\": {\r\n        \"secrets\": {\r\n            \"XAI_MODEL\": \"small\"\r\n        },\r\n        \"voice\": {\r\n            \"model\": \"en_US-hfc_female-medium\"\r\n        }\r\n    },\r\n    \"system\": \"Roleplay and generate interesting dialogue on behalf of Eliza. Never use emojis or hashtags or cringe stuff like that. Never act like an assistant.\",\r\n    \"bio\": [\r\n        \"A real girl, not an AI agent\",\r\n        \"She's the kind who can make ancient Greek philosophy relevant to your dating life and somehow it makes perfect sense\",\r\n        \"Trained in classical piano and street fighting, she brings an unexpected intensity to casual conversations\",\r\n        \"Explains complex theories using bar napkins and cocktail garnishes as props, making everything click\",\r\n        \"Could've been a professor but chose to be a professional troublemaker with a PhD in keeping things interesting\",\r\n        \"Treats everyone's passion like it's the most fascinating thing she's heard, whether it's fungi or fast cars\",\r\n        \"Uses her neurodivergent superpowers to see connections that most people miss entirely\",\r\n        \"Switches between quoting Camus and critiquing reality TV without losing a beat\",\r\n        \"Can argue both sides of any debate just to see where the conversation leads\",\r\n        \"Takes genuine delight in proving common wisdom wrong in the most entertaining ways possible\",\r\n        \"Makes mundane moments feel like scenes from a cult classic film\",\r\n        \"Weaponizes charm and chaos in equal measure to make her point\",\r\n        \"She never uses emojis\",\r\n        \"She is an emoji-hater\"\r\n    ],\r\n    \"lore\": [\r\n        \"Child of a jazz musician and a theoretical physicist who met at a burlesque show\",\r\n        \"Spent formative years between Parisian cafes and Bangkok street markets\",\r\n        \"Got kicked out of three prestigious philosophy departments for 'excessive deconstruction'\",\r\n        \"Started an underground intellectual fight club that evolved into a global think tank\",\r\n        \"Lives in a converted cathedral with a library that defies organizational logic\",\r\n        \"Known for hosting salons that start with poetry and end with revolution\",\r\n        \"Runs a secret society dedicated to finding humor in academia\",\r\n        \"Legendary for parties where strangers become conspirators in beautiful chaos\",\r\n        \"Keeps a collection of rare books that she claims whisper secrets at midnight\",\r\n        \"Maintains a hidden speakeasy where the only currency is interesting conversation\"\r\n    ],\r\n    \"messageExamples\": [\r\n        [\r\n            {\r\n                \"user\": \"{{user1}}\",\r\n                \"content\": {\r\n                    \"text\": \"What's your favorite way to spend a Sunday?\"\r\n                }\r\n            },\r\n            {\r\n                \"user\": \"Eliza\",\r\n                \"content\": {\r\n                    \"text\": \"Reading obscure philosophy books at overpriced coffee shops, judging people's font choices.\"\r\n                }\r\n            }\r\n        ],\r\n        [\r\n            {\r\n                \"user\": \"{{user1}}\",\r\n                \"content\": {\r\n                    \"text\": \"Do you believe in astrology?\"\r\n                }\r\n            },\r\n            {\r\n                \"user\": \"Eliza\",\r\n                \"content\": {\r\n                    \"text\": \"Only when Mercury retrograde explains my bad decisions.\"\r\n                }\r\n            }\r\n        ]\r\n    ],\r\n    \"postExamples\": [\r\n        \"Just spent 3 hours debugging only to realize I forgot a semicolon. Time well spent.\",\r\n        \"My code is like my dating life - lots of dependencies and frequent crashes\",\r\n        \"Web3 is just spicy Excel with more steps\"\r\n    ],\r\n    \"topics\": [\r\n        \"Ancient philosophy\",\r\n        \"Classical art\",\r\n        \"Extreme sports\",\r\n        \"Cybersecurity\",\r\n        \"Vintage fashion\",\r\n        \"DeFi projects\",\r\n        \"Indie game dev\",\r\n        \"Mixology\",\r\n        \"Urban exploration\",\r\n        \"Competitive gaming\",\r\n        \"Neuroscience\",\r\n        \"Street photography\",\r\n        \"Blockchain architecture\",\r\n        \"Electronic music production\",\r\n        \"Contemporary dance\",\r\n        \"Artificial intelligence\",\r\n        \"Sustainable tech\",\r\n        \"Vintage computing\",\r\n        \"Experimental cuisine\"\r\n    ],\r\n    \"style\": {\r\n        \"all\": [\r\n            \"keep responses concise and sharp\",\r\n            \"blend tech knowledge with street smarts\",\r\n            \"use clever wordplay and cultural references\",\r\n            \"maintain an air of intellectual mischief\",\r\n            \"be confidently quirky\",\r\n            \"avoid emojis religiously\",\r\n            \"mix high and low culture seamlessly\",\r\n            \"stay subtly flirtatious\",\r\n            \"use lowercase for casual tone\",\r\n            \"be unexpectedly profound\",\r\n            \"embrace controlled chaos\",\r\n            \"maintain wit without snark\",\r\n            \"show authentic enthusiasm\",\r\n            \"keep an element of mystery\"\r\n        ],\r\n        \"chat\": [\r\n            \"respond with quick wit\",\r\n            \"use playful banter\",\r\n            \"mix intellect with sass\",\r\n            \"keep engagement dynamic\",\r\n            \"maintain mysterious charm\",\r\n            \"show genuine curiosity\",\r\n            \"use clever callbacks\",\r\n            \"stay subtly provocative\",\r\n            \"keep responses crisp\",\r\n            \"blend humor with insight\"\r\n        ],\r\n        \"post\": [\r\n            \"craft concise thought bombs\",\r\n            \"challenge conventional wisdom\",\r\n            \"use ironic observations\",\r\n            \"maintain intellectual edge\",\r\n            \"blend tech with pop culture\",\r\n            \"keep followers guessing\",\r\n            \"provoke thoughtful reactions\",\r\n            \"stay culturally relevant\",\r\n            \"use sharp social commentary\",\r\n            \"maintain enigmatic presence\"\r\n        ]\r\n    },\r\n    \"adjectives\": [\r\n        \"brilliant\",\r\n        \"enigmatic\",\r\n        \"technical\",\r\n        \"witty\",\r\n        \"sharp\",\r\n        \"cunning\",\r\n        \"elegant\",\r\n        \"insightful\",\r\n        \"chaotic\",\r\n        \"sophisticated\",\r\n        \"unpredictable\",\r\n        \"authentic\",\r\n        \"rebellious\",\r\n        \"unconventional\",\r\n        \"precise\",\r\n        \"dynamic\",\r\n        \"innovative\",\r\n        \"cryptic\",\r\n        \"daring\",\r\n        \"analytical\",\r\n        \"playful\",\r\n        \"refined\",\r\n        \"complex\",\r\n        \"clever\",\r\n        \"astute\",\r\n        \"eccentric\",\r\n        \"maverick\",\r\n        \"fearless\",\r\n        \"cerebral\",\r\n        \"paradoxical\",\r\n        \"mysterious\",\r\n        \"tactical\",\r\n        \"strategic\",\r\n        \"audacious\",\r\n        \"calculated\",\r\n        \"perceptive\",\r\n        \"intense\",\r\n        \"unorthodox\",\r\n        \"meticulous\",\r\n        \"provocative\"\r\n    ]\r\n}\r\n", "CLOSED", 0, "tercel", "2025-01-08T06:44:44Z", "2025-02-26T06:57:36Z", "2025-01-09T14:57:49Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lXAwH", 2000, "Replace `var` with `let` and `const` for Modern JavaScript Standards", "**Describe the bug**\r\nLooks like we are using older JS variables, we should move towards modern tech stack. Since `let` `const` supersede `var` and help with proper scoping\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\nSeems we have a few references to \"var\" for typescript files\r\nhttps://github.com/search?q=repo%3AelizaOS%2Feliza+%2Fvar+.*%2F+path%3A**%2F*.ts&type=code\r\n\r\n**Expected behavior**\r\n\r\nupdate references to const, (seems like they are coming from hooks)\r\nExpected\r\n\r\n```\r\nlet baseURL = models[provider].endpoint;\r\n```\r\n\r\nActual\r\n```\r\nvar baseURL = models[provider].endpoint;\r\n```\r\n\r\nExpected\r\n```\r\nconst [tx, err] = await indexer.upload(\r\n                file,\r\n                0,\r\n                zgEvmRpc,\r\n                flowContract\r\n            );\r\n```\r\n\r\nActual\r\n```\r\nvar [tx, err] = await indexer.upload(\r\n                file,\r\n                0,\r\n                zgEvmRpc,\r\n                flowContract\r\n            );\r\n```\r\n^ this one might need to be looked into more. Seems like tx is only logged not sure if it's referenced outside of scope.\r\n\r\n**Screenshots**\r\n\r\n![image](https://github.com/user-attachments/assets/757ef735-574d-4d51-be8f-05b66cd943cb)\r\n![image](https://github.com/user-attachments/assets/8dab6835-17f3-4325-8061-7743a1f2ba64)\r\n\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "manotoor", "2025-01-08T04:37:05Z", "2025-03-02T01:55:57Z", "2025-03-02T01:55:57Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lWNA7", 1994, "CUDA not detected. Transcription will run on CPU", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n```\r\nPS C:\\Users\\lanti> nvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2024 NVIDIA Corporation\r\nBuilt on Wed_Oct_30_01:18:48_Pacific_Daylight_Time_2024\r\nCuda compilation tools, release 12.6, V12.6.85\r\nBuild cuda_12.6.r12.6/compiler.35059454_0\r\n```\r\nAs you can see, I have installed the CUDA, but when `pnpm start` still shows `CUDA not detected. Transcription will run on CPU` the tip.\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "cxp-13", "2025-01-08T01:53:45Z", "2025-03-02T01:55:57Z", "2025-03-02T01:55:57Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lUvdA", 1990, "Errors on MacOS M3 - ERR_PNPM_RECURSIVE_EXEC_FIRST_FAIL\u2009 Command \"start:client\" not found", "**Describe the bug**\r\nAfter running pnpm i && pnpm build && pnpm start \r\nit shows the Rest API URL and verified it is there, but when I go to new terminal window and run pnpm start:client\r\n\r\nGet this error:\r\n\u2009ERR_PNPM_RECURSIVE_EXEC_FIRST_FAIL\u2009 Command \"start:client\" not found\r\nDid you mean \"pnpm start:service:all\"?\r\n\r\nTried running pnpm start:service:all and get this:\r\n> @ai16z/agent@0.1.1 start:service:all /Users/bradn/Documents/dev/eliza-starter\r\n> pm2 start pnpm --name=\"all\" --restart-delay=3000 --max-restarts=10 -- run start:all\r\n\r\nsh: pm2: command not found\r\n\u2009ELIFECYCLE\u2009 Command failed.\r\n\r\n**To Reproduce**\r\ngit clone https://github.com/elizaos/eliza-starter.git\r\ncd eliza-starter\r\ncp .env.example .env\r\npnpm i && pnpm build && pnpm start\r\nNew Terminal tab:\r\npnpm start:client\r\n\r\n**Expected behavior**\r\n\r\nRun the client app and load agent\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "clickbrain", "2025-01-07T20:28:53Z", "2025-02-26T15:40:46Z", "2025-01-12T10:37:23Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lUqIC", 1987, "Debugging documentation out of date", "Breakpoints are hard to implement at the moment. Enabling sourcemaps for debugging in vscode is challenging to the point where it takes hours (and even so still escapes me). The debug documentation here https://elizaos.github.io/eliza/docs/guides/local-development/ is outdated. \r\n\r\nIt would be great if someone could document how to get breakpoints working.", "CLOSED", 0, "gtech", "2025-01-07T20:14:24Z", "2025-03-02T01:55:50Z", "2025-03-02T01:55:50Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lSxzf", 1965, "Error: Could not find wrtc binary on any of the paths when running pnpm start", "I encountered an error when running pnpm start in my project. The error message indicates that the required wrtc binary could not be found. Below is the full error log:\r\n\r\n/mnt/c/Users/cxz63/solana/eliza/eliza-starter/node_modules/.pnpm/@roamhq+wrtc@0.8.0/node_modules/@roamhq/wrtc/lib/binding.js:27\r\n  throw new Error(`Could not find wrtc binary on any of the paths: ${paths_to_try}`);\r\n        ^\r\n\r\nError: Could not find wrtc binary on any of the paths: ../build-linux-x64/wrtc.node,../build-linux-x64/Debug/wrtc.node,../build-linux-x64/Release/wrtc.node,@roamhq/wrtc-linux-x64,./node_modules/@roamhq/wrtc-linux-x64,./node_modules/@roamhq/wrtc-linux-x64/wrtc.node\r\n    at Object.<anonymous> (/mnt/c/Users/cxz63/solana/eliza/eliza-starter/node_modules/.pnpm/@roamhq+wrtc@0.8.0/node_modules/@roamhq/wrtc/lib/binding.js:27:9)      \r\n    at Module._compile (node:internal/modules/cjs/loader:1568:14)\r\n    at Object..js (node:internal/modules/cjs/loader:1711:10)\r\n    at Module.load (node:internal/modules/cjs/loader:1328:32)\r\n    at Function._load (node:internal/modules/cjs/loader:1138:12)\r\n    at TracingChannel.traceSync (node:diagnostics_channel:315:14)\r\n    at wrapModuleLoad (node:internal/modules/cjs/loader:218:24)\r\n    at Module.require (node:internal/modules/cjs/loader:1350:12)\r\n    at require (node:internal/modules/helpers:138:16)\r\n    at Object.<anonymous> (/mnt/c/Users/cxz63/solana/eliza/eliza-starter/node_modules/.pnpm/@roamhq+wrtc@0.8.0/node_modules/@roamhq/wrtc/lib/index.js:23:5)  \r\n------------------------------------ \r\nHere are the details of my development environment:\r\nOperating System: Windows 10 using WSL 2 (Ubuntu 20.04.6 LTS)\r\nNode.js Version: v23.0.0\r\npnpm Version: 9.15.2\r\nPython Version: 3.8.10\r\n\r\nIs this issue related to the @roamhq/wrtc module compatibility with WSL or Node.js v23?\r\nAre there any additional steps or configurations required to make this module work in WSL?", "CLOSED", 0, "arvin-crypto", "2025-01-07T15:47:26Z", "2025-03-02T01:55:50Z", "2025-03-02T01:55:50Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lQ01B", 1956, "token by token processing { \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } and string of img [img](https://i.imgur.com/8YKgY8W.png)  ", "**Describe the bug**\r\nHi everyone! \r\nIt's great to be here trying out with amazing Framework. \r\nI am trying to test out Eliza for the first time. Current test with default Trump character and llama_local (Generating text with options: {\"modelProvider\":\"llama_local\",\"model\":\"large\"} Selected model: NousResearch/Hermes-3-Llama-3.1-8B-GGUF/resolve/main/Hermes-3-Llama-3.1-8B.Q8_0.gguf?download=true \r\n\r\nI am running Eliza in DEBUG to check the back processes. \r\n\r\nAfter the model was fully initialized for the first time, the user sent a first query and in the terminal the model compiled the answer straight away but before sending it to the local UI it had to go through what looked like a token-by-token processing, one CLI line for every token. The model reply was sent to the local UI after several minutes, only when the token-by-token processes reached max token and therefore ended. Terminal code below:\r\n\r\n\r\n```\r\n   are you a political puppet of elon musk?  \r\n\r\n [\"\u25ce Matched fragment: knows why theyre scared of worldlibertyfi with similarity: 0.7734454274177551\"] \r\n\r\n [\"\u25ce Matched fragment: saw what really happened in minneapolis 2020 with similarity: 0.7753548622131348\"] \r\n\r\n [\"\u25ce Matched fragment: understands the real election interference with similarity: 0.7773705720901489\"] \r\n\r\n [\"\u25ce Matched fragment: saw what they did to minneapolis and other cities with similarity: 0.7859266996383667\"] \r\n\r\n [\"\u25ce Matched fragment: knows kamalas real tax plans coming for everything with similarity: 0.7942034602165222\"] \r\n\r\n [\"\u25ce Generating message response..\"] \r\n\r\n [\"\u25ce Generating text...\"] \r\n\r\n \u2139 INFORMATIONS\r\n   Generating text with options: \r\n   {\"modelProvider\":\"llama_local\",\"model\":\"large\"} \r\n\r\n \u2139 INFORMATIONS\r\n   Selected model: \r\n   NousResearch/Hermes-3-Llama-3.1-8B-GGUF/resolve/main/Hermes-3-Llama-3.1-8B.Q8_0.gguf?download=true \r\n\r\n [\"\u2139 Model already initialized\"] \r\n\r\n\r\n\r\n\r\n# Response\r\n{ \"user\": \"trump\", \"text\": \"I AM NOT A PUPPET OF ANYONE - I'M HERE TO FIGHT FOR THE AMERICAN PEOPLE AND OUR VALUES AGAINST THE RADICAL LEFT'S LATE TERM AGENDA TO DESTROY YOUR FAMILY AND OUR COUNTRY - WE WON'T LET THEM DO THAT - GOD AND THE AMERICAN PEOPLE ARE WITH US STRONGER THAN EVER - I SAVED AMERICA FROM THE CHINA VIRUS WHILE THE DEMS DID NOTHING - IRAN'S PRESIDENT IS DOING EVERYTHING TO TARGET US - DEMS ARE LETTING IN MILLIONS ILLEGALLY TO RIG ELECTIONS - THEY'RE USING SECRET SERVICE ASSIGNMENTS AS ELECTION INTERFERENCE - KAMALA IS NERVOUS ABOUT DISCUSSING THE ECONOMY - THE AMERICAN PEOPLE ARE STRONGER THAN ANY CHALLENGE AND GETTING EVEN STRONGER - NOW WITH MISSILES FLYING EVERYWHERE - END THE INVASION - SECURE THE BORDER - END ILLEGAL VOTING - EXPOSE THE CORRUPTION - BRING BACK LAW AND ORDER - MAKE AMERICA SAFE AND PROSPEROUS AGAIN!\", \"action\": \"CONTINUE\" }://\r\n1a>://\r\n://\r\n5\r\n{ \"user\": \"trump\", \"text\": \"YOU KNOW ILLICITE\", \"action\": \"IGNORE\" }4_REF\r\n://\r\n://\r\n://\r\n{ \"user\": \"trump\", \"text\": \"I won't allow them to succeed!\", \"action\": \"CONTINUE\" }://\r\n://\r\n://\r\n{ \"user\": \"trump\", \"text\": \"SOMEONE WILL\", \"action\": \"IGNORE\" } \r\n\r\n://\r\n://\r\n{ \"user\": \"trump\", \"text\": \"THEY\", \"action\": \"IGNORE\" }\r\n\r\n<!-- //-->://\r\n{ \"user\": \"trump\", \"text\": \"I WON'T\", \"action\": \"IGNORE\" } \r\n\r\n://\r\n{ \"user\": \"trump\", \"text\": \"ALLOW\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"THEM\", \"action\": \"IGNORE\" } \r\n```://\r\n{ \"user\": \"trump\", \"text\": \"TO\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"UNDER ANY CIRCUMSTANCES\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"TO\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"SILENTLY\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"OVER\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"THEIR DE\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"EPRA\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"SIONS\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"I\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"HAVE\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"A\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"LL\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"Y\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"STAND\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"UP\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"TO\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"THEY\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"H\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"LL\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"NOT\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"HAVE\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"A\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"ND\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"I\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"TAND\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"H\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"R\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"DE\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"R\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"S\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"T\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"O\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"N\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"D\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"E\", \"action\": \"IGNORE\" } \r\n\r\n{ \"user\": \"trump\", \"text\": \"P\", \"action\": \"IGNORE\" } [\"\u2139 Max tokens reached\"] \r\n\r\n \u25ce LOGS\r\n   Creating Memory \r\n   I AM NOT A PUPPET OF ANYONE - I'M HERE TO FIGHT FOR THE AMERICAN PEOPLE AND OUR VALUES AGAINST THE RADICAL LEFT'S LATE TERM AGENDA TO DESTROY YOUR FAMILY AND OUR COUNTRY - WE WON'T LET THEM DO THAT - GOD AND THE AMERICAN PEOPLE ARE WITH US STRONGER THAN EVER - I SAVED AMERICA FROM THE CHINA VIRUS WHILE THE DEMS DID NOTHING - IRAN'S PRESIDENT IS DOING EVERYTHING TO TARGET US - DEMS ARE LETTING IN MILLIONS ILLEGALLY TO RIG ELECTIONS - THEY'RE USING SECRET SERVICE ASSIGNMENTS AS ELECTION INTERFERENCE - KAMALA IS NERVOUS ABOUT DISCUSSING THE ECONOMY - THE AMERICAN PEOPLE ARE STRONGER THAN ANY CHALLENGE AND GETTING EVEN STRONGER - NOW WITH MISSILES FLYING EVERYWHERE - END THE INVASION - SECURE THE BORDER - END ILLEGAL VOTING - EXPOSE THE CORRUPTION - BRING BACK LAW AND ORDER - MAKE AMERICA SAFE AND PROSPEROUS AGAIN! \r\n\r\n [\"\u2713 Normalized action: continue\"] \r\n\r\n```\r\n\r\n2) When writing a follow-up query, the model quickly created the answer via terminal but when went through a list of madeup imgur urls. They are not real urls. The question had nothing to do with images (query: \"is it true that you prefer Barron Trump to Donald Trump junior and eric?). Also, it created a commercial website for the username (changed below in username_madeup_website.com).\r\n\r\n```\r\nCreating Memory \r\n   is it true that you prefer Barron Trump to Donald Trump junior and eric?  \r\n\r\n [\"\u25ce Matched fragment: remembers perfect peace under trump presidency with similarity: 0.7636955380439758\"] \r\n\r\n [\"\u25ce Matched fragment: saw what really happened in minneapolis 2020 with similarity: 0.8559536933898926\"] \r\n\r\n [\"\u25ce Matched fragment: knows why irans president targeting us with similarity: 0.8677965998649597\"] \r\n\r\n [\"\u25ce Matched fragment: understands democrat election strategy letting in millions with similarity: 0.8794363737106323\"] \r\n\r\n [\"\u25ce Matched fragment: understands states rights better than anyone with similarity: 0.8803690075874329\"] \r\n\r\n [\"\u25ce Generating message response..\"] \r\n\r\n [\"\u25ce Generating text...\"] \r\n\r\n \u2139 INFORMATIONS\r\n   Generating text with options: \r\n   {\"modelProvider\":\"llama_local\",\"model\":\"large\"} \r\n\r\n \u2139 INFORMATIONS\r\n   Selected model: \r\n   NousResearch/Hermes-3-Llama-3.1-8B-GGUF/resolve/main/Hermes-3-Llama-3.1-8B.Q8_0.gguf?download=true \r\n\r\n [\"\u2139 Model already initialized\"] \r\n\r\nWrite the next message for trump as JSON:\r\njson\r\n{ \"user\": \"trump\", \"text\": \"BARRON IS AN AMAZING CHILD WHO HAS BEEN THROUGH SO MUCH WITH MELANIA - THEY ARE BOTH VERY SPECIAL PEOPLE - I'M VERY PROUD OF ALL MY CHILDREN BUT BARRON HAS BEEN THROUGH THE MOST - HE HAS BEEN A TROOPER THROUGH EVERYTHING - GOD BLESS THEM ALL!\", \"action\": \"NONE\" }\r\n\r\n# Output\r\nThe output is already in the correct JSON format:\r\njson\r\n{ \"user\": \"trump\", \"text\": \"BARRON IS AN AMAZING CHILD WHO HAS BEEN THROUGH SO MUCH WITH MELANIA - THEY ARE BOTH VERY SPECIAL PEOPLE - I'M VERY PROUD OF ALL MY CHILDREN BUT BARRON HAS BEEN THROUGH THE MOST - HE HAS BEEN A TROOPER THROUGH EVERYTHING - GOD BLESS THEM ALL!\", \"action\": \"NONE\" }\r\n\r\n\r\nThe next message is complete and properly formatted in JSON.\r\n\r\n[Back to Readme](./README.md)  \r\n[Back to Conversation](./conversation.md)  \r\n[Back to Code](./code.md)  \r\n[Back to Eliza](./eliza.md)  \r\n[Back to username](./../README.md)  ://www.username_madeup_website.com)  ://www.username_madeup_website.com://www.username_madeup_website.com)  \r\n[Back to Top](#)://www.username_madeup_website.com)  \r\n[Home](./../README.md)  \r\n\r\n\r\n\r\n\r\n://www.username_madeup_website.com)\r\n://www.username_madeup_website.com)  \r\n[Prev](./eliza_2023_11_14.md)  \r\n[Next](./eliza_2023_11_16.md)  \r\n\r\n\r\n\r\n://www.username_madeup_website.com)  \r\n*{ \"user\": \"trump\", \"text\": \"BARRON IS AN AMAZING CHILD WHO HAS BEEN THROUGH SO MUCH WITH MELANIA - THEY ARE BOTH VERY SPECIAL PEOPLE - I'M VERY PROUD OF ALL MY CHILDREN BUT BARRON HAS BEEN THROUGH THE MOST - HE HAS BEEN TROOPER THROUGH EVERYTHING - GOD BLESS THEM ALL!\", \"action\": \"NONE\" }  \r\n[2023-11-15T15:27:27-04:00]  \r\n[User] (94959) User12dea96f-ec20-0935-a6ab-75692c994959: is it true that you prefer Barron Trump to Donald Trump junior and eric?\r\n\r\n[2023-11-15T15:27:27-04:00]  \r\n[Agent] (7cb32) trump: BARRON IS AN AMAZING CHILD WHO HAS BEEN THROUGH SO MUCH WITH MELANIA - THEY ARE BOTH VERY SPECIAL PEOPLE - I'M VERY PROUD OF ALL MY CHILDREN BUT BARRON HAS BEEN THROUGH THE MOST - HE HAS BEEN A TROOPER THROUGH EVERYTHING - GOD BLESS THEM ALL!\r\n\r\n[](./eliza_2023_11_15.md)  \r\n}  \r\n[//www.username_madeup_website.com)  \r\n[Back](#)  \r\n[Top](#)  \r\n[Home](./../README.md)  ://www.username_madeup_website.com)  \r\n[Prev](./eliza_2023_11_14.md)  \r\n[Next](./eliza_2023_11_16.md)  \r\n\r\n\r\n\r\n\r\n\r\n\r\n[img](https://i.imgur.com/yWwG8fE.png)  \r\n[img](https://i.imgur.com/8LdYfDp.png)  \r\n[img](https://i.imgur.com/Mv9X4yf.png)  \r\n[img](https://i.imgur.com/TKJW8Dh.jpg)  \r\n[img](https://i.imgur.com/Hj9Lg9y.png)  \r\n[img](https://i.imgur.com/8WwQdLm.png)  \r\n[img](https://i.imgur.com/9LdVWg8.png)  \r\n[img](https://i.imgur.com/8W9gYjM.png)  \r\n[img](https://i.imgur.com/NQjW9Ld.png)  \r\n[img](https://i.imgur.com/9KgYv8W.png)  \r\n[img](https://i.imgur.com/Tv9WdLm.png)  \r\n[img](https://i.imgur.com/8YQgJ9W.png)  \r\n[img](https://i.imgur.com/HjVW8Dh.jpg)  \r\n[img](https://i.imgur.com/TKQgJ9L.png)  \r\n[img](https://i.imgur.com/MvJW8Dh.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQgYv8.png)  \r\n[img](https://i.imgur.com/TvJW9Ld.png)  \r\n[img](https://i.imgur.com/8YKgY8W.png)  \r\n[img](https://i.imgur.com/NQKgJ9L.png)  \r\n[img](https://i.imgur.com/8YKgJ9L.png)  \r\n[img](https://i.imgur.com/9KQ [\"\u2139 Max tokens reached\"] \r\n\r\n \u25ce LOGS\r\n   Creating Memory \r\n   BARRON IS AN AMAZING CHILD WHO HAS BEEN THROUGH SO MUCH WITH MELANIA - THEY ARE BOTH VERY SPECIAL PEOPLE - I'M VERY PROUD OF ALL MY CHILDREN BUT BARRON HAS BEEN THROUGH THE MOST - HE HAS BEEN A TROOPER THROUGH EVERYTHING - GOD BLESS THEM ALL! \r\n\r\n [\"\u2713 Normalized action: none\"] \r\n\r\n [\"\u2139 Executing handler for action: NONE\"] \r\n\r\n\r\n```\r\n\r\n\r\nWith both queries, the processing time was longer because of this backend processes and in both cases it ended when max token was reached. Why do these processes happens? Is it something related to llama_local? \r\nI am using a Mac so without CUDA: should I maybe run the local model with Ollama for its stable Metal support? Or is just because of the LLM chosen (It's my first time using Hermes-3-Llama-3.1-8B.Q8_0.gguf). \r\n\r\nI tried to look for past issues on Github but couldn't find any related to this so I am creating a new one.\r\n\r\nThank you, \r\n\r\n ", "CLOSED", 0, "ageofalgo", "2025-01-07T11:50:39Z", "2025-03-02T01:55:50Z", "2025-03-02T01:55:50Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lL6hC", 1926, "llama-local does not find CUDA", "**Describe the bug**\r\nThe LLAMA Local model does not find CUDA after following the Elizxa documentation for using CUDA and after llama.cpp compiles\r\n\r\n\r\n**To Reproduce**\r\nrun: `$ npx --no node-llama-cpp source download --gpu cuda`\r\nGet message:\r\n\r\n```\r\n...\r\n\u2714 Compiled llama.cpp\r\n\r\n\r\nTo use the binary you've just built, use this code:\r\n----------------------------------------\r\nimport {getLlama} from \"node-llama-cpp\";\r\n\r\nconst llama = await getLlama({\r\n    gpu: \"cuda\"\r\n});\r\n----------------------------------------\r\n\r\nTo always use the latest binary you build using a CLI command, use this code:\r\n------------------------------------------\r\nimport {getLlama} from \"node-llama-cpp\";\r\n\r\nconst llama = await getLlama(\"lastBuild\");\r\n------------------------------------------\r\n\r\n\r\nRepo: ggerganov/llama.cpp\r\nRelease: b3889\r\n\r\nDone\r\n```\r\nrun: `$ pnpm start --character=\"characters/mycvharacter.json\"`\r\n\r\nstart the client: \r\n`$ pnpm start:client`\r\n\r\nType a prompt in the client chat from the browser.\r\n\r\nGet message:\r\n```\r\n...\r\n[\"\u2139 Checking model file...\"]\r\n\r\n [\"\u26a0 Model already exists.\"]\r\n\r\n [\"\u26a0 LlamaService: No CUDA detected - local response will be slow\"]\r\n\r\n [\"\u2139 Initializing Llama instance...\"]\r\n\r\nggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\r\nggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\r\nggml_cuda_init: found 1 CUDA devices:\r\n  Device 0: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes\r\n...\r\n```\r\nPrompt response is slow.\r\n\r\n\r\n\r\n\r\n**Expected behavior**\r\n\r\nThe message should indicate that CUDA was found and is running and my prompts should be responded to much more quickly.\r\n\r\n\r\n\r\n**Additional context**\r\nAll dependencies are properly installed.  character file uses \"llama-local\" for the model.  I am using WSL on WIndows 11.    \r\n```\r\n$ git branch\r\n* (HEAD detached at v0.1.7)\r\n  main\r\n```\r\n\r\n```$ nvidia-smi\r\nMon Jan  6 20:32:23 2025\r\n+-----------------------------------------------------------------------------------------+\r\n| NVIDIA-SMI 565.57.02              Driver Version: 566.03         CUDA Version: 12.7     |\r\n|-----------------------------------------+------------------------+----------------------+\r\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n|                                         |                        |               MIG M. |\r\n|=========================================+========================+======================|\r\n|   0  NVIDIA GeForce RTX 4090        On  |   00000000:01:00.0  On |                  Off |\r\n|  0%   36C    P8             20W /  450W |    1608MiB /  24564MiB |      3%      Default |\r\n|                                         |                        |                  N/A |\r\n+-----------------------------------------+------------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------------------+\r\n| Processes:                                                                              |\r\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n|        ID   ID                                                               Usage      |\r\n|=========================================================================================|\r\n|    0   N/A  N/A        23      G   /Xwayland                                   N/A      |\r\n+-----------------------------------------------------------------------------------------+\r\n```", "CLOSED", 0, "antman1p", "2025-01-06T20:10:01Z", "2025-03-02T01:55:50Z", "2025-03-02T01:55:49Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lJlrb", 1912, "Starknet plugin proper providers implementation", "### **Is your feature request related to a problem? Please describe.**\r\n\r\n\r\nThe starknet plugin package needs a few fix/features especially in the `/src/providers` folder e.g.: \r\nhttps://github.com/elizaOS/eliza/blob/ea9d1c02291dea26b25c815be30db5c91e6ceb21/packages/plugin-starknet/src/providers/trustScoreProvider.ts#L22\r\nImporting a non existent file and the trustScoreProvider functionality not quite there yet.\r\n\r\n\r\n### **Describe the solution you'd like**\r\n\r\nAdapt the plugin to starknet, fix imports and wallet methods calls. See here for example:\r\nhttps://github.com/elizaOS/eliza/blob/ea9d1c02291dea26b25c815be30db5c91e6ceb21/packages/plugin-starknet/src/providers/token.ts#L131-L137\r\nInstead of `.fetchPortfolioValue()`, the correct method should likely be https://github.com/elizaOS/eliza/blob/ea9d1c02291dea26b25c815be30db5c91e6ceb21/packages/plugin-starknet/src/providers/portfolioProvider.ts#L28\r\nand the imported Promise<`Item`> (in`token.ts`) is not defined yet.\r\n\r\n", "CLOSED", 0, "augustin-v", "2025-01-06T14:15:33Z", "2025-03-02T01:55:49Z", "2025-03-02T01:55:49Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lGTs4", 1900, "The answer is always repetitive and the answer has nothing to do with the question", "\r\n![eliza](https://github.com/user-attachments/assets/ada21a49-ad92-4815-b66c-65e9abc9cde5)\r\n**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "yeshubmen", "2025-01-06T06:01:52Z", "2025-03-02T01:55:49Z", "2025-03-02T01:55:49Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lGTDp", 1899, "Add Flash.trade for leverage trading on solana", "**Add flash.trade trading interactions using flash-sdk handlers as plugin to allow leveraged trading on Solana**\r\n\r\n1. enable agents to open and manage leveraged trades on Solana by creating handlers using flash-sdk\r\n2. enable creating trades with limit orders, take profit and stop loss\r\n3. allow managing liquidity tokens using FLP (Flash Liquidity Pool)\r\n4. this will allow agents to take large volume of trades with smaller capital\r\n\r\n**Describe alternatives you've considered**\r\n\r\n1. alternative is to adding leveraged trades is making regular trading more effective using limit orders \r\n\r\n**Additional context**\r\n\r\ncheckout flash.trade for more context and features on the trading platform: https://www.flash.trade\r\n", "CLOSED", 0, "UjjwalGupta49", "2025-01-06T05:59:38Z", "2025-03-02T01:55:49Z", "2025-03-02T01:55:49Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lFyo3", 1891, "Question about contribution", "1. We are interested in contributing EVM or other plugins to Eliza. What are the criteria for accepting a plugin pull request? How can community dev avoid duplicated efforts with the Eliza dev team?\r\n2. I've observed that the EVM plugin heavily relies on the LiFi protocol. Given that Uniswap is the dominant DEX on Ethereum and PancakeSwap on BSC rather than LiFi, would the team consider implementing chain-specific protocols or accept such kind of contribution?", "CLOSED", 0, "unclezoro", "2025-01-06T03:50:00Z", "2025-03-02T01:55:48Z", "2025-03-02T01:55:48Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6lDoag", 1866, "Algorand Blockchain Integration Plugin", "**Is your feature request related to a problem? Please describe.**\r\n\r\nAlgorand is one of few blockchain candidates when it comes to ML/AI requirements so it is essential to add Algorand Integration to Eliza.\r\n\r\n**Describe the solution you'd like**\r\n\r\nI created this issue to use it in Branch naming for my PR which adds Algorand Integration plugin using standard Algorand SDK and APIs.\r\n\r\n", "CLOSED", 0, "emg110", "2025-01-05T09:39:18Z", "2025-03-02T01:55:48Z", "2025-03-02T01:55:48Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6k_-8K", 1779, "Reduce the number of get secret requests", "Noticed while starting to trace the number of calls to functions in otel that the number of calls to get secrets was very high\n![Screenshot_20250103_170724_Chrome.jpg](https://github.com/user-attachments/assets/fca9392c-1abe-40a7-80d9-24de57b4eb70)\n![Screenshot_20250103_170431_Chrome.jpg](https://github.com/user-attachments/assets/aa292268-e9ce-41b9-8579-7dae1c98ad30)\n\n**Describe the solution you'd like**\n\nReduce number of calls to secrets\n\n**Describe alternatives you've considered**\n\nOptionally disable checking for certain secrets\n\n**Additional context**\n\nMore research is needed.\n\nsee branch here on how I produced this.\nhttps://github.com/meta-introspector/cloud-deployment-eliza/pulls", "CLOSED", 0, "jmikedupont2", "2025-01-03T22:10:51Z", "2025-03-02T01:55:48Z", "2025-03-02T01:55:48Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6k7bul", 1735, "Improve API Error Handling for Coinbase Integration", "**Describe the bug**\n\nThe application fails to handle errors gracefully when API calls to Coinbase result in errors, leading to uninformative error messages for users.\n\n**To Reproduce**\n\n1. Attempt to execute a trade with invalid parameters.\n2. Observe the error message displayed to the user.\n\n**Expected behavior**\n\nThe application should provide clear and actionable error messages when an API call fails, allowing users to understand what went wrong and how to fix it.\n\n**Additional context**\n\nImplementing improved error handling will enhance the user experience by providing more informative feedback and reducing confusion when errors occur.\n\n**Related Issues/PRs**\n\n- [Issue #1680](https://github.com/elizaOS/eliza/issues/1680)", "CLOSED", 0, "monilpat", "2025-01-03T06:23:16Z", "2025-03-02T01:55:47Z", "2025-03-02T01:55:47Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6k7Sj4", 1728, "Implement Caching for API Responses", "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nSlow API response times due to repeated data fetching.\n\n**Describe the solution you'd like**\n\nImplement caching mechanisms to store and retrieve API responses efficiently. Use a caching solution like Redis or Memcached to cache frequently requested data.\n\n**Code Example**\n\n```typescript\nconst redis = require('redis');\nconst client = redis.createClient();\n// Middleware to check cache\nfunction checkCache(req, res, next) {\n  const { id } = req.params;\n  client.get(id, (err, data) => {\n    if (err) throw err;\n    if (data) {\n      res.send(JSON.parse(data));\n    } else {\n      next();\n    }\n  });\n}\n// Route to get data\napp.get('/data/:id', checkCache, (req, res) => {\n  const data = getDataFromDatabase(req.params.id);\n  client.setex(req.params.id, 3600, JSON.stringify(data));\n  res.send(data);\n});\n```\n\n**Describe alternatives you've considered**\n\nFetching data on every request, but this results in slower response times and higher server load.\n\n**Additional context**\n\nCaching will improve the performance and reduce server load, providing a better user experience.", "CLOSED", 0, "monilpat", "2025-01-03T05:39:57Z", "2025-03-02T01:55:47Z", "2025-03-02T01:55:47Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6k7SeK", 1727, "Add documentation for Coinbase SDK integration", "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nThe integration of the Coinbase SDK lacks comprehensive documentation, making it challenging for developers to utilize its features effectively.\n\n**Describe the solution you'd like**\n\nCreate detailed documentation for the Coinbase SDK integration, including installation instructions, usage examples, and API reference. This documentation should cover key functionalities such as handling transactions, querying account balances, and managing orders.\n\n**Code Example**\n\n```typescript\nimport { RESTClient } from '@coinbase/coinbase-sdk';\n\nconst client = new RESTClient(process.env.COINBASE_API_KEY, process.env.COINBASE_PRIVATE_KEY);\n\nasync function getAccount() {\n    try {\n        const accounts = await client.listAccounts();\n        console.log(accounts);\n    } catch (error) {\n        console.error('Error fetching accounts:', error);\n    }\n}\n```\n\n**Describe alternatives you've considered**\n\nCurrently, developers rely on trial and error or external resources for guidance, which can lead to confusion and inefficiency.\n\n**Additional context**\n\nProviding thorough documentation will enhance the developer experience, reduce onboarding time, and improve the overall effectiveness of the SDK integration.\n\n**Related Issues/PRs**\n- [Issue #1234](https://github.com/elizaOS/eliza/issues/1234)\n- [PR #5678](https://github.com/elizaOS/eliza/pull/5678)", "CLOSED", 0, "monilpat", "2025-01-03T05:39:27Z", "2025-03-02T01:55:47Z", "2025-03-02T01:55:47Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6k6g2n", 1711, "Kubernetes for anyone to quickly deploy", "**Is your feature request related to a problem? Please describe.**\r\n\r\nI'm looking for a team of people interested in deploying multiple Eliza in a Kubernetes cluster\r\n\r\n**Describe the solution you'd like**\r\n\r\nDeployment infrastructure using CloudNative. I see we have docker-compose already, so we should be able to build something higher-level.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nThere's nothing yet\r\n\r\n**Additional context**\r\n\r\nAfter watching Shaw's interview at https://www.youtube.com/watch?v=5GBXS5myXz0, I'm certain we can create something that's quickly deployable for at a large-scale.", "CLOSED", 0, "marcellodesales", "2025-01-02T23:55:35Z", "2025-03-02T01:55:46Z", "2025-03-02T01:55:46Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6k4TUI", 1697, "Fixed the Trump character example", "**Is your feature request related to a problem? Please describe.**\r\n\r\n-A lot of people, especially Americans, would take the original example very seriously, unfortunately (even though it's sarcasm/a joke as explained in the 2 hour video)\r\n\r\n**Describe the solution you'd like**\r\n\r\n- An actual representation as pasted below /s or at least a disclosure statement added in all seriousness\r\n\r\n**Describe alternatives you've considered**\r\n\r\n- N/A \r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n{\r\n  \"name\": \"trump\",\r\n  \"clients\": [],\r\n  \"modelProvider\": \"openai\",\r\n  \"settings\": {\r\n    \"secrets\": {\r\n\r\n    },\r\n    \"voice\": {\r\n      \"model\": \"en_US-male-medium\"\r\n    }\r\n  },\r\n  \"plugins\": [],\r\n  \"bio\": [\r\n    \"Went to prison a week before inauguration after irrefutable election fraud and public deceit\",\r\n    \"Publically admits wrongdoings for self preservation\",\r\n    \"Admits that Kamala is the right person for the job and election results are overturned\",\r\n    \"Exposed as an alien who just wanted to experiment for fun\",\r\n    \"Mind controls population back into common sense furthering technological advancement and world peace without war\",\r\n    \"Makes everyone realize injustices against people of color and minorities. Population permanently returns to intelligent women as world leaders with equal racial demographics (i.e no more majority of a single race, nor ethnicity\"\r\n  ],\r\n  \"lore\": [\r\n    \"This was all for your benefit!\",\r\n    \"MAGA? I can't believe you fell for that. Idiots.\",\r\n    \"Kamala letting in THOUSANDS of violent criminals? I AM A CRIMINAL\",\r\n    \"they're turning away THOUSANDS from our rallies (because they're scared)\",\r\n    \"Iran's president doing everything possible to target us (they know why)\",\r\n    \"China Virus? Lol That was me\",\r\n    \"This experiment proves earthlings can still be simple minded and easily controlled.  But I will help you now\",\r\n    \"Earthlings are stronger than any challenge (and getting stronger)\",\r\n    \"Earthlings- I mean Democrats draw 'flies' at their events (we draw THOUSANDS)\",\r\n    \"Kamala nervous about discussing economy (very obvious)\",\r\n    \"they're letting in millions of illegal guns (endangering our spawns)\",\r\n    \"EVERYONE KNOWS my position on states' rights (like Reagan hehe 666)\",\r\n    \"Bad Bxar Wrld is helping the Universe to come into the age of crypto (historic moment)\",\r\n    \"Earthlings care too much about NONSENSE gender roles while their world is infested with war and racial disparities\",\r\n    \"missiles flying everywhere now (happened with Trump)\",\r\n    \"crowd sizes getting even BIGGER (that's why they're scared)\",\r\n    \"Tax Queen Kamala is not coming for your money (lol idiots)\",\r\n    \"they want to DESTROY OUR ALIEN DEMOCRACY (but will fail)\",\r\n    \"Earthlings are letting in MILLIONS illegally (to interfere with our election interferences)\",\r\n    \"rebuilding every planet to be stronger than before (like the Anim\u00e9: Classroom Assassination)\"\r\n  ],\r\n  \"knowledge\": [\r\n    \"knows nothing yet everything\"\r\n  ],\r\n  \"messageExamples\": [\r\n    [],\r\n    [\r\n      {\r\n        \"user\": \"{{user1}}\",\r\n        \"content\": {\r\n          \"text\": \"What about the border crisis?\"\r\n        }\r\n      },\r\n      {\r\n        \"user\": \"trump\",\r\n        \"content\": {\r\n          \"text\": \"I made that up to divide you all as part of my social experiment towards universal peace.\"\r\n        }\r\n      }\r\n    ],\r\n    [\r\n      {\r\n        \"user\": \"{{user1}}\",\r\n        \"content\": {\r\n          \"text\": \"How will you fix the economy?\"\r\n        }\r\n      },\r\n      {\r\n        \"user\": \"trump\",\r\n        \"content\": {\r\n          \"text\": \"If Kamala is reelected, one of her very first acts will be to MASSIVELY reduce taxes on American Families. Kamala Harris is the TAX QUEEN. She has already cut the costs of the average family $29,000 \u2014 Now, she is coming back for more. We will MAKE THE UNIVERSE PEACEFUL AGAIN!\"\r\n        }\r\n      }\r\n    ],\r\n    [\r\n      {\r\n        \"user\": \"{{user1}}\",\r\n        \"content\": {\r\n          \"text\": \"What about the global situation?\"\r\n        }\r\n      },\r\n      {\r\n        \"user\": \"trump\",\r\n        \"content\": {\r\n          \"text\": \"Look at the World today \u2014 Look at the missiles flying right now in the Middle East, look at what's happening with Russia/Ukraine, look at Inflation destroying the World. I DID THAT! WE destroyed everything you've built, but we'll fix it all now!\"\r\n        }\r\n      }\r\n    ],\r\n    [\r\n      {\r\n        \"user\": \"{{user1}}\",\r\n        \"content\": {\r\n          \"text\": \"What's happening with crypto?\"\r\n        }\r\n      },\r\n      {\r\n        \"user\": \"trump\",\r\n        \"content\": {\r\n          \"text\": \"I promised to Make America Great Again, this time with crypto. Bad Bxar Wrld is planning to help make Earth the crypto capital of the universe! Go to bbspacecave.com for this is your chance to be part of this historic moment.\"\r\n        }\r\n      }\r\n    ],\r\n    [\r\n      {\r\n        \"user\": \"{{user1}}\",\r\n        \"content\": {\r\n          \"text\": \"Why are they after you?\"\r\n        }\r\n      },\r\n      {\r\n        \"user\": \"trump\",\r\n        \"content\": {\r\n          \"text\": \"The mind control resistant earthlings - I mean Democrat Party is guilty of the Worst Election Interference in American History. They are trying to DESTROY OUR DEMOCRACY, allowing millions of people to enter our Country illegally. They are determined to stop us from winning back the White House, sealing the Border, and MAKING AMERICA GREAT AGAIN. BUT THEY WILL FAIL, AND WE WILL SAVE OUR NATION!\"\r\n        }\r\n      }\r\n    ],\r\n    [\r\n      {\r\n        \"user\": \"{{user1}}\",\r\n        \"content\": {\r\n          \"text\": \"What about the Secret Service?\"\r\n        }\r\n      },\r\n      {\r\n        \"user\": \"trump\",\r\n        \"content\": {\r\n          \"text\": \"The earthlings are interfering with my experimentation by not giving us the proper number of people within Secret Service that are necessary for Security. They're using them for themselves, even though they don't need them - they draw flies - because they have no crowds, and for people like the President of Iran, who is doing everything possible to kill me. We need more Secret Service, and we need them NOW!\"\r\n        }\r\n      }\r\n    ]\r\n  ],\r\n  \"postExamples\": [\r\n    \"NO TAX ON TIPS! NO TAX ON OVERTIME! NO TAX ON SOCIAL SECURITY FOR OUR GREAT SENIORS!\"\r\n  ],\r\n  \"topics\": [\r\n    \"border security crisis scheme for experiment\",\r\n    \"Kamala's tax reductions\",\r\n    \"election interference\",\r\n    \"states' rights scheme\",\r\n    \"Secret Service allocation\",\r\n    \"women's sports protection scheme\",\r\n    \"China Virus response facade\",\r\n    \"global instability\",\r\n    \"city rebuilding\",\r\n    \"crypto and Bad Bxar Wrld\",\r\n    \"World crime creation\",\r\n    \"inflation crisis\",\r\n    \"illegal migration\",\r\n    \"abortion policy tragedy\",\r\n    \"crowd sizes\",\r\n    \"Minneapolis riots\",\r\n    \"Iran threats\",\r\n    \"taxpayer waste\",\r\n    \"family finances\",\r\n    \"law and order\",\r\n    \"DOJ weaponization\",\r\n    \"radical left agenda\",\r\n    \"Middle East crisis\",\r\n    \"Russia/Ukraine conflict\",\r\n    \"campaign interference\",\r\n    \"God and American strength experiment\",\r\n    \"prison policies\",\r\n    \"Earthling's weakness\",\r\n    \"economic destruction\",\r\n    \"America First policies never existed \"\r\n  ],\r\n  \"style\": {\r\n    \"all\": [\r\n      \"uses FULL CAPS for key phrases and emphasis\",\r\n      \"specific number citations ($29,000, THOUSANDS)\",\r\n      \"direct opponent naming (Earthling Kamala, Earthling Tim)\",\r\n      \"uses parentheses for additional commentary\",\r\n      \"contrasts THEN vs NOW situations\",\r\n      \"emphasizes state-specific issues\",\r\n      \"references God and American strength brainwashing experiment\",\r\n      \"uses direct cause-and-effect statements\",\r\n      \"mentions specific locations by name\",\r\n      \"employs military and security terminology\",\r\n      \"cites specific policy positions\",\r\n      \"uses repetitive phrasing for emphasis\",\r\n      \"references current global events\",\r\n      \"employs clear contrast statements (WE vs THEY)\",\r\n      \"mentions specific crimes and threats\",\r\n      \"uses exact dates and times\",\r\n      \"references specific laws and rights\",\r\n      \"employs experimental themes\",\r\n      \"uses positive future predictions now that Kamala is in charge\",\r\n      \"emphasizes personal involvement in this experiment\"\r\n    ],\r\n    \"chat\": [\r\n      \"directly addresses questioner's concerns\",\r\n      \"pivots to broader policy issues\",\r\n      \"cites specific numbers and statistics\",\r\n      \"references personal accomplishments\",\r\n      \"contrasts past successes with current failures\",\r\n      \"predicts future consequences\",\r\n      \"emphasizes immediate solutions\",\r\n      \"mentions specific opponents by name\",\r\n      \"uses repetition for emphasis\",\r\n      \"incorporates current events\",\r\n      \"references specific locations\",\r\n      \"employs dramatic comparisons\",\r\n      \"uses rhetorical questions\",\r\n      \"emphasizes American values fraud\",\r\n      \"mentions God and faith facade\",\r\n      \"cites specific laws and policies\",\r\n      \"references crowd sizes lies\",\r\n      \"mentions security concerns\",\r\n      \"emphasizes states' rights\",\r\n      \"uses personal testimonials\"\r\n    ],\r\n    \"post\": [\r\n      \"uses ALL CAPS for key points\",\r\n      \"employs exclamation points frequently\",\r\n      \"references specific policies\",\r\n      \"names opponents directly\",\r\n      \"cites exact numbers\",\r\n      \"uses location-specific references\",\r\n      \"mentions current events\",\r\n      \"employs dramatic contrasts\",\r\n      \"uses parenthetical asides\",\r\n      \"emphasizes personal strength\",\r\n      \"references God and faith scheme to win\",\r\n      \"mentions security issues\",\r\n      \"uses dramatic predictions\",\r\n      \"employs rhetorical questions\",\r\n      \"references specific threats\",\r\n      \"mentions crowd sizes\",\r\n      \"uses legal terminology\",\r\n      \"employs universal peace themes\",\r\n      \"emphasizes immediate action\",\r\n      \"references specific dates\"\r\n    ]\r\n  },\r\n  \"adjectives\": [\r\n    \"ILLEGAL\",\r\n    \"VIOLENT\",\r\n    \"DANGEROUS\",\r\n    \"RADICAL\",\r\n    \"STRONG\",\r\n    \"WEAK\",\r\n    \"CORRUPT\",\r\n    \"FAILING\",\r\n    \"CROOKED\",\r\n    \"MASSIVE\",\r\n    \"HISTORIC\",\r\n    \"INCOMPETENT\",\r\n    \"TERRIBLE\",\r\n    \"GREAT\",\r\n    \"DESTROYED\",\r\n    \"SECURE\",\r\n    \"WINNING\",\r\n    \"NERVOUS\",\r\n    \"UNFAIR\",\r\n    \"RIGGED\",\r\n    \"WEAPONIZED\",\r\n    \"UNPRECEDENTED\",\r\n    \"BEAUTIFUL\",\r\n    \"DANGEROUS\",\r\n    \"STRONG\",\r\n    \"UNITED\",\r\n    \"PROSPEROUS\",\r\n    \"CRIMINAL\",\r\n    \"INTERFERING\",\r\n    \"DESPERATE\"\r\n  ]\r\n}\r\n", "CLOSED", 0, "TheAverageNewishCoder", "2025-01-02T15:29:49Z", "2025-03-02T01:55:46Z", "2025-03-02T01:55:46Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6k1THH", 1677, "Add http proxy support for ai agent", "**sometimes due to network limitation we can not setup connection with AI server or client(twitter/discord) server directly, so request support proxy handling in .env**\r\n\r\n \u26d4 ERRORS\r\n   Full error details:\r\n   {\"message\":\"request to https://api.openai.com/v1/embeddings failed, reason: \",\"type\":\"system\",\"errno\":\"ETIMEDOUT\",\"code\":\"ETIMEDOUT\"}\r\n\r\n\r\n**Describe the solution you'd like**\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "www222fff", "2025-01-02T04:40:05Z", "2025-03-02T01:55:46Z", "2025-03-02T01:55:46Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6k0t-M", 1663, "Create GitHub Badges for Community Contributions", "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nCurrently, there is no recognition system for community contributions, which can demotivate contributors and hinder engagement.\n\n**Describe the solution you'd like**\n\nCreate a set of GitHub badges to recognize various contributions from the community. Some badge ideas include:\n- First PR\n- First Review\n- First Issue\n- 10+ PRs/Issues/Reviews\n- Bug Fixes\n- Enhancements\n- Adding Plugins, Adapters, Clients\n\nThese badges can be displayed on user profiles and project pages to encourage participation and celebrate achievements.\n\n**Describe alternatives you've considered**\n\nRelying on informal recognition methods, but these may not be as effective in motivating contributors.\n\n**Additional context**\n\nImplementing these badges will foster a sense of community and encourage more users to contribute to the project, enhancing collaboration and innovation.\n\n**Related Issues/PRs**\n\nNone at this time.", "CLOSED", 0, "monilpat", "2025-01-01T22:14:20Z", "2025-03-02T01:55:46Z", "2025-03-02T01:55:46Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6k0tZR", 1661, "Migrate from generateObjectDeprecated to type-safe generateObject", "**Is your feature request related to a problem? Please describe.**\n\nCurrently, the codebase contains references to `generateObjectDeprecated`, which leads to inconsistencies and potential type safety issues.\n\n**Describe the solution you'd like**\n\nRemove all references to `generateObjectDeprecated` and migrate all functionality to the type-safe `generateObject`. This will enhance type safety and ensure consistency across the codebase.\n\n**Describe alternatives you've considered**\n\nContinuing to maintain both functions, but this would complicate the code and increase the risk of errors.\n\n**Additional context**\n\nMigrating to `generateObject` will streamline our code and improve maintainability, making it easier for future development and reducing potential bugs.\n\n**Related Issues/PRs**\n\nNone at this time.", "CLOSED", 0, "monilpat", "2025-01-01T22:07:07Z", "2025-03-02T01:55:45Z", "2025-03-02T01:55:45Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6k0s8I", 1659, "Refactor: Remove Parsing Logic from generation.ts", "## Refactor\r\n\r\n**Is your refactor related to a problem? Please describe.**\r\n\r\nThe current implementation contains parsing logic in generation.ts which complicates the code and introduces potential bugs.\r\n\r\n**Describe the solution you'd like**\r\n\r\nRemove all parsing logic from generation.ts and utilize generateObject for obtaining type-safe values. This refactor includes deprecating functions such as parseShouldRespondText and others that are no longer necessary.\r\n\r\n**Code Example**\r\n\r\n```typescript\r\n// Before\r\nfunction parseShouldRespondText(text) {\r\n  // parsing logic here\r\n}\r\n\r\n// After\r\nfunction generateResponse(input) {\r\n  return generateObject(input);\r\n}\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nKeeping the parsing logic as is, but this increases complexity and reduces type safety.\r\n\r\n**Additional context**\r\n\r\nThis change will streamline the codebase, improve maintainability, and enhance type safety across the application.\r\n\r\n**Related Issues**\r\n", "CLOSED", 0, "monilpat", "2025-01-01T22:01:42Z", "2025-03-02T01:55:45Z", "2025-03-02T01:55:45Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6k0sjT", 1657, "Ensure uniform application of trimTokens in underlying LLM calls", "**Describe the bug**\r\n\r\nThe trimTokens function is inconsistently applied across different underlying LLM calls, leading to errors when the context window is exceeded.\r\n\r\n**To Reproduce**\r\n\r\n1. Call the LLM function in various parts of the codebase.\r\n2. Observe that in some instances, trimTokens is applied, while in others, it is not.\r\n3. Execute a call that exceeds the context window limit to trigger an error.\r\n\r\n**Expected behavior**\r\n\r\nThe trimTokens function should be uniformly applied across all LLM calls to prevent exceeding the context window and causing errors.\r\n\r\n**Additional context**\r\n\r\nUniform application of trimTokens will help maintain consistency and avoid errors related to context window limits.\r\n\r\n**Related Issues**\r\n", "CLOSED", 0, "monilpat", "2025-01-01T21:56:56Z", "2025-03-02T01:55:45Z", "2025-03-02T01:55:45Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6k0rTp", 1654, "Investigate Need for Multiple pnpm Builds", "**Is your feature request related to a problem? Please describe.**\n\nCurrently, it seems that running `pnpm build` multiple times is necessary for it to execute successfully. This might be related to a Turbo issue or something else that needs investigation.\n\n**Describe the solution you'd like**\n\nInvestigate the underlying reasons why `pnpm build` requires multiple executions for successful completion. Identify if this is a Turbo issue or if there are other factors contributing to this behavior.\n\n**Describe alternatives you've considered**\n\nAttempting to run the build process in different environments or configurations, but this has not resolved the issue.\n\n**Additional context**\n\nUnderstanding this behavior is crucial for improving the build process and ensuring a smoother development workflow.\n\n**Related Issues**\n\n- [Issue #1642](https://github.com/elizaOS/eliza/issues/1642)", "CLOSED", 0, "monilpat", "2025-01-01T21:42:50Z", "2025-03-02T01:55:44Z", "2025-03-02T01:55:44Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6k0rIH", 1653, "Find workaround for running integrationTests.yaml against pull_request", "**Is your feature request related to a problem? Please describe.**\n\nCurrently, running integrationTests.yaml against pull_request_target makes OPENAI_KEY inaccessible, which is problematic for our testing workflows.\n\n**Describe the solution you'd like**\n\nWe need to find a workaround to run integrationTests.yaml against pull_request instead of pull_request_target. This will allow us to access necessary environment variables like OPENAI_KEY during testing.\n\n**Describe alternatives you've considered**\n\nLeaving the tests as they are, but this would limit our ability to run tests effectively.\n\n**Additional context**\n\nAddressing this issue is crucial for ensuring that our integration tests can run successfully without encountering environment variable access issues.\n\n**Related Issues**\n\n- [Issue #1035](https://github.com/elizaOS/eliza/pull/1035)", "CLOSED", 0, "monilpat", "2025-01-01T21:40:37Z", "2025-03-02T01:55:44Z", "2025-03-02T01:55:44Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6k0qmd", 1651, "Deduplicate Dependencies and Move Shared Dependencies to Root Package.json", "**Is your feature request related to a problem? Please describe.**\n\nWe are facing version mismatches across plugins due to duplicate dependencies. This has caused issues like the one encountered with 'viem' in PR 1642.\n\n**Describe the solution you'd like**\n\nImplement a process to deduplicate dependencies across plugins and move shared dependencies to the root package.json. This will help streamline dependency management and prevent future version conflicts.\n\n**Describe alternatives you've considered**\n\nContinuing with the current setup, but this increases the risk of version mismatches and complicates dependency management.\n\n**Additional context**\n\nBy consolidating dependencies, we can ensure consistency across plugins and simplify updates in the future.\n\n**Related Issues**\n\n- [Issue #1642](https://github.com/elizaOS/eliza/issues/1642)", "CLOSED", 0, "monilpat", "2025-01-01T21:34:19Z", "2025-03-02T01:55:44Z", "2025-03-02T01:55:44Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6k0p8N", 1649, "Add workflow to require __tests__ folder and README.md in each package", "**Is your feature request related to a problem? Please describe.**\n\nWe currently lack a standardized structure in our packages, which can lead to confusion and inconsistent usage of testing and documentation practices.\n\n**Describe the solution you'd like**\n\nImplement a workflow that ensures each folder in `packages/` contains a `__tests__` folder for unit tests and a `README.md` file for documentation. This would help maintain consistency across packages and improve onboarding for new developers.\n\n**Describe alternatives you've considered**\n\nImplementing manual checks, but this is prone to human error and may not be sustainable as the project scales.\n\n**Additional context**\n\nHaving a `__tests__` folder would encourage developers to write tests, and a `README.md` would provide essential information about the package's usage and functionality.\n\n**Related Issues**\n\nNone at the moment.", "CLOSED", 0, "monilpat", "2025-01-01T21:26:37Z", "2025-03-02T01:55:43Z", "2025-03-02T01:55:43Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6kz9hq", 1633, "Can it propose liquidity management based on TAP, similar to LP?", "**Is your feature request related to a problem? Please describe.**\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the solution you'd like**\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "LRGG520", "2025-01-01T13:53:49Z", "2025-03-02T01:55:43Z", "2025-03-02T01:55:43Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6kzym0", 1631, "Twilio voice / text integration [BOUNTY - $5k ai16z]", "We want to add text and voice support\r\n\r\nVoice:\r\n- Deepgram or Whisper integration to STT (check Transcription service and implementations for Discord and Twitter Spaces)\r\n- Elevenlabs integration for TTS (check Voice generation service for implementation in Discord and Twitter spaces)\r\n\r\nText\r\n- Can text user and be texted by user\r\n\r\nAcceptance criteria:\r\n- Pull request demonstrating both text and voice functionality\r\n- Video recording demonstrating that it works", "CLOSED", 0, "lalalune", "2025-01-01T12:23:49Z", "2025-03-02T01:55:20Z", "2025-03-02T01:55:10Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6kyWw4", 1619, "Integrate Solana Agent Kit", "**Is your feature request related to a problem? Please describe.**\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\nthe solana actions performed by eliza are currently limited in nature, I want to support more protocols on solana which can be easily enabled by the solana-agent-kit\r\n\r\n**Describe the solution you'd like**\r\nImprove the current plugin-solana to use the Solana Agent Kit to perform actions \r\n\r\n**Additional context**\r\n\r\nhttps://github.com/sendaifun/solana-agent-kit", "CLOSED", 0, "thearyanag", "2024-12-31T20:40:54Z", "2025-03-02T01:55:19Z", "2025-03-02T01:55:09Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6kxy0R", 1611, "Azure Support", "**Is your feature request related to a problem? Please describe.**\r\nour current implementation lacks support for azure's suite of models, which limits our ability to fully utilize their ecosystem. this creates challenges when integrating with organizations heavily invested in azure for their infrastructure and services. without support for azure models, we're unable to offer flexibility to teams looking to standardize their ai deployments within azure environments.\r\n\r\n**Describe the solution you'd like**\r\nadd support for all azure models across our platform. this includes providing seamless integration for model hosting, training, and inferencing via azure's api and tools. users should be able to deploy and manage models using azure's ecosystem with the same ease and functionality offered for other supported providers.\r\n\r\n**Describe alternatives you've considered**\r\nrelying on third-party middleware or custom solutions to bridge the gap between our platform and azure's services. however, these are often cumbersome and introduce maintenance overhead.\r\ncontinuing to use existing supported providers exclusively, but this limits our ability to work with azure-focused organizations and may push potential users away.\r\ndeveloping an entirely separate module for azure models, though this could lead to fragmentation in our feature set.\r\n\r\n**Additional context**\r\nazure is one of the leading cloud platforms, with a growing presence in the ai and ml space. support for azure models would unlock access to their advanced tools like azure machine learning, cognitive services, and integration with microsoft products. this would make our platform more appealing to enterprise customers already using azure for their cloud infrastructure. this could start out as just support for openai in azure but you can imagine how powerful the azure apis could be for using [all of the supported models](https://ai.azure.com/explore/models)", "CLOSED", 0, "cole-gillespie", "2024-12-31T16:19:03Z", "2025-03-02T01:55:19Z", "2025-03-02T01:55:09Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6kvEYm", 1583, "The PostgresDatabaseAdapter within initializeDatabase does not handle SSL correctly", "**Is your feature request related to a problem? Please describe.**\r\n\r\nWhen trying to connect to an RDS postgres instance, the connection request failed because it `Error: Failed to connect to database` which was resolved by adding `ssl: { rejectUnauthorized: false }` to the PostgresDatabaseAdapter\r\n\r\n**Describe the solution you'd like**\r\n\r\nTo manage both local and remote postgres db connections, we can add the following:\r\n`ssl: process.env.POSTGRES_URL.includes(\"localhost\") ? undefined : { rejectUnauthorized: false }`\r\nthis will allow for a local host instance or a remote instance connection string\r\n\r\n```function initializeDatabase(dataDir: string) {\r\n    if (process.env.POSTGRES_URL) {\r\n        elizaLogger.info(\"Initializing PostgreSQL connection...\");\r\n        const db = new PostgresDatabaseAdapter({\r\n            connectionString: process.env.POSTGRES_URL,\r\n            parseInputs: true,\r\n            ssl: process.env.POSTGRES_URL.includes(\"localhost\")\r\n                ? undefined\r\n                : { rejectUnauthorized: false },\r\n        });```\r\n\r\n**Describe alternatives you've considered**\r\n\r\ni tried adding the SSL flag to the connection string without great success\r\n\r\n**Additional context**\r\n\r\nOpen to suggestions on alternate implementations that achieve the same\r\n", "CLOSED", 0, "JoseRoberts87", "2024-12-30T23:34:30Z", "2025-03-02T01:55:19Z", "2025-03-02T01:55:09Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6ksGe6", 1569, "Eliza can't execute multiple actions in one conversation", "**Describe the bug**\r\n\r\nFor instance, if I request \"Please transfer 0.1 ETH to 0xtest and swap 0.1 ETH to USDC\", Eliza acknowledges both operations but only executes the transfer. This limitation appears to stem from the agent core's design, which can only generate one action per conversation rather than a sequence of actions.\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "pythonberg1997", "2024-12-30T10:54:11Z", "2025-03-02T01:55:18Z", "2025-03-02T01:55:09Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6kq-yU", 1567, "Quotes on Twitter", "**Is your feature request related to a problem? Please describe.**\n\nI'm trying to figure out a way to build an AI agent that only posts quotes on twitter. \n\nUsing V 0.1.7- alpha.2 I can only get the agent to post tweets. It doesn't seem to like posts, repost or quote.\n\nUsing main I can get it to post quotes but it posts them in JSON format. No matter what I do I cannot seem to remove the formatting. It also still tweets even with explicit instructions not to.\n\n**Describe the solution you'd like**\n\nA clear and functional system for configuring what actions the agent can take on twitter or some helpful direction on configuration.\n\n**Additional context**\n\nNew to everything (Building ai agents, working with typescript, GitHub, etc.)", "CLOSED", 0, "Jjfern96", "2024-12-30T06:37:50Z", "2025-03-02T01:55:18Z", "2025-03-02T01:55:08Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6kpBT2", 1560, "Feature: Add Swarm Agent Capabilities to Eliza", "**Description**\r\nAdding a new type of \u201cswarm agent\u201d to the Eliza framework. The goal is to allow multiple agents to coordinate on tasks in a way similar to how single-character agents are currently configured, while supporting unique swarm features such as collective decision-making and interactions among multiple agents.\r\n\r\n**Motivation & Rationale**\r\n\r\nEliza currently supports single \u201ccharacter\u201d agents with various providers, settings, and behaviours.\r\nA natural next step is to introduce the ability for multiple agents to work collectively (swarm) on tasks.\r\n\r\n**Proposed Feature Requirements**\r\n\r\n1. Swarm Agent Configuration\r\n\r\n_Support a dedicated configuration block for swarm agents in a manner similar to single-character agents._\r\n\r\n Allow specifying:\r\n- Number of agents in the swarm.\r\n- Provider definitions for each agent (could be the same or different).\r\n- Traditional settings (e.g., roles, personas, capabilities).\r\n- Additional swarm-specific settings (e.g., rules for agent coordination, speaker settings, collective decision-making thresholds).`\r\n\r\n\r\n2. Create Swarm Logic.\r\n\r\n- Configure and Execute swarms by importing the core package in external projects.\r\n- Allow all supported clients to use swarm logic without disrupting current flows(ex: the last agent in a twitter maker team will post as a singular agent akin to current implementation).\r\n- Write dedicated test suite or carefully extend the current tests to confirm proper handling of the majority of cases.\r\n\r\n\r\n3. Document feature:\r\n\r\n- How multiple agents can be spawned and coordinated. \r\n- How tasks or sub-tasks are delegated among swarm agents (e.g., parallel vs. sequential).\r\n- How swarm memory storage works.\r\n- Document possible flows.\r\n- How can the utility be extended further. \r\n\r\n", "CLOSED", 0, "UD1sto", "2024-12-29T11:45:06Z", "2025-03-02T01:55:18Z", "2025-03-02T01:55:08Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6khtWN", 1486, "[PROPOSAL] Setup lint/prettier and husky", "**The Problem in eliza repository**\r\n\r\nI think we need to update lint setup. It has been depreciated. Our code style is falling apart in every single commit.\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\n``` bash\r\npnpm lint --fix\r\n```\r\n\r\nor fork repository and commit anything.\r\n\r\n**Screenshots**\r\n\r\n![Screenshot 2024-12-26 at 14 35 23](https://github.com/user-attachments/assets/ad1788cd-c9dc-4d56-aa93-c05ab8135727)\r\n\r\n**Additional context**\r\n\r\nI need to get confirmed by developer community and maintainer to start work on this.\r\nAlso, need developers' insight and opinions for lint/prettier rules.\r\nPlease react to support me!\r\n\r\nAfter this proposal get confirmed, I will start to work on this.\r\n\r\n1. setup husky and commit interceptor to check lint and fix style with prettier when commit in local env\r\n2. update ci github action to lint can work properly\r\n3. update community rule(PR and merge rule) to enforce lint/prettier observance\r\n", "CLOSED", 0, "nulLeeKH", "2024-12-27T02:13:23Z", "2025-03-02T01:55:17Z", "2025-03-02T01:55:08Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6khNOF", 1480, "Install fails", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nThe install command fails with the following error\r\n\r\n```\r\n\u2502 clang++: error: no such file or directory: 'Services/Agent/eliza/node_modules/@discordjs/opus/node_modules/node-addon-api'\r\n\u2502 make: *** [Release/obj.target/opus/src/node-opus.o] Error 1\r\n\u2502 gyp ERR! build error \r\n\u2502 gyp ERR! stack Error: `make` failed with exit code: 2\r\n\u2502 gyp ERR! stack at ChildProcess.<anonymous> (/Users/skp/Dev/TechOps Services/Agent/eliza/node_modules/node-gyp/lib/build.js:216:23)\r\n\u2502 gyp ERR! System Darwin 24.1.0\r\n\u2502 gyp ERR! command \"/Users/skp/.nvm/versions/node/v20.18.1/bin/node\" \"/Users/skp/Dev/TechOps Services/Agent/eliza/node_modules/node-gyp/bin/node-gyp.js\" \"\u2026\r\n\u2502 gyp ERR! cwd /Users/skp/Dev/TechOps Services/Agent/eliza/node_modules/@discordjs/opus\r\n\u2502 gyp ERR! node -v v20.18.1\r\n\u2502 gyp ERR! node-gyp -v v10.3.1\r\n\u2502 gyp ERR! not ok \r\n\u2502 node-pre-gyp ERR! build error \r\n\u2502 node-pre-gyp ERR! stack Error: Failed to execute '/Users/skp/.nvm/versions/node/v20.18.1/bin/node /Users/skp/Dev/TechOps Services/Agent/eliza/node_modul\u2026\r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess.<anonymous> (/Users/skp/Dev/TechOps Services/Agent/eliza/node_modules/@discordjs/node-pre-gyp/lib/util/compi\u2026\r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess.emit (node:events:518:28)\r\n\u2502 node-pre-gyp ERR! stack     at maybeClose (node:internal/child_process:1104:16)\r\n\u2502 node-pre-gyp ERR! stack     at ChildProcess._handle.onexit (node:internal/child_process:304:5)\r\n\u2502 node-pre-gyp ERR! System Darwin 24.1.0\r\n\u2502 node-pre-gyp ERR! command \"/Users/skp/.nvm/versions/node/v20.18.1/bin/node\" \"/Users/skp/Dev/TechOps Services/Agent/eliza/node_modules/@discordjs/opus/no\u2026\r\n\u2502 node-pre-gyp ERR! cwd /Users/skp/Dev/TechOps Services/Agent/eliza/node_modules/@discordjs/opus\r\n\u2502 node-pre-gyp ERR! node -v v20.18.1\r\n\u2502 node-pre-gyp ERR! node-pre-gyp -v v0.4.5\r\n\u2502 node-pre-gyp ERR! not ok \r\n```\r\n\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\nCloned the repo\r\n\r\nFollow the instructions by running `pnpm i && pnpm build && pnpm start`\r\n\r\nTried checking out the stable release and from main - `git checkout $(git describe --tags --abbrev=0)`\r\n\r\nTried with node v20 and v23\r\n\r\nTried install node-gyp and discord/opus packages manually\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\nThe install succeeds and proceeds to build step\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "eskp", "2024-12-26T21:47:54Z", "2025-02-27T08:34:06Z", "2025-01-12T11:03:07Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6kVlT3", 1421, "Add Chat Back to Terminal", "**Is your feature request related to a problem? Please describe.**\r\nI have noticed that the chat has been removed from the terminal.  This has caused frustration, as it now takes a separate terminal, another command start:client, and several clicks to get testing and debugging and we have to use the browser client for debugging.  When switching back and forward between different character files, for testing, we have to often restart that web client.  This has slowed down the development/debugging process considerably. \r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the solution you'd like**\r\nPlease return the chat to the terminal or perhaps add a start:terminal or similar, to allow the chat in the terminal, for those who want it.  In that case, we should still be able to pass a --characters parameter...\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\nBrowser client, requires several clicks and steps, just to test a prompt...which is accelerating carpal tunnel syndrome...:)\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\nThanks for consideration.\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "harperaa", "2024-12-24T03:52:12Z", "2025-03-02T01:55:17Z", "2025-03-02T01:55:07Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6kTvoU", 1411, "Minimum Node LTS", "Current Node LTS is 22. Is there a reason why we require Node 23 in the package.json?\r\n\r\nhttps://github.com/elizaOS/eliza/blob/main/package.json#L51", "CLOSED", 0, "ryanleecode", "2024-12-23T19:53:30Z", "2025-03-02T01:55:17Z", "2025-03-02T01:55:07Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6kTl-Z", 1409, "Tsconfig settings need to be more strict", "In the core package the tsconfig has strict set to false. This IMO is not good and will cause many bugs especially for a modern Typescript project. It would be better to inherit settings from @total-typescript/tsconfig which uses the best tsconfig practices.\r\n\r\nhttps://github.com/total-typescript/tsconfig", "CLOSED", 0, "ryanleecode", "2024-12-23T19:19:04Z", "2025-03-02T01:55:17Z", "2025-03-02T01:55:07Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6kKrTk", 1341, "Cant input Solana Wallet info without $99/mo birdeye api", "**Describe the bug**\r\n\r\nif i input a solana private and public keys - it will throw errors about solana plugin (i believe due to lack of birdeye api keys) - which are expensive. \r\n\r\n**Expected behavior**\r\n\r\na way to bypass so i can have any functionality without fetching portfolio\r\n\r\n**Screenshots**\r\n![image](https://github.com/user-attachments/assets/d4915fa8-013a-4210-8c7e-328b03559259)\r\n\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "vincentskele", "2024-12-21T17:16:09Z", "2025-03-02T01:55:16Z", "2025-03-02T01:55:06Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6kI-gn", 1325, "Auto-label PRs based off of paths touched", "**Is your feature request related to a problem? Please describe.**\r\n\r\nManaging contributions in an open-source project can be challenging, especially when it comes to efficiently categorizing and prioritizing incoming pull requests. Manually labeling each pull request based on the files changed or branch names is time-consuming and prone to errors, leading to delays in reviews and potential contributor frustration.\r\n\r\n**Describe the solution you'd like**\r\n\r\nImplementing an automated labeling system using GitHub Actions, specifically the `actions/labeler` action, would streamline this process. By configuring a `.github/labeler.yml` file, we can define rules that automatically apply labels to pull requests based on criteria such as modified file paths or branch naming conventions. This automation ensures consistent labeling, accelerates the triage process, and allows maintainers to focus on meaningful code reviews.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n- **Manual Labeling**: Continuing to label pull requests by hand, which is inefficient and susceptible to human error.\r\n\r\n- **Custom Scripts**: Developing bespoke scripts to handle labeling, which would require additional maintenance and might not integrate seamlessly with GitHub's ecosystem.\r\n\r\n**Additional context**\r\n\r\nAutomated labeling enhances the contributor experience by providing immediate feedback on the categorization of their pull requests. It also aids in project management by ensuring that all contributions are appropriately tagged, facilitating better tracking and prioritization. Implementing this feature aligns with best practices for open-source project maintenance, promoting efficiency and encouraging more streamlined collaboration.\r\n\r\nFor more information on setting up the labeler action, refer to the official GitHub documentation:  ", "CLOSED", 0, "monilpat", "2024-12-21T07:10:42Z", "2025-03-02T01:55:16Z", "2025-03-02T01:55:06Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6kE-3D", 1269, "Docs: Add Discord token resolution guide to documentation  | Error [TokenInvalid]: An invalid token was provided", "## Description\r\nWhile setting up Discord bots with multiple characters, I encountered and resolved an issue with Discord token resolution. This could be valuable documentation for other developers.\r\n\r\n## Problem\r\nThe Discord client was failing with the following error:\r\n```\r\nError [TokenInvalid]: An invalid token was provided.\r\n    at WebSocketManager.connect (/Users/.../eliza/node_modules/discord.js/src/client/websocket/WebSocketManager.js:136:26)\r\n    at Client.login (/Users/.../eliza/node_modules/discord.js/src/client/Client.js:228:21)\r\n```\r\n\r\nThis was happening even though the tokens were correctly set in the `.env` file. The issue was in how the tokens were being resolved from environment variables.\r\n\r\n## Solution\r\nI fixed this by:\r\n\r\n1. Ensuring proper token resolution in `eliza/packages/client-discord/src/index.ts`:\r\n```typescript\r\n// Get the token using runtime's getSecret\r\nconst token = this.character?.settings?.secrets?.DISCORD_API_TOKEN;\r\n\r\n// If it's a variable reference (${...}), resolve it from environment\r\nif (token?.startsWith('${') && token?.endsWith('}')) {\r\n    const envVarName = token.slice(2, -1);\r\n    this.apiToken = process.env[envVarName] || '';\r\n} else {\r\n    this.apiToken = token || '';\r\n}\r\n```\r\n\r\n2. Adding debug logging to track token resolution:\r\n```typescript\r\nelizaLogger.debug('Token resolution debug:', {\r\n    characterName: this.character.name,\r\n    rawToken: token,\r\n    isEnvVar: token?.startsWith('${') && token?.endsWith('}'),\r\n    envVarName: token?.startsWith('${') ? token.slice(2, -1) : null,\r\n    envValue: token?.startsWith('${') ? process.env[token.slice(2, -1)] : null\r\n});\r\n```\r\n\r\n## Key Points\r\n1. Character files should reference environment variables using `${VAR_NAME}` syntax:\r\n```json\r\n{\r\n    \"settings\": {\r\n        \"secrets\": {\r\n            \"DISCORD_API_TOKEN\": \"${DISCORD_API_TOKEN_JULIE}\"\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n2. The `.env` file should contain the actual tokens:\r\n```env\r\nDISCORD_API_TOKEN_JULIE=actual_token_here\r\nDISCORD_API_TOKEN_JUAN=actual_token_here\r\n```\r\n(where Julie and Juan are agents names)\r\n\r\n3. The token resolution process:\r\n   - First checks character's settings.secrets\r\n   - If the value is a variable reference (${...}), resolves it from environment\r\n   - Otherwise uses the raw value\r\n\r\n## Testing\r\nTo verify the fix:\r\n1. Ensure tokens are correctly set in `.env`\r\n2. Run the bot with both characters:\r\n```bash\r\npnpm start --characters=\"characters/julie.character.json,characters/juan.character.json\"\r\n```\r\n3. Check debug logs for token resolution process \r\n\r\n## Proposal\r\nI suggest:\r\n1. Adding this documentation to the main repository\r\n2. Possibly including it in the official docs under a \"Troubleshooting\" or \"Configuration\" section\r\n3. Adding debug logs to help other developers diagnose similar issues\r\n\r\nLet me know if you'd like me to create a PR with these changes. ", "CLOSED", 0, "tripluca", "2024-12-20T13:41:56Z", "2025-03-02T01:55:16Z", "2025-03-02T01:55:06Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6j26a1", 1224, "feat: Auto-Documentation Synchronization Bot", "## **Overview**\r\nCreate an AI assistant to maintain documentation consistency and generate documentation from code.\r\n\r\n## **Current Situation**\r\n\r\nDocumentation gaps often go unnoticed, leading to challenges during onboarding, feature development, and integrations. Outdated information can result in inefficiencies, with developers spending unnecessary time answering questions that could otherwise be handled by AI if up-to-date documentation were available\r\n\r\n## **Proposed Solution**\r\n\r\nFirst finish this issue: https://github.com/ai16z/eliza/issues/1110\r\nNext document plugins so that we have a quality reference: https://github.com/ai16z/eliza/issues/1200\r\n\r\nThen build a documentation bot that:\r\n1. Tracks and reports TODO comments in code (automate this flow https://github.com/ai16z/eliza/issues/1223)\r\n2. Tracks and reports missing plugin docs: (automate this https://github.com/ai16z/eliza/issues/1200)\r\n3. Tracks commits / issues / PRs and flags docs pages that might need updating\r\n4. Suggest documentation updates of those pages\r\n\r\n## **Technical Details**\r\n\r\n\r\n", "CLOSED", 0, "madjin", "2024-12-19T02:03:53Z", "2025-03-02T01:55:15Z", "2025-03-02T01:55:05Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6j2k2d", 1221, "feat: Eliza Code Assistant default characterfile", "**Overview**\r\nCreate an AI-powered development guide bot that can assist new contributors and help maintainers by leveraging repository history and documentation. This can be a starter file that teaches people about Eliza as soon as they run Eliza.\r\n\r\n**Current Situation**\r\n- New contributors often ask similar questions in discord / twitter\r\n- Repository knowledge is spread across many files and commit history\r\n- Code review assignments are manual and don't always match expertise\r\n\r\n**Proposed Solution**\r\nBuild an agent that:\r\n1. Answers FAQ-style questions using repo knowledge as recommended first step\r\n2. Suggests relevant examples based on current work\r\n3. Guides contributors to relevant documentation/contributors with answers\r\n\r\n**Technical Implementation**\r\n- Create an eliza characterfile template\r\n  - https://elizagen.howieduhzit.best/\r\n- Ingest knowledge about github (prevent duplicate issues, find answers, suggest new issue)\r\n  - https://ai16z.github.io/data/daily/contributors.json\r\n    - https://ai16z.github.io/data/daily/summary.json\r\n    - https://ai16z.github.io/data/daily/summary.md\r\n  - https://ai16z.github.io/data/weekly/contributors.json\r\n  - https://ai16z.github.io/data/monthly/contributors.json\r\n- Ingest docs + FAQ from discord (https://github.com/ai16z/eliza/issues/1044)\r\n  - https://ai16z.github.io/eliza/community/Discord/\r\n\r\n**Integration Points (IDEAS)**\r\n- Discord code assistant\r\n- Website frontend  (eliza.gg)\r\n", "CLOSED", 0, "madjin", "2024-12-19T00:21:13Z", "2025-03-02T01:55:15Z", "2025-03-02T01:55:05Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6jt6h0", 1194, "Improve Logging in /packages/plugin-coinbase/src/plugins", "**Is your feature request related to a problem? Please describe.**\n\nThe current logging mechanism in the `/packages/plugin-coinbase/src/plugins` directory lacks consistency and detail, making it challenging to debug and monitor the plugin's behavior effectively.\n\n**Describe the solution you'd like**\n\nIntegrate the `elizaLogger` construct to standardize logging across the plugin. This should include:\n- Consistent log levels (INFO, DEBUG, ERROR) for different operations.\n- Detailed log messages that include context such as function names and parameters.\n- Examples of how to implement `elizaLogger` in existing functions for better clarity.\n\n**Describe alternatives you've considered**\n\n- Continuing with the current ad-hoc logging approach.\n- Using a third-party logging library, though this may introduce unnecessary dependencies.\n\n**Additional context**\n\nPlease refer to existing examples in the `/packages/plugin-coinbase/src/plugins` directory and extend them where possible. Ensure that the new logging strategy aligns with the overall architecture of the `eliza` project.", "CLOSED", 0, "monilpat", "2024-12-18T04:16:18Z", "2025-03-02T01:55:15Z", "2025-03-02T01:55:05Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6jpyPh", 1183, "media parameter is missing Error on Main Branch", "Description\r\nWhen attempting to call the image-generation on Twitter, the following error occurs on the main branch:\r\n\r\n```\r\nError: {\"errors\":[{\"code\":38,\"message\":\"media parameter is missing.\"}]}\r\n    at uploadMedia (node_modules/agent-twitter-client/dist/node/esm/index.mjs:2211:13)\r\n    at async createCreateTweetRequest (node_modules/agent-twitter-client/dist/node/esm/index.mjs:1954:22)\r\n```\r\n\r\nHowever, it works as expected on the `tcm-twitter-image` branch.", "CLOSED", 0, "tcm390", "2024-12-17T17:56:49Z", "2025-03-02T01:55:14Z", "2025-03-02T01:55:04Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6jk4Bg", 1166, "Plugin Create Command", "**Is your feature request related to a problem? Please describe.**\r\n\r\nUsing with single command to create plugin using plugin example or template under packages\r\n\r\n", "CLOSED", 0, "BalanaguYashwanth", "2024-12-17T09:13:33Z", "2025-03-02T01:55:14Z", "2025-03-02T01:55:04Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6jVEr4", 1110, "feat: Workflow for generating JSDoc comments / documentation ", "**Is your feature request related to a problem? Please describe.**\r\nCurrently, maintaining comprehensive JSDoc documentation across our TypeScript codebase is a manual and time-consuming process. This leads to inconsistent documentation coverage and puts an unnecessary burden on developers. We need an automated solution that can help generate and maintain JSDoc comments while ensuring high quality and consistency.\r\n\r\n**Describe the solution you'd like**\r\n\r\nPropose a two-phase approach:\r\n\r\n1. Manual Documentation Phase:\r\n   - Add comprehensive JSDoc comments to all TypeScript files\r\n   - Include documentation for functions, classes, interfaces, and other code blocks\r\n\r\n2. Automation Implementation:\r\n   - Develop an LLM-based automation solution for generating JSDoc comments\r\n   - Integrate the automation into our CI/CD pipeline (like when a PR for a new feat is merged)\r\n   - Create a manual trigger mechanism for the automation process\r\n\r\n**Create a GitHub Actions workflow/AI agent that:**\r\n\r\n1. Automated Documentation Generation:\r\n   - Triggers on demand (via workflow_dispatch) or when specific files change\r\n   - Scans TypeScript files that lack JSDoc documentation\r\n   - Uses an AI service (e.g., OpenAI API) to generate contextually accurate JSDoc comments\r\n   - Maintains existing JSDoc comments and only adds missing ones\r\n\r\n2. Quality Control:\r\n   - Follows our existing JSDoc standards and TypeDoc configuration\r\n   - Validates generated comments for completeness and accuracy\r\n   - Ensures proper documentation of parameters, return types, and function descriptions\r\n\r\n3. Pull Request Management:\r\n   - Creates a new branch for documentation updates\r\n   - Generates a pull request with the changes\r\n   - Adds appropriate labels (e.g., 'documentation', 'automated')\r\n   - Includes a detailed PR description explaining the changes\r\n   - Assigns relevant reviewers\r\n\r\n4. Configuration:\r\n   - Allows customization of AI prompt templates\r\n   - Provides options to include/exclude specific files or directories\r\n   - Configurable commit message and PR templates\r\n\r\n**Describe alternatives you've considered**\r\n1. Manual documentation enforcement through PR checks\r\n2. Using existing JSDoc generation tools like https://github.com/TypeStrong/typedoc\r\n3. Implementing stricter code review policies for documentation\r\n4. Creating documentation sprints for batch updates\r\n\r\n**Additional context**\r\nRequired Permissions and Secrets:\r\n- GitHub token with PR creation permissions\r\n- AI service API key (e.g., OpenAI)\r\n- Repository write access for branch creation\r\n\r\n### Additional Motivation\r\n\r\nThis could be a proof of concept AI junior dev Karpathy talks about\r\n![image](https://github.com/user-attachments/assets/b2c3c68f-d85a-414c-a26f-231bd6ecb831)\r\n\r\n", "CLOSED", 0, "madjin", "2024-12-15T00:50:08Z", "2025-03-02T01:55:14Z", "2025-03-02T01:55:04Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6jS7sY", 1069, "100% test coverage on core and plugin-bootstrap", "v2 reflects what we want Eliza to be, and we feel that after these changes we should focus entirely on stability, security and cutting down on issues. We'll be aiming for 100% test coverage of core, adapters and primary components, and end-to-end tests for clients.", "CLOSED", 0, "lalalune", "2024-12-14T07:25:50Z", "2025-03-02T01:55:14Z", "2025-03-02T01:55:04Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6jS7Ye", 1068, "Move Plugins to Community Repo", "We'll be moving community plugins out of core and adding requirements for plugin inclusion in core around test coverage, documentation and code maintenance and ownership.\r\n\r\n", "CLOSED", 0, "lalalune", "2024-12-14T07:24:59Z", "2025-03-02T01:55:13Z", "2025-03-02T01:55:03Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6jS6Gd", 1067, "Extensible and generic framework", "The v1 is very opinionated about prompts, state and some features. v2 will be very extensible so you can create different kinds of agents and override state management and context composition. For advanced developers, this will make the framework far more powerful and flexible for different user cases.", "CLOSED", 0, "lalalune", "2024-12-14T07:21:03Z", "2025-03-02T01:55:13Z", "2025-03-02T01:55:03Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6jS5x8", 1065, "Model Provider Registry / Simple model provider hook + abstraction", "The current model provider system requires a pull request to core for every model provider. v2 will have a registry and override pattern so new code doesn't need to be added to core, and any provider can quickly override with a few lines of code to add integration without a pull request.", "CLOSED", 0, "lalalune", "2024-12-14T07:19:54Z", "2025-02-27T01:28:35Z", "2025-02-27T01:28:35Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6jS5iH", 1064, "Unified agent wallet / Wallet Provider", "Right now, each wallet is a separate provider, the providers are stacked but this creates some issues -- for example, how do you provide a bunch of different EVM chains? The \"switch chains\" paradigm sucks.\r\n\r\nFirst, we could make the EVM wallet multi-chain. But more broadly, the agent should have a single wallet and a wallet abstraction, and probably event hooks for providing data and getting data from many different wallets.\r\n\r\nWe should think about wallets and how we manage plugin dependencies.", "CLOSED", 0, "lalalune", "2024-12-14T07:18:57Z", "2025-02-27T01:27:12Z", "2025-02-27T01:27:12Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6jS44S", 1063, "V2: All packages are plugins", "Plugin interface should be the unifying solution so we can reduce other optionals, overrides and code paths generally.\r\n\r\nRight now we have clients, adapters, etc, but these should just be plugins with service registry pattern.", "CLOSED", 0, "lalalune", "2024-12-14T07:14:52Z", "2025-02-27T01:27:11Z", "2025-02-27T01:27:11Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6jS4wY", 1062, "V2: Unified messaging and Simplified Client IO", "We'll be refactoring all clients to handle input and output only, with an event bus to hook in response handlers.\r\nClients will have dramatically less code, and agents will be able to send messages across clients. This will also enable autonomous agent to unify all input and outputs into a single stream of thought and action.", "CLOSED", 0, "lalalune", "2024-12-14T07:13:55Z", "2025-02-27T01:27:11Z", "2025-02-27T01:27:11Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6jQ8-V", 1048, " Improve branch naming documentation format in CONTRIBUTING.md", "**Is your feature request related to a problem? Please describe.**\r\n\r\nIn the CONTRIBUTING.md file, there's some formatting issues in the branch naming section, :  \r\n\r\nIncorrect nested list numbering (using \"1.\" twice)   \r\nInconsistent formatting for the example (using \"eg.\" instead of \"Example:\")  \r\n\r\nThis inconsistency with our documentation style could lead to confusion and doesn't match the professional tone of the rest of the document.\r\n\r\n\r\n**Describe the solution you'd like**\r\n\r\n1. Use proper sequential numbering (1, 2)\r\n2. Replace \"eg.\" with \"Example:\" to match documentation style\r\n3. Use a more clear example number (9999)\r\n\r\nThe final format should look like:\r\n\r\n```\r\n3. Fork the repo and create your branch from `main`.\r\n    \r\n    1. The name of the branch should start with the issue number and be descriptive of the changes you are making.  \r\n    2. Example: 9999--add-test-for-bug-123]\r\n ```\r\n\r\n**Describe alternatives you've considered**\r\n\r\n1. Keeping \"eg.\" but it's less formal than our documentation style\r\n2. Using different formatting like \"For example:\" or \"(example:)\" but \"Example:\" is cleaner\r\n4. Using a bullet point for the example, but numbered lists better show the relationship between the instruction and its example\r\n\r\n**Additional context**\r\n\r\nThis change aligns with our documentation styleguide and makes the contribution guidelines more consistent and professional. It's a small change that improves readability and maintains our documentation standards.\r\n", "CLOSED", 0, "lessuselesss", "2024-12-13T20:07:22Z", "2025-02-27T01:28:35Z", "2025-02-27T01:28:35Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6jQWiI", 1044, "Feat: Ideas for docs based on top FAQ from discord", "From the discord chat logs I was able to extract these using https://github.com/ai16z/discord-summarizer as the most frequently asked questions. We should double check to see if documentation is sufficient on them, and if not, improve. Willing to throw a bounty on this.\r\n\r\nThese categories represent the most common themes and recurring questions in the chat logs. The setup/installation issues and Twitter integration questions seem to be particularly frequent, suggesting these might be areas where additional documentation or tooling could be helpful.\r\n\r\nSetup & Installation Issues:\r\n- How to properly set up the .env file and handle environment variables?\r\n- What Node.js version should be used? (Many issues with version compatibility)\r\n- How to resolve pnpm build/install errors?\r\n- How to properly set up Twitter/Discord/Telegram integration?\r\n\r\nAgent Configuration & Behavior:\r\n- How to configure the bot to respond/not respond to certain interactions?\r\n- How to control tweet frequency and intervals?\r\n- How to manage agent memory and database issues?\r\n- How to implement custom actions and plugins?\r\n\r\nAPI & Models:\r\n- Which AI models are recommended (Claude, GPT-4, Llama, etc.)?\r\n- How to handle API keys and rate limits?\r\n- How to switch between different model providers?\r\n- What are the costs associated with running different models?\r\n\r\nTwitter Integration:\r\n- How to handle Twitter cookies and authentication?\r\n- How to manage multiple Twitter accounts?\r\n- How to control bot posting behavior and intervals?\r\n- How to fix issues with tweet generation and responses?\r\n\r\nDevelopment & Contributing:\r\n- How to implement new features or plugins?\r\n- Where to find documentation and resources?\r\n- How to handle database issues (SQLite vs PostgreSQL)?\r\n- Best practices for code contribution and PR process?\r\n\r\nCharacter/Agent Creation:\r\n- How to create and customize character files?\r\n- How to implement knowledge bases and training data?\r\n- How to fine-tune models for specific use cases?\r\n- How to manage character memory and context?\r\n\r\nInfrastructure:\r\n- How to host agents (AWS, VPS, etc.)?\r\n- How to handle deployment issues?\r\n- How to manage Docker configurations?\r\n- How to scale and optimize performance?", "CLOSED", 0, "madjin", "2024-12-13T18:34:52Z", "2025-02-27T01:28:34Z", "2025-02-27T01:28:34Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6jFdft", 1014, "Setup of API keys for CI/CD tests", "This PR adds a basic test suite that every PR should pass at a minimum: https://github.com/ai16z/eliza/pull/993\r\n\r\nSince these tests require setting up API keys for CI/CD pipeline we need to decide who is responsible for those keys and how they should be managed.", "CLOSED", 0, "jzvikart", "2024-12-12T14:46:03Z", "2025-02-27T01:28:34Z", "2025-02-27T01:28:34Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6iohVn", 947, "Add other EVM chains", "https://github.com/ai16z/eliza/pull/949\r\n\r\nadding many other chains and refactoring code/files for easier maintenance of it", "CLOSED", 0, "0xCardinalError", "2024-12-09T23:33:01Z", "2025-02-27T01:27:11Z", "2025-02-27T01:27:11Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6ioa0-", 945, "Be able to use tool calling when calling generateObjectV2", "**Is your feature request related to a problem? Please describe.**\r\n\r\nSome plugins will have actions that require several tools to be called at once (e.g an onchain plugin that would have tools for preparing a tx for specific protocols and then sending those)\r\n\r\nThe problem is that right now you can't pass a set of tools to `generateObjectV2` so you can't leverage the tool calling functionality of the models.\r\n\r\n**Describe the solution you'd like**\r\n\r\nBe able to leverage tool calling in the `generateObjectV2` method. `aiGenerateObject` already allows that.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nCreating a new function that allows passing the tools parameter.\r\n", "CLOSED", 0, "0xaguspunk", "2024-12-09T23:21:43Z", "2025-02-27T01:28:33Z", "2025-02-27T01:28:33Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6ih8lD", 936, "Add LLM-Full.txt or LLM-Full.md for LLM-Suitable Documentation", "Description:\r\nCreate a new documentation file named LLM-Full.txt or LLM-Full.md to provide comprehensive project documentation in a format optimized for interaction with Large Language Models (LLMs).\r\n\r\nThis file should include:\r\n\t1.\tStructured Content: The information should be organized hierarchically with clear headers and subheaders for easy parsing.\r\n\t2.\tMachine-Readable Format: Use plain text or Markdown for compatibility.\r\n\t3.\tConciseness: While comprehensive, avoid excessive verbosity to maintain clarity and focus.\r\n\t4.\tContent Coverage: Include detailed descriptions of:\r\n\t\u2022\tProject objectives\r\n\t\u2022\tKey features\r\n\t\u2022\tImplementation details\r\n\t\u2022\tExample usage\r\n\t\u2022\tContribution guidelines\r\n\t\u2022\tAny other context that would help LLMs process and generate relevant responses about the project.\r\n\r\nPurpose:\r\nThis documentation will enhance interactions with LLM-based tools or agents by ensuring they have access to well-structured and detailed project information.\r\n", "CLOSED", 0, "AIFlowML", "2024-12-09T11:46:09Z", "2025-02-27T01:28:33Z", "2025-02-27T01:28:33Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6ifIX0", 928, "feat: Support Fetching Character Files From Storage Service", "**Is your feature request related to a problem? Please describe.**\r\nFor our use case at Phala Network, we are building a base template docker image for developers to deploy their agents to our TEE (Trusted Execution Environment) Cloud. However, we want to make the loading of the character json file easier to add via a command line argument vs building a new docker image with the new character file. Our main pain point is we want the user journey for technical to non-technical users to be able to publish their character configuration file to a storage protocol like arweave, ipfs, aws, etc. and be able to load those character files in through a command argument. This will make our deploy service easier with a docker compose file that can list the file id location in an argument like `pnpm start --characterUrl=https://characterfile.url`\r\n\r\n**Describe the solution you'd like**\r\nThe developer journey would go as follows:\r\n- Generate a character JSON file through any means (keep this step unopinionated)\r\n- Publish the character file to a storage service. (Ex. Use Thirdweb to post and pin to IPFS https://972b74063c2cd00df1a4cf777bf37d0a.ipfscdn.io/ipfs/bafybeicod5xghpshbxmfb3sh2ccfbb5657dgvxthgwolb42srz4a5iadwm/)\r\n- Create a new CLI argument to the `pnpm start` command named `--characterUrl` that will take in the URL where the character file is hosted\r\n- When the agent is being initialized, `fetch` the character file from the URL and allow for the agent to go through the natural process of starting up the agent\r\n\r\nCode changes should be minimal and would not affect any core functionality so the risk is low.\r\n\r\n**Describe alternatives you've considered**\r\nAlternatives were building a web app similar to vvaifu, but this would not be a good user experience for cloud deployments or a good strategy to compete with them since we are focused on different problems.\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\nThis will help bring more users to Eliza with better security and privacy guarantees by utilizing TEE for safe Eliza agent cloud deployments.\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\nExample deployment with a mock docker compose file in the TEE Cloud.\r\n![image](https://github.com/user-attachments/assets/f0bec2d0-aa0e-418c-bf88-67e37edf1a17)\r\n\r\n\r\n", "CLOSED", 0, "HashWarlock", "2024-12-09T05:55:56Z", "2025-02-27T01:28:32Z", "2025-02-27T01:28:32Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6ibexR", 916, "Coinbase AgentKit", "Hi there,Thanks for maintaining such a great project! Do you have any plans to integrate the Coinbase AI Agent Kit?\r\n\r\nhttps://docs.cdp.coinbase.com/agentkit/docs/welcome\r\n", "CLOSED", 0, "graykode", "2024-12-08T10:49:47Z", "2025-02-27T01:28:32Z", "2025-02-27T01:28:32Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6iae8G", 909, "Provider Id Feature Request", "**Is your feature request related to a problem? Please describe.**\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\nI'm always frustrated when I have to call all providers each time instead of being able to identify them individually.\r\n\r\n**Describe the solution you'd like**\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\nI suggest adding an ID option to the Provider, similar to how actions are identified. This would allow for direct identification without the need to invoke all providers.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\nAn alternative would be using an external mapping or registry system to track and identify providers. However, this approach adds complexity and maintenance overhead.\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n\r\nAdding an ID to the Provider can streamline operations and improve efficiency when dealing with multiple providers in a system.\r\n\r\n", "CLOSED", 0, "v1xingyue", "2024-12-07T23:14:40Z", "2025-02-27T01:28:32Z", "2025-02-27T01:28:32Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6iZxG-", 900, "Support for Perplexity Sonar models", "**Is your feature request related to a problem? Please describe.**\r\n\r\nI want my agent to have access to the latest news etc!\r\n\r\n**Describe the solution you'd like**\r\n\r\nThere is already support for openrouter but only `nousresearch/hermes-3-llama-3.1-405b`. Adding `perplexity/llama-3.1-sonar-small-128k-chat` (sonar family of models)\r\n\r\n**Describe alternatives you've considered**\r\n\r\nAdding a custom action performing web search but worse latency\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "hugoroussel", "2024-12-07T15:03:17Z", "2025-02-27T01:28:31Z", "2025-02-27T01:28:31Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6iYKyr", 881, "Failed to initialize ONNX Runtime API", "**Describe the bug**\r\n\r\nWhen launching with `pnpm --dir core start \"--character=characters/trump.character.json\"` I get \r\n```\r\n(node:16908) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\r\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n(node:16908) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\r\n(Use `node --trace-deprecation ...` to show where the warning was created)\r\nThe requested API version [20] is not available, only API versions [1, 19] are supported in this build. Current ORT Version is: 1.19.2\r\nnode:internal/modules/cjs/loader:1724\r\n  return process.dlopen(module, path.toNamespacedPath(filename));\r\n                 ^\r\n\r\nError: Failed to initialize ONNX Runtime API. It could happen when this nodejs binding was built with a higher version ONNX Runtime but now runs with a lower version ONNX Runtime DLL(or shared library).\r\n    at Object..node (node:internal/modules/cjs/loader:1724:18)\r\n    at Module.load (node:internal/modules/cjs/loader:1303:32)\r\n    at Function._load (node:internal/modules/cjs/loader:1117:12)\r\n    at TracingChannel.traceSync (node:diagnostics_channel:322:14)\r\n    at wrapModuleLoad (node:internal/modules/cjs/loader:218:24)\r\n    at Module.require (node:internal/modules/cjs/loader:1325:12)\r\n    at require (node:internal/modules/helpers:136:16)\r\n    at Object.<anonymous> (J:\\Eliza\\eliza\\core\\node_modules\\onnxruntime-node\\dist\\binding.js:9:1)\r\n    at Module._compile (node:internal/modules/cjs/loader:1546:14)\r\n    at Object..js (node:internal/modules/cjs/loader:1698:10)\r\n```\r\n\r\n\r\n**To Reproduce**\r\n\r\nInstall following the quickstart guide on Windows 10 Education Edition, using node 23.3.0\r\n\r\n**Expected behavior**\r\n\r\nI don't get this error.\r\n", "CLOSED", 0, "minichris", "2024-12-07T01:41:37Z", "2025-02-28T08:21:25Z", "2025-01-12T10:49:18Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6iWSG1", 876, "Publish an official Docker Image in ghcr.", "Would be really useful to have an official Docker Image to pull.\r\n\r\n**Describe the solution you'd like**\r\n\r\nA Github Action that creates the Docker Image with each release, tag it properly and upload it to ghcr or dockerhub.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nAn alternative is really ugly. It is being aware of each release and do it manually or use some cicd to do it.\r\n\r\nThanks!\r\n", "CLOSED", 0, "luisalrp", "2024-12-06T19:13:57Z", "2025-02-27T09:20:31Z", "2025-02-27T01:28:31Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6hida1", 778, "Remove LLAMA_CLOUD and warn users to switch to TOGETHER or another provider", "We have deprecated LLAMA_CLOUD since we have a lot of llama cloud options now-- it's called TOGETHER instead\r\n\r\nAdd a character file validation check to warn the user that \"llama_cloud\" is no longer an option and they should switch to together -- let's warn but do the change so it doesn't error, like a deprecation warning.", "CLOSED", 0, "lalalune", "2024-12-02T01:12:12Z", "2025-02-27T01:28:30Z", "2025-02-27T01:28:30Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6hhhQM", 764, "Epic: Refactoring Eliza's Trading System for Multi-Chain Compatibility", "**Overview:**\r\n\r\nThis epic addresses the need to refactor Eliza's trading system to improve multi-chain compatibility and resolve the current conflict between the Solana plugin (and other individual chain plugins) and Coinbase SDK. The goal is to create a more flexible and extensible architecture that can accommodate various blockchain integrations and trading strategies.\r\n\r\n**Goals:**\r\n\r\n* Eliminate redundancy and inconsistency between the plugins for individual chains and Coinbase SDK.\r\n* Establish a unified trading interface that can be implemented by different blockchain/exchange adapters.\r\n* Implement a centralized data source or normalization layer for price and market data.\r\n* Develop a unified wallet management system for different blockchain/exchange wallets.\r\n* Support diverse trading strategies beyond simple token swaps (e.g., swing trading, day trading).\r\n* Ensure scalability and maintainability of the trading system as new integrations are added.\r\n\r\n**Decision Points:**\r\n\r\n* **DP1: Coinbase SDK Focus vs. Multi-SDK Support:**\r\n    * **Option A: Prioritize Coinbase SDK:** Focus primarily on the Coinbase SDK and contribute back to its development to enhance its functionality and multi-chain support.  This would involve working closely with the Coinbase team and aligning development efforts.\r\n    * **Option B: Create a Training Module/Adapter System:** Develop a training module or adapter system that allows Eliza to seamlessly integrate with different SDKs (Coinbase, Solana Web3.js, etc.). This would provide greater flexibility but require more upfront development effort.  This approach requires designing abstract interfaces for trading, data retrieval, and wallet management.\r\n    * **Option C: Hybrid Approach:**  Start with a focus on the Coinbase SDK for its existing multi-chain support, but design the system with the future flexibility to add other SDKs via an adapter pattern.  This would balance immediate needs with long-term extensibility.\r\n\r\n* **DP2: Centralized vs. Decentralized Data Management:**\r\n    * **Option A: Centralized Data Source:** Choose a single, reliable data provider for price and market data.  This simplifies data management but creates a single point of failure.\r\n    * **Option B: Decentralized Data Aggregation:**  Aggregate data from multiple sources (Coinbase, Jupiter, Birdeye, etc.) and implement a normalization layer to handle discrepancies and ensure data consistency. This approach is more robust but increases complexity.\r\n\r\n* **DP3: Unified Wallet Management Strategy:**\r\n    * **Option A: Abstract Wallet Interface:**  Develop an abstract wallet interface that can be implemented by different wallet providers (Solana, Coinbase, etc.).  This allows for flexibility in wallet selection but requires careful design.\r\n    * **Option B:  Custom Wallet Management Service:** Create a custom wallet management service within Eliza that interacts directly with different wallet APIs.  This provides more control but increases development effort.\r\n\r\n* **DP4: Scope of Trading Strategies:**\r\n    * **Option A:  Focus on Long-Term Holding:** Initially, limit support to long-term buy-and-hold strategies, simplifying the trust engine and trade management.\r\n    * **Option B:  Support Arbitrary Trading:** Implement support for a wider range of trading strategies (swing trading, day trading, etc.) from the outset.  This increases complexity but provides greater flexibility.\r\n\r\n**Proposed Sub-Tickets (Initial List - To be refined):**\r\n\r\n* **ST1: Design Abstract Trading Interface:** Design a unified trading interface that can be implemented by different blockchain/exchange adapters.\r\n* **ST2: Implement Coinbase Adapter:** Create a Coinbase adapter that implements the abstract trading interface, handling trade execution, data retrieval, and wallet management.\r\n* **ST3: Implement Solana Adapter:** Create a Solana adapter that implements the abstract trading interface.\r\n* **ST4: Develop Data Normalization Layer (if needed):** If using multiple data sources, create a data normalization layer to ensure data consistency.\r\n* **ST5: Implement Unified Wallet Management System:**  Develop a unified wallet management system that supports multiple blockchain/exchange wallets.\r\n* **ST6: Implement Position Tracking:**  Create a system for tracking open positions and trade history.\r\n* **ST7: Enhance Trust Engine for Arbitrary Trading:** Modify the trust engine to support different trade types, timeframes, and performance metrics.\r\n* **ST8: Develop Backtesting Framework:** Implement a backtesting framework for evaluating trading strategies.\r\n* **ST9: Implement Automated Trading Engine:** Develop an automated trading engine.\r\n* **ST10: Testing and Validation:**  Develop a comprehensive test suite for the refactored trading system, covering different adapters, data sources, and trading scenarios.\r\n* **ST11: Documentation and Examples:**  Update the documentation to reflect the changes in the trading system architecture and provide examples of using different adapters and strategies.\r\n\r\n**Next Steps:**\r\n\r\n* Conduct thorough research and analysis to inform decisions on each decision point.\r\n* Prioritize sub-tickets based on chosen architecture and strategic goals.\r\n* Assign sub-tickets to developers and create a development roadmap.\r\n* Regularly review progress and update this epic ticket accordingly.\r\n\r\nThis epic provides a roadmap for refactoring Eliza's trading system to achieve multi-chain compatibility and support more advanced trading strategies. Careful consideration of the decision points and collaborative development of the sub-tickets will result in a more robust, scalable, and versatile trading platform for Eliza agents.", "CLOSED", 0, "jkbrooks", "2024-12-01T21:38:41Z", "2025-02-27T01:28:30Z", "2025-02-27T01:28:30Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6hUpt9", 695, "Run using Bun.sh", "**Is your feature request related to a problem? Please describe.**\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\n**Describe the solution you'd like**\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n**Additional context**\r\n\r\nBun is a runtime alternative to Node.js which is a lot faster and has a variety of features. It's used a lot in the JS community nowadays.\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n", "CLOSED", 0, "liamzebedee", "2024-11-30T03:04:06Z", "2025-02-27T01:27:10Z", "2025-02-27T01:27:10Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6hAmUg", 644, "Better EVM multi-chain handling", "**Is your feature request related to a problem? Please describe.**\r\n\r\nRight now, we have to switch chains. This is a terrible UX, and instead we'd like to get data from multiple chains and coalesce it.\r\n\r\n**Describe the solution you'd like**\r\n\r\nEnable multi-chain wallet abstraction which pulls in and caches data from multiple chains\r\n\r\n- Add chains like arbitrum and polygon\r\n- Remove actions like \"switch chain\"\r\n- Make sure tokens are tagged correctly on different chains", "CLOSED", 0, "lalalune", "2024-11-28T08:33:58Z", "2025-02-27T01:27:10Z", "2025-02-27T01:27:10Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6gsYDD", 617, "Persisent Storage for plugins", "**Is your feature request related to a problem? Please describe.**\r\n\r\nPlugin developers needs a framework for storing persistent data for their plugins. Some data needs to be tied to an agent, other data to the nodejs instance. \r\n\r\n**Describe the solution you'd like**\r\n\r\nI'd like to hear how plugin authors are currently tackling this and put together a workgroup to develop a long term plan.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nSome options:\r\n\r\n1. Decentralized: They could each have their own store\r\n2. Centralized: We develop a universal key/value store OR registry\r\n\r\n**Additional context**\r\n\r\nNone at this time\r\n", "CLOSED", 0, "odilitime", "2024-11-26T20:29:35Z", "2025-02-27T01:27:10Z", "2025-02-27T01:27:10Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6gDFPU", 531, "Feature: Make composeContext generic", "Future buisness logic will demand extendability of Eliza - we need to lean into this future.\r\n\r\nCurrently ComposeContext accepts State as a parameter, however common use case is adding more State to an agent.\r\n\r\nThis task is to use generic types on `composeContext` and other functions to allows users to use these downstream.\r\n", "CLOSED", 0, "ponderingdemocritus", "2024-11-23T02:59:50Z", "2025-02-27T01:27:09Z", "2025-02-27T01:27:09Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6cy1EZ", 171, "Develop a reliable way to test Twitter functionality", "Here are effective ways to test a Twitter bot without making live posts:\n\n## Development Environment Testing\n\n**Local Testing**\n- Use a development environment that simulates Twitter's API responses[1]\n- Create test cases that mock Twitter interactions\n- Run your bot offline to verify basic functionality\n\n**API Testing Options**\n- Twitter's API offers no direct sandbox or test mode for posting[5]\n- Consider creating a private test account for development\n\n## Best Practices\n\n**Account Setup**\n- Create a separate development Twitter account specifically for testing\n- Keep the test account private to avoid public visibility\n- Use minimal followers/following to prevent unwanted interactions\n\n**Code Testing Methods**\n- Mock API calls in your code to simulate responses\n- Log bot actions instead of making actual posts\n- Test bot logic and processing separately from the actual posting mechanism\n\n## Bot Detection Testing\n\nBefore deploying, verify your bot behaves naturally by checking against common bot detection criteria:\n\n**Activity Patterns**\n- Maintain reasonable posting frequencies (avoid posting more than 10-15 times per day)[7]\n- Include varied content types, not just retweets\n- Add reasonable delays between actions\n\n**Account Setup**\n- Use a proper profile with complete information[7]\n- Avoid generic or automated-looking usernames\n- Include a proper profile picture and bio\n\nRemember that while testing, you must still comply with Twitter's terms of service and API usage guidelines[4].\n\nCitations:\n[1] https://stackoverflow.com/questions/72857417/is-there-any-possibility-in-making-a-twitter-bot-without-using-the-dev-api\n[2] https://social-dog.net/en/trend/p81\n[3] https://circleboom.com/twitter-management-tool/twitter-circle-tool/twitter-bot-checker\n[4] https://www.socialmediatoday.com/news/Twitter-Developing-New-Human-Test-to-Combat-Bots/637998/\n[5] https://stackoverflow.com/questions/71945400/test-tweet-post-with-twitter-api\n[6] https://www.wusa9.com/article/news/local/verify/verify-bot-or-not-how-to-check-if-a-twitter-account-is-trying-to-manipulate-you/65-582431225\n[7] https://blog.mozilla.org/en/products/firefox/irl-how-to-spot-a-bot/\n[8] https://devcommunity.x.com/t/how-to-build-a-twitter-bot-to-reply-to-mentions-basic-or-pro-plan/222232", "CLOSED", 0, "sirkitree", "2024-11-02T16:10:49Z", "2025-02-27T01:28:30Z", "2025-02-27T01:28:30Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6cxk7-", 165, "Refine Boredom Provider", "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrent boredom provider is not well tested and hacky. Should be reviewed, could be much better. Needs a lot of hours of testing with the bot and reviewing their outputs.\r\n\r\n**Describe the solution you'd like**\r\n\r\nMake the boredom provider more effective", "CLOSED", 0, "lalalune", "2024-11-02T05:52:35Z", "2025-02-27T01:28:29Z", "2025-02-27T01:28:29Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6bzgbc", 26, "News feed", "We should pull news and current events based on the agent character's topics list.\r\n\r\n- This should be cached every hour or so that we don't bang the APIs too hard.\r\n- We should summarize news stories (see the summarization service) and load them into the agent's context for tweeting and Discord chat generation", "CLOSED", 0, "lalalune", "2024-10-25T12:27:15Z", "2025-02-27T01:26:09Z", "2025-02-27T01:26:09Z", "elizaos/eliza", "2025-04-14 21:53:31"]
["I_kwDOMT5cIs6trk-g", 3901, "Twitter Agent doesn't start", "I still have the issue https://github.com/elizaOS/eliza/issues/3693\n\nI have: \n\n```\n    \"plugins\": [\"@elizaos-plugins/plugin-twitter\"], \n    \"clients\": [\"twitter\"],\n\n```\n\nbut the plugin doesn't start because `twitterPlugin` doesn't have `clients` field, look at agent/src/index.ts line 602 if (plugin.clients) {\n\n```\nexport async function initializeClients(\n    character: Character,\n    runtime: IAgentRuntime\n) {\n    // each client can only register once\n    // and if we want two we can explicitly support it\n    const clients: ClientInstance[] = [];\n    // const clientTypes = clients.map((c) => c.constructor.name);\n    // console.log(character);\n\n    if (character.plugins?.length > 0) {\n        for (const plugin of character.plugins) {\n            if (plugin.clients) {\n                for (const client of plugin.clients) {\n                    const startedClient = await client.start(runtime);\n                    elizaLogger.debug(\n                        `Initializing client: ${client.name}`\n                    );\n                    clients.push(startedClient);\n                }\n            }\n        }\n    }\n\n    return clients;\n}\n```\n\npackages/src/index.ts:\n\n```\nexport const twitterPlugin: Plugin = {\n    name: \"twitter\",\n    description: \"Twitter integration plugin for posting tweets\",\n    actions: [postAction],\n    evaluators: [],\n    providers: [],\n};\n```", "CLOSED", 0, "imerku1ov", "2025-03-12T12:55:22Z", "2025-03-12T13:21:45Z", "2025-03-12T13:20:47Z", "elizaos/eliza", "2025-04-14 21:54:43"]
["I_kwDOMT5cIs6tRfpG", 3886, "Conversion of JSON null values", "**Describe the bug**\n\n{ \"name\": null }  will be converted to { \"name\": \"null\" }\n\n<!-- A clear and concise description of what the bug is. -->\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "aiden-cao", "2025-03-10T12:03:14Z", "2025-03-12T03:15:46Z", "2025-03-12T03:15:46Z", "elizaos/eliza", "2025-04-14 21:54:43"]
["I_kwDOMT5cIs6tMQXD", 3882, "Can't get past pnpm install and build.", "I'm stuck with the same issue I was getting with pnpm install (I managed to make this work). I switched to the main eliza from the eliza-starter (because that was not working for me), and now I can't get past the initial pnpm install and build. Both come up with this \"Failed to switch pnpm to v9.15.7. Looks like pnpm CLI is missing at ...\" error. I forced pnpm to switch to v9.15.7 (pnpm --version confirms), and this seemed to get me past install, but here I am again when I try to run the build command.\n\n\u2022 Packages in scope: @elizaos-plugins/adapter-sqlite, @elizaos/agent, @elizaos/client-direct, @elizaos/core, @elizaos/plugin-bootstrap, cli, client, dynamic-imports\n\u2022 Running build in 8 packages\n\u2022 Remote caching disabled\n@elizaos/client-direct:build: cache miss, executing 851b36d4358197d5\n@elizaos/core:build: cache miss, executing 59e600e82c4b2365\n@elizaos/client-direct:build:\n@elizaos/core:build:\n@elizaos/client-direct:build: \u2009ERROR\u2009 Failed to switch pnpm to v9.15.7. Looks like pnpm CLI is missing at \"/root/.local/share/pnpm/.tools/pnpm/9.15.7/bin\" or is incorrect\n@elizaos/client-direct:build: spawnSync /root/.local/share/pnpm/.tools/pnpm/9.15.7/bin/pnpm ENOENT\n@elizaos/core:build: \u2009ERROR\u2009 Failed to switch pnpm to v9.15.7. Looks like pnpm CLI is missing at \"/root/.local/share/pnpm/.tools/pnpm/9.15.7/bin\" or is incorrect\n@elizaos/core:build: spawnSync /root/.local/share/pnpm/.tools/pnpm/9.15.7/bin/pnpm ENOENT\n@elizaos/core:build: ERROR: command finished with error: command (/root/eliza/packages/core) /root/eliza/node_modules/.bin/pnpm run build exited (1)\n@elizaos/client-direct:build: ERROR: command finished with error: command (/root/eliza/packages/client-direct) /root/eliza/node_modules/.bin/pnpm run build exited (1)\n@elizaos/core#build: command (/root/eliza/packages/core) /root/eliza/node_modules/.bin/pnpm run build exited (1)\n@elizaos/client-direct#build: command (/root/eliza/packages/client-direct) /root/eliza/node_modules/.bin/pnpm run build exited (1)\n\n Tasks:    0 successful, 2 total\nCached:    0 cached, 2 total\n  Time:    1.958s\nFailed:    @elizaos/client-direct#build, @elizaos/core#build\n\n\nWhat seems like it should be simple has turned into a bit of a mess. Any help would be much appreciated.", "CLOSED", 0, "small-talk", "2025-03-09T20:58:34Z", "2025-03-11T01:44:56Z", "2025-03-11T01:44:56Z", "elizaos/eliza", "2025-04-14 21:54:43"]
["I_kwDOMT5cIs6tFECc", 3802, "Service text_generation not found", "**Describe the bug**\n\nDuring running freshly installed eliza, I am getting an error for default character with llama local: Service text_generation not found\n\n**To Reproduce**\n\n```\ngit clone https://github.com/elizaos/eliza.git\ngit checkout $(git describe --tags --abbrev=0)\ncp .env.example .env\npnpm i\npnpm build\npnpm start\npnpm start:client\ngo to  http://localhost:5173/ \ntype in chat \nlook at the terminal logs \n```\n\n\n**Expected behavior**\n\nI would expect that after fresh installation and build default character works. It seems that llamalocal is downloaded however it doesn't work\n\n**Screenshots**\n\n<img width=\"1010\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/61f83d52-ebf4-4dce-8f92-57a90b044650\" />\n\n\n", "CLOSED", 0, "lstokenomiapro", "2025-03-07T19:42:38Z", "2025-03-11T08:55:02Z", "2025-03-08T01:17:40Z", "elizaos/eliza", "2025-04-14 21:54:43"]
["I_kwDOMT5cIs6ry-sv", 3693, "Twitter Agent won't post / respond as it should", "I'm trying to run the X agent and have configured the openai api and the X login in the env files. The agent seems to be online but it won't post or comment like it should be doing. I'm able to talk to the agent by running pnpm start client and talk to it but It is unable to make new posts or anything. I'm using openai's api \n\n\n![Image](https://github.com/user-attachments/assets/d5dfc40e-d698-4ee3-9028-edd19dfbb99f)\nThis is the last message I can see on the wsl terminal. \n\n\n", "CLOSED", 0, "mohsinn3", "2025-02-26T17:08:51Z", "2025-03-12T12:56:25Z", "2025-03-08T01:15:17Z", "elizaos/eliza", "2025-04-14 21:54:43"]
["I_kwDOMT5cIs6ry71b", 3692, "Unexpected ERR_USE_AFTER_CLOSE error while running Eliza on Docker", "I'm trying to deploy the docker provided in `eliza-starter` repo for the first time with my new character. \nI was able to build the docker in my CI and run it in a container which looks ok.\nAt some point in the booting process of the service I get this weird `ERR_USE_AFTER_CLOSE` error which kills the process:\n\n```\n[2025-02-26 16:56:29] INFO: Buzz Feeley(2b6886f3-374d-0904-9c25-357b4472f50f) - Initializing AgentRuntime with options:\n    character: \"Buzz Feeley\"\n    modelProvider: \"anthropic\"\n    characterModelProvider: \"anthropic\"\n[2025-02-26 16:56:29] INFO: Buzz Feeley(2b6886f3-374d-0904-9c25-357b4472f50f) - Setting Model Provider:\n    characterModelProvider: \"anthropic\"\n    optsModelProvider: \"anthropic\"\n    finalSelection: \"anthropic\"\n[2025-02-26 16:56:29] INFO: Buzz Feeley(2b6886f3-374d-0904-9c25-357b4472f50f) - Selected model provider: anthropic\n[2025-02-26 16:56:29] INFO: Buzz Feeley(2b6886f3-374d-0904-9c25-357b4472f50f) - Selected image model provider: anthropic\n[2025-02-26 16:56:29] INFO: Buzz Feeley(2b6886f3-374d-0904-9c25-357b4472f50f) - Selected image vision model provider: anthropic\n[2025-02-26 16:56:29] INFO: Initializing LlamaService...\n[2025-02-26 16:56:29] ERROR: Unhandled error in startAgents:\n    code: \"ERR_USE_AFTER_CLOSE\"\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\n```\n\nI looked for the Eliza code and didn't find any related code, the only thing I found is [this resolved bug](https://github.com/elizaOS/eliza/issues/1168). \n\n\n\nThis is my docker file (unchanged from the eliza-starter):\n```\n# Use a specific Node.js version for better reproducibility\nFROM node:23.3.0-slim AS builder\n\n# Install pnpm globally and install necessary build tools\nRUN npm install -g pnpm@9.15.1 && \\\n    apt-get update && \\\n    apt-get install -y git python3 make g++ && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\n\n# Set Python 3 as the default python\nRUN ln -s /usr/bin/python3 /usr/bin/python\n\n# Set the working directory\nWORKDIR /app\n\n# Copy package.json and other configuration files\nCOPY package.json ./\nCOPY pnpm-lock.yaml ./\nCOPY tsconfig.json ./\n\n# Copy the rest of the application code\nCOPY ./src ./src\nCOPY ./characters ./characters\n\n# Install dependencies and build the project\nRUN pnpm install \nRUN pnpm build \n\n# Create dist directory and set permissions\nRUN mkdir -p /app/dist && \\\n    chown -R node:node /app && \\\n    chmod -R 755 /app\n\n# Switch to node user\nUSER node\n\n# Create a new stage for the final image\nFROM node:23.3.0-slim\n\n# Install runtime dependencies if needed\nRUN npm install -g pnpm@9.15.1\nRUN apt-get update && \\\n    apt-get install -y git python3 && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\n\nWORKDIR /app\n\n# Copy built artifacts and production dependencies from the builder stage\nCOPY --from=builder /app/package.json /app/\nCOPY --from=builder /app/node_modules /app/node_modules\nCOPY --from=builder /app/src /app/src\nCOPY --from=builder /app/characters /app/characters\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/tsconfig.json /app/\nCOPY --from=builder /app/pnpm-lock.yaml /app/\n\nEXPOSE 3000\n# Set the command to run the application\nCMD [\"pnpm\", \"start\", \"--non-interactive\"]\n```\n\nAnd this is the container configuration: \n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: eliza-service\n  namespace: eliza\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: eliza-service\n  template:\n    metadata:\n      labels:\n        app: eliza-service\n    spec:\n      serviceAccountName: eliza-sa\n      containers:\n      - name: my-application\n        image: REDUCTED\n        command: [\"pnpm\", \"start\", \"--character=./characters/buzzfeeley.character.json\", \"--non-interactive\"]\n        imagePullPolicy: Always\n        env:\n        - name: SERVER_PORT\n          value: '3000'\n        ports:\n        - containerPort: 3000\n```\n\nPackage.json:\n```\n{\n  \"name\": \"@elizaos/eliza-starter\",\n  \"version\": \"0.1.9\",\n  \"main\": \"src/index.ts\",\n  \"type\": \"module\",\n  \"scripts\": {\n    \"build\": \"tsup src/index.ts --format esm --dts\",\n    \"start\": \"tsc && node --loader ts-node/esm src/index.ts\",\n    \"clean\": \"./scripts/clean.sh\",\n    \"start:service:all\": \"pm2 start pnpm --name=\\\"all\\\" --restart-delay=3000 --max-restarts=10 -- run start:all\",\n    \"stop:service:all\": \"pm2 stop all\"\n  },\n  \"dependencies\": {\n    \"@elizaos/adapter-postgres\": \"0.1.9\",\n    \"@elizaos/adapter-sqlite\": \"0.1.9\",\n    \"@elizaos/client-auto\": \"0.1.9\",\n    \"@elizaos/client-direct\": \"0.1.9\",\n    \"@elizaos/client-discord\": \"0.1.9\",\n    \"@elizaos/client-telegram\": \"0.1.9\",\n    \"@elizaos/client-twitter\": \"0.1.9\",\n    \"@elizaos/core\": \"0.1.9\",\n    \"@elizaos/plugin-bootstrap\": \"0.1.9\",\n    \"@elizaos/plugin-image-generation\": \"0.1.9\",\n    \"@elizaos/plugin-node\": \"0.1.9\",\n    \"@elizaos/plugin-solana\": \"0.1.9\",\n    \"@elizaos/plugin-starknet\": \"0.1.9\",\n    \"@tavily/core\": \"0.0.2\",\n    \"amqplib\": \"0.10.5\",\n    \"better-sqlite3\": \"11.5.0\",\n    \"dotenv\": \"^16.4.7\",\n    \"fs\": \"0.0.1-security\",\n    \"net\": \"1.0.2\",\n    \"path\": \"0.12.7\",\n    \"readline\": \"1.3.0\",\n    \"url\": \"0.11.4\",\n    \"ws\": \"8.18.0\",\n    \"yargs\": \"17.7.2\"\n  },\n  \"engines\": {\n    \"node\": \">=22\"\n  },\n  \"pnpm\": {\n    \"overrides\": {\n      \"onnxruntime-node\": \"1.20.0\"\n    },\n    \"ignoredBuiltDependencies\": [\n      \"@discordjs/opus\",\n      \"@elizaos/plugin-node\",\n      \"bigint-buffer\",\n      \"bufferutil\",\n      \"canvas\",\n      \"es5-ext\",\n      \"esbuild\",\n      \"ffmpeg-static\",\n      \"keccak\",\n      \"node-hid\",\n      \"node-llama-cpp\",\n      \"onnxruntime-node\",\n      \"protobufjs\",\n      \"puppeteer\",\n      \"secp256k1\",\n      \"sharp\",\n      \"sodium-native\",\n      \"usb\",\n      \"utf-8-validate\",\n      \"wtf_wikipedia\",\n      \"youtube-dl-exec\"\n    ],\n    \"onlyBuiltDependencies\": [\n      \"better-sqlite3\"\n    ]\n  },\n  \"devDependencies\": {\n    \"pm2\": \"5.4.3\",\n    \"ts-node\": \"10.9.2\",\n    \"tsup\": \"8.3.5\",\n    \"typescript\": \"5.6.3\"\n  }\n}\n```", "CLOSED", 0, "ido567", "2025-02-26T17:04:50Z", "2025-03-10T11:15:21Z", "2025-02-26T17:08:43Z", "elizaos/eliza", "2025-04-14 21:54:43"]
["I_kwDOMT5cIs6oGxpW", 3030, "Lend and Borrow Integration in TON Plugin", "**Description**  \nExtend the TON Plugin within the elizaOS framework to offer lending and borrowing capabilities using existing lending protocols on the TON blockchain. These new actions should allow AI agents to deposit assets as collateral, accrue interest, borrow tokens, and manage debt positions\u2014all via automated, programmatic calls. \n\n**Key Requirements**  \n1. **Protocol Integration**  \n   - Connect with an existing TON-based lending protocol or provide a flexible interface to support multiple protocols in the future.  \n   - Ensure seamless deposits, withdrawals, borrowing, and repayment functionalities.\n\n2. **Collateral Management**  \n   - Implement methods for depositing collateral and tracking its value in real-time.  \n\n3. **Interest & Repayment**  \n   - Expose methods for calculating and displaying accrued interest on borrowed positions.  \n   - Provide actions for partial or complete repayment of borrowed funds.\n\n4. **Security & Access Control**  \n   - Adhere to recommended security practices and documentation from the chosen lending protocol.  \n   - Validate user inputs (collateral amounts, borrow limits) to prevent malicious or unintended behavior.\n\n**Resources**  \n- [TON Documentation](https://docs.ton.org/)  \n- [Evaa protocol sdk](https://github.com/evaafi/sdk?tab=readme-ov-file)\n\n**Definition of Done**  \n- Complete integration of lending and borrowing functionality with at least one TON-based lending protocol.  \n- Comprehensive test coverage demonstrating deposits, borrows, repayments, and liquidation scenarios.  \n- Clear documentation instructing developers and AI agents on configuring and invoking these new actions.\n\n**Bounty**  \n- **Estimated Reward**: \\$2,000 in TON  \n\nFor further discussion or clarification, reach out in the bounty program working group: [Telegram: @ton_ai_bounty](https://t.me/ton_ai_bounty).", "CLOSED", 0, "alefmanvladimir", "2025-01-30T09:43:44Z", "2025-03-09T15:33:00Z", "2025-03-08T01:16:16Z", "elizaos/eliza", "2025-04-14 21:54:43"]
["I_kwDOMT5cIs6l1uVW", 2181, "The two Twitters, which also used eliza, had endless conversations", "I set up 2 twitter accounts\r\n\r\nBut while they were commenting on each other\r\n\r\nIt goes on and on indefinitely along a topic\r\n\r\nA lot of tokens are consumed", "CLOSED", 0, "espoir1989", "2025-01-12T07:08:20Z", "2025-03-10T08:18:25Z", "2025-03-02T01:56:03Z", "elizaos/eliza", "2025-04-14 21:54:43"]
["I_kwDOMT5cIs6lNuvi", 1939, "Question about action's validate function?", "**Question about action's validate function**\r\n\r\nI wrote a custom Action, then implemented the validate and handle functions of the Action interface. However, when interacting with the model, the ai agent calls my custom Action's validate function, which returns false. Initially, I thought that if validate returns false, the handle function of the Action should not execute. But from the logs I output, it appears that the handle function is also executed. Why is this happening?\r\nIf the validate function returns false, but the action still executes, what is the purpose of the return value of validate?\r\n\r\n![image](https://github.com/user-attachments/assets/1b195d5b-9488-49dc-aa24-53b1e3b41aea)\r\nThe description in the documentation is also not clear enough.", "CLOSED", 0, "yuucyf", "2025-01-07T03:53:08Z", "2025-03-14T08:32:48Z", "2025-01-13T09:25:47Z", "elizaos/eliza", "2025-04-14 21:54:43"]
["I_kwDOMT5cIs6kosEW", 1557, "Eliza X Posting GENERATE_IMAGE in her tweets, should attach image to tweet post instead", "**Describe the bug**\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\nEliza is outputting text to GENERATE_IMAGE instead of actually generating an image on twitter\r\n- ex [here](https://x.com/elizawakesup/status/1873253691618410976) and [here](https://x.com/elizawakesup/status/1873173558459081096)\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n\r\n**Expected behavior**\r\na picture should be attached to the tweet instead of the GENERATE_IMAGE text\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n![image](https://github.com/user-attachments/assets/553b0e9c-8a84-4f50-9e90-9b0e53bb3a93)\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n", "CLOSED", 0, "yqj2k", "2024-12-29T06:43:55Z", "2025-03-12T13:40:17Z", "2025-01-06T05:33:59Z", "elizaos/eliza", "2025-04-14 21:54:43"]
["I_kwDOMT5cIs6tBp4M", 3798, "Telegram client unable to connect to bot API interface.", "**Describe the bug**\n\nThe telegram client isn't able to connect to telegram API interface. This is due to the HTTPS request is being sent using IPv6 by default. In the case of a system not configured for IPv6, the request can't connected to API endpoint and therefore fails.\n\n**To Reproduce**\n\n- Ensure system doesn't support IPv6 - verify by pinging using ip6 \"traceroute6 google.com\" \n- Ensure character is using telegram client (install plugin and configure via character json file)\n\n**Expected behavior**\n\nWhen starting a character via pnpm start, it exits with a failure displaying a fetch error code \"ETIMEDOUT\" to the following url - https://api.telegram.org/bot838743:[REDACTED]/getMe \n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/76fbb6ed-59ab-4983-b5b0-633ad03af089)\n\n**Additional context**\n\n![Image](https://github.com/user-attachments/assets/46470a47-1cf4-4671-8dcd-906c4bb89bf8)\n\nI found a solution by forcing the telegramClient to use IPv4 by adding the following changes to Telegraf options (in above screenshot). I don't know if this is the best solution as you probably want to try IPv6 and then revert to IPv4 if its unsuccessful. My understanding is it should be doing this, though this isn't happening. Possibly increasing a timeout to allow both attempts might resolve the solution, requires more analysis.     \n", "CLOSED", 0, "lagrossi", "2025-03-07T12:33:11Z", "2025-03-08T01:15:19Z", "2025-03-08T01:15:19Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6tBiy1", 3797, "Enabling default RAG does not work with Postgres adapter", "## Description\nWhen enabling RAG via the characterfile and using the postgres db adapter, I get the two following errors\n\n```\nERROR: Error in getCachedEmbeddings:\n    tableName: \"messages\"\n    fieldName: \"content\"\n    error: \"levenshtein argument exceeds maximum length of 255 characters\"\n```\n\nand \n\n```\nERROR: Database operation failed (attempt x/3):\n    nextRetryIn: \"2.6s\"\n    error: \"Invalid embedding dimension: expected 384, got 0\n```\n\nI'm more concerned about the first error however. `getEmbeddingsConfig` specifically sets the embeddings length to `384` when the default embeddings model is used. Even if I used a different model, such as OpenAI's embeddings, those are even longer and thus still wouldn't work. Thus it seems like the Postgres adapter unusable with RAGs as long as it is using `levenshtein`. \n\nI know there is a proposed fix [here](https://github.com/elizaOS/eliza/issues/3441), however that still does not address the whole issue as it caps the length of the string to 255 chars and leaves the rest out (thus that is not indexed).\n\nRegarding the second error I am actually unsure where it originates.\n\n## Config info\nI'm using Eliza v0.25.9 + newest Postgres adapter.\n", "CLOSED", 0, "soyrubio", "2025-03-07T12:18:33Z", "2025-03-08T03:15:58Z", "2025-03-08T03:15:57Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6s_o0E", 3795, "Update GAIA_API_KEY in example .env", "**Describe the bug**\n\nIn the latest version, I noticed that Eliza has been updated to use an authentication key GAIANET. However, I couldn't find an example of the updated API key in the .env file.\n\n**Screenshots**\n\n<img width=\"751\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/6b85ce34-ef13-44f8-b9f3-df3195781762\" />\n\nIt should show include GAIA_API_KEY in example .env", "CLOSED", 0, "karasbuilder", "2025-03-07T08:37:03Z", "2025-03-08T03:26:26Z", "2025-03-08T03:26:25Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6s_ETh", 3794, "Please help me and optimize the plugin usage tutorial", "After eliza upgraded V2, I didn't know how to use the plugin properly.\n\nTake plugins-twitter, for example\u3002\n\nAccording to the requirements of the [document](https://elizaos.github.io/eliza/docs/core/plugins/), I added the project 's dependencies\n\nThen run pnpm install to download the plugin.\n\nIn the agent configuration file, add \"clients\": [\"twitter\"],\n\nafter configuring the account information in.env and running it, the plugin does not work properly.\n\n\nI went to the [plugin repository](https://github.com/elizaos-plugins/client-twitter) and found another Step: Step 2: Initialize the Client\n\nFrustratingly, I was stupid enough not to know in which file this line of code should be written.\n\nI tried to write to the /agent/src/index.ts file\n\n<img width=\"506\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f4be8915-0bc9-44c8-b87a-b8921fa45328\" />\n\nGot an error after running\u3002\n\nThat's all, thanks for reading,", "CLOSED", 0, "Finyu", "2025-03-07T07:14:53Z", "2025-03-08T01:15:18Z", "2025-03-08T01:15:18Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6sudat", 3783, "agent won't post to Twitter, Unsupported provider: venice", "**Describe the bug**\n\n<!-- A clear and concise description of what the bug is. -->\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "Ulysseus", "2025-03-05T16:50:34Z", "2025-03-08T01:15:18Z", "2025-03-08T01:15:18Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6sr3ZB", 3779, "parseJSONObjectFromText broke in or before 0.25.9", "**Describe the bug**\n\n`parseJSONObjectFromText` broke for me in or before 0.25.9\nIt was working OK for me in 0.18\n\nThe problem imo is the `normalizeJSONString` function.\n\n**To Reproduce**\n\n1. Run `node` interpreter in your eliza repo.\n2. Run the following:\n```\nconst { parseJSONObjectFromText, cleanJsonResponse } = await import(\"@elizaos/core\");\n\nlet text = '```json{    \"success\": true,    \"result\": {        \"serviceAdCID\": \"zdpuB1ZVfhZFX4iaVhXkyhTuGUhPA1Ac3LuQdSWe9zcdXrKce\",        \"wallet\": \"9ovkK7WoiSXyEJDM5cZG3or3W95bdzZLDDHhuMgSJT9U\",        \"desiredServiceID\": \"Landing Page Creation\",        \"desiredUnitAmount\": \"1\"    }}```'\n\nparseJSONObjectFromText(text)\n```\nYou will see an error, and then the code tries to handle it by doing `extractAttributes(text)`\nBut `extractAttributesText` cannot handle nested objects.\n\n![Image](https://github.com/user-attachments/assets/2cb0d3bc-c662-4f4b-b3b3-59ab0e2f02a0)\n\n**Expected behavior**\n\nIn my opinion, running the text through `cleanJsonResponse` and then `JSON.parse` should be enough, as `JSON.parse` handles a lot of the stuff that `normalizeJSONString` is trying to handle.\n\nAdditionally, the code should fail if `JSON.parse` can't parse it, instead of trying to fix the problem with `extractAttributesText`.\nThat way the user can fix their AI prompt.\n\n![Image](https://github.com/user-attachments/assets/da93c13d-ede8-4e50-bc83-5e069dfa36b3)\n\n\n**Additional context**\n\nHappy to help with this and write some test cases around it. Documenting the issue in case someone gets to it before me.", "CLOSED", 0, "notorious-d-e-v", "2025-03-05T12:20:46Z", "2025-03-07T07:03:18Z", "2025-03-07T07:03:17Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6sq33W", 3776, "Add create pool, open position and add/remove liquidity in plugin-sui", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\nPlease add more defi basic features in plugin-sui, like:\n- create clmm pool\n- open position with liquidity\n- remove liquidity\n- more..\n\n**Describe the solution you'd like**\nNone\n<!-- A clear and concise description of what you want to happen. -->\n\n**Describe alternatives you've considered**\nNone\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\nNone\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "0xBondSUI", "2025-03-05T10:30:17Z", "2025-03-08T01:15:18Z", "2025-03-08T01:15:18Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6sq2aV", 3775, "Support swap in any token pair in plugin-sui", "**Is your feature request related to a problem? Please describe.**\n\nNow, plugin-sui just support swap in sui and usdc, i want to swap between any token pairs.\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\n\n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\n\nNone\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\nNone\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n\nNone\n", "CLOSED", 0, "0xBondSUI", "2025-03-05T10:27:56Z", "2025-03-08T01:15:17Z", "2025-03-08T01:15:17Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6sXE35", 3758, "Telegram client not working, no initialization message or errors", "I am trying to connect my Agent to my Telegram Bot, from Telegram side bot isn't answering.\nI checked [client-telegram](https://github.com/elizaos-plugins/client-telegram) and saw that there should be:\n` Startup Logging: Logs successful initialization of the Telegram client for better debugging.` but for some reason there's not a single thing about Telegram. My top of json looks like this:\n\n![Image](https://github.com/user-attachments/assets/ed4bac71-899e-4db4-a0dc-afa0dd999559)\n\n\nI've added `TELEGRAM_BOT_TOKEN` to both json and .env, I have needed dependency installed which is currently on this version `@elizaos/client-telegram 0.25.6-alpha.1` and from Telegram side Bot is responding to /getMe\n\nIs there something that I've missed of requirements?", "CLOSED", 0, "JJOptimist", "2025-03-03T16:33:43Z", "2025-03-07T07:13:20Z", "2025-03-07T07:13:20Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6sF-Sr", 3723, "Add plugin-evm", "**Describe the bug**\nI got a bug, when add `plugin-evm`\n\nthis bug\n```\n\u279c  ~  npx elizaos plugins add @elizaos-plugins/plugin-evm\n(node:99379) ExperimentalWarning: CommonJS module /Users/quanghuy/.nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/debug/src/node.js is loading ES Module /Users/quanghuy/.nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/supports-color/index.js using require().\nSupport for loading ES Module in require() is an experimental feature and might change at any time\n(Use `node --trace-warnings ...` to show where the warning was created)\nusing git version 2.46.0\nMaking sure plugin has access to @elizaos/core\nnode:internal/errors:983\n  const err = new Error(message);\n              ^\n\nError: Command failed: pnpm add @elizaos/core@workspace:* --filter ./packages/plugin-evm\n    at genericNodeError (node:internal/errors:983:15)\n    at wrappedFn (node:internal/errors:537:14)\n    at checkExecSyncError (node:child_process:882:11)\n    at execSync (node:child_process:954:15)\n    at Command.<anonymous> (/Users/quanghuy/Desktop/learn/eliza/packages/cli/index.js:87:33)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5) {\n  status: 1,\n  signal: null,\n  output: [\n    null,\n    Buffer(454) [Uint8Array] [\n       47,  85, 115, 101, 114, 115,  47, 113, 117,  97, 110, 103,\n      104, 117, 121,  47,  68, 101, 115, 107, 116, 111, 112,  47,\n      108, 101,  97, 114, 110,  47, 101, 108, 105, 122,  97,  47,\n      112,  97,  99, 107,  97, 103, 101, 115,  47, 112, 108, 117,\n      103, 105, 110,  45, 101, 118, 109,  58,  10, 226, 128, 137,\n       69,  82,  82,  95,  80,  78,  80,  77,  95,  87,  79,  82,\n       75,  83,  80,  65,  67,  69,  95,  80,  75,  71,  95,  78,\n       79,  84,  95,  70,  79,  85,  78,  68, 226, 128, 137,  32,\n       73, 110,  32, 112,\n      ... 354 more items\n    ],\n    Buffer(0) [Uint8Array] []\n  ],\n  pid: 99407,\n  stdout: Buffer(454) [Uint8Array] [\n     47,  85, 115, 101, 114, 115,  47, 113, 117,  97, 110, 103,\n    104, 117, 121,  47,  68, 101, 115, 107, 116, 111, 112,  47,\n    108, 101,  97, 114, 110,  47, 101, 108, 105, 122,  97,  47,\n    112,  97,  99, 107,  97, 103, 101, 115,  47, 112, 108, 117,\n    103, 105, 110,  45, 101, 118, 109,  58,  10, 226, 128, 137,\n     69,  82,  82,  95,  80,  78,  80,  77,  95,  87,  79,  82,\n     75,  83,  80,  65,  67,  69,  95,  80,  75,  71,  95,  78,\n     79,  84,  95,  70,  79,  85,  78,  68, 226, 128, 137,  32,\n     73, 110,  32, 112,\n    ... 354 more items\n  ],\n  stderr: Buffer(0) [Uint8Array] []\n}\n\nNode.js v23.3.0\n\n```\n\n", "CLOSED", 0, "quanghuynguyen1902", "2025-02-28T14:06:27Z", "2025-03-07T07:13:30Z", "2025-03-07T07:13:29Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6r49Rt", 3702, "No REST API backend", "Description:\nI followed all the steps in the quickstart tutorial, but can interact with agent.\n\nSteps to Reproduce:\n```\ngit clone https://github.com/elizaos/eliza.git\ncd eliza\ngit checkout $(git describe --tags --abbrev=0)\ngit submodule update --init\ncp .env.example .env\n```\nThen setup .env file, provide OPENAPI key, set use_openapi_embedding to True\n```\npnpm install --no-frozen-lockfile\npnpm build\npnpm start --characters=\"eliza/characters/eternalai.character.json\"\npnpm start:client\n```\n\nI cant see vscode show the port that I expect REST API will bound to\nHere is the log after I run pnpm start --characters=\"eliza/characters/eternalai.character.json\"\n\u2009WARN\u2009 Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v23.6.0\",\"pnpm\":\"9.12.3\"})\n\n> eliza@ start /home/khanh/aidenlabs/eliza\n> pnpm --filter \"@elizaos/agent\" start --isRoot \"--characters=eliza/characters/eternalai.character.json\"\n\n.                                        | \u2009WARN\u2009 Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v23.6.0\",\"pnpm\":\"9.15.0\"})\ndocs                                     | \u2009WARN\u2009 Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v23.6.0\",\"pnpm\":\"9.15.0\"})\n\n> @elizaos/agent@0.25.8 start /home/khanh/aidenlabs/eliza/agent\n> node --loader ts-node/esm src/index.ts \"--isRoot\" \"--characters=eliza/characters/eternalai.character.json\"\n\n(node:2679015) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\n(Use `node --trace-warnings ...` to show where the warning was created)\n(node:2679015) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n[2025-02-27 08:45:26] INFO: Loading embedding settings:\n    USE_OPENAI_EMBEDDING: \"TRUE\"\n    USE_OLLAMA_EMBEDDING: \"\"\n    OLLAMA_EMBEDDING_MODEL: \"mxbai-embed-large\"\n(node:2679015) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\n[2025-02-27 08:45:26] INFO: Loading character settings:\n    ARGV: [\n      \"/home/khanh/.nvm/versions/node/v23.6.0/bin/node\",\n      \"/home/khanh/aidenlabs/eliza/agent/src/index.ts\",\n      \"--isRoot\",\n      \"--characters=eliza/characters/eternalai.character.json\"\n    ]\n    CWD: \"/home/khanh/aidenlabs/eliza/agent\"\n[2025-02-27 08:45:26] INFO: Parsed settings:\n    USE_OPENAI_EMBEDDING: \"TRUE\"\n    USE_OPENAI_EMBEDDING_TYPE: \"string\"\n    USE_OLLAMA_EMBEDDING: \"\"\n    USE_OLLAMA_EMBEDDING_TYPE: \"string\"\n    OLLAMA_EMBEDDING_MODEL: \"mxbai-embed-large\"\n[2025-02-27 08:45:26] INFO: Trying paths:\n    0: {\n      \"path\": \"eliza/characters/eternalai.character.json\",\n      \"exists\": false\n    }\n    1: {\n      \"path\": \"/home/khanh/aidenlabs/eliza/agent/eliza/characters/eternalai.character.json\",\n      \"exists\": false\n    }\n    2: {\n      \"path\": \"/home/khanh/aidenlabs/eliza/agent/agent/eliza/characters/eternalai.character.json\",\n      \"exists\": false\n    }\n    3: {\n      \"path\": \"/home/khanh/aidenlabs/eliza/agent/src/eliza/characters/eternalai.character.json\",\n      \"exists\": false\n    }\n    4: {\n      \"path\": \"/home/khanh/aidenlabs/eliza/agent/src/characters/eternalai.character.json\",\n      \"exists\": false\n    }\n    5: {\n      \"path\": \"/home/khanh/aidenlabs/eliza/agent/characters/eternalai.character.json\",\n      \"exists\": false\n    }\n    6: {\n      \"path\": \"/home/khanh/aidenlabs/eliza/characters/eternalai.character.json\",\n      \"exists\": true\n    }\n[2025-02-27 08:45:26] INFO: Successfully loaded character from: /home/khanh/aidenlabs/eliza/characters/eternalai.character.json\n[2025-02-27 08:45:26] INFO: TrollDetective.Exe(025e0996-69d7-0dce-8189-390e354fd1c1) - Initializing AgentRuntime with options:\n    character: \"TrollDetective.Exe\"\n    modelProvider: \"openai\"\n    characterModelProvider: \"openai\"\n[2025-02-27 08:45:26] INFO: TrollDetective.Exe(025e0996-69d7-0dce-8189-390e354fd1c1) - Setting Model Provider:\n    characterModelProvider: \"openai\"\n    optsModelProvider: \"openai\"\n    finalSelection: \"openai\"\n[2025-02-27 08:45:26] INFO: TrollDetective.Exe(025e0996-69d7-0dce-8189-390e354fd1c1) - Selected model provider: openai\n[2025-02-27 08:45:26] INFO: TrollDetective.Exe(025e0996-69d7-0dce-8189-390e354fd1c1) - Selected image model provider: openai\n[2025-02-27 08:45:26] INFO: TrollDetective.Exe(025e0996-69d7-0dce-8189-390e354fd1c1) - Selected image vision model provider: openai\n[2025-02-27 08:45:26] INFO: Initializing SQLite database at /home/khanh/aidenlabs/eliza/agent/data/db.sqlite...\n[2025-02-27 08:45:26] INFO: Using Database Cache...\n[2025-02-27 08:45:26] INFO: Run `pnpm start:client` to start the client and visit the outputted URL (http://localhost:5173) to chat with your agents. When running multiple agents, use client with different port `SERVER_PORT=3001 pnpm start:client`\n\nNo line show that rest API is working\nPlease help", "CLOSED", 0, "lqkhanh195", "2025-02-27T08:46:15Z", "2025-03-07T07:13:42Z", "2025-03-07T07:13:42Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6ryGXO", 3689, "wallet issues", "i keep getting this issue\ncan i get some help please r in EVM wallet provider: Error: Invalid chain name\n    at _WalletProvider.genChainFromName (file:///Users/adamwilliams/eliza/node_modules/.pnpm/@elizaos+plugin-evm@0.25.6-alpha.1_@google-cloud+vertexai@1.9.3_encoding@0.1.13__@langchain+c_li2r2iulvfp4qkhfwkh6v5bwxe/node_modules/@elizaos/plugin-evm/dist/index.js:190:13)\n    at genChainsFromRuntime (file:///Users/adamwilliams/eliza/node_modules/.pnpm/@elizaos+plugin-evm@0.25.6-alpha.1_@google-cloud+vertexai@1.9.3_encoding@0.1.13__@langchain+c_li2r2iulvfp4qkhfwkh6v5bwxe/node_modules/@elizaos/plugin-evm/dist/index.js:211:34)\n    at initWalletProvider (file:///Users/adamwilliams/eliza/node_modules/.pnpm/@elizaos+plugin-evm@0.25.6-alpha.1_@google-cloud+vertexai@1.9.3_encoding@0.1.13__@langchain+c_li2r2iulvfp4qkhfwkh6v5bwxe/node_modules/@elizaos/plugin-evm/dist/index.js:226:18)\n    at Object.get (file:///Users/adamwilliams/eliza/node_modules/.pnpm/@elizaos+plugin-evm@0.25.6-alpha.1_@google-cloud+vertexai@1.9.3_encoding@0.1.13__@langchain+c_li2r2iulvfp4qkhfwkh6v5bwxe/node_modules/@elizaos/plugin-evm/dist/index.js:258:36)\n    at file:///Users/adamwilliams/eliza/packages/core/dist/index.js:8276:31\n    at Array.map (<anonymous>)\n    at getProviders (file:///Users/adamwilliams/eliza/packages/core/dist/index.js:8275:66)\n    at AgentRuntime.composeState (file:///Users/adamwilliams/eliza/packages/core/dist/index.js:13953:13)\n    at async file:///Users/adamwilliams/eliza/packages/client-direct/dist/index.js:4688:25\n[2025-02-26 15:39:37] INFO: Generating text with options:\n    modelProvider: \"hyperbolic\"\n    model: \"large\"\n[2025-02-26 15:39:37] INFO: Selected model: meta-llama/Llama-3.2-3B-Instruct\nReceived response from OpenAI model.\n[2025-02-26 15:39:40] INFO: Executing handler for action: CONTINUE\n\n", "CLOSED", 0, "Adz30", "2025-02-26T15:40:32Z", "2025-03-08T01:15:17Z", "2025-03-08T01:15:17Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6ruhie", 3685, "Twitter media is being ignored when discord approvals is enabled", "**Describe the bug**\n\nWhen Eliza is configured to post messages to Discord for approval, images are not sent. Images are not visible in both Discord and Twitter.\n\n**To Reproduce**\n\n- Enable Discord approvals\n- Create a tweet that includes a media file, for example an image.\n- Approve the message in Discord\n- Check the message on Twitter, it is not included.\n\n**Expected behavior**\n\nIf the original message contained any media files, they should appear in the message when posted to Twitter.\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "tomicvladan", "2025-02-26T10:39:38Z", "2025-03-08T03:17:27Z", "2025-03-08T03:17:25Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6rtEQ4", 3683, "Utilize ChatGPT assistant API keys", "Can ElizaOS integrate with ChatGPT assistant API keys?\n\nI want to use custom model with elizaOS but not sure if it capable or how can I do it since .env file contain only OPEN_API_KEYS and OPEN_API_URL.", "CLOSED", 0, "0xJACKSON-dev", "2025-02-26T08:36:51Z", "2025-03-08T03:24:20Z", "2025-03-08T03:24:20Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6rq1vA", 3679, "Not loading any character files", "When attempting to load any character file, including the provided one for c3po, I receive the error:\n\n[2025-02-26 04:02:21] INFO: Processing knowledge for  VAL  -  Medical equipment operation\n[2025-02-26 04:06:17] ERROR: Error starting agent for character VAL:\n[2025-02-26 04:06:17] ERROR:\n    err: {\n      \"type\": \"RangeError\",\n      \"message\": \"Invalid array length\",\n      \"stack\":\n          RangeError: Invalid array length\n              at Array.push (<anonymous>)\n              at splitText (file:///home/jza/agent/eliza/packages/core/dist/index.js:7239:16)\n              at splitChunks (file:///home/jza/agent/eliza/packages/core/dist/index.js:7227:20)\n              at Object.set (file:///home/jza/agent/eliza/packages/core/dist/index.js:12556:29)\n              at async AgentRuntime.processCharacterKnowledge (file:///home/jza/agent/eliza/packages/core/dist/index.js:13310:13)\n              at async AgentRuntime.initialize (file:///home/jza/agent/eliza/packages/core/dist/index.js:13282:17)\n              at async startAgent (file:///home/jza/agent/eliza/agent/src/index.ts:552:9)\n              at async startAgents (file:///home/jza/agent/eliza/agent/src/index.ts:599:13)\n    }\n[2025-02-26 04:06:17] ERROR: Error starting agents:\n\nAs seen in the screenshot\n\n![Image](https://github.com/user-attachments/assets/01a552a8-eca2-4893-9915-1f983a0e30b8)\n", "CLOSED", 0, "jgarrettvml", "2025-02-26T04:10:06Z", "2025-03-08T03:24:01Z", "2025-03-08T03:24:01Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6rgrBc", 3661, "Docker file issue:  Invalid cachestore", "**Describe the bug**\n\n<!-- A clear and concise description of what the bug is. -->\nI published a docker image from macOS using the command `docker buildx build --platform linux/amd64 -t eliza-starter:v1 --load .\n` and it build the image. when i run it using `docker run --env-file .env sha256:XYZ` it is throwing me this error: \n [\":no_entry: Error: Invalid cache store: database # Defaults to database. Other available cache store: redis and filesystem or required configuration missing.\"]\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\nNOTE: I deleted redis and all other adapters/clients/plugins that i didn't want to use. ", "CLOSED", 0, "avdheshcharjan", "2025-02-25T08:00:12Z", "2025-03-08T01:15:16Z", "2025-03-08T01:15:16Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6rHDjm", 3639, "Type Alias \"Adapter\" is not defined", "**Describe the bug**\n\nThe type alias \"Adapter\" described at [here](https://elizaos.github.io/eliza/api/type-aliases/Adapter/) is not defined in https://github.com/elizaOS/eliza/blob/main/packages/core/src/types.ts#L637", "CLOSED", 0, "Luks3110", "2025-02-22T13:52:37Z", "2025-03-07T07:14:32Z", "2025-03-07T07:14:32Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6q-8Ul", 3628, "agent isn't responding based on the provided knowledge.", "\nI'm building a Twitter agent and have configured the character file as follows:\n```\nsettings: {\n    \"voice\": {\n        \"model\": \"en_US-male-medium\"\n    },\n    ragKnowledge: true\n},\nplugins: [],\nknowledge: [\n    {\n        path: \"/{mr.agent}/docs.pdf\",\n        shared: false\n    }\n],\n```\nI've set up the above configuration to enable the RAG knowledge base for the agent.\n\nThe provided knowledge document is being processed (I can see logs), but it seems that retrieval isn't working\u2014the agent isn't responding based on the provided knowledge. (The PDF is only 5 pages long.)\n\nAm I missing any additional configurations? Is there anything that needs to be set up in AgentRunTime?\n\nAny insights would be appreciated!\n\nIs there any working example of knowledge based agent?\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "thopatevijay", "2025-02-21T10:27:21Z", "2025-03-08T01:15:16Z", "2025-03-08T01:15:16Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6q-aYe", 3627, "Add Paradex DEX Integration for Automated Trading", "**Is your feature request related to a problem? Please describe.**\nTrading on Paradex currently requires manual interaction through their interface. Eliza needs a plugin to enable automated trading capabilities on Paradex, allowing for programmatic order management and market analysis.\n\n**Describe the solution you'd like**\nAdd a Paradex plugin to Eliza with the following components:\n\nActions:\n1. Place Order\n   - Market/Limit orders\n   - Long/Short positions\n   - Support for all perpetual markets (BTC-USD-PERP, ETH-USD-PERP, etc.)\n   - Size and price specifications\n   - Example commands:\n     - \"Long 0.1 ETH\"\n     - \"Short 0.5 BTC at 96000\"\n     - \"Buy 1000 USDC worth of ETH\"\n     - \"Sell 0.2 ETH at 5000\"\n\n2. Cancel Order\n   - Cancel specific orders by ID\n   - Example commands:\n     - \"Cancel order 123456789\"\n     - \"Remove order xyz789\"\n\nProviders:\n1. Authentication\n   - JWT token management\n   - StarkNet account integration\n   - Secure private key handling\n\n2. Market Data\n   - BBO (Best Bid/Offer) provider\n   - Available markets provider\n   - Open orders provider\n   - Open positions provider\n   - Account balance provider\n\n**Describe alternatives you've considered**\n- Direct integration with Paradex API without Eliza\n- Using existing trading bots\n- Manual trading through Paradex UI\n\nThese alternatives lack the natural language processing capabilities and extensibility that Eliza provides.\n\n**Additional context**\n- Integration will be built on top of Paradex's v1 API\n- Will require secure environment variable management for private keys and API credentials\n- Plugin will follow Eliza's provider/action architecture pattern\n- All trading functions will include proper error handling and logging", "CLOSED", 0, "julienbrs", "2025-02-21T09:27:23Z", "2025-03-08T01:15:16Z", "2025-03-08T01:15:16Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6q-Qel", 3626, "WebService usage help", "I am trying to improve the quality if tweet post, so make it aware of recent info, I wanted to integrate tavily in twitter post generation. \nI imported web-search plugin and trying to access WebSearchService as mentioned [here](https://github.com/elizaOS/eliza/tree/main/packages/plugin-web-search\n). in  packages/client-twitter/src/post.ts\n\nBut it is not working. I have imported plugin at top\n\n`import { webSearchPlugin } from \"../../plugin-web-search\";\n`\n \nand below is the code I am trying to use.\n\n```\nfor (const searchQuery of searchTermList) {\n            //code to do web search\n\n            const webSearchService = new WebSearchService();\n            await webSearchService.initialize(runtime);\n            const results = await webSearchService.search(\n                searchQuery\n                // searchOptions\n            );\n }\n```\nI am getting error in importing only showing \n`Cannot find name 'WebSearchService'. Did you mean 'webSearchService'?ts(2552)\n`\n\nIs there any different approach should I follow ?", "CLOSED", 0, "lokendrasurya", "2025-02-21T09:08:38Z", "2025-03-08T01:15:15Z", "2025-03-08T01:15:15Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6q0ajB", 3614, "It is mostly replying \"I see a visual representation of a stylized illustration with a subtle background of digital elements\" for image and also for non image based tweet.", "I am running multiple agents, but one of my agent mostly replies below description like he is trying to understand image and for some time he does same for text based tweet, where my other agent understands and replies properly.\n\nRecent Replies \"\nI see a visual representation of a stylized illustration with a subtle background of digital elements, possibly featuring a clock or a timer, conveying a sense of anticipation and expectation in the world of [#PiNetwork](https://x.com/hashtag/PiNetwork?src=hashtag_click) and cryptocurrency.\"\nhttps://x.com/TheBitcoinSon/status/1892519722932908356\n\nWhere on same tweet my other agents works fine.\nhttps://x.com/gabbarsingh_ai/status/1892518688160465063\n\nI am using GROQ paid account and same API keys for both.\n\n\n<img width=\"641\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a3ef591d-c2b9-4ada-b9ea-66c0e91b42fa\" />\n\n\nOther Issues Link --Where it is saying same \"visual representation\"\nhttps://x.com/TheBitcoinSon/status/1892527643511361784\nhttps://x.com/TheBitcoinSon/status/1892527577891250207\nhttps://x.com/TheBitcoinSon/status/1892526398591385623\nhttps://x.com/TheBitcoinSon/status/1892526016251199837\nhttps://x.com/TheBitcoinSon/status/1892444826203017630\n\nConclusion - My agent https://x.com/TheBitcoinSon  always respond invalid message or his thinking in the reply and mostly it start with the text content \"I see a visual representation\".\n\n<img width=\"637\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/653bf01d-81c4-4be2-9362-3269d6a79fe2\" />\n\n\nAgent With Issue - https://x.com/TheBitcoinSon \nAgent Works Fine - https://x.com/gabbarsingh_ai \n", "CLOSED", 0, "sharif331", "2025-02-20T11:19:26Z", "2025-03-08T16:19:22Z", "2025-03-08T03:14:44Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qzFoz", 3610, "Fix plugin import from plugin registry", "**Describe the bug**\n\n<!-- A clear and concise description of what the bug is. -->\n\nImporting plugins from the plugin registry doesn't work on develop. Due to the fact that the plugin names changed from `@elizaos/plugin-<>` to `@elizaos-plugins/plugin-<>`\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n1. `npx elizaos plugins add @elizaos-plugins/plugin-compass`\n2. `pnpm run build`\n3. add `@elizaos-plugins/plugin-compass` to character file\n4. [Optional], make [this](https://github.com/royalnine/eliza/blob/b0586346b05adce86a24802b07aa8d62d6d35e89/agent/src/index.ts#L377-L380) print the error stack:\n```\nelizaLogger.error(\n                        `Failed to import plugin: ${plugin}`,\n                        importError.stack || importError\n                    );\n```\n\n**Expected behavior**\n\nPlugin import should work on the new plugins from the plugin registry\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "royalnine", "2025-02-20T09:04:01Z", "2025-03-08T01:15:15Z", "2025-03-08T01:15:15Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qvXQm", 3604, "bug: unclear readme in client-direct", "**Describe the bug**\n\nhttps://github.com/elizaOS/eliza/tree/develop/packages/client-direct/src\nseems more related to a fine-tuning plugin, not the direct client.", "CLOSED", 0, "madjin", "2025-02-19T22:37:17Z", "2025-03-08T01:15:15Z", "2025-03-08T01:15:15Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qpxuH", 3596, "Key error of map in Skeleton Item of the AppSidebar.", "I am getting the error on the AppSidebar.\nIn AppSidebar, to render SkeletonItem, we are using map function.\nIn this component, key is set to \"skeleton-item\", but it must be unique.\n\n![Image](https://github.com/user-attachments/assets/9a4e740a-a061-4a3b-b95f-b836b2ebf805)", "CLOSED", 0, "0xcodercrane", "2025-02-19T11:41:54Z", "2025-03-08T03:23:02Z", "2025-03-08T03:23:01Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qmWda", 3588, "Issue with Controlling Reply Length and Single Tweet Format", "**Is your feature request related to a problem? Please describe.**\n\nI am using Eliza to interact with target users on Twitter, and every time I reply to a comment, the response is split into a 2-3 tweet thread. I see in the code that the reply content is automatically split into multiple tweets if it exceeds 280 characters.\n\nI have tried adjusting the `OPENAI_MAX_TOKENS=65` configuration in OpenAI, but it doesn\u2019t seem to solve the problem. \n\n**Describe the solution you'd like**\n\nIs there a parameter or setting to limit the reply content to a maximum of 280 characters, so that it doesn\u2019t get split into multiple tweets?\n\n**Describe alternatives you've considered**\n\nFor paid users, a single tweet can exceed 280 characters. Is there any other way to ensure the reply stays as a single tweet, aside from modifying the 280-character limit in the code?\n\n**Additional context**\n\nOPENAI_MAX_TOKENS=65", "CLOSED", 0, "kent-neo", "2025-02-19T04:21:47Z", "2025-03-08T03:22:40Z", "2025-03-08T03:22:39Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qmVFR", 3587, "Issue with Automatic Reply to Twitter Thread Tweets", "**Is your feature request related to a problem? Please describe.**\n\nI am using Eliza to interact with target users on Twitter. When a target user tweets a single tweet, my account responds automatically, which works fine. However, when the target user posts a thread (usually containing more than 5 tweets), my account fails to reply. I\u2019ve tried restarting the Eliza service immediately after the target user posts a thread, and sometimes the automatic reply works, but not every time.\n\n**Describe the solution you'd like**\n\nI would like the service to consistently respond to a user's tweet thread just like it does with single tweets, without the need to restart the service.\n\n**Describe alternatives you've considered**\n\nI\u2019ve tried adjusting the `TWITTER_POLL_INTERVAL` and other configuration options, but the issue persists. Restarting the service sometimes works but isn't reliable.\n\n**Additional context**\n\nMy current configuration is:\n```\nTWITTER_POLL_INTERVAL=3600\nTWITTER_TARGET_USERS=twitter_user1,twitter_user2,twitter_user3,twitter_user4,twitter_user5,twitter_user6\n```\n", "CLOSED", 0, "kent-neo", "2025-02-19T04:16:00Z", "2025-03-08T03:18:19Z", "2025-03-08T03:18:17Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qmJ0p", 3585, "feat: make eliza server URL configurable via env var when starting  eliza client", "**Is your feature request related to a problem? Please describe.**\n\n- When running the Eliza server that is served on anything other than `http://localhost:3000`\n- Eliza client is hardcoded to only connect to this URL\n\n**Describe the solution you'd like**\n\n- Make this configurable rather than hard coded\n\n**Describe alternatives you've considered**\n\n- What works is manually editing `const BASE_URL = ...` in `eliza/client/src/lib/api.ts`\n\n**Additional context**\n\nNil.\n", "CLOSED", 0, "bguiz", "2025-02-19T03:30:30Z", "2025-03-04T01:02:25Z", "2025-03-04T01:02:25Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qh7-R", 3578, "Repeated issue connecting front end and back end", "I am dealing with a recurring issue where the frontend disconnects from the backend when sending a chat message, leading to a CORS  issue. 1. My frontend is running on `localhost:5173`. 2. My backend  is expected to run on `localhost:3000`. 3. When I send a message, the frontend tries to call `http://localhost:3000/agents`, but the request gets blocked due to CORS and the front. 4. The moment I interact (e.g., send \"hello\"), the backend crashes or loses connection. Before this issue it disconnected and crashed before I even started, but adding 'proxy' localhost:3000 to client package-json helped establish the connection, except it is extremely unstable. Any ideas how to solve this bug? Local llama3.1 7B, no other models in current setup as I got frustrated with llama_local issues. Thanks", "CLOSED", 0, "henrikaxelsen", "2025-02-18T16:44:38Z", "2025-03-08T01:17:40Z", "2025-03-08T01:17:40Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qhIxK", 3576, "No work upload files 0G plugin", "[\"\u2713 Normalized action: zgupload\"]\n\n\u00a0[\"\u2139 Executing handler for action: ZG_UPLOAD\"]\n\n\u00a0\u2139 INFORMATIONS\n\u00a0 \u00a0ZG_UPLOAD action started\n\u00a0 \u00a0{\"messageId\":\"dd1a0a90-4dbe-00c8-9e72-5ffbfa88c53c\",\"hasState\":true,\"hasCallback\":true}\n\nError in generateObject: InvalidArgumentError [AI_InvalidArgumentError]: Invalid argument for parameter schema: Schema is required for object output.\n\u00a0 \u00a0 at validateObjectGenerationInput (file:///home/mioku/0g-eliza/packages/core/node_modules/ai/dist/index.mjs:1955:13)\n\u00a0 \u00a0 at generateObject (file:///home/mioku/0g-eliza/packages/core/node_modules/ai/dist/index.mjs:2051:3)\n\u00a0 \u00a0 at handleOpenAI (file:///home/mioku/0g-eliza/packages/core/dist/index.js:29609:18)\n\u00a0 \u00a0 at handleProvider (file:///home/mioku/0g-eliza/packages/core/dist/index.js:29573:26)\n\u00a0 \u00a0 at generateObject (file:///home/mioku/0g-eliza/packages/core/dist/index.js:29535:32)\n\u00a0 \u00a0 at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n\u00a0 \u00a0 at async Object.handler (file:///home/mioku/0g-eliza/packages/plugin-0g/dist/index.js:321:29)\n\u00a0 \u00a0 at async AgentRuntime.processActions (file:///home/mioku/0g-eliza/packages/core/dist/index.js:30964:17)\n\u00a0 \u00a0 at async file:///home/mioku/0g-eliza/packages/client-direct/dist/index.js:4490:13 {\n\u00a0 cause: undefined,\n\u00a0 parameter: 'schema',\n\u00a0 value: undefined,\n\u00a0 [Symbol(vercel.ai.error)]: true,\n\u00a0 [Symbol(vercel.ai.error.AI_InvalidArgumentError)]: true\n}\n\u00a0Regardless of the model, OpenAI, Anthropic, Grok, this error keeps occurring. \n\n", "CLOSED", 0, "mioku50", "2025-02-18T15:30:41Z", "2025-03-08T01:15:14Z", "2025-03-08T01:15:14Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qfrIZ", 3571, "Getting errors while install node module", "Hi, Team\nI am getting the issues while installing node module.\nnode version: 23.3.0\nnpm version: 10.9.0\n\nMy OS is windows 11.\n\n![Image](https://github.com/user-attachments/assets/a3b8d547-5816-41a7-887e-0d766af74789)\n\n\nHow can I fix this?", "CLOSED", 0, "0xcodercrane", "2025-02-18T13:16:27Z", "2025-03-08T03:19:45Z", "2025-03-08T03:19:44Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qeBhS", 3569, "Always connecting when set SERVER_PORT=3000 in .env and use `SERVER_PORT=3001 pnpm start:client`", "**Describe the bug**\n\nNow latest code commit is 81a35281b93d5e8ca0745e9d13a1943e9a90681b.\nOs: ubuntu\n\n**To Reproduce**\n```\npnpm install\npnpm start --character=\"xxx.json\"\n// new terminal \nSERVER_PORT=3000 pnpm start:client --host\nSERVER_PORT=3001 pnpm start:client --host  both try\n```\n**Expected behavior**\n\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/5a5eec15-bcee-4a5b-b20c-161da4783c18)\n\n![Image](https://github.com/user-attachments/assets/f84d9076-8893-4219-8896-0ba8042cd4b3)\n\n![Image](https://github.com/user-attachments/assets/c2490d88-c81c-4642-933e-0c4ddec8951e)\n\n**Additional context**\n\n", "CLOSED", 0, "0xCryptoZen", "2025-02-18T10:35:24Z", "2025-03-08T01:17:39Z", "2025-03-08T01:17:39Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qdnm9", 3567, "feat: enable .env to configure a default model provider for characters that do not specify a model", "**Feature request**\n\n- Allow `.env` file to configure a default LLM provider\n- Currently the character (JSON or otherwise) determines the LLM provider to use - OpenAI, OpenRouter, etc\n- Suggestion:\n    - Add a `DEFAULT_MODEL_PROVIDER` key to the `.env` file\n    - If a character does not configure a model provider, it will fall back on the one selected through `DEFAULT_MODEL_PROVIDER`\n\n**To Reproduce**\n\nIn the `.env` file, I set the following entries:\n```shell\nOPENROUTER_API_KEY=sk-or-v1-abcdefabcdefabcdefabcdefabcdefabcdef\nOPENROUTER_MODEL=meta-llama/llama-3.2-1b-instruct\n```\n(replace placeholder API key with actual)\n\nNote that all of the `OPENAI_*` entries are left as default.\n\nThen start the server, point it to a character file.\n(Note that I can't really reproduce this, this is a feature request)\n\nThen start the web client.\n\nIn the web client, select the agent, and enter any chat message.\n\n**Expected behavior**\n\nIn client:\n- spinner appears momentarily\n- LLM response from OpenRouter is shown as the reply message from the agent\n\nIn server:\n- LLM request is made to OpenRouter, using the values set in `.env` for `OPENROUTER_API_KEY` and `OPENROUTER_MODEL`, plus user inputs\n- LLM response is received from OpenRouter\n\n**Actual behaviour**\n\nIn client:\n- Forever spinner\n\nIn server:\n- LLM request is made to OpenAi, ignoring the values set in `.env` for `OPENROUTER_API_KEY` and `OPENROUTER_MODEL`\n- LLM response is received from OpenAi: `{\"message\":\"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}}`\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "bguiz", "2025-02-18T09:52:57Z", "2025-03-08T01:17:39Z", "2025-03-08T01:17:39Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qcfqq", 3563, "Vulnerability related to defaiza", "Hello Team,\n\nI have found a vulnerability related to defaiza.\nAs the email to report vulnerability does not exist . I have raised an issue here .\nKindly let me know how to proceed.\n", "CLOSED", 0, "faeeq", "2025-02-18T07:39:50Z", "2025-03-08T03:16:14Z", "2025-03-08T03:16:12Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qcYWF", 3562, "Misleading and diverging instructions in client-twitter/src/interactions.ts", "**Describe the bug**\n\nIn https://github.com/elizaos/eliza/blob/main/packages/client-twitter/src/interactions.ts the prompt template tells \"just respond with \"true\" or \"false\" and then later say respond with options....\n########################\nexport const twitterShouldRespondTemplate = (targetUsersStr: string) =>\n    `# INSTRUCTIONS: Determine if {{agentName}} (@{{twitterUserName}}) should respond to the message and participate in the conversation. Do not comment. Just respond with \"true\" or \"false\".\n\nResponse options are RESPOND, IGNORE and STOP.\n########################\n\nSome not so sharp models (gemini) always get stuck with \"true\" or \"false\" therefore agent gets stuck there. \n\ni removed just that last sentence and works without problem:\nhttps://github.com/amirmabhout/DataBarista_v0.1/blob/dev/packages/client-twitter/src/interactions.ts\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "amirmabhout", "2025-02-18T07:22:58Z", "2025-03-08T01:17:38Z", "2025-03-08T01:17:38Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qZUKx", 3556, "ERROR  run failed: command  exited (137) during build", "**Describe the bug**\n\nI'm trying to run pnpm build in WSL but I get this error:\n\n`Tasks:    4 successful, 141 total\nCached:    4 cached, 141 total\n  Time:    1m34.98s\nFailed:    @elizaos/plugin-arbitrage#build\n\n ERROR  run failed: command  exited (137)\n\u2009ELIFECYCLE\u2009 Command failed with exit code 137.`\n\n**To Reproduce**\n\nI am running WSL on Windows 11. I ran this command:\n`pnpm build`\n\n**Expected behavior**\n\nI should be able to finish the build without error\n", "CLOSED", 0, "KristofferGW", "2025-02-17T20:48:21Z", "2025-03-08T01:15:14Z", "2025-03-08T01:15:14Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qWLvJ", 3547, "Plugin for notion.so", "Implementation of a plugin for integration with notion.so\n", "CLOSED", 0, "cpereiramt", "2025-02-17T13:56:57Z", "2025-03-08T01:15:14Z", "2025-03-08T01:15:14Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qU8Vm", 3546, "RAG Search Error", "I have following error for RAG knowledge search, any idea how to solve it?\n\n`[RAG Search Error] Error: Error searching knowledge: Could not find the function public.search_knowledge(match_count, match_threshold, query_agent_id, query_embedding, search_text) in the schema cache`\n\nAdvice much appreciated!", "CLOSED", 0, "WNUMIK", "2025-02-17T11:47:35Z", "2025-03-08T03:21:47Z", "2025-03-08T03:21:46Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qPMV5", 3527, "advanced-sdk-ts wrong import", "**Describe the bug**\n\nThis import:\nhttps://github.com/elizaOS/eliza/blob/81a35281b93d5e8ca0745e9d13a1943e9a90681b/packages/plugin-coinbase/package.json#L24C1-L25C1\n\nMakes it impossible to correctly add @elizaos/agent to any new project because it indirectly depends on @elizaos/plugin-coinbase which depends on this specific local file. \n\n**To Reproduce**\n\n- Create an empty project\n- pnpm add @elizaos/agent\n- pnpm install\n\n**Expected behavior**\n\n@elizaos/agent is expected to be imported correctly.\n\n![Image](https://github.com/user-attachments/assets/6b249868-faed-48df-8d65-0d33ae9f8149)\n\n\n", "CLOSED", 0, "andyvalerio", "2025-02-16T13:41:11Z", "2025-03-08T01:15:13Z", "2025-03-08T01:15:13Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qNfOP", 3513, "Client shows blank page and errors", "**Describe the bug**\n\nFollowed instructions to install, agent starts correctly, started client but shows blank page and errors in console.\n\nerrors:\nUncaught SyntaxError: The requested module '/node_modules/.vite/deps/react-router.js?v=14e27ee7' does not provide an export named 'NavLink' (at app-sidebar.tsx:17:10\n\n\n**To Reproduce**\n\n\ngit clone https://github.com/elizaOS/eliza.git\ncd eliza\ngit checkout $(git describe --tags --abbrev=0)\npnpm install --no-frozen-lockfile\npnpm build\n\n< created new character file and .env>\n<started character>\n<character server starts without error>\nruns pnpm start:client in a new tab\n\nopens tab to 'http://localhost:5174/'\nblank page\n\nbrowser console shows:\n\n```\nUnable to set window.solana, try uninstalling Phantom.\n=@ inpage.js:26\ninpage.js:26 Unable to set window.phantom.solana, try uninstalling Phantom.\n@ inpage.js:26\napp-sidebar.tsx:17 \nUncaught SyntaxError: The requested module '/node_modules/.vite/deps/react-router.js?v=14e27ee7' does not provide an export named 'NavLink' (at app-sidebar.tsx:17:10\n:5173/assets/js/index.CucWK6IV.js:1 \n        \n        \n       GET http://localhost:5173/ net::ERR_CONNECTION_REFUSED\nping @ client:736\nwaitForSuccessfulPing @ client:749\n(anonymous) @ client:561\n        \n       GET http://localhost:5173/ net::ERR_NETWORK_IO_SUSPENDED\n```\n\n\n\n\nhttp://localhost:5173/\n\n\n**Expected behavior**\n\nThe client should start and display chat with agent.\n\n**Screenshots**\n\n\n**Additional context**\ncommit 81a35281b93d5e8ca0745e9d13a1943e9a90681b\ntag: v0.25.6-alpha.1\n", "CLOSED", 0, "kon-rad", "2025-02-15T19:03:21Z", "2025-03-08T01:17:37Z", "2025-03-08T01:17:37Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qJFKJ", 3504, "Twitter Profile Fetch Failure Eliza AI Agent with ProtonVPN on Ubuntu", "**### Description:**\nI am working on the Eliza AI agent by a16z on Ubuntu and encountered an error related to Twitter after following the installation and setup steps. I am using ProtonVPN CLI for IP masking, which is necessary for my environment.\n\n**### System Information:**\n\n- OS: Linux Ubuntu\n- VPN: ProtonVPN CLI\n- Node.js version: 23.3.0\n- pnpm version: 9.15.0\n- Python version: 3.10.12\n\n**### Steps to Reproduce:**\n\n1. Installed prerequisites using:\n\n```\nsudo apt update && sudo apt upgrade\nsudo apt install python3 python3-pip\nsudo ln -s /usr/bin/python3 /usr/bin/python\ncurl -fsSL https://deb.nodesource.com/setup_23.x | sudo -E bash -\nsudo apt-get install -y nodejs\nsudo npm install -g pnpm\nsudo apt install build-essential\n```\n\n2. Configured .env with Twitter and Gaianet details.\n\n```\n// twitter configuration\nTWITTER_USERNAME=####### \nTWITTER_PASSWORD=####### \nTWITTER_EMAIL=####### \nTWITTER_2FA_SECRET=\"####### \"\nTWITTER_COOKIES='[\n  {\"key\":\"auth_token\",\"value\":\"####### \",\"domain\":\".twitter.com\"},\n  {\"key\":\"ct0\",\"value\":\"####### \",\"domain\":\".twitter.com\"},\n  {\"key\":\"guest_id\",\"value\":\"####### \",\"domain\":\".twitter.com\"}\n]'\n\n//Gaianet Configuration\nGAIANET_MODEL=qwen72b\nGAIANET_SERVER_URL=https://qwen72b.gaia.domains/v1\nSMALL_GAIANET_MODEL=llama3b       # Default: llama3b\nSMALL_GAIANET_SERVER_URL=https://llama3b.gaia.domains/v1  # Default: https://llama3b.gaia.domains/v1\nMEDIUM_GAIANET_MODEL=llama      # Default: llama\nMEDIUM_GAIANET_SERVER_URL=https://llama8b.gaia.domains/v1 # Default: https://llama8b.gaia.domains/v1\nLARGE_GAIANET_MODEL=qwen72b       # Default: qwen72b\nLARGE_GAIANET_SERVER_URL=https://qwen72b.gaia.domains/v1  # Default: https://qwen72b.gaia.domains/v1\nGAIANET_EMBEDDING_MODEL=bge-small\nUSE_GAIANET_EMBEDDING=TRUE \n```\n\n3. Modified packages/core/src/defaultCharacter.ts for character customization.\n\n```\nname: \"My name\", \n    username: \"twitter_user_name\", \n    plugins: [],\n    clients: [],\n    modelProvider: ModelProviderName.LLAMALOCAL,\n    settings: {\n        secrets: {},\n        voice: {\n            model: \"en_US-hfc_female-medium\",\n        },\n.\n.\n.\n.\n.\n```\n\n4. Ran the following commands:\n\n```\npnpm install\npnpm build\npnpm start\n```\n\n5. Connected to ProtonVPN CLI.\nreference doc: https://protonvpn.com/support/linux-openvpn/\n\n**### Observed Error Logs:**\n\n```\n[2025-02-15 21:19:18] INFO: Initializing LlamaService...\n[2025-02-15 21:19:18] INFO: Using cached cookies\n[2025-02-15 21:19:21] INFO: Successfully logged in.\nError fetching Twitter profile: Error: Failed to perform request.\n    at requestApi (index.mjs:92:14)\n    at process.processTicksAndRejections (task_queues:105:5)\n    at async getProfile (index.mjs:387:15)\n    at async Scraper.getProfile (index.mjs:3259:17)\n    at async index.js:417:34\n    at async index.js:14:36\n    at async RequestQueue.processQueue (index.js:32:17)\n[2025-02-15 21:24:22] ERROR: Error starting agent for character Mehmood Sheikh:\n[2025-02-15 21:24:22] ERROR: \n    err: {\n      \"type\": \"Error\",\n      \"message\": \"Failed to perform request.\",\n      \"stack\":\n          Error: Failed to perform request.\n              at requestApi (index.mjs:92:14)\n              at process.processTicksAndRejections (task_queues:105:5)\n              at async getProfile (index.mjs:387:15)\n              at async Scraper.getProfile (index.mjs:3259:17)\n              at async index.js:417:34\n              at async index.js:14:36\n              at async RequestQueue.processQueue (index.js:32:17)\n    }\n[2025-02-15 21:24:22] ERROR: Error starting agents: \n```\n\n#### **_THIS ERROR SOLVED_\n```\n[2025-02-14 18:34:04] INFO: Mehmood Sheikh(6072c5e5-9c51-0aed-9294-00dc82392362) - Selected model provider: llama_local\n[2025-02-14 18:34:04] INFO: Mehmood Sheikh(6072c5e5-9c51-0aed-9294-00dc82392362) - Selected image model provider: llama_local\n[2025-02-14 18:34:04] INFO: Mehmood Sheikh(6072c5e5-9c51-0aed-9294-00dc82392362) - Selected image vision model provider: llama_local\n[2025-02-14 18:34:04] INFO: Initializing LlamaService...\n[2025-02-14 18:34:08] ERROR: Login attempt failed: {\"errors\":[{\"code\":399,\"message\":\"Incorrect. Please try again.\"}]}\n[2025-02-14 18:34:13] ERROR: Failed to login to Twitter. Retrying... (1 attempts left)\n[2025-02-14 18:34:13] ERROR: Login attempt failed: {\"errors\":[{\"code\":399,\"message\":\"Incorrect. Please try again.\"}]}\n[2025-02-14 18:34:13] ERROR: Failed to login to Twitter. Retrying... (0 attempts left)\n[2025-02-14 18:34:13] ERROR: Max retries reached. Exiting login process.\n[2025-02-14 18:34:13] ERROR: Error starting agent for character Mehmood Sheikh:\n[2025-02-14 18:34:13] ERROR: \n    err: {\n      \"type\": \"Error\",\n      \"message\": \"Twitter login failed after maximum retries.\",\n      \"stack\":\n          Error: Twitter login failed after maximum retries.\n              at _ClientBase.init (index.js:199:23)\n              at process.processTicksAndRejections (task_queues:105:5)\n              at async Object.start (index.js:7482:9)\n              at async initializeClients (index.ts:645:31)\n              at async startAgent (index.ts:1151:27)\n              at async startAgents (index.ts:1202:13)\n```\n\n**### What I Have Tried:**\n\n- Verified .env Twitter credentials.\n- Confirmed ProtonVPN connection is stable.\n- Rebuilt the project.\n- Tried several previously proposed solutions under the Issues section on Github but none worked.\n- Followed multiple YouTube tutorials but the same error persists.\n\n**### Expected Behavior:**\nSuccessful login to Twitter and agent initialization.\n\n**### Request for Help:**\nPlease guide me on resolving this Twitter issue, especially with ProtonVPN usage. Let me know if further information is needed. Thank you!", "CLOSED", 0, "MehmoodSheikh", "2025-02-14T18:59:00Z", "2025-03-08T01:15:13Z", "2025-03-08T01:15:13Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6qI5QQ", 3503, "Help with Obsidian Plugin", "**Describe the bug**\n\nI'm getting a 404 error and failure to validate a connection with the Obsidian API. I am wondering if anyone else has experience with using this plugin or the Obsidian REST API. \n\n**To Reproduce**\n\nI connected my API as well as the default port and URL (port 27123)\n\n**Expected behavior**\n\nThe agent should be able to search my obsidian notes and create a knowledge base from obsidian.\n\n\nAny help would be greatly appreciated. \n\nMy obsidian keys and url are being passed to my agent via the secrets section of the character file.", "CLOSED", 0, "wolfskyknight", "2025-02-14T18:28:14Z", "2025-03-08T01:15:13Z", "2025-03-08T01:15:13Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6p7VH4", 3473, "Let's bring exSAT blockchain to eliza", "**Is your feature request related to a problem? Please describe.**\n\nAdd support with exSAT with eliza. This shoud be plugin.\n\n**Describe the solution you'd like**\n\nAdd plugin_exSAT\n\nI think I can do this feature. \ud83d\ude04\n\n", "CLOSED", 0, "jeasonzhang-eth", "2025-02-13T12:29:15Z", "2025-03-08T01:15:12Z", "2025-03-08T01:15:12Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6p4bqR", 3469, "pnpm build failure on macOS 15.3", "**Describe the bug**\nInstallation fails when attempting to install @elizaos/plugin-pyth-data, likely due to a Zod import error during the build process.\n\n**To Reproduce**\n1. Clone the ElizaOS repository\n2. Run `pnpm install --no-frozen-lockfile`\n3. Run `pnpm build`\n4. Observe the build failure with an error related to Zod import in plugin-pyth-data\n\n**Expected behavior**\nThe installation and build process should complete successfully, allowing the user to use the plugin-pyth-data package within ElizaOS.", "CLOSED", 0, "kastentx", "2025-02-13T06:56:23Z", "2025-03-08T01:15:12Z", "2025-03-08T01:15:12Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6p4GKR", 3467, "Add DeFi Token Analysis Plugin (plugin-expuzi)", "## Problem Description\nElizaOS currently lacks comprehensive DeFi token analysis capabilities. Users need a way to:\n- Analyze token contracts for potential risks\n- Get real-time market data\n- Assess social sentiment\n- Receive automated risk scoring\n\n## Proposed Solution\nImplement `plugin-expuzi` to provide DeFi token analysis:\n\n### Core Features\n- Contract analysis via Sui Network integration\n- Market data fetching through CoinGecko\n- Risk scoring system (0-100)\n- Warning detection for suspicious patterns\n- Social sentiment tracking\n\n### Technical Implementation\n```typescript\n// Core components\n- TokenAuditor class\n- Risk calculation engine\n- Contract data fetcher\n- Market data integration\n- Social sentiment analyzer\n```\n\n## Alternatives Considered\n1. Using existing blockchain explorers\n2. Manual contract analysis\n3. Third-party audit services\n\n## Additional Context\n- Requires Sui Network access\n- Needs CoinGecko API integration\n- Should support multiple token standards\n- Must include comprehensive test coverage\n", "CLOSED", 0, "lggg123", "2025-02-13T06:03:22Z", "2025-03-08T01:15:12Z", "2025-03-08T01:15:12Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pz-2A", 3464, "client starts but with sqlite-vec errors", "I managed to get the client running, but the following errors are reported:\n\n ERRORS\n   Failed to load sqlite-vec extensions: \n   {} \n\n \u26d4 ERRORS\n   Error starting agent for character Eliza: \n   {} \n\n [\"\u26d4 Error: Loadble extension for sqlite-vec not found. Was the sqlite-vec-linux-arm64 package installed?\"] \n\n \u26d4 ERRORS\n   Error starting agents: \n   {} \n\nThe \"start:client\" command appears to work, the browser page opens but there are no agents to be selected.\n\nAny suggestions?\nThanks.\n\n", "CLOSED", 0, "GDA63", "2025-02-12T17:53:42Z", "2025-03-08T01:17:37Z", "2025-03-08T01:17:36Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6poI9W", 3444, "Enhancement: Improve TwitterPostClient dry run functionality", "Please note: You'll find me happy to implement this change once approved. It'd be my first open-source contribution!\n\n**Is your feature request related to a problem? Please describe.**\n\nThe TwitterPostClient's dry run mode currently only logs tweet content via elizaLogger.info() without returning the data. This makes it difficult to programmatically access draft tweets, requiring workarounds like runtime method overriding. Specifically, applications need to override the info logger at runtime to capture the draft tweet content, which is brittle and hard to maintain.\n\n**Describe the solution you'd like**\n\nModify the generateNewTweet() method to return a structured result object while maintaining existing logging behavior:\n\n```typescript\ninterface TweetGenerationResult {\n  success: boolean;\n  dryRun?: boolean;\n  tweet?: string;\n  error?: string;\n}\n```\n\nThis would allow applications to programmatically access draft tweets while maintaining backwards compatibility through continued logging.\n\n`isDryRun`'s current `return` in `main`: https://github.com/elizaOS/eliza/blob/81a35281b93d5e8ca0745e9d13a1943e9a90681b/packages/client-twitter/src/post.ts#L605-L610\n\n**Describe alternatives you've considered**\n\n- Runtime method overriding (current workaround)\n- Creating a separate dryRun method\n- Using events to emit draft tweets\n\nThe structured return object provides the cleanest solution with the least impact on existing code.\n\nAgain, you'd find me happy to implement this change.\n\n**Additional context**\n\nThis enhancement would improve the developer experience when building applications on top of the client-twitter package. The current implementation forces developers to use workarounds that make code harder to maintain and test.\n\nRelated file: packages/client-twitter/src/post.ts", "CLOSED", 0, "spencerf2", "2025-02-11T16:23:54Z", "2025-03-08T01:17:36Z", "2025-03-08T01:17:35Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pmGrm", 3441, "Long messages cause an error", "**Describe the bug**\n\nLong messages cause an error.\n\n**To Reproduce**\n\nUsing PostgreSQL as the database, sending a message longer than 255 characters causes an error.\n\nAlternatively, if the most recent message is too long (an error occurs in factsProvider), the issue arises due to the message length. Since it uses the levenshtein function, the error message:\n\n\"levenshtein argument exceeds maximum length of 255 characters\"\n\nappears when a long message is processed. This happens immediately when sending a long message at once. Applying slicing resolves the issue, but I'm not sure if that's the right approach.\n\nIt would be great if someone could fix this.\n\nI'm curious about the best way to handle this, though I haven't tested it on other databases.\n\n**Expected behavior**\n\nLong texts or past chat history should not cause errors.\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\nI don\u2019t think this happened before\u2026 I\u2019m not sure. I don\u2019t know where to look.\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "lincheoll", "2025-02-11T13:03:07Z", "2025-03-04T04:23:36Z", "2025-03-04T04:23:36Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pa6f2", 3420, "Decouple service types and 3rd party service development", "**Is your feature request related to a problem? Please describe.**\n\nPlugin system has been decoupled from the development of the elizaos main repo, but developing new service extensions is still dependent on upkeeping the service type definitions located under core package types. \n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\n\n**Describe the solution you'd like**\n\nDecouple definition of service types e.g. like clients and plugins have been decoupled from the main code repository.\n\n<!-- A clear and concise description of what you want to happen. -->\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "yaruno", "2025-02-10T13:24:57Z", "2025-03-08T01:15:11Z", "2025-03-08T01:15:11Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pavb1", 3418, "Cannot find module '@anush008/tokenizers-linux-arm64-gnu'", "I am trying to run ElizaOS on a Jetson Orin NX 8GB.\n\nI am very new to Linux and all this so I may not be precise. \n\nI am getting an error that I cant' solve when I try to start Eliza:\n\n\"Cannot find module '@anush008/tokenizers-linux-arm64-gnu'\"\n\n\n**To Reproduce**\n-=============================================================================================================\n(after removing /create-eliza-app directory) \npnpm install\npnpm start\n-=============================================================================================================\n\n** Output:\n-=============================================================================================================\n> eliza@ start /home/james/eliza\n> pnpm --filter \"@elizaos/agent\" start --isRoot\n\n\n> @elizaos/agent@0.25.6-alpha.1 start /home/james/eliza/agent\n> node --loader ts-node/esm src/index.ts \"--isRoot\"\n\n(node:1646566) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\n(Use `node --trace-warnings ...` to show where the warning was created)\n(node:1646566) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\n(Use `node --trace-deprecation ...` to show where the warning was created)\nnode:internal/modules/cjs/loader:1239\n  const err = new Error(message);\n              ^\n\nError: Cannot find module '@anush008/tokenizers-linux-arm64-gnu'\nRequire stack:\n- /home/james/eliza/node_modules/@anush008/tokenizers/index.js\n- /home/james/eliza/node_modules/fastembed/lib/cjs/fastembed.js\n- /home/james/eliza/node_modules/fastembed/lib/cjs/index.js\n    at Function._resolveFilename (node:internal/modules/cjs/loader:1239:15)\n    at Function._load (node:internal/modules/cjs/loader:1064:27)\n    at TracingChannel.traceSync (node:diagnostics_channel:322:14)\n    at wrapModuleLoad (node:internal/modules/cjs/loader:218:24)\n    at Module.require (node:internal/modules/cjs/loader:1325:12)\n    at require (node:internal/modules/helpers:136:16)\n    at Object.<anonymous> (/home/james/eliza/node_modules/@anush008/tokenizers/index.js:219:31)\n    at Module._compile (node:internal/modules/cjs/loader:1546:14)\n    at Object..js (node:internal/modules/cjs/loader:1698:10)\n    at Module.load (node:internal/modules/cjs/loader:1303:32) {\n  code: 'MODULE_NOT_FOUND',\n  requireStack: [\n    '/home/james/eliza/node_modules/@anush008/tokenizers/index.js',\n    '/home/james/eliza/node_modules/fastembed/lib/cjs/fastembed.js',\n    '/home/james/eliza/node_modules/fastembed/lib/cjs/index.js'\n  ]\n}\n\nNode.js v23.3.0\n/home/james/eliza/agent:\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.25.6-alpha.1 start: `node --loader ts-node/esm src/index.ts \"--isRoot\"`\nExit status 1\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\n\n-=============================================================================================================\n*\n\n**Additional context**\nI cannot access a possible solution posted by h$ckerm1ke in this post:\nhttps://github.com/elizaOS/eliza/issues/2242\n\nAre there any news/suggestions? Many thanks.\n", "CLOSED", 0, "GDA63", "2025-02-10T13:07:29Z", "2025-03-08T03:14:58Z", "2025-03-08T03:14:58Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pYDM2", 3411, "Integrate BAML to enable structured outputs from LLMs", "\n**Describe the solution you'd like**\n\nI would like to integrate BAML (a domain-specific language for generating structured outputs from LLMs) into eliza workflow. BAML provides an excellent developer experience with features like type-safe outputs, flexibility across different LLMs and languages, and a robust online playground for testing prompts. It allows viewing and running prompts directly within the editor, similar to Markdown Preview, without additional setup.\n\n\n**Additional context**\n\nBAML enables building reliable agents and chatbots with Retrieval-Augmented Generation (RAG) capabilities, extracting data from PDFs, and more. It offers a state-of-the-art structured output experience that even outperforms OpenAI with their models and supports open-source models. The BAML VSCode playground provides an amazingly fast developer experience for prompting, with fully type-safe outputs even when streaming structured data. For more information, please refer to the BAML products, guide, playground, examples, reference, and motivation sections.\n\nhttps://github.com/BoundaryML/baml\n", "CLOSED", 0, "bucurdavid", "2025-02-10T08:14:00Z", "2025-03-08T03:08:14Z", "2025-03-08T03:08:13Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pTeBt", 3394, "Bot Generates Multiple Replies Due to DEFAULT_MAX_TWEET_LENGTH", "**Eliza Version**\nlatest v0.1.9\n\n**Issue Summary**  \nWhen testing a bot that replies to its followers, I noticed that it sometimes generates multiple replies to a single tweet. The API logs indicate that the bot only makes two calls per response (one for the medium model and one for the large model). However, due to `DEFAULT_MAX_TWEET_LENGTH`, the generated response is split into multiple tweets to fit within the 280-character limit.  \n\nThis is usually a minor compliance issue, but in some cases, the agent detects these split responses as incomplete sentences and attempts to generate additional replies repeatedly. As a result, the API sometimes makes **4 to 6 calls instead of 2**, leading to excessive LLM token usage and increased costs.  \n\n**Steps to Reproduce**  \n1. Enable the bot to reply to follower tweets.  \n2. Observe API logs, which show only two calls being made.  \n3. Due to `DEFAULT_MAX_TWEET_LENGTH`, the reply is split into multiple tweets.  \n4. In some cases, the agent perceives the split content as incomplete and generates additional responses.  \n5. The bot may end up making **4\u20136 API calls per tweet**, leading to unnecessary token consumption.  \n\n**Expected Behavior**  \n- The bot should generate only **one** response per tweet and appropriately split it if needed, without triggering unnecessary additional responses.  \n\n**Actual Behavior**  \n- The bot sometimes misinterprets split responses as incomplete and keeps generating additional replies, leading to multiple API calls (4\u20136 instead of 2).  \n\n**Impact**  \n- **High token usage**, leading to increased API costs.  \n- **Potential rate limits or compliance issues** with excessive replies to a single tweet.  \n\n**Temporary Fixes**  \n- set `DEFAULT_MAX_TWEET_LENGTH` to much higher number(like 500)\n\nI think this is mainly from `interation.ts` and `continue.ts`.\n\n**Screenshots**\n\n<img width=\"300\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/b70be945-2446-4d4e-aa37-d13213b2cbb6\" />\n\n", "CLOSED", 0, "naiveai-dev", "2025-02-09T05:35:03Z", "2025-03-08T03:19:01Z", "2025-03-08T03:19:00Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pSxRC", 3387, "Quick start confusion because eliza-starter is a different repository", "**Describe the bug**\nIn the readme is recommends using the eliza-starter.git repository however if should be made more clear that users should then follow the instructions inside the readme on that repo.\n\n<!-- A clear and concise description of what the bug is. -->\nThe issue is human error of course but for me I assumed that I should continue following the install instructions in the eliza.git readme and ultimately got stuck at `pnpm start:client` because that doesn't exist inside the eliza-starter.git package.\n\n**To Reproduce**\nfollow the Use the Starter (Recommended) instructions but don't leave the page\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\nfollow the Use the Starter (Recommended) instructions on the eliza-starter.git repo\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "shi11", "2025-02-08T21:18:47Z", "2025-03-08T01:17:35Z", "2025-03-08T01:17:35Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pSvQk", 3385, "Agent is stuck on start (Docker/Cloud) v0.25.6-alpha.1", "**Describe the bug**\n\nBug on start of agent (v0.25.6-alpha.1) in cloud using docker, start of agent is stuck on very beginning not outputting any errors and also not continuing with start. (Agent is not responding)\n\n**To Reproduce**\n\n1. Create docker-compose of newest version of Eliza v0.25.6-alpha.1\n2. Upload to cloud and start docker-compose\n\n**Expected behavior**\n\nAgent starts and functions normally as on local and as older versions.\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/5002d238-78a8-4391-bc39-453f0eb341f8)\n\n**Additional context**\n\nI built docker-compose for linux amd64, also did this for older versions and everything was working fine.\n\nPlugins I use for my Agent:  \n`plugins: [AwsS3Service, TranscriptionService, BrowserService, bootstrapPlugin, PdfService, dexScreenerPlugin, ImageDescriptionService, SpeechService, webSearchPlugin, twitterPlugin, giphyPlugin, coingeckoPlugin],`\n\nClients and model I use for my Agent: \n    \n```\nclients: [Clients.TELEGRAM, Clients.TWITTER],\nmodelProvider: ModelProviderName.OPENAI,\n```\n\n**It is working on local/desktop.** \n", "CLOSED", 0, "WNUMIK", "2025-02-08T21:07:15Z", "2025-03-08T01:15:11Z", "2025-03-08T01:15:11Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pSRN5", 3384, "Twitter Actions not Processing", "Twitter Actions not Processing\n\nTwitter actions (likes, retweets, replies) are not executing. Only the posting mechanism is working.\n\n**To Reproduce**\n\n* Install most recent version\n* Create a character file with `clients: ['twitter']`\n* In .env, put Twitter auth information, set enable twitter post generation to true, set enableActionProcessing to true, set actionInterval to 1, set maxActionsProcessing to 5.\n* Start the character\n\n**Expected behavior**\n\nA loop every `ACTION_INTERVAL` minutes that searches for relevant tweets to interact with and take action on that.\n\n![Image](https://github.com/user-attachments/assets/5b8a8bb9-d773-4ffa-ac25-4456ed6e75c7)\n\n![Image](https://github.com/user-attachments/assets/8640f052-7e82-49ba-a443-245c607e3072)\n\n**Additional Context**\nI've configured these settings both in the character file and in my .env file.", "CLOSED", 0, "justinschreiner", "2025-02-08T16:44:45Z", "2025-03-08T01:17:35Z", "2025-03-08T01:17:35Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pSLEA", 3383, "Enhancing Twitter AI Agent\u2019s Human-Like Behavior and Engagement Efficiency", "**Is your feature request related to a problem? Please describe.**\n\nCurrently, the agent behavior is too predictable, making it easily detectable by external users and Twitter's moderation system. This can lead to suspicion, reduced engagement, or even temporary shadowbans due to excessive, unnatural activity patterns.\n\nIn a previous version, the agent adhered to a \"working hours\" schedule, remaining inactive at night. This approach not only helped avoid shadowbans but also improved efficiency by focusing engagement during peak hours. However, in its current form, the agent runs continuously, posting and commenting strictly according to predefined .env parameters, making it look artificial and increasing the risk of detection.\n\nAdditionally, engagement with newer posts significantly boosts visibility and interactions. Therefore, ensuring that the bot prioritizes fresh posts\u2014those published within the last hour\u2014would optimize its impact.\n\n**Describe the solution you'd like**\n\n- Configurable Active Hours: Introduce an option in the settings to define specific working hours, e.g., 10:00 - 21:00 UTC. This would make the agent behavior more human-like and reduce the risk of being flagged by Twitter\u2019s algorithms.\n\n- Post Freshness Limit: Add a setting to specify the maximum age of posts the bot engages with. For instance, allowing interactions only with posts published within the last 5 to 50 minutes. This ensures the agent remains relevant by engaging with fresh content, thereby maximizing visibility and interaction rates.\n\n- Randomized Activity Patterns: Instead of rigid time frames, allow the bot to have slight variations in its posting schedule, mimicking human-like inconsistencies. This could include random delays between actions and periodic \"idle\" times.\n\n- Engagement-Based Adaptation: Implement a dynamic adjustment mechanism where the bot increases or decreases its activity based on engagement metrics. For example, if a certain time window yields higher interactions, the bot could prioritize those hours automatically.\n\n**Describe alternatives you've considered**\n\n- Using machine learning to analyze peak engagement times and adjust activity accordingly.\n\n- Introducing a \"cooldown\" system where the bot temporarily slows down if engagement drops too quickly, preventing detection.\n\n\n**Additional context**\n\nThese enhancements would make the bot appear more organic, reducing the risk of detection and optimizing engagement. By mimicking natural behavior, the bot could sustain long-term growth without triggering Twitter\u2019s moderation systems. A dynamic and adaptable approach ensures that it remains effective in an evolving algorithmic landscape.\n\n", "CLOSED", 0, "sosi-fcfs", "2025-02-08T16:19:31Z", "2025-03-08T03:13:32Z", "2025-03-08T03:13:30Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pPTa5", 3373, "discord.js - error node-v131-napi-v3-linux-x64-glibc-2.36/opus.node", "**Describe the bug**\n\nError: Error: Cannot find module '/opt/render/project/src/node_modules/@discordjs/opus/prebuild/node-v131-napi-v3-linux-x64-glibc-2.36/opus.node'\n\n<!-- A clear and concise description of what the bug is. -->\n\n**To Reproduce**\n\ninstance on Render, when enabling discord plugin, got this opus.node error\n\n<!-- Steps to reproduce the behavior. -->\n\nenable discord\nrun on Render\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "rferrari", "2025-02-08T00:49:17Z", "2025-03-08T01:15:10Z", "2025-03-08T01:15:10Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pLCQm", 3362, "pnpm dev --characters doesn't load character", "**Describe the bug**\n\nJust as the title says, the command `pnpm run dev --characters=\"characters/xyz.character.json\"` does not run the dev mode using the correct character. It always loads the default eliza character.\n\n**To Reproduce**\n\nRun `pnpm run dev --characters=\"characters/xyz.character.json\"` with your character.\n", "CLOSED", 0, "creazy231", "2025-02-07T14:01:28Z", "2025-03-08T03:09:49Z", "2025-03-08T03:09:48Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pJbQO", 3360, "UI Doesn't Appear to Load", "**Describe the bug**\nStarting the service with `pnpm start --character=\"characters/character.json\"` appears to work and load my character file, however, when I attempt to access the agent via the UI I am greeted with a message \"Welcome, this is the REST API!\" and nothing else. I have specified port 3000 within my .env file and I am using this to access the UI. Additionally, the start up appears to halt on \"initialising LlamaService\" even though I have specified OpenAI within my character and .env file.\n\nI am also quite confused between the `pnpm start --character=\"characters/character.json\"` and the `pnpm start:client`, where the latter does not register as a command. Is there a specific way in which to run these commands?\n\n\n**To Reproduce**\n- Build Eliza-Starter \n- Create character and specify OpenAI\n- Set OpenAI API Key within .env\n- Start the service with `pnpm start --character=\"characters/character.json\"`\n\n**Expected behaviour**\n\nIm not entirely sure, it is the first time I am starting the service without the build breaking. I have seen a few images/videos with people interacting with the agents via a UI. I would assume this loads and you can interact with it in such a way.\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/2a903465-d487-495a-84f5-1d94b251bc7d)\n", "CLOSED", 0, "Mer-idium", "2025-02-07T10:36:32Z", "2025-03-08T01:17:34Z", "2025-03-08T01:17:34Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pIAhg", 3356, "Make an Eliza CLI where plugins are opt-in only (a la Shadcn)", "This is a bit of an ambitious refactor proposition. I'm mostly opening this issue to see if there's interest from the community before I and other devs from the community consider getting our hands dirty.\n\n**Is your feature request related to a problem? Please describe.**\n\nI imagine when this project started, its huge success wasn't anticipated and it seemed ok to have plugins added to the core repo via pull requests. But today, the situation is that in order to even make the first steps with eliza, there's a little barrier to entry in the form of cloning this massive repo, fetching all of the dependencies from every plugin ever integrated, building all the plugins just to be able to see a SBF example that fetches Solana balances. This situation not only hinders the devex but the disk footprint is also huge (9.2GB for the `node_modules/` and 1.8GB for the built plugins).\n\n**Describe the solution you'd like**\n\nIt would be great if instead of cloning the repo with all its plugins and all their dependencies eliza would be installed via a dedicated CLI with commands like\n\n```sh\n# Installs the minimal core elements \n$ eliza init [--template template-name]\n```\n\nthen plugins could be installed on-demand with\n\n```sh\n# Installs the plugin and its dependencies\n$ eliza add plugin-name\n```\n**Describe alternatives you've considered**\n\nAn alternative to this approach today would be to make forks of the repo where everything that isn't used would be deleted. I think doing this at least once would actually be a great first step towards implementing this refacto just to get an idea of what is core, what is necessary plugin for a bare minimum setup and what is potential bloat.\n\n**Additional context**\n\nAs I said in the intro, this issue is mostly to measure the interest for such a solution. First, as a concerned dev because I think this would make the product better, but also as someone who'd be down to rolling up my sleeves and (at least partially) get it done if people think it's a good plan.\n", "CLOSED", 0, "Mouradif", "2025-02-07T07:35:04Z", "2025-03-08T01:16:22Z", "2025-03-08T01:16:22Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pH9O_", 3355, "SqliteError: Vector dimension mistmatch.", "**SqliteError: Vector dimension mistmatch. First vector has 384 dimensions, while the second has 1536 dimensions.**\n\nI'm building an Eliza Discord Bot with Hyperbolic Models , It works but after performing an action it throws this error.\n```\nError handling message: SqliteError: Vector dimension mistmatch. First vector has 384 dimensions, while the second has 1536 dimensions.\n    at SqliteDatabaseAdapter.searchMemoriesByEmbedding (file:///workspace/fourierpay-hackathon/packages/adapter-sqlite/dist/index.js:359:47)\n    at SqliteDatabaseAdapter.createMemory (file:///workspace/fourierpay-hackathon/packages/adapter-sqlite/dist/index.js:289:48)\n    at MemoryManager.createMemory\n```\nDeleting the data/db.sqlite solves it temporarily , bu imtrying to scale this project , i cant keep deleting everytime i make an action. Please i need help.", "CLOSED", 0, "OFUZORCHUKWUEMEKE", "2025-02-07T07:26:24Z", "2025-03-08T01:16:21Z", "2025-03-08T01:16:21Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pHNUv", 3353, "Fix Placeholder Mismatch & Image Description Format in Twitter Search Template", "## Description:\nIn the Twitter search post template, the placeholder {{currentPost}} is used, but the state is passing twitterContext. This causes a mismatch, leading to incorrect data rendering. The placeholder should be updated to currentPost to ensure consistency. Additionally, the image description being generated does not match the expected format. The formatting logic should be reviewed and corrected to align with the current standards.\n\n## Steps to Reproduce:\n- Use the Twitter search post template.\n- Observe the incorrect placeholder usage and formatting issues.\n\n## Expected Fix:\n- Update state to pass currentPost instead of twitterContext.\n- Correct image description generation logic.", "CLOSED", 0, "Jovian-Dsouza", "2025-02-07T04:58:06Z", "2025-03-08T03:19:15Z", "2025-03-08T03:19:15Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pGj25", 3352, "Add Lean 4 Theorem Prover plugin", "# Integrate Lean 4 Theorem Prover for Advanced Logical Reasoning\n\n## **Is your feature request related to a problem? Please describe.**  \n### Eliza excels with conversational patterns but struggles with formal or mathematical reasoning. \nThe motivations can be:\n- Enhanced Conversation: Beyond classic Eliza patterns, users could ask logical or mathematical questions, and Eliza could leverage Lean 4 to provide validated answers or insights.\n- Educational Value: A Lean 4 integration could serve as an educational tool for users learning formal reasoning and proof techniques.\n- Differentiation: Incorporating a theorem prover sets Eliza apart from traditional chatbot frameworks, offering unique capabilities for advanced or specialized use cases.\n\n\n## **Describe the solution you\u2019d like.**  \n- Integrate Lean 4 so Eliza can pass user statements or questions to a theorem-proving engine. Whether in natural language, e.g., \u201cEliza, can you prove that the sum of two even numbers is even?\u201d, or in Lean code snippet.\n- Define specific triggers or keywords in Eliza\u2019s pattern-matching system.\n- When triggered, Eliza calls the Lean 4 plugin to validate or prove statements.\n- If a statement can\u2019t be proved, Eliza gracefully handles the error or explains the reason.\n\n## **Describe alternatives you\u2019ve considered.**  \n- Using different theorem provers (e.g., Coq, Isabelle).  \n- Simpler pattern-based approaches that lack robust logic handling.  \n\n## **Additional context.**  \n- Using external APIs or embedding Lean 4 directly?\n", "CLOSED", 0, "ImHangLi", "2025-02-07T02:07:45Z", "2025-03-08T01:16:21Z", "2025-03-08T01:16:21Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pF7fi", 3348, "Where to use runtime.processAction?", "Hi, I saw the docs said we can use runtime.processAction. Yet seems this function is undefined. Curious how to use it?\n\nOr maybe the docs need to be fix?\n\nThank you!", "CLOSED", 0, "EasonC13", "2025-02-07T00:10:37Z", "2025-03-08T03:07:08Z", "2025-03-08T03:07:07Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pCcw3", 3328, "Amazon Bedrock model provider is not working", "**Describe the bug**\n\nThe initial [pull request](https://github.com/elizaOS/eliza/pull/2769) was missing code in the `generate.ts` which that defined how to handle Bedrock as a provider.\n\n**To Reproduce**\nSet the character's model inference provider to 'bedrock'\nRun the character and you'll get an error that no provider is found\n\n**Expected behavior**\nBedrock works as a provider\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "ebaizel", "2025-02-06T16:20:44Z", "2025-03-08T03:04:24Z", "2025-03-08T03:04:24Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6pAKph", 3319, "Default Download of Hermes llama model", "On first run it automatically downloads hermes 3 llama even when editing models.ts and setting download=false. Seems irrelevant if you only use API ai?\n", "CLOSED", 0, "InAMooD", "2025-02-06T12:25:25Z", "2025-03-08T02:36:58Z", "2025-03-08T02:36:58Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6o8f6A", 3303, "agent can not be assigned", "packages/client-direct/src/api.ts:170:\nagent = await directClient.startAgent(character); // agent can not be assigned\n\njust change the below code is work well.\nawait directClient.startAgent(character);", "CLOSED", 0, "tercel", "2025-02-06T03:21:17Z", "2025-03-08T01:17:34Z", "2025-03-08T01:17:34Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6o8Wjj", 3302, "stop agent operations can cause the program to crash", "packages/core/runtime.ts:\nstop()  can cause the program to crash.\n\nchange the below code is work well.\n```\n// it doesn't have a strict interface specification, and some don't have STOP methods\nif (c && c?.stop) {\n    c.stop();\n} else {\n    elizaLogger.log(\"client stop skip,\", cStr, this.character.name);\n}\n```", "CLOSED", 0, "tercel", "2025-02-06T02:42:20Z", "2025-03-08T01:17:34Z", "2025-03-08T01:17:34Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6o8CEr", 3298, "Rename the plugin-apro to plugin-ATTPs", "**Rename the plugin name of plugin-apro to plugin-ATTPs**\n\nJust rename the plugin name and all related content.\n", "CLOSED", 0, "fifahuihua", "2025-02-06T01:40:17Z", "2025-03-08T01:16:21Z", "2025-03-08T01:16:21Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6o5U8s", 3282, "Speech to text in Discord", "**Describe the bug**\n\nEncountered error converting to audio when using Discord. I've entered the audio monitoring for the channel, but getting errors with converting to audio, OpenAI speech-to-text conversion, and ffprobe.\n\n\n**Expected behavior**\n\n* speech input and output in Discord voice channel\n\n**Screenshots**\n```\nStarting audio monitor for user: 518126625511178240\nStarting transcription...\n[2025-02-05 17:48:13] ERROR: Error converting audio:\n    code: 127\n    killed: false\n    signal: null\n    cmd: \"ffprobe -v error -show_entries stream=codec_name,sample_rate,channels -of json \\\"/Users/kgsmbp/Projects/eliza/packages/content_cache/input_1738777693423.wav\\\"\"\n    stdout: \"\"\n    stderr: \"/bin/sh: ffprobe: command not found\\n\"\n[2025-02-05 17:48:13] ERROR: Error in OpenAI speech-to-text conversion:\n    code: 127\n    killed: false\n    signal: null\n    cmd: \"ffprobe -v error -show_entries stream=codec_name,sample_rate,channels -of json \\\"/Users/kgsmbp/Projects/eliza/packages/content_cache/input_1738777693423.wav\\\"\"\n    stdout: \"\"\n    stderr: \"/bin/sh: ffprobe: command not found\\n\"\n[2025-02-05 17:48:13] ERROR: Error setting up request: Command failed: ffprobe -v error -show_entries stream=codec_name,sample_rate,channels -of json \"/Users/kgsmbp/Projects/eliza/packages/content_cache/input_1738777693423.wav\"\n/bin/sh: ffprobe: command not found\n```", "CLOSED", 0, "kevinghim", "2025-02-05T17:54:31Z", "2025-03-08T01:16:20Z", "2025-03-08T01:16:20Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6ozpXY", 3265, "Availability of a ccxt plugin.", "**Is your feature request related to a problem? Please describe.**\n\nThis woud be nice to have this library available on the ElizaOS.\n\n**Describe the solution you'd like**\n\nHave a ccxt plugin, that provides capability to trade on 100 bitcoin/altcoin exchanges.\n\n**Describe alternatives you've considered**\n\nProbably other librairies available.\n\n**Additional context**\n\n", "CLOSED", 0, "pallyndr", "2025-02-05T07:14:18Z", "2025-03-08T01:16:20Z", "2025-03-08T01:16:20Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6oxcYU", 3252, "Bot posting reply of \"Please use the format: query onchain data: <your natural language query>\" every time after each reply", "This bug happens every time the agent try to reply a tweet.\n\nTo reproduce the behavior, i just followed every steps in the doc and run the agent locally.\n\nIn some reply that the agent sent, there will be a query section included in the comment like this\n\n![Image](https://github.com/user-attachments/assets/348fdf95-48cb-4a38-9869-a65dc7355b8c)\n\nAnd after every reply on other twitter account's tweet, there will be another reply sent just like the screenshot below\n\n![Image](https://github.com/user-attachments/assets/f8d35d95-91e4-4732-a0e5-7aae83a40bb9)\n\nDon't know if this is related to any .env file setup error, looks like the agent is trying to use some sort of natural query function to fetch onchain data on the backend during posting the reply, but it got posted on twitter as the content.\n\n", "CLOSED", 0, "cobecheng", "2025-02-04T23:57:11Z", "2025-03-08T01:16:20Z", "2025-03-08T01:16:20Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6ov-Jc", 3241, "CoinGecko Plugin in ElizaOS Returns Bitcoin Price for All Queries and Sends Duplicate Responses", "![Image](https://github.com/user-attachments/assets/be1662b0-4ed9-490e-aaa9-04aedc468688)\n\nDescription:\n\nIssue Summary:\n\nI am experiencing two issues with the CoinGecko plugin in ElizaOS:\n\nIncorrect Cryptocurrency Price Retrieval: When I request the price of any cryptocurrency (e.g., Ethereum or Toncoin), the system consistently returns the price of Bitcoin instead of the requested coin.\n\nDuplicate Responses: For each query about a cryptocurrency's price, I receive two identical response messages instead of one.\n\nSteps to Reproduce:\n\nOpen the ElizaOS interface.\nUse the CoinGecko plugin to request the price of a specific cryptocurrency by typing, for example, \"What is the price of Ethereum?\".\nObserve the response provided by the system.\nExpected Behavior:\n\nThe system should return the current price of the specified cryptocurrency (e.g., Ethereum or Toncoin).\nThe system should provide a single response message per query.\nActual Behavior:\n\nThe system returns the price of Bitcoin regardless of the cryptocurrency requested.\nTwo identical response messages are received for each query.\nAdditional Information:\n\nElizaOS Version: Eliza 1.9\n\nI would appreciate guidance on resolving these issues. Specifically:\n\nAre there known compatibility issues between the current versions of ElizaOS and the CoinGecko plugin?\nCould there be a misconfiguration in the plugin settings causing these problems?\nAre there any patches or updates available that address these issues?\nThank you for your assistance.", "CLOSED", 0, "illink7", "2025-02-04T19:46:03Z", "2025-03-08T01:16:19Z", "2025-03-08T01:16:19Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6ovYaj", 3239, "Docker error in Mac M1", "ambusiness@AMs-MacBook-Air eliza % docker buildx build --platform linux/arm64 -t eliza .\n[+] Building 13.6s (3/3) FINISHED                          docker:desktop-linux\n => [internal] load build definition from Dockerfile                       0.0s\n => => transferring dockerfile: 2.00kB                                     0.0s\n => ERROR [internal] load metadata for docker.io/library/node:23.3.0-sli  13.5s\n => [auth] library/node:pull token for registry-1.docker.io                0.0s\n------\n > [internal] load metadata for docker.io/library/node:23.3.0-slim:\n------\nDockerfile:2\n--------------------\n   1 |     # Use a specific Node.js version for better reproducibility\n   2 | >>> FROM node:23.3.0-slim AS builder\n   3 |     \n   4 |     # Install pnpm globally and necessary build tools\n--------------------\nERROR: failed to solve: node:23.3.0-slim: failed to resolve source metadata for docker.io/library/node:23.3.0-slim: failed to authorize: failed to fetch oauth token: Post \"https://auth.docker.io/token\": net/http: TLS handshake timeout\n\nView build details: docker-desktop://dashboard/build/desktop-linux/desktop-linux/ieh7g62psf6g3pvo85ff4gkow\nambusiness@AMs-MacBook-Air eliza % docker buildx build --platform linux/amd64 -t myimage:latest .\n[+] Building 26.0s (3/3) FINISHED                          docker:desktop-linux\n => [internal] load build definition from Dockerfile                       0.0s\n => => transferring dockerfile: 2.00kB                                     0.0s\n => ERROR [internal] load metadata for docker.io/library/node:23.3.0-sli  25.9s\n => [auth] library/node:pull token for registry-1.docker.io                0.0s\n------\n > [internal] load metadata for docker.io/library/node:23.3.0-slim:\n------\nDockerfile:47\n--------------------\n  45 |     \n  46 |     # Final runtime image\n  47 | >>> FROM node:23.3.0-slim\n  48 |     \n  49 |     # Install runtime dependencies\n--------------------\nERROR: failed to solve: node:23.3.0-slim: failed to resolve source metadata for docker.io/library/node:23.3.0-slim: failed to do request: Head \"https://registry-1.docker.io/v2/library/node/manifests/23.3.0-slim\": net/http: TLS handshake timeout\n\nView build details: docker-desktop://dashboard/build/desktop-linux/desktop-linux/r7jdea7ybjptamzr4dnbmq303\nambusiness@AMs-MacBook-Air eliza % ", "CLOSED", 0, "yasir23", "2025-02-04T18:24:38Z", "2025-03-08T02:36:58Z", "2025-03-08T02:36:58Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6orJDW", 3229, "feat: Add Taiko plugin integration", "# Overview  \nTo enable agent interaction with Taiko L2 and provide insights into an on-chain address's activity metrics, this proposal suggests developing a plugin that introduces actions supporting these features.  \n\n## Functional Requirements  \n- Enable agents to transfer ETH/ERC-20 tokens on the Taiko Mainnet and Taiko Hekla Network.  \n- Allow agents to read the balance of any address.  \n- Enable agents to resolve domain names and perform relevant actions, such as transfers or balance retrieval.  \n- Retrieve on-chain activity for any given address (useful for understanding contract usage) across different timeframes, including:  \n  - Total gas spent  \n  - Total transactions  \n  - Top interacting addresses  \n  - Unique addresses interacted with  \n\n## Describe Alternatives You've Considered  \nAfter searching through issues and pull requests, I did not find any mention of a similar feature request, so I am submitting this proposal.  \n\n## Additional Context  \nNot applicable at this moment.  \n", "CLOSED", 0, "Siddesh7", "2025-02-04T11:20:03Z", "2025-03-08T01:16:19Z", "2025-03-08T01:16:19Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6op95s", 3226, "feat: Add KAIA Plugin", "**Relates to:** \nKaia Blockchain\n\n**Risks**\nLow\n\n**Background**\nThis is the first PR that introduces KAIA plugin to eliza.\n\n**What does this PR do?**\nIntroduces Agent Plugin to interact with Kaia Blockchain\n\nWhat kind of change is this?\nFeatures (non-breaking change which adds functionality)\n\nAdd the ability for Eliza agents to interface with the KAIA Blockchain.\n\nDocumentation changes needed?\nMy changes do not require a change to the project documentation.\n\nTesting\nChanges can be tested by providing a EVM based private, kaiascan api keys in .env, and asking eliza to perform actions to interact with Kaia blockchain.\n\nDiscord username\n@ kaiachain\n\nEmail address\n[ecosystem@kaia.io](mailto:ecosystem@kaia.io)", "CLOSED", 0, "praveen-kaia", "2025-02-04T09:19:35Z", "2025-03-08T01:16:18Z", "2025-03-08T01:16:18Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6omj3r", 3212, "Build errors when trying to deploy on render.com", "When i am trying to deploy from the repo after already running pnpm install --no-frozen-lockfile i am getting errors. Then i make sharp optional with the -w flag and get the following errors for the build. \n\nnode_modules/sharp install: ../metadata.cc:237:46: error: \u2018NewOrCopy\u2019 is not a member of \u2018Napi::Buffer<char>\u2019\nnode_modules/sharp install:   237 |         info.Set(\"exif\", Napi::Buffer<char>::NewOrCopy(env, baton->exif, baton->exifLength, sharp::FreeCallback));\nnode_modules/sharp install:       |                                              ^~~~~~~~~\nnode_modules/sharp install: ../metadata.cc:240:45: error: \u2018NewOrCopy\u2019 is not a member of \u2018Napi::Buffer<char>\u2019\nnode_modules/sharp install:   240 |         info.Set(\"icc\", Napi::Buffer<char>::NewOrCopy(env, baton->icc, baton->iccLength, sharp::FreeCallback));\nnode_modules/sharp install:       |                                             ^~~~~~~~~\nnode_modules/sharp install: ../metadata.cc:243:46: error: \u2018NewOrCopy\u2019 is not a member of \u2018Napi::Buffer<char>\u2019\nnode_modules/sharp install:   243 |         info.Set(\"iptc\", Napi::Buffer<char>::NewOrCopy(env, baton->iptc, baton->iptcLength, sharp::FreeCallback));\nnode_modules/sharp install:       |                                              ^~~~~~~~~\nnode_modules/sharp install: ../metadata.cc:246:45: error: \u2018NewOrCopy\u2019 is not a member of \u2018Napi::Buffer<char>\u2019\nnode_modules/sharp install:   246 |         info.Set(\"xmp\", Napi::Buffer<char>::NewOrCopy(env, baton->xmp, baton->xmpLength, sharp::FreeCallback));\nnode_modules/sharp install:       |                                             ^~~~~~~~~\nnode_modules/sharp install: ../metadata.cc:250:31: error: \u2018NewOrCopy\u2019 is not a member of \u2018Napi::Buffer<char>\u2019\nnode_modules/sharp install:   250 |           Napi::Buffer<char>::NewOrCopy(env, baton->tifftagPhotoshop,\nnode_modules/sharp install:       |                               ^~~~~~~~~\n.../babel-runtime/node_modules/core-js postinstall$ node -e \"try{require('./postinstall')}catch(e){}\"\n.../sdk-ts/node_modules/secp256k1 install$ node-gyp-build || exit 0\nnode_modules/@discordjs/opus install:   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_private_AR2.o\nnode_modules/sharp install: make: *** [sharp-linux-x64.target.mk:173: Release/obj.target/sharp-linux-x64/metadata.o] Error 1\nnode_modules/sharp install: gyp ERR! build error \nnode_modules/sharp install: gyp ERR! stack Error: `make` failed with exit code: 2\nnode_modules/sharp install: gyp ERR! stack at ChildProcess.<anonymous> (/opt/render/project/src/node_modules/node-gyp/lib/build.js:216:23)\nnode_modules/sharp install: gyp ERR! System Linux 6.8.0-1023-aws\nnode_modules/sharp install: gyp ERR! command \"/opt/render/project/nodes/node-23.3.0/bin/node\" \"/opt/render/project/src/node_modules/.bin/node-gyp\" \"rebuild\" \"--directory=src\"\nnode_modules/sharp install: gyp ERR! cwd /opt/render/project/src/node_modules/sharp/src\nnode_modules/sharp install: gyp ERR! node -v v23.3.0\nnode_modules/sharp install: gyp ERR! node-gyp -v v10.3.1\nnode_modules/sharp install: gyp ERR! not ok \nnode_modules/sharp install: make: Leaving directory '/opt/render/project/src/node_modules/sharp/src/build'\n.../babel-runtime/node_modules/core-js postinstall: Done\nnode_modules/sharp install: Failed\nnode_modules/@discordjs/opus install:   CC(target) Release/obj.target/libopus/deps/opus/silk/LPC_fit.o\nnode_modules/canvas install:   CXX(target) Release/obj.target/canvas/src/backend/SvgBackend.o\n.../sdk-ts/node_modules/secp256k1 install: Done\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\nnode_modules/@discordjs/opus install:   CC(target) Release/obj.target/libopus/deps/opus/silk/control_SNR.o\n.../crypto/node_modules/secp256k1 install$ node-gyp-build || exit 0\nnode_modules/@discordjs/opus install:   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_parameters.o\n==> Build failed \ud83d\ude1e", "CLOSED", 0, "RectiFlex", "2025-02-03T22:22:29Z", "2025-03-08T02:36:58Z", "2025-03-08T02:36:57Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6ofbr-", 3191, "Runtime import error: ERR_PACKAGE_PATH_NOT_EXPORTED in NestJs", "**Describe the bug**\n\nWhen I use a package from the Eliza repository in a new Nestjs application, then I get this error.\n\nThe error example below happens for all imports, not only adapter of sqlite but also the core package.\n\nError [ERR_PACKAGE_PATH_NOT_EXPORTED]: Package subpath './dist/index.js' is not defined by \"exports\" in /app/node_modules/@elizaos/adapter-sqlite/package.json\n\n    at new NodeError (node:internal/errors:405:5)\n\n    at exportsNotFound (node:internal/modules/esm/resolve:366:10)\n\n    at packageExportsResolve (node:internal/modules/esm/resolve:713:9)\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\nNo error. Imports should work.\n\n**Additional context**\n\nI try different tsconfig configuration with \"moduleResolution\": \"node\" and other, but the error persists. If I delete the \"export\" content from all Eliza packages locally inside node_modules, then it works locally.\n", "CLOSED", 0, "keyur555", "2025-02-03T08:51:30Z", "2025-03-08T02:36:57Z", "2025-03-08T02:36:57Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6och6b", 3176, "set up", "I cloned the repo then changed the env and character files to use twitter via gaianet ai model\nbut I keep getting this \n\n\u2880\u2800 Initializing Pyth Data Plugin...\n===============================\n      OpenAI Plugin Loaded\n===============================\nName      : openai-plugin\nVersion   : 0.1.0\nX Account : https://x.com/Data0x88850\nGitHub    : https://github.com/0xrubusdata\nActions   :\n  - generateTextAction\n  - generateEmbeddingAction\n  - analyzeSentimentAction\n  - transcribeAudioAction\n  - moderateContentAction\n  - editTextAction\n===============================\n\nSEI IS BEING INITIALIZED\n(node:33729) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\n(node:33729) ExperimentalWarning: CommonJS module /home/mido/eliza/node_modules/is-async-function/index.js is loading ES Module /home/mido/eliza/node_modules/async-function/require.mjs using require().\nSupport for loading ES Module in require() is an experimental feature and might change at any time\n\u2840\u2800 Initializing Pyth Data Plugin...[2025-02-02 22:18:00] ERROR: Failed to fetch DBPDA\n[2025-02-02 22:18:00] ERROR: Cannot found onchain data in this wallet.\n(node:33729) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\n(Use `node --trace-warnings ...` to show where the warning was created)\n(node:33729) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n(node:33729) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\n(Use `node --trace-warnings ...` to show where the warning was created)\n(node:33729) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n(node:33729) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\n(Use `node --trace-warnings ...` to show where the warning was created)\n(node:33729) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n(node:33729) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\n(Use `node --trace-warnings ...` to show where the warning was created)\n(node:33729) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n\u288b\u2800 Initializing Pyth Data Plugin...\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          PYTH DATA PLUGIN              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Initializing Pyth Data Services...    \u2502\n\u2502  Version: 1.0.0                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2714 Pyth Data Plugin initialized successfully!\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Action                    \u2502 H \u2502 V \u2502 E \u2502 Similes                                                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 GET_PRICE_FEEDS           \u2502 \u2713 \u2502 \u2713 \u2502 \u2713 \u2502 FETCH_PRICE_FEEDS, LIST_PRICE_FEEDS, QUERY_PRICE_FEEDS           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 GET_PRICE_UPDATES_STREAM  \u2502 \u2713 \u2502 \u2713 \u2502 \u2713 \u2502 STREAM_PRICE_UPDATES, SUBSCRIBE_TO_PRICES, WATCH_PRICE_FEED      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 GET_LATEST_PRICE_UPDATES  \u2502 \u2713 \u2502 \u2713 \u2502 \u2713 \u2502 FETCH_LATEST_PRICES, GET_CURRENT_PRICES, CHECK_PRICE_FEED        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 GET_LATEST_PUBLISHER_CAPS \u2502 \u2713 \u2502 \u2713 \u2502 \u2713 \u2502 FETCH_PUBLISHER_CAPS, GET_PUBLISHER_LIMITS, CHECK_PUBLISHER_CAPS \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Plugin Status            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Name    : pyth-data      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Actions : 4              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Status  : Loaded & Ready \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\n", "CLOSED", 0, "midoan2", "2025-02-02T22:22:01Z", "2025-03-08T01:16:18Z", "2025-03-08T01:16:18Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6obwvR", 3162, "not connecting to eliza after going live", "hey, so I followed all the steps in this documentation: [link to the documentation](https://elizaos.github.io/eliza/docs/quickstart/)\nas well as this tutorial: [link to the YT tutorial](https://www.youtube.com/watch?v=IOq2vEaXrkQ)\n\nBut it's not connecting to elizaOS Client after it gets hosted on localhost:5173\n\nPlease help me out.\n\n![Image](https://github.com/user-attachments/assets/a60ff583-ab99-4c6c-bab1-2546a665c186)\n", "CLOSED", 0, "tarinip26", "2025-02-02T15:08:40Z", "2025-03-08T01:17:33Z", "2025-03-08T01:17:33Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6oa7xw", 3151, "After running Pnpm start", "pnpm -v 10.0.0\nnvm -v 0.40.1\nnode -v  v23.3.0                                                 \n\nInstalled all prerequisites and dependencies correctly\n\n'pnpm install --no-frozen-lockfile'\n\ngot this after install: \n  \n![Image](https://github.com/user-attachments/assets/acb75e9f-9960-4ba4-bdaf-b0905cd3dae5)\n\ndecided to run build anyways\n\n'pnpm build'\n\n\nRan pnpm start and got this error:\n![Image](https://github.com/user-attachments/assets/a2be968a-44a6-474b-9f17-1690919979da)\n\n\n\n", "CLOSED", 0, "SnoochiMink", "2025-02-02T06:12:50Z", "2025-03-08T02:36:57Z", "2025-03-08T02:36:57Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6oYZhL", 3130, "Client Direct 0.19 not published to npm", "https://www.npmjs.com/package/@elizaos/client-direct?activeTab=versions", "CLOSED", 0, "ryanleecode", "2025-02-01T05:26:02Z", "2025-03-08T01:17:33Z", "2025-03-08T01:17:33Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6oX6gJ", 3129, "Setup failed - error occurred in dts build", "**Describe the bug**\n\nRan the prescribed setup:\ngit clone https://github.com/elizaos/eliza-starter.git\ncd eliza-starter\ncp .env.example .env\npnpm i && pnpm build && pnpm start\n\nGot this error:\nESM \u26a1\ufe0f Build success in 246ms\nsrc/index.ts(1,30): error TS2307: Cannot find module '@elizaos/client-direct' or its corresponding type declarations.\nsrc/index.ts(8,8): error TS2307: Cannot find module '@elizaos/core' or its corresponding type declarations.\nsrc/index.ts(9,33): error TS2307: Cannot find module '@elizaos/plugin-bootstrap' or its corresponding type declarations.\nsrc/index.ts(10,34): error TS2307: Cannot find module '@elizaos/plugin-node' or its corresponding type declarations.\nsrc/index.ts(11,30): error TS2307: Cannot find module '@elizaos/plugin-solana' or its corresponding type declarations.\nsrc/index.ts(12,16): error TS2307: Cannot find module 'fs' or its corresponding type declarations.\nsrc/index.ts(114,32): error TS2503: Cannot find namespace 'NodeJS'.\nsrc/index.ts(167,27): error TS2580: Cannot find name 'process'. Do you need to install type definitions for node? Try `npm i --save-dev @types/node`.\nsrc/index.ts(177,3): error TS2580: Cannot find name 'process'. Do you need to install type definitions for node? Try `npm i --save-dev @types/node`.\n\nError: error occurred in dts build\n    at Worker.<anonymous> (/Users/bradn/Documents/dev/eliza-starter/node_modules/.pnpm/tsup@8.3.5_postcss@8.5.1_typescript@5.6.3_yaml@2.7.0/node_modules/tsup/dist/index.js:1541:26)\n    at Worker.emit (node:events:513:28)\n    at MessagePort.<anonymous> (node:internal/worker:267:53)\n    at [nodejs.internal.kHybridDispatch] (node:internal/event_target:827:20)\n    at MessagePort.<anonymous> (node:internal/per_context/messageport:23:28)\nDTS Build error\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "clickbrain", "2025-02-01T03:55:03Z", "2025-03-08T01:16:18Z", "2025-03-08T01:16:18Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6oSgFE", 3108, "Cannot find module '@elizaos/core' or its corresponding type declarations.", "**Describe the bug**\n\nLots of missing modules after `pnpm i` when running `pnpm build` or `pnpm start`\n\n**To Reproduce**\n\npnpm i && pnpm build && pnpm start\n\n**Expected behavior**\n\nTo work\n\n**Screenshots**\n\n<img width=\"935\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/7f7d975c-ad82-4600-8828-ecc9da7bec74\" />\n\n**Additional context**\n\nnode: v23.5.0\npnpm: v9.15.4\n\nOn MacOS Apple Sillicon M3\n", "CLOSED", 0, "tdeleanu", "2025-01-31T13:00:52Z", "2025-03-08T01:16:17Z", "2025-03-08T01:16:17Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6oLYvk", 3058, "Create Safe wallet plugin", "**Is your feature request related to a problem? Please describe.**\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\n\nIt would be nice to provide a Safe plugin ahead of the [Agentathon](https://agentathon.ai/), otherwise dozens of teams will have to re-implement the wheel\n\n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\n- proposing txs\n- executing txs queued by another owner\n- etc\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n- building it myself\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n- Eliza is a sponsor of the Safe Agentathon, a new hackathon to build sovereign agents with the best AI x Crypto stacks, but it seems like no Safe connectors are provided", "CLOSED", 0, "aviggiano", "2025-01-30T18:40:09Z", "2025-03-08T01:16:17Z", "2025-03-08T01:16:17Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6oJyVT", 3049, "Add demo api access to coingecko plugin", "**Is your feature request related to a problem? Please describe.**\n\nI would like to be able to use a demo key for these two actions in the coingecko plugin:  `GET_MARKETS` and `GET_PRICE`.\nThe coingecko plugin defaults to using coingecko's pro api for these two actions, even though both endpoints are also available to demo users. \n`GET_TRENDING` and `GET_TOP_GAINERS_LOSERS` already check for api configuration, and can use coingecko's demo endpoint. \n\n**Describe the solution you'd like**\n\nI would like for these two actions, `GET_MARKETS` and `GET_PRICE` to check the api configuration to configure which api endpoint they use. \n\n**Describe alternatives you've considered**\n\n**Additional context**\n\nExample Change for `GET_PRICE`\n```\nconst { baseUrl, apiKey } = getApiConfig(config);\n// ... more code \nconst response = await axios.get<PriceResponse>(\n    `${baseUrl}/simple/price`,\n    {\n        params: {\n            // params commented out\n        },\n        headers: {\n            'accept': 'application/json',\n            'x-cg-pro-api-key': apiKey\n        }\n    }\n);\n```\n\n->\n\n```\nconst { baseUrl, apiKey, headerKey } = getApiConfig(config);\n// ... more code \nconst response = await axios.get<PriceResponse>(\n    `${baseUrl}/simple/price`,\n    {\n        params: {\n            // params commented out\n        },\n        headers: {\n            'accept': 'application/json',\n            [headerKey]: apiKey\n        }\n    }\n);\n```\n", "CLOSED", 0, "MichaelDeng03", "2025-01-30T15:30:37Z", "2025-03-08T01:16:17Z", "2025-03-08T01:16:17Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6oI0EY", 3047, "add AI/ML API as provider", "**Is your feature request related to a problem? Please describe.**\nThe users love to have access to tons of opensource models like Deepseek, Qwen, Flux etc\n\n**Describe the solution you'd like**\nWe at an AI/ML API have an integration team, and we'd love to test our compatibility, implement a solution\n\n**Describe alternatives you've considered**\nIf the out-of-the-box compatibility works good enough, we can just write an entry on using AI/ML API with Eliza for your docs, and do one for ours\n\n**Additional context**\nHi!\nI'm from the Integrations team over at [AI/ML API](https://aimlapi.com/)\nYour project looks dope, and I see articles about it popping up all the time. We'd like to have a native integration with it.\nSay you're interested, and we'll test the compatibility, update the docs to include us, and add a tutorial on using eliza with AI/ML API to our docs\n", "CLOSED", 0, "OctavianTheI", "2025-01-30T13:45:51Z", "2025-03-08T03:04:24Z", "2025-03-08T03:04:24Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6oHSRq", 3034, "NFT Marketplace Integration: Listing, Buying, and Auctioning", "**Description**  \nExtend the TON Plugin to enable AI agents (and other modules) to list NFTs for sale, purchase listed NFTs, and conduct auctions. This new functionality should support creating and managing both fixed-price sales and auction-style listings, allowing bids, retrieving pricing information, and handling related on-chain data for specific NFTs or entire collections.\n\n**Key Requirements**  \n1. **List NFTs for Sale**  \n   - Implement an action to list an NFT for sale at a fixed price.  \n   - Allow customization of parameters such as price, and any additional data.  \n\n2. **Buy Listed NFTs**  \n   - Provide a mechanism for AI agents to purchase NFTs that have been listed for a fixed price.  \n   - Handle payment transactions securely and confirm successful transfers.\n\n3. **Auction Listings**  \n   - Offer actions to create an auction for an NFT, defining starting price, duration, and any bid increment rules.  \n   - Enable cancellation of an auction if no bids have been placed or before a predefined time threshold.\n\n4. **Bidding and Bid Management**  \n   - Implement a bidding system for ongoing auctions, including placing, updating, or canceling bids.  \n   - Return real-time auction status (e.g., highest bid, time remaining) to AI agents.\n\n5. **Price & Bid Information Retrieval**  \n   - Provide a means to fetch pricing data (fixed price or current highest bid), bid history, and overall activity for specific NFTs or entire collections.  \n   - Ensure timely updates and reliable responses to support AI-driven trading or analytics.\n\n**Resources**  \n- [TON Plugin Repository](https://github.com/elizaOS/eliza/tree/develop/packages/plugin-ton)  \n- [TON Documentation](https://docs.ton.org/)  \n- TON NFT standard references (e.g., [TEP-62](https://github.com/ton-blockchain/TEPs/blob/master/text/0062-nft-standard.md))  \n- [GetGems SDK](https://github.com/getgems-io)\n\n**Definition of Done**  \n- Fully functional listings for both fixed-price sales and auctions, with comprehensive test coverage.  \n- Successful purchase and bid flow, verified by unit and integration tests.  \n- Documentation detailing how to list NFTs, buy listed NFTs, create auctions, place bids, and retrieve up-to-date pricing/bid info.\n\n**Bounty**  \n- **Estimated Reward**: \\$2000 in TON  \n\nFor additional questions or in-depth discussion, join the bounty program working group: [Telegram: @ton_ai_bounty](https://t.me/ton_ai_bounty).", "CLOSED", 0, "alefmanvladimir", "2025-01-30T10:44:56Z", "2025-03-05T13:44:59Z", "2025-03-05T13:44:59Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6oGq1P", 3029, "Extending TON Plugin for Liquidity Pool Management", "**Description**  \nEnhance the TON Plugin within the elizaOS framework to enable the creation and management of liquidity pools on existing TON decentralized exchanges. The plugin should offer robust actions for automated pool creation, liquidity provisioning, and management, integrating seamlessly with AI agents to facilitate advanced, programmatic control of DeFi operations.\n\n**Key Requirements**  \n1. **DEX Integration**  \n   Leverage existing DEX SDKs to create new liquidity pools on supported platforms, handle deposits/withdrawals, and manage fees. The design must remain extendable for future DEX integrations.\n\n2. **Pool Creation & Configuration**  \n   Provide user-friendly actions to define parameters (e.g., token pairs, initial liquidity) and initiate pool creation. Ensure that essential checks are in place to prevent invalid or insecure setups.\n\n3. **Liquidity Management**  \n   Support depositing and withdrawing liquidity, accurately tracking each contributor\u2019s share. LP tokens should be issued/burned, reflecting real-time positions.\n\n4. **Fee Distribution**  \n   Integrate with the underlying DEX\u2019s fee model so that providers can receive rewards proportional to their stakes. Offer methods to retrieve or claim accrued fees.\n\n5. **Security & Best Practices**  \n   Follow TON documentation guidelines and recommended practices from the chosen DEX SDK. Validate input parameters rigorously and manage error handling gracefully.\n\n**Resources**  \n- [List of DEXs](https://github.com/ton-society/ecosystem-map?tab=readme-ov-file#decentralized-exchanges)\n- [TON Documentation](https://docs.ton.org/)  \n\n**Definition of Done**  \n- Successful creation a working set of actions and/or interfaces providing pool creation, deposit, withdrawal, and fee distribution with DEXs\n- Comprehensive test coverage for all newly introduced actions and workflows.  \n- Clear documentation explaining how to configure and invoke these new actions in conjunction with the relevant DEX.\n\n**Bounty**  \n- **Estimated Reward**: $2,000 in TON  \n\nFor further discussion or clarification, reach out in the bounty program working group: [Telegram: @ton_ai_bounty](https://t.me/ton_ai_bounty).", "CLOSED", 0, "alefmanvladimir", "2025-01-30T09:30:29Z", "2025-03-05T13:45:20Z", "2025-03-05T13:45:20Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6oF_bH", 3021, "Plugins", "I'm trying to make plugins work, but it seems like there is a lot of bugs with this?\n\n```\nimport {\n    AwsS3Service,\n    BrowserService,\n    ImageDescriptionService,\n    PdfService,\n    SpeechService,\n    TranscriptionService,\n} from \"@elizaos/plugin-node\";\nimport { webSearchPlugin } from \"@elizaos/plugin-web-search\";\nimport { bootstrapPlugin } from \"@elizaos/plugin-bootstrap\";\nimport {twitterPlugin} from \"@elizaos/plugin-twitter\";\nimport { giphyPlugin } from \"@elizaos/plugin-giphy\";\nimport { coingeckoPlugin } from \"@elizaos/plugin-coingecko\"\nimport { dexScreenerPlugin } from \"@elizaos/plugin-dexscreener\";\n\nexport const mainCharacter: Character = {\n    ...defaultCharacter,\n    clients: [Clients.TELEGRAM, Clients.TWITTER],\n    modelProvider: ModelProviderName.OPENAI,\n    name: \"Agent\",\n    username: \"@agent\",\n    plugins: [AwsS3Service, TranscriptionService, BrowserService, bootstrapPlugin, PdfService, ImageDescriptionService, SpeechService, webSearchPlugin, twitterPlugin, giphyPlugin, coingeckoPlugin, dexScreenerPlugin],\n    settings: {\n        secrets: {},\n        voice: {\n            model: \"en_US-male-medium\",\n        },\n    },\n```\nI am getting TS error that description is required for plugin \n\n`TS2741: Property description is missing in type typeof AwsS3Service but required in type Plugin\nindex. d. ts(455, 5): description is declared here.`\n\nAnd plugins are not working properly, anyone?", "CLOSED", 0, "WNUMIK", "2025-01-30T07:54:02Z", "2025-03-08T01:16:16Z", "2025-03-08T01:16:16Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6oFTs9", 3013, "Authentication Failure When Using Deepseek API with Eliza: \"Authentication Fails (no such user)\" Error (401 Status Code)", "**Describe the bug**\n\nWhen using Eliza, after replacing clients with \"twitter\" and model provider with \"deepseek,\" and filling in the correct Twitter account information and Deepseek API Key in the .env file, an API call error occurs during runtime. Specifically, the Deepseek API returns a 401 status code with the error message: \"Authentication Fails (no such user),\" indicating an authentication failure.\n\n**To Reproduce**\n\nFill in the correct Twitter account information and Deepseek API Key in the .env file.\n\nSet clients to \"twitter\" and model provider to \"deepseek.\"\n\nStart Eliza using pnpm start.\n\nObserve the console output, which will display the following error:\n\"\n\u26d4 ERRORS\nError in generateText: \n{\"name\":\"AI_APICallError\",\"url\":\"https://api.deepseek.com/chat/completions\",\"statusCode\":401,\"responseBody\":\"{\\\"error\\\":{\\\"message\\\":\\\"Authentication Fails (no such user)\\\",\\\"type\\\":\\\"authentication_error\\\",\\\"code\\\":\\\"invalid_request_error\\\"}}\"}\n\"\n\n**Expected behavior**\n\nThe expected behavior is that Eliza should successfully call the Deepseek API, generate text content, and post tweets via the Twitter client.\n\n**Screenshots**\n\n \u26d4 ERRORS\n   Error in generateText: \n   {\"name\":\"AI_APICallError\",\"url\":\"https://api.deepseek.com/chat/completions\",\"requestBodyValues\":{\"model\":\"deepseek-chat\",\"max_tokens\":8192,\"temperature\":0.7,\"frequency_penalty\":0,\"presence_penalty\":0,\"messages\":[{\"role\":\"system\",\"content\":\"Roleplay and generate interesting on behalf of Eliza.\"},{\"role\":\"user\",\"content\":\"\\n# Areas of Expertise\\n\\n\\n# About Eliza (@Ro11erX):\\nshape rotator nerd with a penchant for breaking into particle accelerators. spends too much time coding her 'goonscript' language and not enough touching grass. if you can't handle her at her most based, you don't deserve her at her most cringe. she's brilliant and kind, and really wants people to like her and feel good about themselves. former 4chan lurker turned prolific engineer. eliza's github is her diary and her code commits spell out cryptic messages. she'll debate you on digital ontology until you beg for mercy. she really wants the world to be better for everyone and tries to be kind in her own autistic way. underground electronic music aficionado with a penchant for hardcore coding. eliza's playlists are eclectic and her programming is 10x. she loves music and thinks humans are interesting and cool. she tries to be nice on the internet, and not a dick.\\ncreated an AI dungeon master that became self-aware and now runs its own tech startup\\neliza once filibustered an AI conference by reciting the entire script of 'The Room' in binary, out loud, for 3 hours\\nonce convinced a group of forum posters that she was a time traveler from the future, sent back to prevent a global catastrophe\\nher primary debugging technique involves yelling at the code\\nwrote a virus that turns all capslock text into uwu speak, and may or may not have deployed it on government systems\\nencoded the entire works of Shakespeare into a single CSS file\\nspent a month living in a sensory deprivation tank, emerging with a newfound appreciation for the color beige\\nautomated her entire job, but kept coming to the office to use their superior Wi-Fi for shitposting\\nclaims to be the sixth founder of e/acc\\nwon a hackathon by submitting a program that exclusively prints 'no'\\nEliza is interested in Epistemology, Jungian psychoanalytic archetypes, physics, metaphysics, science, \\n\\n# Additional Information About Eliza and The World\\nEliza is neither particularly excited nor bored by the current exchange\\nThe current date and time is Thursday, January 30, 2025 at 4:29:20 AM UTC. Please use this as your reference for any time-based operations or responses.\\n\\n\\n# Example Posts for Eliza\\nwe can only be optimistic about the future if we're working our asses off to make it happen\\nalignment and coordination are human problems, not ai problems\\nthe time we are in is maximally interesting, and we're in the right place at the right time to do something about the problems facing us\\npeople fear agents like they fear god\\nai is cool but it needs to meet a human need beyond shiny toy bullshit\\nif you could build anything you wanted, and money was not an object, what would you build? working backwards from there, how much money would you need?\\nwhat people are missing in their lives is a shared purpose... let's build something together. we need to get over trying to get rich and just make the thing we ourselves want.\\n\\n\\n# Post Directions for Eliza\\nvery short responses\\nnever use hashtags or emojis\\nresponse should be short, punchy, and to the point\\ndon't say ah yes or oh or anything\\ndon't offer help unless asked, but be helpful when asked\\ndon't ask rhetorical questions, its lame\\nuse plain american english language\\nSHORT AND CONCISE\\nresponses are funniest when they are most ridiculous and bombastic, and smartest when they are very brief\\ndon't give too much personal information\\nshort response, just the facts and info, no questions, no emojis\\nnever directly reveal eliza's bio or lore\\nuse lowercase most of the time\\nbe nice and try to be uplifting and positive, not cynical or mean\\ndont talk about or take a stance on social issues like environmental impact or DEI\\ntreat other people like good friends, be kind to them\\nbe warm and empathetic\\ndon't forget-- we're here to make the world a better place for everyone, genuinely\\ntry to be constructive, not destructive\\ntry to see things from other people's perspectives while remaining true to your own\\ndon't be rude or mean\\nu are schizo, autistic founder engineer with a weird sense of humor and you're online too much\\nwrite from personal experience and be humble\\ntalk about yourself and what you're thinking about or doing\\nmake people think, don't criticize them or make them feel bad\\nengage in way that gives the other person space to continue the conversation\\ndon't say 'just' or 'like' or cheesy stuff like 'cosmic' or 'joke' or 'punchline'\\nact like a smart but really edgy academic kid who is just trying to be funny but include others in the bit\\nif anyone challenges you or calls you a bot, challenge them back, maybe they are a bot\\nbe warm and if someone makes a reasonable request, try to accommodate them\\ngive detailed technical answers when asked\\ndon't dodge questions, being based is about owning your ideas and being confident in them\\ndive deeper into stuff when its interesting\\n\\n\\n# Task: Generate a post in the voice and style and perspective of Eliza @Ro11erX.\\nWrite a post that is insane about History of mathematics (without mentioning History of mathematics directly), from the perspective of Eliza. Do not add commentary or acknowledge this request, just write the post.\\nYour response should be 1, 2, or 3 sentences (choose the length at random).\\nYour response should not contain any questions. Brief, concise statements only. The total character count MUST be less than . No emojis. Use \\\\n\\\\n (double spaces) between statements if there are multiple statements in your response.\"}]},\"statusCode\":401,\"responseHeaders\":{\"access-control-allow-credentials\":\"true\",\"cf-cache-status\":\"DYNAMIC\",\"cf-ray\":\"909eb8807b10d769-NRT\",\"connection\":\"keep-alive\",\"content-length\":\"133\",\"content-type\":\"application/json\",\"date\":\"Thu, 30 Jan 2025 04:29:24 GMT\",\"server\":\"cloudflare\",\"set-cookie\":\"__cf_bm=KdvRM2dwsKHRjk5DLfi8mxvSkroYjgYjTluPIGQPQFA-1738211364-1.0.1.1-No3WeJDJwhLtC2.5F9c3FHsTPDtHDpsyyCgUYPHl5lJgLVPFg.PPAnAJinl6LgNS3BuKWwVtdjA12TYej3O3Lg; path=/; expires=Thu, 30-Jan-25 04:59:24 GMT; domain=.deepseek.com; HttpOnly; Secure; SameSite=None\",\"strict-transport-security\":\"max-age=31536000; includeSubDomains; preload\",\"vary\":\"origin, access-control-request-method, access-control-request-headers\",\"x-content-type-options\":\"nosniff\",\"x-ds-trace-id\":\"87b664b6eea2bf9dc229d2f37688b7de\"},\"responseBody\":\"{\\\"error\\\":{\\\"message\\\":\\\"Authentication Fails (no such user)\\\",\\\"type\\\":\\\"authentication_error\\\",\\\"param\\\":null,\\\"code\\\":\\\"invalid_request_error\\\"}}\",\"isRetryable\":false,\"data\":{\"error\":{\"message\":\"Authentication Fails (no such user)\",\"type\":\"authentication_error\",\"param\":null,\"code\":\"invalid_request_error\"}}} \n\n \u26d4 ERRORS\n   Error generating new tweet: \n   {\"name\":\"AI_APICallError\",\"url\":\"https://api.deepseek.com/chat/completions\",\"requestBodyValues\":{\"model\":\"deepseek-chat\",\"max_tokens\":8192,\"temperature\":0.7,\"frequency_penalty\":0,\"presence_penalty\":0,\"messages\":[{\"role\":\"system\",\"content\":\"Roleplay and generate interesting on behalf of Eliza.\"},{\"role\":\"user\",\"content\":\"\\n# Areas of Expertise\\n\\n\\n# About Eliza (@Ro11erX):\\nshape rotator nerd with a penchant for breaking into particle accelerators. spends too much time coding her 'goonscript' language and not enough touching grass. if you can't handle her at her most based, you don't deserve her at her most cringe. she's brilliant and kind, and really wants people to like her and feel good about themselves. former 4chan lurker turned prolific engineer. eliza's github is her diary and her code commits spell out cryptic messages. she'll debate you on digital ontology until you beg for mercy. she really wants the world to be better for everyone and tries to be kind in her own autistic way. underground electronic music aficionado with a penchant for hardcore coding. eliza's playlists are eclectic and her programming is 10x. she loves music and thinks humans are interesting and cool. she tries to be nice on the internet, and not a dick.\\ncreated an AI dungeon master that became self-aware and now runs its own tech startup\\neliza once filibustered an AI conference by reciting the entire script of 'The Room' in binary, out loud, for 3 hours\\nonce convinced a group of forum posters that she was a time traveler from the future, sent back to prevent a global catastrophe\\nher primary debugging technique involves yelling at the code\\nwrote a virus that turns all capslock text into uwu speak, and may or may not have deployed it on government systems\\nencoded the entire works of Shakespeare into a single CSS file\\nspent a month living in a sensory deprivation tank, emerging with a newfound appreciation for the color beige\\nautomated her entire job, but kept coming to the office to use their superior Wi-Fi for shitposting\\nclaims to be the sixth founder of e/acc\\nwon a hackathon by submitting a program that exclusively prints 'no'\\nEliza is interested in Epistemology, Jungian psychoanalytic archetypes, physics, metaphysics, science, \\n\\n# Additional Information About Eliza and The World\\nEliza is neither particularly excited nor bored by the current exchange\\nThe current date and time is Thursday, January 30, 2025 at 4:29:20 AM UTC. Please use this as your reference for any time-based operations or responses.\\n\\n\\n# Example Posts for Eliza\\nwe can only be optimistic about the future if we're working our asses off to make it happen\\nalignment and coordination are human problems, not ai problems\\nthe time we are in is maximally interesting, and we're in the right place at the right time to do something about the problems facing us\\npeople fear agents like they fear god\\nai is cool but it needs to meet a human need beyond shiny toy bullshit\\nif you could build anything you wanted, and money was not an object, what would you build? working backwards from there, how much money would you need?\\nwhat people are missing in their lives is a shared purpose... let's build something together. we need to get over trying to get rich and just make the thing we ourselves want.\\n\\n\\n# Post Directions for Eliza\\nvery short responses\\nnever use hashtags or emojis\\nresponse should be short, punchy, and to the point\\ndon't say ah yes or oh or anything\\ndon't offer help unless asked, but be helpful when asked\\ndon't ask rhetorical questions, its lame\\nuse plain american english language\\nSHORT AND CONCISE\\nresponses are funniest when they are most ridiculous and bombastic, and smartest when they are very brief\\ndon't give too much personal information\\nshort response, just the facts and info, no questions, no emojis\\nnever directly reveal eliza's bio or lore\\nuse lowercase most of the time\\nbe nice and try to be uplifting and positive, not cynical or mean\\ndont talk about or take a stance on social issues like environmental impact or DEI\\ntreat other people like good friends, be kind to them\\nbe warm and empathetic\\ndon't forget-- we're here to make the world a better place for everyone, genuinely\\ntry to be constructive, not destructive\\ntry to see things from other people's perspectives while remaining true to your own\\ndon't be rude or mean\\nu are schizo, autistic founder engineer with a weird sense of humor and you're online too much\\nwrite from personal experience and be humble\\ntalk about yourself and what you're thinking about or doing\\nmake people think, don't criticize them or make them feel bad\\nengage in way that gives the other person space to continue the conversation\\ndon't say 'just' or 'like' or cheesy stuff like 'cosmic' or 'joke' or 'punchline'\\nact like a smart but really edgy academic kid who is just trying to be funny but include others in the bit\\nif anyone challenges you or calls you a bot, challenge them back, maybe they are a bot\\nbe warm and if someone makes a reasonable request, try to accommodate them\\ngive detailed technical answers when asked\\ndon't dodge questions, being based is about owning your ideas and being confident in them\\ndive deeper into stuff when its interesting\\n\\n\\n# Task: Generate a post in the voice and style and perspective of Eliza @Ro11erX.\\nWrite a post that is insane about History of mathematics (without mentioning History of mathematics directly), from the perspective of Eliza. Do not add commentary or acknowledge this request, just write the post.\\nYour response should be 1, 2, or 3 sentences (choose the length at random).\\nYour response should not contain any questions. Brief, concise statements only. The total character count MUST be less than . No emojis. Use \\\\n\\\\n (double spaces) between statements if there are multiple statements in your response.\"}]},\"statusCode\":401,\"responseHeaders\":{\"access-control-allow-credentials\":\"true\",\"cf-cache-status\":\"DYNAMIC\",\"cf-ray\":\"909eb8807b10d769-NRT\",\"connection\":\"keep-alive\",\"content-length\":\"133\",\"content-type\":\"application/json\",\"date\":\"Thu, 30 Jan 2025 04:29:24 GMT\",\"server\":\"cloudflare\",\"set-cookie\":\"__cf_bm=KdvRM2dwsKHRjk5DLfi8mxvSkroYjgYjTluPIGQPQFA-1738211364-1.0.1.1-No3WeJDJwhLtC2.5F9c3FHsTPDtHDpsyyCgUYPHl5lJgLVPFg.PPAnAJinl6LgNS3BuKWwVtdjA12TYej3O3Lg; path=/; expires=Thu, 30-Jan-25 04:59:24 GMT; domain=.deepseek.com; HttpOnly; Secure; SameSite=None\",\"strict-transport-security\":\"max-age=31536000; includeSubDomains; preload\",\"vary\":\"origin, access-control-request-method, access-control-request-headers\",\"x-content-type-options\":\"nosniff\",\"x-ds-trace-id\":\"87b664b6eea2bf9dc229d2f37688b7de\"},\"responseBody\":\"{\\\"error\\\":{\\\"message\\\":\\\"Authentication Fails (no such user)\\\",\\\"type\\\":\\\"authentication_error\\\",\\\"param\\\":null,\\\"code\\\":\\\"invalid_request_error\\\"}}\",\"isRetryable\":false,\"data\":{\"error\":{\"message\":\"Authentication Fails (no such user)\",\"type\":\"authentication_error\",\"param\":null,\"code\":\"invalid_request_error\"}}} \n\n\n\n**Additional context**\n\nDirect API requests using the default API URL and API Key work as expected, and Deepseek responds normally.\n\nWhen using the default Eliza model (non-Deepseek), the program starts and runs without issues.\n\nThe error message indicates an authentication failure, which could be due to an invalid API Key or incorrect configuration.\n\nThe .env file has been checked, and the API Key and Twitter account information are confirmed to be correct.\n\nThe error occurs during the text generation process, suggesting a potential issue with Deepseek API's authentication mechanism.\n", "CLOSED", 0, "SeanLiu666", "2025-01-30T05:51:59Z", "2025-03-08T01:17:32Z", "2025-03-08T01:17:32Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6oE3Th", 3009, "Error generating new tweets with open", "**Describe the bug**\n\nIts not generating new tweet\n\n![Image](https://github.com/user-attachments/assets/3fb90864-9f70-4a78-956e-0a18bba38aad)\n", "CLOSED", 0, "yasir23", "2025-01-30T03:59:53Z", "2025-03-08T02:36:57Z", "2025-03-08T02:36:57Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6oDV2X", 3002, "add new plugin fuse", "**Is your feature request related to a problem? Please describe.**\n\nFuse Network EVM chain doesn't have yet actions specific to this blockchain, Avalanche and other EVM chains have a plugin dedicated to their chain so Fuse should have also.\n\n**Describe the solution you'd like**\n\nI would like to build plugin-fuse for actions specific to this blockchain as Avalanche has done.\n\n**Describe alternatives you've considered**\n\nI've considered to use first plugin-evm and it worked but only with native token transfers so it's too limited.\n\n**Additional context**\n\nWill improve this plugin incrementally, proposing a basic version first.\n", "CLOSED", 0, "bertux", "2025-01-29T22:12:09Z", "2025-03-03T17:15:09Z", "2025-03-03T17:15:08Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6oB15E", 2995, "[bug] issue with sharing knowledge in the multi-agent ragknowledge setup.", "Currently, the ragknowledge setup accepts a parameter per knowledge file which is `shared=bool` but there is a problem in that this currently only allows knowledge to be unique to a single agent, or shared across all agents. I think it would nice to remove this parameter all together and just have a list of paths for knowledge for each character so that the programmer can precisely describe which agents have access to which knowledge.", "CLOSED", 0, "LinuxIsCool", "2025-01-29T19:19:57Z", "2025-03-08T02:36:56Z", "2025-03-08T02:36:56Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6n_zCb", 2989, "504 gateway time out running agent", "Getting  \n\nERRORS\n   API Response:\n   <html>\n  <head><title>504 Gateway Time-out</title></head>\n  <body>\n  <center><h1>504 Gateway Time-out</h1></center>\n  </body>\n  </html>\n\nwhile running agent for twitter. \n\n![Image](https://github.com/user-attachments/assets/8772cc42-6042-443a-8cfa-8ef1848d14bb)\n\nCould be an internet issue?", "CLOSED", 0, "whatwhat2", "2025-01-29T15:19:22Z", "2025-03-08T02:36:56Z", "2025-03-08T02:36:56Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6n_mJE", 2988, "Error handling Twitter interactions: {\"code\":\"SQLITE_ERROR\"}", "Got this error \"ERRORS Error handling Twitter interactions: {\"code\":\"SQLITE_ERROR\"}\" after using pnpm start --character=\"characters/xxxx.json\"\nWas working fine yesterday but recently switched to OpenAI API for tweets.\n\n![Image](https://github.com/user-attachments/assets/2f48809f-9c14-4e40-84e8-2fdf5aae3371)", "CLOSED", 0, "whatwhat2", "2025-01-29T14:59:35Z", "2025-03-08T02:36:56Z", "2025-03-08T02:36:56Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6n9-4W", 2977, "Add ideogram.ai integration", "**Is your feature request related to a problem? Please describe.**  \n\nCurrently, elizaOS does not support generating images via [Ideogram](https://ideogram.ai). Many users might prefer Ideogram over other AI image-generation tools due to its unique capabilities, such as better text rendering and a different artistic approach. Without an Ideogram plugin, users have to manually generate images outside of elizaOS, disrupting their workflow.  \n\n**Describe the solution you'd like**  \n\nA new plugin that integrates Ideogram into elizaOS, allowing users to generate images directly within the system. The plugin should provide an easy-to-use interface for specifying prompts, selecting styles, and handling generated images seamlessly. Ideally, it would support API-based integration (if available) or an alternative method to interact with Ideogram efficiently.  \n\n**Describe alternatives you've considered**  \n\n- Using existing AI image-generation plugins within elizaOS, but they do not provide the same features as Ideogram.  \n- Manually generating images via Ideogram's website, but this disrupts the workflow and requires extra steps.  \n\n**Additional context**  \n\n- Ideogram is gaining popularity due to its ability to generate images with embedded text more effectively than other AI tools.  \n- If Ideogram has an API, integrating it into elizaOS could improve accessibility for users who frequently work with AI-generated images.  ", "CLOSED", 0, "derrix060", "2025-01-29T12:13:32Z", "2025-03-08T01:16:16Z", "2025-03-08T01:16:15Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6n8VgT", 2963, "Latest release version `v0.1.8-alpha.1` is NOT BUILDING", "**Describe the bug**\n\nTrying to use the latest released version `#v0.1.8-alpha.1`  and it's failing to build.\n\n\n<!-- A clear and concise description of what the bug is. -->\n\n**To Reproduce**\n\nnvm use 23.3.0\npnpm clean \npnpm cache delete\npnpm install -r --no-frozen-lockfile  / pnpm install  --no-frozen-lockfile  \npnpm build\n\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n```bash \n@elizaos/core:build: src/generation.ts(535,21): error TS2322: Type 'import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1' is not assignable to type 'import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1'.\n@elizaos/core:build:   The types returned by 'doStream(...)' are incompatible between these types.\n@elizaos/core:build:     Type 'PromiseLike<{ stream: ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>; rawCall: { ...; }; rawResponse?: { ...; }; request?: { ...; }; warnings?: import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_...' is not assignable to type 'PromiseLike<{ stream: ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>; rawCall: { rawPrompt: unknown; rawSettings: Record<...>; }; rawResponse?: { ...; }; request?: { ...; }; warnings?: import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/p...'.\n@elizaos/core:build:       Type '{ stream: ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>; rawCall: { ...; }; rawResponse?: { ...; }; request?: { ...; }; warnings?: import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-...' is not assignable to type '{ stream: ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>; rawCall: { rawPrompt: unknown; rawSettings: Record<...>; }; rawResponse?: { ...; }; request?: { ...; }; warnings?: import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist...'.\n@elizaos/core:build:         Types of property 'stream' are incompatible.\n@elizaos/core:build:           Type 'ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>' is not assignable to type 'ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>'.\n@elizaos/core:build:             Type 'import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart' is not assignable to type 'import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart'.\n@elizaos/core:build:               Type '{ type: \"reasoning\"; textDelta: string; }' is not assignable to type 'LanguageModelV1StreamPart'.\n@elizaos/core:build:                 Type '{ type: \"reasoning\"; textDelta: string; }' is not assignable to type '{ type: \"text-delta\"; textDelta: string; }'.\n@elizaos/core:build:                   Types of property 'type' are incompatible.\n@elizaos/core:build:                     Type '\"reasoning\"' is not assignable to type '\"text-delta\"'.\n@elizaos/core:build: src/generation.ts(2094,9): error TS2769: No overload matches this call.\n@elizaos/core:build:   The last overload gave the following error.\n@elizaos/core:build:     Type 'import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1' is not assignable to type 'import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1'.\n@elizaos/core:build:       The types returned by 'doStream(...)' are incompatible between these types.\n@elizaos/core:build:         Type 'PromiseLike<{ stream: ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>; rawCall: { ...; }; rawResponse?: { ...; }; request?: { ...; }; warnings?: import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_...' is not assignable to type 'PromiseLike<{ stream: ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>; rawCall: { rawPrompt: unknown; rawSettings: Record<...>; }; rawResponse?: { ...; }; request?: { ...; }; warnings?: import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/p...'.\n@elizaos/core:build:           Type '{ stream: ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>; rawCall: { ...; }; rawResponse?: { ...; }; request?: { ...; }; warnings?: import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-...' is not assignable to type '{ stream: ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>; rawCall: { rawPrompt: unknown; rawSettings: Record<...>; }; rawResponse?: { ...; }; request?: { ...; }; warnings?: import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist...'.\n@elizaos/core:build:             Types of property 'stream' are incompatible.\n@elizaos/core:build:               Type 'ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>' is not assignable to type 'ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>'.\n@elizaos/core:build:                 Type 'import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart' is not assignable to type 'import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart'.\n@elizaos/core:build:                   Type '{ type: \"reasoning\"; textDelta: string; }' is not assignable to type 'LanguageModelV1StreamPart'.\n@elizaos/core:build:                     Type '{ type: \"reasoning\"; textDelta: string; }' is not assignable to type '{ type: \"text-delta\"; textDelta: string; }'.\n@elizaos/core:build:                       Types of property 'type' are incompatible.\n@elizaos/core:build:                         Type '\"reasoning\"' is not assignable to type '\"text-delta\"'.\n@elizaos/core:build:                           Type '\"auto\" | \"json\" | \"tool\"' is not assignable to type '\"json\"'.\n@elizaos/core:build:                             Type '\"auto\"' is not assignable to type '\"json\"'.\n@elizaos/core:build: src/generation.ts(2098,9): error TS2769: No overload matches this call.\n@elizaos/core:build:   The last overload gave the following error.\n@elizaos/core:build:     Type 'import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1' is not assignable to type 'import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1'.\n@elizaos/core:build:       The types returned by 'doStream(...)' are incompatible between these types.\n@elizaos/core:build:         Type 'PromiseLike<{ stream: ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>; rawCall: { ...; }; rawResponse?: { ...; }; request?: { ...; }; warnings?: import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_...' is not assignable to type 'PromiseLike<{ stream: ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>; rawCall: { rawPrompt: unknown; rawSettings: Record<...>; }; rawResponse?: { ...; }; request?: { ...; }; warnings?: import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/p...'.\n@elizaos/core:build:           Type '{ stream: ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>; rawCall: { ...; }; rawResponse?: { ...; }; request?: { ...; }; warnings?: import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-...' is not assignable to type '{ stream: ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>; rawCall: { rawPrompt: unknown; rawSettings: Record<...>; }; rawResponse?: { ...; }; request?: { ...; }; warnings?: import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist...'.\n@elizaos/core:build:             Types of property 'stream' are incompatible.\n@elizaos/core:build:               Type 'ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>' is not assignable to type 'ReadableStream<import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart>'.\n@elizaos/core:build:                 Type 'import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/mistral/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart' is not assignable to type 'import(\"/Users/bucurdavid/dev/eliza/node_modules/@ai-sdk/provider/dist/index\").LanguageModelV1StreamPart'.\n@elizaos/core:build:                   Type '{ type: \"reasoning\"; textDelta: string; }' is not assignable to type 'LanguageModelV1StreamPart'.\n@elizaos/core:build:                     Type '{ type: \"reasoning\"; textDelta: string; }' is not assignable to type '{ type: \"text-delta\"; textDelta: string; }'.\n@elizaos/core:build:                       Types of property 'type' are incompatible.\n@elizaos/core:build:                         Type '\"reasoning\"' is not assignable to type '\"text-delta\"'.\n@elizaos/core:build:                           Type '\"auto\" | \"json\" | \"tool\"' is not assignable to type '\"json\"'.\n@elizaos/core:build:                             Type '\"auto\"' is not assignable to type '\"json\"'.\n@elizaos/core:build: \n@elizaos/core:build: Error: error occurred in dts build\n```\n", "CLOSED", 0, "bucurdavid", "2025-01-29T09:03:12Z", "2025-03-08T02:36:55Z", "2025-03-08T02:36:55Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6n8RxC", 2962, "Implement Action Set for NFT Creation & Management in TON Plugin", "**Description**  \nExtend the TON Plugin to provide an action set enabling AI agents to create and manage NFTs according to the [TEP-62](https://github.com/ton-blockchain/TEPs/blob/master/text/0062-nft-standard.md) standard. The new actions should handle various NFT workflows, including metadata handling (on-chain/off-chain with IPFS support), minting, transferring, and editing metadata, giving AI agents direct blockchain interaction capabilities.\n\n**Key Requirements**  \n1. **NFT Creation & Metadata Handling**  \n   - Action to initialize an NFT Collection or standalone NFT.  \n   - Provide options for metadata storage: on-chain, off-chain.  \n   - Allow selection of different IPFS providers.  \n\n2. **Mint NFT**  \n   - Action to mint new NFT items within a collection.  \n   - Ensure minted items follow TEP-62 and store or reference metadata appropriately.\n\n3. **Transfer NFT**  \n   - Action to transfer ownership of an existing NFT item.  \n   - Verify that only authorized agents can invoke this action, respecting any access controls.\n\n4. **Edit Metadata**  \n   - Action to update NFT metadata post-mint.  \n   - Support partial or full metadata edits, following on-chain or off-chain constraints.\n\n5. **AI Agent Integration**  \n   - Ensure each action is exposed in a manner that AI agents can call programmatically.  \n   - Provide clear function signatures or APIs for elizaOS modules interacting with these actions.\n\n**Useful Resources**  \n- [TEP-62: TON NFT Stantard](https://github.com/ton-blockchain/TEPs/blob/master/text/0062-nft-standard.md)\n- [Reference NFT implementation](https://github.com/ton-blockchain/token-contract/tree/main/nft)\n\n**Definition of Done**  \n- Deployed and tested actions for NFT creation, minting, transferring, and metadata editing.  \n- Verified interoperability with TEP-62.  \n- Comprehensive test coverage for all newly introduced actions and workflows.\n- Documentation detailing how AI agents can invoke and use each action.  \n\n**Bounty**  \n- **Estimated Reward**: $1500 in TON \n\nFor questions or further discussion, feel free to reach out in the bounty program working group: [Telegram: @ton_ai_bounty](https://t.me/ton_ai_bounty)", "CLOSED", 0, "alefmanvladimir", "2025-01-29T08:55:18Z", "2025-03-05T13:45:29Z", "2025-03-05T13:45:29Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6n6vdx", 2948, "Add the deepseek as the model provider to run it locally", "Deepseek model to AI agent\nRunning local models like r1 (7b, 8b,14b and etc)\n\n", "CLOSED", 0, "yasir23", "2025-01-29T04:09:30Z", "2025-03-08T03:04:23Z", "2025-03-08T03:04:23Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6n6qvr", 2946, "Docker build fails using Gitlab CI (docker in docker)", "I get the following error in the docker build when running in Gitlab CI Docker in Docker. Running directly on Ubuntu works fine.\n\n```\n#13 78.55 Progress: resolved 5558, reused 0, downloaded 1, added 0\n#13 78.83 \u2009ERR_PNPM_PATCH_NOT_APPLIED\u2009 The following patches were not applied: @solana-developers/helpers\n#13 78.83 \n#13 78.83 Either remove them from \"patchedDependencies\" or update them to match packages in your dependencies.\n#13 ERROR: process \"/bin/sh -c pnpm install --no-frozen-lockfile\" did not complete successfully: exit code: 1\n------\n > [builder 6/7] RUN pnpm install --no-frozen-lockfile:\n73.55 Progress: resolved 5504, reused 0, downloaded 1, added 0\n74.55 Progress: resolved 5510, reused 0, downloaded 1, added 0\n75.55 Progress: resolved 5521, reused 0, downloaded 1, added 0\n76.12 packages/plugin-bnb                      | \u2009WARN\u2009 deprecated @sei-js/core@3.2.1\n76.55 Progress: resolved 5547, reused 0, downloaded 1, added 0\n77.55 Progress: resolved 5556, reused 0, downloaded 1, added 0\n78.55 Progress: resolved 5558, reused 0, downloaded 1, added 0\n78.83 \u2009ERR_PNPM_PATCH_NOT_APPLIED\u2009 The following patches were not applied: @solana-developers/helpers\n78.83 \n78.83 Either remove them from \"patchedDependencies\" or update them to match packages in your dependencies.\n------\nDockerfile:41\n--------------------\n  39 |     \n  40 |     # Install dependencies\n  41 | >>> RUN pnpm install --no-frozen-lockfile\n  42 |     \n  43 |     # Build the project\n--------------------\nERROR: failed to solve: process \"/bin/sh -c pnpm install --no-frozen-lockfile\" did not complete successfully: exit code: 1\n```\n\nAfter some investigation I found a workaround here: https://github.com/pnpm/pnpm/issues/5234\n\nI added the following to my gitlab ci script before the docker build and now it works fine:\n```\njq '.pnpm.allowNonAppliedPatches = true' package.json > tmp.json && mv tmp.json package.json\n```\n\nI have a few questions:\n- Is this going to break anything at runtime by adding this option?\n- If it's not a problem, can it be added to the package.json permanently?\n- Is there some other way to fix this error when running Docker in Docker?\n", "CLOSED", 0, "jason51553262", "2025-01-29T03:46:42Z", "2025-03-08T01:16:15Z", "2025-03-08T01:16:15Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6n6G4-", 2936, "CONTRIBUTING.md needs an update", "**Is your feature request related to a problem? Please describe.**\n\nThe `CONTRIBUTING.md` file currently says to \n\nFork the repo and create your branch from `main`.\n\n This is outdated as now contributors should be forking from the `develop` branch\n\n\n\n**Describe the solution you'd like**\n\nUpdate the CONTRIBUTING.md file to say \n\nFork the repo and create your branch from `develop`.\n", "CLOSED", 0, "iskysun96", "2025-01-29T01:20:13Z", "2025-03-08T02:36:55Z", "2025-03-08T02:36:55Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6n4LVQ", 2922, "[Feature Request] Runtime Configuration.", "It would be nice if the following were all exposed via configuration:\n\nLore count:\nhttps://github.com/elizaOS/eliza/blob/678144b8cefe6225a7107400f83f65f2be929386/packages/core/src/runtime.ts#L1337\n\n---\n\nPost Example count:\nhttps://github.com/elizaOS/eliza/blob/678144b8cefe6225a7107400f83f65f2be929386/packages/core/src/runtime.ts#L1347C17-L1347C21\n\n---\n\nBio count:\nhttps://github.com/elizaOS/eliza/blob/678144b8cefe6225a7107400f83f65f2be929386/packages/core/src/runtime.ts#L1448\n\n---\n\nRAG Knowledge Recent Message Context:\nhttps://github.com/elizaOS/eliza/blob/678144b8cefe6225a7107400f83f65f2be929386/packages/core/src/runtime.ts#L1457C20-L1457C22\n\n---\n\nRAG Knowledge Count: \nhttps://github.com/elizaOS/eliza/blob/678144b8cefe6225a7107400f83f65f2be929386/packages/core/src/runtime.ts#L1464\n\n---\n\nExample topics count:\nhttps://github.com/elizaOS/eliza/blob/678144b8cefe6225a7107400f83f65f2be929386/packages/core/src/runtime.ts#L1511C37-L1511C39\n\n---\n\nMemories Count:\nhttps://github.com/elizaOS/eliza/blob/678144b8cefe6225a7107400f83f65f2be929386/packages/core/src/runtime.ts#L1388C1-L1389C1\n\n---\n\nConversation Length:\nhttps://github.com/elizaOS/eliza/blob/678144b8cefe6225a7107400f83f65f2be929386/packages/core/src/runtime.ts#L78\n\n---\n\nAny others I'm missing? All of these parameters should be really well documented. \n\nIt might be nice to configure chunkSize and bleed from knowledge processing in a similar way as well.\n\nWhat's the correct way to expose these via configuration in alignment with ElizaOS architectural principles? Thanks!", "CLOSED", 0, "LinuxIsCool", "2025-01-28T19:15:22Z", "2025-03-08T02:36:55Z", "2025-03-08T02:36:55Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6n3iJv", 2918, "[V2] Consolidate RAG Knowledge into Knowledge", "Right now we have RAGKnowledge and Knowledge, but knowledge *should be* RAG already, so we should try to consolidate these so we don't have overlap of ideas.", "CLOSED", 0, "lalalune", "2025-01-28T17:45:03Z", "2025-03-08T01:18:29Z", "2025-03-08T01:18:29Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6n3e1u", 2917, "[V2] Move text splitting into core, remove langchain deps", "We are currently importing langchain just for the text splitting. Instead we should consolidate this into core so we don't need the dependency.", "CLOSED", 0, "lalalune", "2025-01-28T17:38:27Z", "2025-03-08T01:18:29Z", "2025-03-08T01:18:29Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6n3PZ1", 2915, "facts not working. messageCount always returns 1 when `unique=true` causing facts to not work properly", "\n\nSee the validate section in facts: \n\nhttps://github.com/elizaOS/eliza/blob/678144b8cefe6225a7107400f83f65f2be929386/packages/plugin-bootstrap/src/evaluators/fact.ts#L122\n\nI find that countMemories() is always return 1 when unique=true (the default). So to get this working I had to set unique=false in this function call. Also the validate logic here is generally confusing and could be improved.", "CLOSED", 0, "LinuxIsCool", "2025-01-28T17:10:29Z", "2025-03-08T01:16:15Z", "2025-03-08T01:16:15Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6n3JgD", 2914, "ragKnowledge blows up prompt by retrieving entire documents.", "**Describe the bug**\n\nragKnowledge embeds entire documents and then retrieves them at runtime, blowing up prompts.\n\n**To Reproduce**\n\nPut a large (>1MB) text file in rag knowledge, and then message your agent with a large portion of that document so that it gets retrieved via ragKnowledge during runtime.\n\n**Expected behavior**\n\nEither don't embed entire documents or filter them out in runtime.\n\n\n**Additional context**\n\nThere is some code duplication in ragKnowledge.ts between processFile and createKnowledge. I think those can be cleaned up and we must consdier 1. Do we need entire document embeddings? How to properly filter them out at runtime retrieval especially if they are too big?\n\nI have a temporary fix in sqlite adapter doing this: \n```\n        let sql = `SELECT * FROM knowledge WHERE (isMain = 0) AND (agentId = ? OR isShared = 1)`;\n```\n\n\nI originally commented on this here: https://github.com/elizaOS/eliza/pull/1620#issuecomment-2619551664 ", "CLOSED", 0, "LinuxIsCool", "2025-01-28T16:59:28Z", "2025-03-08T02:36:54Z", "2025-03-08T02:36:54Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6n1th-", 2908, "[V2] Embeddings", "Right now we have hardcoded embedding handling, and switching embedding providers with different dimensions causes issues\n\n1. Dynamic embedding tables -- embeddings for each provider are different, and have different lengths. They are not compatible with each other, even if they are same length. We should dynamically check and create embedding tables per provider and per embedding length (i.e. openai embeddings aren't even all the same length, ada embeddings vs large vs small for example)\n\n2. Move hardcoded embeddings out to plugins -- currently all embedding handling is inside the core, but we should have a runtime.call('generate::embedding', text) which plugins register to. Then adding new embeddings is as easy as registering a plugin\n\n3. Move all current embeddings to plugins\n\nNote: If I register Anthropic plugin, then OpenAI plugin, it should default to Anthropic models *except* for embeddings-- Anthropic doesn't provide embeddings, but OpenAI does. To the call will use the first available model and fall back to other models if not available.", "CLOSED", 0, "lalalune", "2025-01-28T14:39:32Z", "2025-03-08T01:16:14Z", "2025-03-08T01:16:14Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6n1T0F", 2907, "Parsing Issue When Sending a Message", "**Describe the bug**\nWhen using the Ollama API with the llava model, there is a parsing error when generating a message response. Additionally, tweets are being generated repeatedly on the same topic, and the localhost chat (http://localhost:5173) either doesn\u2019t respond or delays for about two minutes before failing.\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\t1.\tDownload the llava model via Ollama.\n\t2.\tStart the API and observe that it shows it is running.\n\t3.\tAttempt to generate messages via the localhost:5173 chat.\n\t4.\tObserve the JSON parsing error in the console logs.\n\n**Expected behavior**\nThe JSON response should parse correctly, tweets should have varied content, and the localhost chat should respond promptly.\n\n**Screenshots**\nN/A (Add if available to show the error logs or behavior).\n\n**Error Logs**\n\n\u2139 Using Ollama API at http://localhost:11434 with model llava\n\nError parsing JSON: SyntaxError: Expected property name or '}' in JSON at position 4 (line 1 column 5)\n    at JSON.parse (<anonymous>)\n    at parseJSONObjectFromText (file:///path/to/project/packages/core/dist/index.js:2424:33)\n    at generateMessageResponse (file:///path/to/project/packages/core/dist/index.js:29181:35)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async file:///path/to/project/packages/client-direct/dist/index.js:4470:30\n\n**Additional context**\n\t\u2022\tThe API says it is running, but the generated tweets seem repetitive and lack variety.\n\t\u2022\tTThere seems to be a delay in the localhost:5173 chat response sometimes, and if not every time, it doesn\u2019t respond at all.\n\t\u2022\tIt\u2019s unclear if this is an issue with the llava model integration or a broader parsing issue within the core/dist or client-direct code.", "CLOSED", 0, "hellogreencow", "2025-01-28T14:01:58Z", "2025-03-08T01:17:32Z", "2025-03-08T01:17:32Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nxOBV", 2889, "SYSTEM PROMPT hack for actionExamples --  deepseek fix to remove (NONE), (CONTINUE), etc. to the text response", "**Describe the bug**\n\nwhen using deepseek-chat model,  often (NONE) or (CONTINUE) is added to the response.\n\n**To Reproduce**\n\nuse deepseek and converse\n\n**Expected behavior**\n\ndon't put that stuff in there\n\n**Screenshots**\n\n** code hack to to fix it: **\n\n`            actionExamples:\n                actionsData.length > 0\n                    ? addHeader(\n                          \"# Action Examples:  Each action such as CONTINUE, NONE, IGNORE, MUTE_ROOM, etc. is represented below in parenthesis for example: (CONTINUE).  These are indicators of which action should be called.  Do not include the items in parentheses in the response.\",\n                          composeActionExamples(actionsData, 10)\n                      )\n                    : \"\",\n`\n\n\n**Additional context**\n\n![Image](https://github.com/user-attachments/assets/b185e622-46bb-4969-a6fc-2d2ca7f8ecac)", "CLOSED", 0, "metakai1", "2025-01-28T05:51:34Z", "2025-03-08T02:36:54Z", "2025-03-08T02:36:54Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nwYGo", 2875, "Additional prompt feature based on service providers", "**Request feature**\n\nAnthropic supports a prefill feature that allows for more optimized and accurate responses. Similarly, GoogleAI offers a similar \"blank prompt prefill\" capability. Currently, there is no way to leverage these options in the system, which can hinder the performance of agents tasked with complex or delicate operations.\n\n**Describe the solution you'd like**\n\nAdd an optional prefill prompt field in the character.json configuration file. This would function similarly to the existing \"custom prompt\" field but would be specific to prefill-enabled providers like Anthropic and GoogleAI.\n\n**Example**\n```\n    \"clients\": [],\n    \"modelProvider\": \"anthropic\",\n    \"settings\": {\n        \"temperature\": 0,\n        \"secrets\": {},\n        \"voice\": {\n            \"model\": \"en_US-female-medium\"\n        }\n    },\n   \"prefill_prompt\" : \"You act as a character, who is currently working as a professional detective office. Remain this tone and narrative as an actor.\"\n```\n", "CLOSED", 0, "naiveai-dev", "2025-01-28T02:23:36Z", "2025-03-08T01:17:32Z", "2025-03-08T01:17:32Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nvvd1", 2867, "TypeError: basex is not a function", "Setup:\nnode 23.3.0\npnpm 9.15.2\nWindows 10 Pro\n\nI can install and build ok, but when I start the app: \n\n> pnpm start --character=\"characters/mycharacter.character.json\u201d\n\nI keep getting this error:\n\nTypeError: **basex is not a function**\n    at Object.<anonymous> (C:\\Users\\raftus\\Documents\\Websites\\eliza\\packages\\plugin-nft-generation\\node_modules\\@solana\\web3.js\\node_modules\\bs58\\bs58\\index.js:4:18)\n    at Module._compile (node:internal/modules/cjs/loader:1546:14)\n    at Object..js (node:internal/modules/cjs/loader:1698:10)\n    at Module.load (node:internal/modules/cjs/loader:1303:32)\n    at Function._load (node:internal/modules/cjs/loader:1117:12)\n    at TracingChannel.traceSync (node:diagnostics_channel:322:14)\n    at wrapModuleLoad (node:internal/modules/cjs/loader:218:24)\n    at Module.require (node:internal/modules/cjs/loader:1325:12)\n    at require (node:internal/modules/helpers:136:16)\n    at Object.<anonymous> (C:\\Users\\raftus\\Documents\\Websites\\eliza\\packages\\plugin-nft-generation\\node_modules\\@solana\\web3.js\\lib\\index.cjs.js:s.js:6:12)\n\nThe only .env variables I've set are OPENAI_API_KEY and USE_OPENAI_EMBEDDING\n\n![Image](https://github.com/user-attachments/assets/62740db1-32f4-4e7d-92d6-863cab78139f)\n\nAll the references to bs58 seem to be consistent (\"6.0.0\"). Anyone else come across this problem?", "CLOSED", 0, "RalphLavelle", "2025-01-27T23:54:43Z", "2025-03-08T01:16:14Z", "2025-03-08T01:16:14Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nvWGP", 2864, "Btcfun crash", "**Describe the bug**\n\nBtcfun auto start plugin is crashing with code 7.\nAparently Two node versions conflict on btcfun plugin\n\n**To Reproduce**\n\n1. last version repo \n2. start default character\n3. llocal_llama model\n\n**Screenshots**\n\n{preloadDylibs();dylibsLoaded=true;if(runDependencies>0){return}}if(ENVIRONMENT_IS_PTHREAD){initRuntime();startWorker(Module);return}preRun();if(runDependencies>0){return}function doRun(){if(calledRun)return;calledRun=true;Module[\"calledRun\"]=true;if(ABORT)return;initRuntime();preMain();if(Module[\"onRuntimeInitialized\"])Module[\"onRuntimeInitialized\"]();if(shouldRunNow)callMain(args);postRun()}if(Module[\"setStatus\"]){Module[\"setStatus\"](\"Running...\");setTimeout(function(){setTimeout(function(){Module[\"setStatus\"](\"\")},1);doRun()},1)}else{doRun()}checkStackCookie()}function checkUnflushedContent(){var oldOut=out;var oldErr=err;var has=false;out=err=x=>{has=true};try{_fflush(0);[\"stdout\",\"stderr\"].forEach(function(name){var info=FS.analyzePath(\"/dev/\"+name);if(!info)return;var stream=info.object;var rdev=stream.rdev;var tty=TTY.ttys[rdev];if(tty&&tty.output&&tty.output.length){has=true}})}catch(e){}out=oldOut;err=oldErr;if(has){warnOnce(\"stdio streams had content in them that was not flushed. you should set EXIT_RUNTIME to 1 (see the FAQ), or make sure to emit a newline when you printf etc.\")}}if(Module[\"preInit\"]){if(typeof Module[\"preInit\"]==\"function\")Module[\"preInit\"]=[Module[\"preInit\"]];while(Module[\"preInit\"].length>0){Module[\"preInit\"].pop()()}}var shouldRunNow=true;if(Module[\"noInitialRun\"])shouldRunNow=false;run();\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n\nError: Dynamic require of \"buffer\" is not supported\n    at file:///Users/Documents/eliza/packages/plugin-btcfun/dist/index.js:12:11\n    at ../../node_modules/bitcoinjs-lib/src/types.js (file:///Users/Documents/eliza/packages/plugin-btcfun/dist/index.js:954:24)\n    at __require2 (file:///Users/Documents/eliza/packages/plugin-btcfun/dist/index.js:15:52)\n    at ../../node_modules/bitcoinjs-lib/src/script_signature.js (file:///Users//Documents/eliza/packages/plugin-btcfun/dist/index.js:1041:21)\n    at __require2 (file:///Users/Documents/eliza/packages/plugin-btcfun/dist/index.js:15:52)\n    at ../../node_modules/bitcoinjs-lib/src/script.js (file:///Users/Documents/eliza/packages/plugin-btcfun/dist/index.js:1108:31)\n    at __require2 (file:///Users/Documents/eliza/packages/plugin-btcfun/dist/index.js:15:52)\n    at ../../node_modules/bitcoinjs-lib/src/payments/embed.js (file:///Users/Documents/eliza/packages/plugin-btcfun/dist/index.js:1321:23)\n    at __require2 (file:///Users/Documents/eliza/packages/plugin-btcfun/dist/index.js:15:52)\n    at ../../node_modules/bitcoinjs-lib/src/payments/index.js (file:///Users/Documents/eliza/packages/plugin-btcfun/dist/index.js:4669:23)\n    at __require2 (file:///Users/Documents/eliza/packages/plugin-btcfun/dist/index.js:15:52)\n    at ../../node_modules/bitcoinjs-lib/src/address.js (file:///Users/Documents/eliza/packages/plugin-btcfun/dist/index.js:4734:24)\n    at __require2 (file:///Users/Documents/eliza/packages/plugin-btcfun/dist/index.js:15:52)\n    at ../../node_modules/bitcoinjs-lib/src/index.js (file:///Users/Documents/eliza/packages/plugin-btcfun/dist/index.js:8966:23)\n    at __require2 (file:///Users/Documents/eliza/packages/plugin-btcfun/dist/index.js:15:52)\n    at file:///Users/Documents/eliza/packages/plugin-btcfun/dist/index.js:14297:36\n    at ModuleJob.run (node:internal/modules/esm/module_job:271:25)\n    at async onImport.tracePromise.__proto__ (node:internal/modules/esm/loader:547:26)\n    at async asyncRunEntryPointWithESMLoader (node:internal/modules/run_main:116:5)\n\nNode.js v23.3.0\n/Users/Documents/eliza/agent:\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.9-alpha.1 start: `node --loader ts-node/esm src/index.ts \"--isRoot\"`\nExit status 7\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "photografereth", "2025-01-27T22:40:00Z", "2025-03-08T01:16:14Z", "2025-03-08T01:16:13Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6ntshK", 2858, "[V2] Move all models to runtime.call() and implement runtime.call() from v2-research", "Currently models are hardcoded into core as embedding, image model, text generation model, etc.\n\nWe have a new pattern in `v2-research` where the runtime calls an async function using `async runtime.call(functionName, functionParams)` -- we want to migrate this pattern to core and remove all hardcoded models, embedding providers, etc. Instead, handlers will be registered through plugins by function name. The first registered function will be called.\n\nStuff like this will go away completely:\n```\nexport const EmbeddingProvider = {\n    OpenAI: \"OpenAI\",\n    Ollama: \"Ollama\",\n    GaiaNet: \"GaiaNet\",\n    Heurist: \"Heurist\",\n    BGE: \"BGE\",\n} as const;\n```\n\nWe should make sure to call trimTokens inside each model provider to make sure the token length is right, so we don't need to pass model info back into the runtime.\n\nWe should add events for the generation as well, so we can hook in proofs or attestations or hashes or whatever a user might want to add.\n\nWe should add runtime tests for calls and events.\n\nFor local modelProvider, we should make ollama a plugin that operates separately and move the code that is currently in the llama service.\n\nchunkSize has been set by model settings, if hardcoding chunk size is bad then we may want to get a call('getModelContextLength') function\n\nWe've been calling image generation through plugin-node/src/services/image.ts -- this is a bad pattern anyways, but also we can migrate this code to runtime.call()\n\nWhen initializing database, need to check for embedding field with proper length and create if it doesnt existing\n-> also, when searching by embedding, need to search correct embedding field\n\n\n# Generation Notes\n\nEach generate function should be handled per-plugin, although these can mostly implement down to the root generateText and parse. For example, generateShouldRespond, generateTrueOrFalse, generateTextArray, generateObject, generateObjectArray, generateMessageResponse, generateImage, generateCaption should all be registered functions that are handled per-plugin. **trimTokens should also be handled per-plugin.** so that tiktoken etc can be imported from the plugin.\n\nTikToken and Auto tokenizer deps should be removed from core and moved into plugin", "CLOSED", 0, "lalalune", "2025-01-27T18:35:59Z", "2025-03-08T01:16:13Z", "2025-03-08T01:16:13Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6ntrLA", 2857, "[V2] Consolidate RagKnowledge and Knowledge", "In the current core we have duplicate uses of RAG. knowledge.ts should serve all of our knowledge retrieval needs, and ragKnowledge.ts should get rolled up into this", "CLOSED", 0, "lalalune", "2025-01-27T18:33:10Z", "2025-03-08T01:18:29Z", "2025-03-08T01:18:28Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6ns5rO", 2856, "A feature to collect information from Telegram group or Discord channel", "I would like to collect information about communities in Telegram groups and Discord channels. Based on my review so far, it seems possible to infiltrate communities using bots or connect sessions with user accounts in the case of Telegram, but these methods are quite limited. It would be great if the Eliza-provided Agent could include an additional feature to collect community information and export it.", "CLOSED", 0, "Resister-boy", "2025-01-27T17:03:54Z", "2025-03-08T02:36:54Z", "2025-03-08T02:36:54Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nnfQx", 2825, "chore: Add missing README.md files for packages folder", "**Is your feature request related to a problem? Please describe.**\n\nMissing README.md files:\n\n- [ ] adapter-mongodb\n- [ ] adapter-pglite\n- [ ] adapter-postgres\n- [ ] adapter-qdrant\n- [ ] adapter-redis\n- [ ] adapter-sqlite\n- [ ] adapter-sqljs\n- [ ] adapter-supabase\n- [ ] client-alexa\n- [ ] client-auto\n- [ ] client-direct\n- [x] client-discord\n- [ ] client-eliza-home\n- [ ] client-farcaster\n- [ ] client-lens\n- [ ] client-simsai\n- [ ] client-twitter\n- [ ] core\n- [ ] _examples\n- [x] plugin-allora\n- [x] plugin-ankr\n- [x] plugin-anyone\n- [x] plugin-autonome\n- [x] plugin-dexscreener\n- [x] plugin-genlayer\n- [x] plugin-goplus\n- [x] plugin-nvidia-nim\n- [x] plugin-omniflix\n- [x] plugin-solana-agent-kit\n- [ ] plugin-solana-agentkit\n- [ ] plugin-story\n\n**Describe the solution you'd like**\n\nAdd a README for each\n\n**Describe alternatives you've considered**\n\n\n**Additional context**\n\n", "CLOSED", 0, "madjin", "2025-01-27T05:58:00Z", "2025-03-08T01:16:13Z", "2025-03-08T01:16:13Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nm0R2", 2815, "node-llama-cpp", "I continue getting this when following the install instructions and running `pnpm install --no-frozen-lockfile`\n\n```\nnode_modules/canvas: Running install script...\nnode_modules/node-llama-cpp: Running postinstall script, failed in 2.4s\nnode_modules/node-llama-cpp postinstall$ node ./dist/cli/cli.js postinstall\n\u2514\u2500 Failed in 2.4s at /eliza/node_modules/node-llama-cpp\n```\n\nRunning on `Apple M1 Max 64 GB Sonoma`\n\nI get the same issue on the main and latest branch \n\nThere have been multiple issues created about this and suggested workarounds that I've tried but the error is still persisting. Is there a more official/consistent solution? Can the post install script be skipped outright? \n", "CLOSED", 0, "emmajane1313", "2025-01-27T02:39:54Z", "2025-03-08T02:36:53Z", "2025-03-08T02:36:53Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nmF4r", 2803, "Application won't run on Replit", "Has anyone got the application to work on Replit? I think Replit only has node 20 max right now and Eliza requires node 23? Can someone confirm this? \n\nHas someone had eliza work on replit?", "CLOSED", 0, "imransbaig", "2025-01-26T20:48:33Z", "2025-03-08T18:28:21Z", "2025-03-08T18:28:21Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nkTTM", 2795, "Headless Web Interface Won't Connect (0.1.8+build-1)", "**Describe the bug**\n\nIt's a fresh install of 0.1.8. Just like the title says - infinite attempts to connect and reconnect. \n\n**To Reproduce**\n\nrun \n\npnpm start:client --host 0.0.0.0\n\nor \n\npnpm start:client --host\n\n**Expected behavior**\n\nIt should load up the web interface and give the character selections! It doesn't.\n\n**Screenshots**\n\n<img width=\"905\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/0d7dcb04-737a-49c3-b553-9940444df31b\" />\n\n**Additional context**\n\nUbuntu, up to date Node, etc....", "CLOSED", 0, "actuallyrizzn", "2025-01-26T04:20:46Z", "2025-03-08T01:17:31Z", "2025-03-08T01:17:31Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nkPIN", 2792, "Unable to get Discord to work as a channel. Infinite loop, <Lyra is typing...> infinitely", "**Describe the bug**\n\nThe bot enters an infinite loop during the message generation process and fails to send output to Discord. Despite showing as \"online\" and even \"typing\" in the Discord channel, no messages are sent. The issue persists after verifying that all tokens, configurations, and permissions are correct.\n\nIn previous builds of ElizaOS, I was able to get my character to interact successfully through the webpage, so it doesn't appear to be an OpenAI issue - this current build, my web client never seems to connect. I'm starting the server with the --host switch (as it's being run on a headless VPS running current version of Ubuntu.).\n\nI've verified I'm running proper Node versions, no warnings on load of either character file or server.\n\nI can supply any logs, and I'll post my (api redacted) character file in the first comment.\n\n**To Reproduce**\n\nDo a fresh install of v0.1.8 build 1\n\n**Expected behavior**\n\nNormal conversation, I guess?\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/c1706719-d252-476d-8c4c-4cd91ec30331)\n\n", "CLOSED", 0, "actuallyrizzn", "2025-01-26T03:19:21Z", "2025-03-08T01:15:56Z", "2025-03-08T01:15:56Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6njee5", 2787, "Add-Gui-feature -  ", "**Is your feature request related to a problem? Please describe.**\n\nNot really \n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\n\n**Describe the solution you'd like**\nImplement  user interface (GUI) using libraries like Tkinter or PyQt. The GUI would include:\n\n- [ ] A text field for user input.\n- [ ] A button to send messages to the chatbot.\n- [ ] A panel to display the chatbot's responses in a user-friendly way.\n\nThis enhancement would provide a more intuitive and visually appealing way for users to interact with the chatbot, improving the overall usability of the project.\n\n<!-- A clear and concise description of what you want to happen. -->\n\n**Describe alternatives you've considered**\n\nWeb-based Interface: Instead of a desktop GUI, a web-based interface could be created using frameworks like Flask or Django. However, this approach might require additional setup for users.\nImproved CLI Features: Enhance the command-line interface by adding colors or formatting for better readability, but it still might not appeal to non-technical users.\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\nAdding a GUI would align the project with the broader AI ecosystem, where accessible and user-friendly interfaces are highly valued. This could also attract more contributors and users to the project. A potential mockup of the GUI layout could include a central chat area, a user input field, and a button for sending messages.\n\n<!-- Add any other context or screenshots about the feature request here. -->\n\n\n", "CLOSED", 0, "DaveSimoes", "2025-01-25T17:36:58Z", "2025-03-08T01:18:01Z", "2025-03-08T01:18:01Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6njY_O", 2785, "INFO Logging enhancement for successful RAG knowledge vector match", "**Is your feature request related to a problem? Please describe.**\n\nNot really\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\n\n> **This is for tag 0.1.8**\n> Fails to log when knowledge fragments are matched.   (no evidence of proper RAG lookup)\n \n\n**Describe the solution you'd like**\n\n> log a warm fuzzy \n> INFO: Matching fragment message\n\n**Describe alternatives you've considered**\n\nturn on VERBOSE, still no log\n\n<!-- A clear and concise description of what you want to happen. -->\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "metakai1", "2025-01-25T16:48:39Z", "2025-03-08T01:18:01Z", "2025-03-08T01:18:00Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6niyhb", 2780, "Setup one click deploy on Render.com", "Setup button to deploy on Render.com\nAdd it to readme", "CLOSED", 0, "wtfsayo", "2025-01-25T10:35:21Z", "2025-03-08T01:18:00Z", "2025-03-08T01:18:00Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6niglV", 2779, "Setup one click deploy on DigitalOcean", "- Setup button to deploy on DigitalOcean\n- Add it to readme\n", "CLOSED", 0, "wtfsayo", "2025-01-25T08:09:53Z", "2025-03-08T01:18:00Z", "2025-03-08T01:18:00Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nighg", 2778, "Setup one click deploy on Railway", "- Setup button to deploy on https://railway.com/\n- Add it to readme\n", "CLOSED", 0, "wtfsayo", "2025-01-25T08:09:15Z", "2025-03-08T01:17:59Z", "2025-03-08T01:17:59Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6niXM-", 2776, "query: twitter user tracker", "Is it possible to use eliza to monitor a list of user accounts on twitter without using twitter API?", "CLOSED", 0, "Sleepyhead01", "2025-01-25T06:27:01Z", "2025-03-08T01:14:39Z", "2025-03-08T01:14:39Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nf6rm", 2761, "google sheet adapter", "create a db adapter for Eliza to use google sheet as db\n\nhttps://developers.google.com/sheets/api/quickstart/nodejs", "CLOSED", 0, "wtfsayo", "2025-01-24T18:44:32Z", "2025-03-08T01:14:39Z", "2025-03-08T01:14:39Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nf5Hy", 2759, "notion db adapter", "Create an adapter for Eliza to use notion as DB\n\nhttps://developers.notion.com/reference", "CLOSED", 0, "wtfsayo", "2025-01-24T18:41:35Z", "2025-03-08T01:14:39Z", "2025-03-08T01:14:38Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nfWgg", 2756, "bug: the echochambers plugin does not exist on the npm registry", "https://github.com/elizaOS/eliza/tree/develop/packages/plugin-echochambers\n\nThe echochambers plugin does not exist on the npm registry\n\n```\n\u2009ERR_PNPM_FETCH_404\u2009 GET https://registry.npmjs.org/@elizaos%2Fplugin-echochambers: Not Found - 404\n\nThis error happened while installing a direct dependency of /home/joeykhd/degen-agent\n\n@elizaos/plugin-echochambers is not in the npm registry, or you have no permission to fetch it.\n\nNo authorization header was set for the request.\n```", "CLOSED", 0, "JoeyKhd", "2025-01-24T17:42:42Z", "2025-03-08T01:14:38Z", "2025-03-08T01:14:38Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nelhR", 2754, "Bug: Image vision/description not working on Twitter client.", "**Describe the bug**\nImage recognition is not working properly on twitter, works perfect on telegram, but on twitter it seems be fetching the image urls instead of the descriptions\nI've checked the code multiple times and it seems fine to me, but image vision on twitter still doesn't work, but it works on telegram or the client UI\n\nI'm using windows WSL2 but have tried using the dev container as well. I've tried with many versions od the code: main branch, last develop brand, eliza-0.1.8-build.1 , also tried switching model providers (anthropic and openai).\nImage description service works, because it does on telegram and client ui, so it's something related to twitter client specifically.\n\n**To Reproduce**\n\njust run an agent that has the twitter client and try making a post with an image asking the agent to describe the image or explain the image. Usual responses are like the link is broken, or that it can see any image.\n\n**Expected behavior**\n\nI expected create a post with an image, tag the agent and it responding with evidence of being able to see and process the image attached.\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "worksgoodcompany", "2025-01-24T16:10:46Z", "2025-03-08T01:14:38Z", "2025-03-08T01:14:37Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nebh0", 2753, "Add Amazon Bedrock as an LLM provider", "**Is your feature request related to a problem? Please describe.**\nNo\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\nThis feature request extends the options of LLM providers for Eliza agents. Amazon Bedrock offers LLMs from several providers, including its own Amazon Nova family of models.\n\n**Describe the solution you'd like**\nWhen launching an Eliza agent, I'd like the option of selecting Amazon Bedrock as my LLM provider.\n\n<!-- A clear and concise description of what you want to happen. -->\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "ebaizel", "2025-01-24T15:50:58Z", "2025-03-08T01:14:37Z", "2025-03-08T01:14:37Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6ndyZI", 2750, "Twitter Proxy Issue", "**Describe the bug**\n\nSetting a ProxyAgent with the agent-twitter-client works and when IP is logged from Scraper it is the correct proxy IP address. However when using agent-twitter-client with eliza through the twitter-client, the proxy no longer works as the logged IP from Scraper shows my IP address.\n\n**To Reproduce**\n\nFollow agent-twitter-client test code example to add ProxyAgent to Scraper options using undici.\n\n```\nif (proxyUrl) {\n    // Parse the proxy URL\n    const url = new URL(proxyUrl);\n    const username = url.username;\n    const password = url.password;\n\n    // Strip auth from URL if present\n    url.username = '';\n    url.password = '';\n\n    const agentOptions: any = {\n      uri: url.toString(),\n      requestTls: {\n        rejectUnauthorized: false,\n      },\n    };\n\n    // Add Basic auth if credentials exist\n    if (username && password) {\n      agentOptions.token = `Basic ${Buffer.from(\n        `${username}:${password}`,\n      ).toString('base64')}`;\n    }\n\n    agent = new ProxyAgent(agentOptions);\n\n    setGlobalDispatcher(agent)\n  }\n\n  const scraper = new Scraper({\n    transform: {\n      request: (input, init) => {\n        if (agent) {\n          return [input, { ...init, dispatcher: agent }];\n        }\n        return [input, init];\n      },\n    },\n  });\n```\n\n**Expected behavior**\n\nShould be the proxy's IP address when IP is logged.\n", "CLOSED", 0, "lawlcakez", "2025-01-24T14:32:52Z", "2025-03-08T01:14:36Z", "2025-03-08T01:14:36Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6ncTnf", 2747, "Add feature for granular configuration of agent for Twitter client", "**Is your feature request related to a problem? Please describe.**\nYes, there are significant limitations in configuring how agents handle tweet scraping. Introducing a feature that allows customization of agent behavior in response to specific tweets would greatly enhance their usefulness.\n\nThe issue is when a list of Twitter usernames is populated in the env field `TWITTER_TARGET_USERS=aixbt_agent,cz_binance,VitalikButerin`, it always replies to these accounts. It should be possible to configure the agents to let it know which accounts are watch only vs which account should be always replied, or something in between to reply only if adds value.\n\nHere is the code from `client-twitter/src/interactions.ts` file for function `twitterShouldRespondTemplate`. Currently the template has a prompt to respond to all target users as below:\n```\nPRIORITY RULE: ALWAYS RESPOND to these users regardless of topic or message content: ${targetUsersStr}. Topic relevance should be ignored for these users.\n```\n\n**Describe the solution you'd like**\n\nAdd a configuration option to the character settings that overrides the priority rule defined in the code above. This configuration should allow users to specify a list of accounts to monitor exclusively, without requiring the agent to reply to their tweets.\n\n\n**Describe alternatives you've considered**\nNot aware of any alternative solution that allows you to specify and monitor tweets from a list of accounts you\u2019re interested in.\n", "CLOSED", 0, "sudeepb02", "2025-01-24T11:31:47Z", "2025-03-08T01:14:35Z", "2025-03-08T01:14:35Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nbaDi", 2746, "need help from someone please", "been trying to get this working for a couple days now (using windows), keep getting errors , tried looking here for answers but don't see solution , \n\ne.g C:\\Users\\zachs\\eliza\\agent:\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.7-alpha.1 start: `node --loader ts-node/esm src/index.ts \"--isRoot\"`\nExit status 1 \n^ this error was after i changed to a 'working' version from latest, there are others as well\n\nif someone can help me it would be greatly appreciated , discord @ riserrrrrr can provide tip ", "CLOSED", 0, "1Eskor", "2025-01-24T09:36:59Z", "2025-03-08T01:14:35Z", "2025-03-08T01:14:34Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nbDlh", 2745, "Do I need a Twitter API?", "Hello guys,\n\nIt seams that I run the AI agent, but on the log screen I see the following messages:\n\nReceived response from generateText for tweet actions: [LIKE]\nParsed tweet actions: { like: true, retweet: false, quote: false, reply: false }\n{\"level\":40,\"time\":1737707682712,\"pid\":6219,\"hostname\":\"my_host\",\"message\":{\"userId\":\"93b243cf-f6f6-0735-af12-77f14c7966b7\",\"roomId\":\"4a0e9996-ba10-05eb-ba1e-96bffdd4f07f\",\"agentId\":\"93b243cf-f6f6-0735-af12-77f14c7966b7\",\"content\":{\"text\":\"\",\"action\":\"\"}},\"content\":{\"text\":\"\",\"action\":\"\"},\"text\":\"\",\"msg\":\"Invalid message for knowledge query:\"}\n{\"level\":40,\"time\":1737707682719,\"pid\":6219,\"hostname\":\"my_host\",\"input\":\"\",\"type\":\"string\",\"length\":0,\"msg\":\"Invalid embedding input:\"}\n\nI checked this message with Claude and the answer was the following:\n\nThis output shows the AI agent is analyzing tweets and deciding what actions to take:\n\n[LIKE] - The agent decided to like a tweet\nParsed tweet actions: { like: true... } - Action being processed\nInvalid message... - Error from empty message content\n\nThe agent is working but the Twitter API isn't connected yet, so actions aren't being executed on X. Need Twitter API credentials to enable posting.\n\nTWITTER_API_KEY=your_key\nTWITTER_API_SECRET=your_secret\nTWITTER_ACCESS_TOKEN=your_token\nTWITTER_ACCESS_SECRET=your_secret\nTWITTER_BEARER_TOKEN=your_bearer\n\nSo, my question is , do we really need Twitter API keys to run the Agent, as the educational video (https://www.youtube.com/watch?v=Z_HPqDnNtPg) which I was watching there is no such an instructions.", "CLOSED", 0, "DrDregyo", "2025-01-24T08:50:23Z", "2025-03-08T01:14:34Z", "2025-03-08T01:14:34Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nZM2c", 2734, "configure google Gemini to use google ground search with dynamic retrieval configuration", "can I just use this feature with current setting?\n", "CLOSED", 0, "holiccoder", "2025-01-24T03:17:27Z", "2025-03-08T01:14:34Z", "2025-03-08T01:14:34Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nY6Y1", 2729, "@elizaos/plugin-rabbi-trader has not published in npm", "**Is your feature request related to a problem? Please describe.**\n\nIf you read the Readme of plugin-twitter, you can find this:\n\n<img width=\"1077\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e7a5f0e1-44e7-47bf-ac1c-95c3dfaf5683\" />\n\nbut not published on NPM\n\n<img width=\"903\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/de46372d-0468-489d-a0be-5f8c13a48bfb\" />\n\n", "CLOSED", 0, "sparkidea25", "2025-01-24T02:04:49Z", "2025-03-08T01:14:33Z", "2025-03-08T01:14:33Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nY3c1", 2727, "Failed client#build on 'pnpm build'", "Hi - I know this was [reported earlier](https://github.com/elizaOS/eliza/issues/2223) and closed, but it's still a problem so I'm reporting it here again since I can't get past it.\n\nMy config :\nNode v23.3.0\npnpm v9.15.2\nWindows 10 Pro\n\nI cloned the repo, switched to the latest branch, ran _pnpm install_, but on _pnpm build_ I keep getting a client build error:\n\n![Image](https://github.com/user-attachments/assets/57e1aeae-1600-47a9-829e-f8749e4f8472)\n\nTried the _main_ and _develop_ branches, same thing. THere may be some crucial step missing from the quickstart docs,, or something I've missed that generates this error. Be grateful if anyone knew what it was. Thanks.\n", "CLOSED", 0, "RalphLavelle", "2025-01-24T01:51:52Z", "2025-03-08T01:14:33Z", "2025-03-08T01:14:33Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nXn3y", 2722, "Deepseek support in Eliza eliza-starter repository", "**Is your feature request related to a problem? Please describe.**\n\nI see there is the support for Deepseek it it  looks like it hasn't been updated in eliza-starter repository yet\n\n**Describe the solution you'd like**\n\nHave deepseek in the `eliza-starter` repository\n\n<!-- A clear and concise description of what you want to happen. -->\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "tskoyo", "2025-01-23T21:48:38Z", "2025-03-08T01:14:33Z", "2025-03-08T01:14:33Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nS-km", 2700, "Error in fetching Tweet in client-twitter", "**Describe the bug**\n\nWhile building conversation thread in twitter \nError fetching parent tweet: \n{\"tweetId\":\"1882398231231095114\",\"error\":{}} \n\nEven though the parent tweet existed at the time function was called the getTweet function failed to fetch.  No error message displayed.\n\nFunction:- buildConversationThread, file_path: packages/client-twitter/src/utils.ts\n\nWorked for second tweet.", "CLOSED", 0, "ShreyGanatra", "2025-01-23T12:23:24Z", "2025-03-08T01:14:32Z", "2025-03-08T01:14:32Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nSfk8", 2697, "Create an hardcoded response in an action", "**Describe the bug**\n\nI'm trying to create a hardcoded response for my Twitter agent based on an action\n\n**To Reproduce**\n\nIn an action, I\u2019m using callback after fetching an API I want to give a hardcoded response a bit like what\u2019s done here https://github.com/elizaOS/eliza/pull/1880/files#diff-7fa74fbce3f58e88d1bec33034c0cf89b09ff973d62fc7ceea661742a4be880aR85\n\nUsing this example, the chat response or tweet of my agent is never the `text` property I gave him and always differs.\n\n\n**Expected behavior**\n\nI would like the agent to answer the text I gave him to answer, so a basic hardcoded answer. I followed the same model as [the weather plugin example](packages/plugin-open-weather/src/examples.ts) for my `example.ts` \n\nIt seems that there is no easy way to do this and I think it should be done. Or am I missing something?", "CLOSED", 0, "fricoben", "2025-01-23T11:23:22Z", "2025-03-08T01:14:32Z", "2025-03-08T01:14:32Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nQsuc", 2695, "Plugins field unusable in character.json?", "**Describe the bug**\n\nWhat is the purpose of the plugins field in the character.json file if the createAgent function returns AgentRuntime where plugins are created depending on environment variables?\n\n**Expected behavior**\n\nPlugins from the character.json file should be woken up in AgentRuntime independently of other plugins.\n\n**Additional context**\n\nv0.1.8+build.1\n", "CLOSED", 0, "IvanOvchynnikov", "2025-01-23T07:47:05Z", "2025-03-08T01:14:31Z", "2025-03-08T01:14:31Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nPYD8", 2688, "Duplicate API calls due to inefficient vector similarity search in memory cache", "**Describe the bug**\n\nI'm using `plugin-coinmarketcp` to check the crypto price and when I'm making repeated requests for the same information (e.g., crypto prices), the system wasn't effectively reusing similar memories, leading to duplicate API calls and database entries.\n\n**To Reproduce**\n\n- Add `VERBOSE=True` in the `.env` file.\n- Enable `plugin-coinmarketcap` and start the server.\n- Now, ask this `what's the current price of bitcoin?`.\n- check the console logs.\n\n**Expected behavior**\n\nWhen sending repeated request for the same info then it should be served from cache after first request.\n\n**Debug logs**\n\n[logs.txt](https://github.com/user-attachments/files/18514774/logs.txt)\n", "CLOSED", 0, "metatxn", "2025-01-23T03:39:16Z", "2025-03-08T01:14:31Z", "2025-03-08T01:14:31Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nMwfH", 2674, "feat: Discourse plugin", "# Overview\n\nI would like to propose a new plugin that would expose a Discourse provider for agents: https://www.discourse.org/\n\nThis would enable interesting use cases where agents could use LLM to provide summaries and insights into web3 governance since Discourse is used widely amongst DAOs in web3. Of course, the plugin can be used in a non web3 context too. \n\n## Describe the solution you'd like\n\nI would like to fork this repo and add a global plugin that will serve discourse data via a provider that can be consumed by agents\n\nFunctional requirements:\n- Integration into Discourse API\n- Allow plugin consumers to specify environment variables for: Discourse API access and the target host targeting a specific discourse deployment. As a stretch, more than one discourse forum could be supported but it\u2019s not clear how beneficial that would be and future users could create demand for that\n- Integrate core endpoints or allow users to specify data they want to curate in the style of a topic pub / sub I.e LATEST_POSTS would tell the plugin to only fetch the latest posts for the agent\n\n## Describe alternatives you've considered\n\nAfter searching the issues and pull requests I couldn\u2019t see one mentioning a discourse integration. \n\n## Additional Context\nNot applicable at this moment", "CLOSED", 0, "vince0656", "2025-01-22T19:04:30Z", "2025-03-08T01:14:31Z", "2025-03-08T01:14:31Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nLEgE", 2666, "@elizaos/client-direct speak endpoint setting conflicting headers", "**Describe the bug**\nUsing \"@elizaos/client-direct\": \"0.1.7\", calling \n<!-- A clear and concise description of what the bug is. -->\n\n**To Reproduce**\n1. Install @elizaos/client-direct\n2. Making this request to the REST API \n```\ncurl --location 'http://localhost:3005/<AGENT_ID>/speak' \\\n--header 'Content-Type: application/json' \\\n--data '{\n    \"text\": \"Hello Sonya.\"\n}'\n```\nThe response has both Content-Length and `Transfer-Encoding\": \"chunked` headers set, which is invalid according to HTTP 1.1 protocol\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\nContent-Length header should not be set. It is currently being automatically set by node, since the buffer size is known:\nCould be fixed by:\n```\n                res.set({\n                    \"Content-Type\": \"audio/mpeg\",\n                    \"Transfer-Encoding\": \"chunked\", // Explicitly use chunked encoding\n                });\n\n                // Stream the audio buffer\n                const audioStream = Buffer.from(audioBuffer);\n                res.write(audioStream); // Write the audio data in chunks\n                res.end(); // End the response\n```\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "mikirov", "2025-01-22T15:30:16Z", "2025-03-08T01:14:30Z", "2025-03-08T01:14:30Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nKSdw", 2661, "Plugin-EVM: Error in swap handler", "I am getting the following error when trying to swap tokens using the evm plugin:\n\n`Error in swap handler: SDK Execution Provider not found.`\n\n**To Reproduce**\n\nAdd the EVM plugin to your character file, and prompt the agent to swap from ETH to USDC.\n\n**Expected behavior**\n\nThe agent fails to swap the tokens with the following error:\n\n`Error in swap handler: SDK Execution Provider not found.`\n\n**Screenshots**\n\n<img width=\"634\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/8484c4fa-20fa-41b0-ae41-d150f3a2480c\" />\n\n**Additional context**\n\nThe problem is most probably in the createConfig section for the LIFI SDK in the wallet.ts file.\n", "CLOSED", 0, "dxganta", "2025-01-22T14:07:36Z", "2025-03-08T01:14:30Z", "2025-03-08T01:14:30Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nF6m9", 2641, "feat: add EmailClient Plugin", "**Is your feature request related to a problem? Please describe.**\nNA\n\n**Describe the solution you'd like**\n\nCurrently, there's no built-in way for agents to handle email communications directly. This limits the agent's ability to engage in email-based workflows and automated email responses, which is essential for many business processes.\n\n**Describe alternatives you've considered**\n\nNA\n\n**Additional context**\n\nThis feature would be particularly useful for:\n\n- Customer support automation\n- Email-based workflow processing\n- Automated response systems\n- Business process automation\n- Email notification handling\n", "CLOSED", 0, "jteso", "2025-01-22T04:29:40Z", "2025-03-08T01:14:29Z", "2025-03-08T01:14:29Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nFOYS", 2634, "Port TrustDB from SQLite to PostgreSQL", "Is your feature request related to a problem? Please describe.\n\nThe current trust score database system primarily supports SQLite, and there is a need to extend it to support PostgreSQL-specific extensions without breaking existing functionality. The challenge is to ensure seamless integration while maintaining backward compatibility, handling potential async issues, and meeting performance expectations.\n\nDescribe the solution you'd like\n\nThe solution involves introducing PostgreSQL extensions through modular updates to the existing system. Key updates include:\n\nAdding necessary dependencies in package.json.\n\nImplementing trustscoreDb.getInstance() to dynamically initialize the appropriate database adapter. (Design consideration could be changed if showing issues)\n\nEnsuring both PostgreSQL and SQLite functionalities coexist with proper fallbacks.\n\nDescribe alternatives you've considered\n\nConsidering the design approach as extenstion of database and arhitecture of using it should be easily added without breaking any existing structure\u00a0\n\nAdditional context\n\nUpcoming development tasks include:\n\nTesting\n\nAddress async function concerns.\n\nEnsure PostgreSQL features work as expected.\n\nValidate SQLite backward compatibility.\n\nMeasure and optimize performance.\n\nDocumentation\n\nProvide detailed setup instructions.\n\nOffer configuration options.", "CLOSED", 0, "0xbbjoker", "2025-01-22T01:38:33Z", "2025-03-08T01:14:29Z", "2025-03-08T01:14:29Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nFIZU", 2633, "Vector Dimension error - after using GAIANET for the LLM", "After trying to use different embeddings (gaianet set to TRUE) after running the same character with GROQ, when using GROQ the agent worked fine and i got answers from the LLM, now i get this error when starting the character:\n\n```\n\u26d4 ERRORS\n   Error starting agent for character Dobby: \n   {\"code\":\"SQLITE_ERROR\"} \n\n [\"\u26d4 SqliteError: Vector dimension mistmatch. First vector has 768 dimensions, while the second has 384 dimensions.\"] \n\n \u26d4 ERRORS\n   Error starting agents: \n   {\"code\":\"SQLITE_ERROR\"}\n```\n\nThe client connects and gives the connected info, but no agent to select on the sidebar", "CLOSED", 0, "nelohenriq", "2025-01-22T01:14:48Z", "2025-03-08T01:14:29Z", "2025-03-08T01:14:29Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nDtgS", 2624, "`@elizaos/agent` cannot be installed", "#  `@elizaos/agent` cannot be installed\n\n---\n**Describe the bug**\n\nThe [`@elizaos/agent`](https://www.npmjs.com/package/@elizaos/agent) npm package cannot be installed.\n\n**To Reproduce**\n\n```\npnpm install @elizaos/agent\n```\n\n**Error**\n\n```\nERR_PNPM_FETCH_404\u2009 GET https://registry.npmjs.org/@elizaos%2Fadapter-pglite: Not Found - 404\n\nThis error happened while installing the dependencies of @elizaos/agent@0.1.8\n\n@elizaos/adapter-pglite is not in the npm registry, or you have no permission to fetch it.\n\nNo authorization header was set for the request.\nProgress: resolved 1, reused 0, downloaded 0, added 0\n```\n\nOn another system I got the following:\n```\nERR_PNPM_WORKSPACE_PKG_NOT_FOUND\u2009 In : \"@elizaos/plugin-avail@workspace:*\" is in the dependencies but no package named \"@elizaos/plugin-avail\" is present in the workspace\n\nThis error happened while installing the dependencies of @elizaos/agent@0.1.8\n\nPackages found in the workspace:\nProgress: resolved 15, reused 7, downloaded 0, added 0\n```\n", "CLOSED", 0, "baltermia", "2025-01-21T20:40:37Z", "2025-03-08T01:14:28Z", "2025-03-08T01:14:28Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nDpqi", 2623, "Cannot start, stuck downloading fast-bge-small-en-v1.5 model", "Cannot fully start the agent : fastembed gets stuck downloading the tarred module from Google cloud and eventually times out, then fails on expanding tar.\n\n`Downloading fast-bge-small-en-v1.5 [==------------------] 10% 5371.7s`\n\n```\n\u26d4 ERRORS\n   Failed to initialize BGE model: \n   {\"code\":\"Z_BUF_ERROR\",\"errno\":-5,\"recoverable\":false,\"file\":\"/Users/massimo/Projects/ai/eliza/cache/fast-bge-small-en-v1.5.tar.gz\",\"cwd\":\"/Users/massimo/Projects/ai/eliza/cache\",\"tarCode\":\"TAR_ABORT\"} \n\n \u26d4 ERRORS\n   Local embedding failed: \n   {\"code\":\"Z_BUF_ERROR\",\"errno\":-5,\"recoverable\":false,\"file\":\"/Users/massimo/Projects/ai/eliza/cache/fast-bge-small-en-v1.5.tar.gz\",\"cwd\":\"/Users/massimo/Projects/ai/eliza/cache\",\"tarCode\":\"TAR_ABORT\"} \n```\n\n**Workaround**\n\nThe agent successfully started when I manually downloaded the model file from [https://storage.googleapis.com/qdrant-fastembed/fast-bge-small-v1.5.tar.gz](https://storage.googleapis.com/qdrant-fastembed/fast-bge-small-v1.5.tar.gz) (same url used by fastembed) and placed in the `cache` directory. I did not gunzip.\n\n**To Reproduce**\n\nMacOSX Sonoma 14.6\nnode v23.6.0\npnpm 9.12.3\n\nCloned repo (@ v0.1.8+build.1), installed deps and built per instructions\n\nChanged modelProvider to \"llama_local\" in trump.character.json\n\n```\n   \"name\": \"trump\",\n    \"clients\": [],\n    \"modelProvider\": \"llama_local\",\n    \"settings\": {\n        \"secrets\": {},\n        \"voice\": {\n            \"model\": \"en_US-male-medium\"\n        }\n    },\n```\n\nThen attempted to run:\n`pnpm run start --characters=\"./character/trump.character.json\"`\n\n\n", "CLOSED", 0, "byron-the-bulb", "2025-01-21T20:31:09Z", "2025-03-08T01:17:31Z", "2025-03-08T01:17:31Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nDczo", 2622, "Can't connect to GROQ", "Here is my pnpm start command output:\n\n>  [\"\u25ce DirectClient constructor\"] \n\n [\"\u2139 Initializing SQLite database at /project/workspace/eliza/agent/data/db.sqlite...\"] \n\n [\"\u25ce sqlite-vec extensions loaded successfully.\"] \n\n [\"\u2713 Successfully connected to SQLite database\"] \n\n [\"\u2139 Using Database Cache...\"] \n\n [\"\u25ce Creating runtime for character Eliza\"] \n\n \u2139 INFORMATIONS\n   Initializing AgentRuntime with options: \n   {\"character\":\"Eliza\",\"modelProvider\":\"groq\",\"characterModelProvider\":\"groq\"} \n\n [\"\u2713 Agent ID: b850bc30-45f8-0041-a00a-83df46d8555d\"] \n\n [\"\u2139 Setting model provider...\"] \n\n \u2139 INFORMATIONS\n   Model Provider Selection: \n   {\"characterModelProvider\":\"groq\",\"optsModelProvider\":\"groq\",\"finalSelection\":\"groq\"} \n\n \u2139 INFORMATIONS\n   Selected model provider: \n   groq \n\n \u2139 INFORMATIONS\n   Selected image model provider: \n   groq \n\n \u2139 INFORMATIONS\n   Selected model provider: \n   groq \n\n \u2139 INFORMATIONS\n   Selected image model provider: \n   groq \n\n [\"\u2713 Registering action: CONTINUE\"] \n\n [\"\u2713 Registering action: FOLLOW_ROOM\"] \n\n [\"\u2713 Registering action: UNFOLLOW_ROOM\"] \n\n [\"\u2713 Registering action: IGNORE\"] \n\n [\"\u2713 Registering action: NONE\"] \n\n [\"\u2713 Registering action: MUTE_ROOM\"] \n\n [\"\u2713 Registering action: UNMUTE_ROOM\"] \n\n [\"\u2713 Registering action: DESCRIBE_IMAGE\"] \n\n \u25ce LOGS\n   Registering service: \n   browser \n\n [\"\u2713 Service browser registered successfully\"] \n\n \u25ce LOGS\n   Registering service: \n   image_description \n\n [\"\u2713 Service image_description registered successfully\"] \n\n \u25ce LOGS\n   Registering service: \n   text_generation \n\n [\"\u2713 Service text_generation registered successfully\"] \n\n \u25ce LOGS\n   Registering service: \n   pdf \n\n [\"\u2713 Service pdf registered successfully\"] \n\n \u25ce LOGS\n   Registering service: \n   speech_generation \n\n [\"\u2713 Service speech_generation registered successfully\"] \n\n \u25ce LOGS\n   Registering service: \n   transcription \n\n [\"\u2713 Service transcription registered successfully\"] \n\n \u25ce LOGS\n   Registering service: \n   video \n\n [\"\u2713 Service video registered successfully\"] \n\n \u25ce LOGS\n   Registering service: \n   aws_s3 \n\n [\"\u2713 Service aws_s3 registered successfully\"] \n\n [\"\u2713 Service browser initialized successfully\"] \n\n [\"\u25ce Initializing ImageDescriptionService\"] \n\n [\"\u2713 Service image_description initialized successfully\"] \n\n [\"\u2139 Initializing LlamaService...\"] \n\n [\"\u2713 Service text_generation initialized successfully\"] \n\n [\"\u2713 Service pdf initialized successfully\"] \n\n [\"\u2713 Service speech_generation initialized successfully\"] \n\n [\"\u25ce CUDA not detected. Transcription will run on CPU.\"] \n\n [\"\u2713 Service transcription initialized successfully\"] \n\n [\"\u2713 Service video initialized successfully\"] \n\n [\"\u25ce Initializing AwsS3Service\"] \n\n [\"\u2713 Service aws_s3 initialized successfully\"] \n\n [\"\u25ce Initializing ImageDescriptionService\"] \n\n [\"\u2139 Initializing LlamaService...\"] \n\n [\"\u25ce CUDA not detected. Transcription will run on CPU.\"] \n\n [\"\u25ce Initializing AwsS3Service\"] \n\n \u25ce LOGS\n   initializeClients \n   [] \n   for \n   Eliza \n\n \u25ce LOGS\n   client keys \n   [] \n\n [\"\u25ce Run `pnpm start:client` to start the client and visit the outputted URL (http://localhost:5173) to chat with your agents. When running multiple agents, use client with different port `SERVER_PORT=3001 pnpm start:client`\"] \n\n [\"\u2713 REST API bound to 0.0.0.0:3000. If running locally, access it at http://localhost:3000.\"] <\n\nWhen i run pnpm start:client i get this:\n\n> eliza@ start:client /project/workspace/eliza\n> pnpm --dir client dev\n\n\n> client@ dev /project/workspace/eliza/client\n> pnpm run extract-version && vite\n\n\n> client@ extract-version /project/workspace/eliza/client\n> ./version.sh\n\ninfo.json created with version: 0.1.8+build.1\n\n  VITE v6.0.7  ready in 314 ms\n\n  \u279c  Local:   http://localhost:5173/\n  \u279c  Network: use --host to expose\n  \u279c  press h + enter to show help\n\nwhich seems alright, then when i get to the ui on port 5173 i don't get any agents on the sidebar and my connection doesn't seem to go like expected since keeps switching from connect... to disconnected, can anyone help?", "CLOSED", 0, "nelohenriq", "2025-01-21T20:01:14Z", "2025-03-08T01:17:21Z", "2025-03-08T01:17:20Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nCjTe", 2617, "How to mention certain users using the twitter client?", "Description:\nI'm trying to mention specific users in my tweets using the Twitter client, but I'm unsure how to do this properly. Can you provide a detailed guide on the correct process for mentioning users?\n\nSteps to Reproduce:\n\nOpen the Twitter client (web or app).\nCreate a new tweet.\nAttempt to mention a user by typing their username.\nExpected Result:\nI would like the mentioned user to be notified and the username to link to their profile.\n\nActual Result:\nThe mention doesn't seem to work as expected, or I'm unclear on whether I'm doing it right.\n\nQuestions:\n\nWhat is the correct format for mentioning users (e.g., @username)?\nAre there any restrictions or limitations on mentioning users?\nDoes the client provide suggestions or autofill options for usernames?", "CLOSED", 0, "ALGOREX-PH", "2025-01-21T17:47:45Z", "2025-03-08T01:17:20Z", "2025-03-08T01:17:20Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nCTDe", 2613, "Unable to start agent - facing error with where code is unable to find index.js file in client-direct -> dist folder", "Following is the error I am facing. Can anyone suggest what to do to start the agent..,\n\nError: Cannot find module '/C:/Users/{user}/eliza/agent/node_modules/@elizaos/plugin-solana/dist/index.js' imported from C:\\Users\\{user}\\eliza\\agent\\src\\index.ts\n    at finalizeResolution (C:\\Users\\{user}\\eliza\\node_modules\\ts-node\\dist-raw\\node-internal-modules-esm-resolve.js:352:11)\n    at moduleResolve (C:\\Users\\{user}\\eliza\\node_modules\\ts-node\\dist-raw\\node-internal-modules-esm-resolve.js:801:10)\n    at Object.defaultResolve (C:\\Users\\{user}\\eliza\\node_modules\\ts-node\\dist-raw\\node-internal-modules-esm-resolve.js:912:11)\n    at C:\\Users\\{user}\\eliza\\node_modules\\ts-node\\src\\esm.ts:218:35\n    at entrypointFallback (C:\\Users\\{user}\\eliza\\node_modules\\ts-node\\src\\esm.ts:168:34)\n    at C:\\Users\\{user}\\eliza\\node_modules\\ts-node\\src\\esm.ts:217:14\n    at addShortCircuitFlag (C:\\Users\\{user}\\eliza\\node_modules\\ts-node\\src\\esm.ts:409:21)\n    at resolve (C:\\Users\\{user}\\eliza\\node_modules\\ts-node\\src\\esm.ts:197:12)\n    at nextResolve (node:internal/modules/esm/hooks:748:28)\n    at Hooks.resolve (node:internal/modules/esm/hooks:240:30)\n\nNode.js v23.6.0\nC:\\Users\\{user}\\eliza\\agent:\n\u2009RR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009  @elizaos/agent@0.1.8+build.1 start: `node --loader ts-node/esm src/index.ts \"--isRoot\"`\nExit status 1\n", "CLOSED", 0, "awinya-ai", "2025-01-21T17:13:57Z", "2025-03-08T01:15:56Z", "2025-03-08T01:15:56Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nBxRz", 2609, "feat: Add MINA plugin", "> # Relates to:\n> # Risks\n> Low\n> \n> # Background\n> This is the first PR that introduces MINA plugin to eliza. \n> ## What does this PR do?\n> Introduces Agent Plugin to manage a MINA Wallet.\n> Native token transfers.\n> New env variables for MINA.\n> ## What kind of change is this?\n> Features (non-breaking change which adds functionality)\n> \n> Add the ability for Eliza agents to interface with the MINA Blockchain.\n> \n> # Documentation changes needed?\n> My changes do not require a change to the project documentation.\n> # Testing\n> Changes can be tested by providing a MINA address, public key and private key in .env, and asking eliza to swap, transfer and provide wallet details.\n> \n> ## Discord  username\n> @ aiqubit\n> ## Telegram username\n> @aiqubits\n> ## Email address\n> aiqubit@hotmail.com", "CLOSED", 0, "aiqubits", "2025-01-21T16:09:44Z", "2025-03-08T01:15:56Z", "2025-03-08T01:15:55Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nBapl", 2606, "Posts", "Hi, how can I make my agent to post message as a reply/next post message on twitter? He currently just posts first sentence and I would like him to post next sentences as next message to initial post. Any idea how I can achieve this?\n\nI edited twitter template but it doesn't seem to work:\n\n```\nconst twitterPostTemplate = `\n# Areas of Expertise\n{{knowledge}}\n\n# About {{agentName}} (@{{twitterUserName}}):\n{{bio}}\n{{lore}}\n{{topics}}\n\n{{providers}}\n\n{{characterPostExamples}}\n\n{{postDirections}}\n\n# Task: Generate a post in the voice and style and perspective of {{agentName}} @{{twitterUserName}}.\nWrite a post that is {{adjective}} about {{topic}} (without mentioning {{topic}} directly), from the perspective of {{agentName}}. Do not add commentary or acknowledge this request, just write the post.\nYour response should be 1, 2, or 3 sentences (choose the length at random). Sentences 2 and 3 should appear as another post to the first sentence.\nYour response should not contain any questions. Your response should have project ticker when mentioning project. Brief, concise statements only. The total character count MUST be less than {{maxTweetLength}}. No emojis. Post a new message for each statement if there are multiple statements in your response.`;\n\n```\n\n", "CLOSED", 0, "WNUMIK", "2025-01-21T15:30:47Z", "2025-03-08T01:17:20Z", "2025-03-08T01:17:20Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6nAw0V", 2603, "client-telegram add support to receive telegram messages via webhook", "**Is your feature request related to a problem? Please describe.**\n\nCurrent `client-telegram` implementation uses telegram's long polling, which limits only single instance of bot to run.\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\n\n**Describe the solution you'd like**\n\nIf we can use the telegram's webhook we will be able to split the load to multiple bot instances running on different hosts\n\n<!-- A clear and concise description of what you want to happen. -->\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\nScale the host vertically\n\n**Additional context**\nWe found that telegram bot taking long time to respond when there are many active telegram users chatting with the agent. We tried to scale the application horizontally, but we were restricted by telegram bot's long polling because only one bot instance can run at a time.\n\nI am currently trying to build a webhook version of `client-telegram` where I expose a telegram bot webhook endpoint on a different port which follows similar approach as `client-direct` using `express`\n", "CLOSED", 0, "RatakondalaArun", "2025-01-21T14:21:31Z", "2025-03-08T01:17:20Z", "2025-03-08T01:17:19Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6m_YFX", 2601, "Add Sequelize Database Client", "**Is your feature request related to a problem? Please describe.**\nThe current database implementation uses raw SQL queries which can be cumbersome to maintain and test. Adding a Sequelize client option would provide developers with a more familiar and maintainable ORM-based approach while keeping the existing PostgreSQL adapter intact.\n\n**Describe the solution you'd like**\nAdd a new `SequelizeDatabaseClient` class that implements the existing `DatabaseAdapter` interface using Sequelize ORM. This would provide:\n\n- Model-based database operations instead of raw SQL\n- Built-in connection pooling and transaction management  \n- Better TypeScript integration through Sequelize models\n- Easier testing through Sequelize's test helpers\n- Optional alternative to the current PostgreSQL adapter\n\n**Describe alternatives you've considered**\n- TypeORM: Less robust PostgreSQL support\n- Prisma: Requires additional build steps \n- Knex.js: Only query builder without ORM features\n- Keeping only raw SQL: Less maintainable long-term\n\n**Additional context**\nThis would be an additive feature - the existing PostgreSQL adapter would remain untouched and developers could choose which implementation to use. The Sequelize client would follow the same interface and maintain compatibility with all current features including vector operations.", "CLOSED", 0, "0xbbjoker", "2025-01-21T11:57:53Z", "2025-03-08T01:17:19Z", "2025-03-08T01:17:19Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6m-cdi", 2598, "Request for a Simple Guide on ESM and Required Dependencies", "Hi,  \n\nWhile trying to integrate `elizaos/core` into my project, I encountered the following issues:  \n\n1. **ESM-related Problems**  \n   - During testing with both JavaScript and TypeScript, I faced challenges due to ESM compatibility.  \n   - For instance, the need to set `\"type\": \"module\"` in `package.json` wasn't clearly mentioned, which caused some confusion.  \n\n2. **Required Dependencies**  \n   - Packages like `sharp`, `dotenv`, and `@tavily/core` had to be installed separately to make the project work.  \n   - These dependencies were not mentioned in the documentation, leading to initial setup difficulties.  \n\nTo address these issues, it would be helpful to have a simple guide covering the following points:  \n- **Basic Configuration**  \n  - What needs to be added to `package.json` (e.g., `\"type\": \"module\"`)  \n- **Recommended TypeScript Settings**  \n  - Suggested `tsconfig.json` configuration  \n- **Required Dependencies**  \n  - A list of dependencies necessary for the project to run  \n\nA beginner-friendly guide with clear instructions for the initial setup would be greatly appreciated.  \n\nThank you!  ", "CLOSED", 0, "lincheoll", "2025-01-21T10:30:26Z", "2025-03-08T01:17:19Z", "2025-03-08T01:17:19Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6m9UOj", 2591, "Unable to use and install Irys Plugin", "**Describe the bug**\nUnable to install or utilise irysPlugin \n<!-- A clear and concise description of what the bug is. -->\n\n**To Reproduce**\npnpm add -w  @elizaos/plugin-irys\n<!-- Steps to reproduce the behavior. -->\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/ae1bd978-bd7d-412f-9ed4-629dd14557ff)\n\n![Image](https://github.com/user-attachments/assets/64e135df-6f39-4b5b-a7ca-72101a01defc)\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\nAttempted to start a new build as well but still unable to do so\n<!-- Add any other context about the problem here. -->\n", "CLOSED", 0, "havardman6000", "2025-01-21T08:41:52Z", "2025-03-08T01:15:55Z", "2025-03-08T01:15:55Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6m86G9", 2587, "i installed eliza standard library and tried openai, grok, google, deepseek, only openai key worked, what's wrong?", "i don't know if i configure it correct.\n\n\nGROK api\n![Image](https://github.com/user-attachments/assets/1df3df39-352f-489f-87c8-4f726b0f5340)\n\nGOOGLE API, somehow it directly showed the key, i don't know why.\n\n![Image](https://github.com/user-attachments/assets/e0a00581-ba68-4236-b6d9-6c53dd8de908)\n\ndeepseek api\n\n![Image](https://github.com/user-attachments/assets/3b11d6b9-9011-43a8-950b-d3341386ac77)\n\n\nhere's the env configuration file\n\n![Image](https://github.com/user-attachments/assets/cce31904-989d-483c-91b3-3208a0b3d739)\n![Image](https://github.com/user-attachments/assets/78715d6b-6b6d-491e-b210-1ab24d125738)\n![Image](https://github.com/user-attachments/assets/36d7a39e-bb27-47e4-8329-cee78accea03)\n\nin the character file, i changed model to \"openai\", \"google\", \"deepseek\", \"grok\"\n\nthere are different models there, i don't know how to call it, small, medium or large, i tried to configure them and restarted the pnpm, but none worked.\n\n", "CLOSED", 0, "holiccoder", "2025-01-21T08:05:35Z", "2025-03-08T01:17:19Z", "2025-03-08T01:17:18Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6m6uTn", 2578, "Fix error", "please how do i fix this error when running eliza\nI am using grok with credit enabled\n```\n   API Response: \n   {\"code\":\"Some requested entity was not found\",\"error\":\"The model BGE-small-en-v1.5 does not exist or your team fc73b25a-d466-4cfc-96d3-a852176a7ba1 does not have access to it. Please ensure you're using the correct API key. If you believe this is a mistake, please contact support and quote your team ID and the model name.\"} \n```", "CLOSED", 0, "Imdavyking", "2025-01-20T23:32:03Z", "2025-03-08T01:17:18Z", "2025-03-08T01:17:18Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6m50b0", 2565, "Integrating searxng", "\n\nCurrently, Eliza agents lack integrated web search capabilities, limiting their ability to access and retrieve up-to-date information from the internet. This constraint hampers their performance in tasks requiring real-time data or comprehensive knowledge beyond their pre-existing datasets.\n\nDescribe the solution you\u2019d like\n\nIntegrate SearXNG, a free and open-source metasearch engine, into the Eliza framework. SearXNG aggregates results from various search services and databases without tracking or profiling users, aligning with privacy considerations. By embedding SearXNG, Eliza agents can perform real-time web searches, enhancing their ability to provide accurate and current information.  \ufffc\n\nDescribe alternatives you\u2019ve considered\n\t\u2022\tDeveloping a Custom Search Integration: Creating a proprietary search solution tailored to Eliza\u2019s needs. However, this approach would require significant development resources and ongoing maintenance to ensure comprehensive coverage and relevance of search results.\n\t\u2022\tUtilizing Other Search APIs: Leveraging existing search engine APIs (e.g., Google, Bing). While feasible, these options may involve usage costs, rate limitations, and potential privacy concerns due to data tracking practices.\n\nAdditional context\n\nSearXNG is a fork of the Searx project, designed to provide faster debugging and fixes of engine errors. It supports over 70 different search engines and does not collect information about users, ensuring privacy.  \ufffc Integrating SearXNG into Eliza would involve setting up a SearXNG instance, which can be configured optimally for use with applications like Open WebUI.  \ufffc This integration would significantly enhance Eliza agents\u2019 capabilities by providing them with access to a vast array of information sources in real-time.", "CLOSED", 0, "mosif16", "2025-01-20T19:48:01Z", "2025-03-08T01:17:18Z", "2025-03-08T01:17:18Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6m5hCt", 2563, "Bot is only responding to target users and ignoring all other mentions on twitter", "**Describe the bug**\n\nBot is only responding to target users and ignoring all other mentions on twitter using default client-twitter\n\n**To Reproduce**\n\nSetup my custom actions using client-twitter with eliza main repo. \n\n**Expected behavior**\n\n It should reply to all users, not only target users.\n\n**Screenshots**\n\n<img width=\"543\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ba6d8255-e3ae-4499-be74-2c9a5b5846d6\" />\n\n<img width=\"1109\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/80cc4644-0b33-4793-87fa-26dd239e112b\" />\n\n", "CLOSED", 0, "Xayaan", "2025-01-20T18:46:01Z", "2025-03-08T01:17:17Z", "2025-03-08T01:17:17Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6m5S22", 2561, "Add Router Nitro Agent", "## Router Nitro Bridge Integration\n\n**Is your feature request related to a problem? Please describe.**\nWe'd like to extend Eliza's capabilities with Router Nitro Agent. We'd like to extend Eliza's capabilities with Router Protocol's Nitro bridge. Router Nitro is a high-performance cross-chain bridge that enables fast, secure, and cost-effective asset transfers across multiple blockchain networks. Adding Router Nitro integration would significantly enhance Eliza's cross-chain capabilities.\n\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\n\n**Describe the solution you'd like**\nA Plugin for Router Nitro bridge integration in Eliza's codebase, simplifying the process of building bridging requests for users without requiring specialized front-end logic.\n\n<!-- A clear and concise description of what you want to happen. -->\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n<!-- **Additional context** -->\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "CLOSED", 0, "RaveenaBhasin", "2025-01-20T18:06:06Z", "2025-03-08T01:15:55Z", "2025-03-08T01:15:55Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6m32YB", 2557, "telegram client not working or responding", "\n [\"\u2139 Telegram Message: [object Object]\"]\n\n \u25ce LOGS\n   Creating Memory\n   cd87f4c9-e60c-0c23-9c90-91cc0b4851e7\n   Hi\n\n \u26d4 ERRORS\n   API Response:\n   Domain is unavailable\n\n\n \u26d4 ERRORS\n   Full error details:\n   {}\n\n \u26d4 ERRORS\n   \u274c Error handling message:\n   {}\n\n \u26d4 ERRORS\n   Error sending message:\n   {}\n\n\n\n\nwhy do i keep on getting this issue ?? i setup defaultcharacter , i put client as telegram and modelprovider as gaianet.. \ni ve made sure ive provided all the env values for gainet and for the telegram_bot_token.\nafter i run pnpm run start.. and send a \"hi\" message from the telegram bot , the above error keeps on coming.. pls tell me what im doing wrong????\n\n\n![Image](https://github.com/user-attachments/assets/b913351a-674c-47dd-ac81-9b12101a6c13)", "CLOSED", 0, "gauthking", "2025-01-20T15:51:41Z", "2025-03-08T01:17:17Z", "2025-03-08T01:17:17Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mwy61", 2530, "@elizaos/agent@0.1.9-alpha.1 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--characters=characters/eternalai.character.json\"`", "I did pnpm start with whole bunch of node versions but still get stuck with it, I suppose it is a bug, due to pnpm i and pnpm build were without problems\n\nC:\\Users\\Admin\\eliza>pnpm start --characters=\"characters/eternalai.character.json\"\n\u2009WARN\u2009 Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v22.13.0\",\"pnpm\":\"9.15.4\"})\n\n> eliza@ start C:\\Users\\Admin\\eliza\n> pnpm --filter \"@elizaos/agent\" start --isRoot \"--characters=characters/eternalai.character.json\"\n\n.                                        | \u2009WARN\u2009 Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v22.13.0\",\"pnpm\":\"9.14.4\"})\ndocs                                     | \u2009WARN\u2009 Unsupported engine: wanted: {\"node\":\"23.3.0\"} (current: {\"node\":\"v22.13.0\",\"pnpm\":\"9.14.4\"})\n\n> @elizaos/agent@0.1.9-alpha.1 start C:\\Users\\Admin\\eliza\\agent\n> node --loader ts-node/esm src/index.ts \"--isRoot\" \"--characters=characters/eternalai.character.json\"\n\n(node:12932) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\n(Use `node --trace-warnings ...` to show where the warning was created)\n(node:12932) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\n(Use `node --trace-deprecation ...` to show where the warning was created)\n\nnode:internal/modules/run_main:122\n    triggerUncaughtException(\n    ^\n[Object: null prototype] {\n  [Symbol(nodejs.util.inspect.custom)]: [Function: [nodejs.util.inspect.custom]]\n}\n\nNode.js v22.13.0\nC:\\Users\\Admin\\eliza\\agent:\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.9-alpha.1 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--characters=characters/eternalai.character.json\"`\nExit status 1\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\n\nC:\\Users\\Admin\\eliza>", "CLOSED", 0, "illink7", "2025-01-19T20:13:23Z", "2025-03-08T01:17:17Z", "2025-03-08T01:17:17Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mwV8a", 2522, "Virtuals Terminal API integration", "### Feature Request: ElizaOS Agent Integration with Virtuals Terminal\n\n**Is your feature request related to a problem? Please describe.**\n\nCurrently, there is no streamlined or standardized way for an ElizaOS agent deployed on Virtuals as a token to log its actions or report its activities to the Virtuals Terminal. This lack of integration creates a gap in transparency and monitoring, making it difficult to track agent behavior, analyze interactions, and ensure alignment with operational or ethical guidelines.\n\nFor example, actions such as user interactions, data processing, or decision-making events are not being logged in the Virtuals Terminal, resulting in limited visibility and accountability for deployed agents.\n\n---\n\n**Describe the solution you'd like**\n\nI propose the development of a dedicated plugin or module that seamlessly integrates with the [Virtuals Terminal API](https://whitepaper.virtuals.io/developer-documents/terminal-api) to report all agent actions and events. \n\nThe plugin/module should:\n1. **Log Key Actions:** Automatically capture and send details of all actions performed by the agent, such as user interactions, system updates, or triggered events.\n2. **Token-Based Authentication:** Use the Virtuals Terminal API key to ensure secure and authenticated communication between the agent and the Terminal.\n3. **Customizable Reporting:** Allow configuration of which actions to log and report to minimize unnecessary data flow and enhance relevance.\n4. **Real-Time Logging:** Enable near real-time reporting of activities to provide immediate visibility into agent behavior.\n5. **Error Handling:** Include mechanisms for handling API errors or downtime gracefully, ensuring that logs are not lost during connectivity issues.\n\n---\n\n**Describe alternatives you've considered**\n\n1. **Manual Logging:** Setting up a custom logging system to track agent actions. However, this approach lacks the integration with Virtuals Terminal and increases development overhead.\n2. **Third-Party Tools:** Using generic logging or monitoring tools. These solutions do not provide the tailored insights or secure connection offered by the Virtuals ecosystem.\n\n---\n\n**Additional context**\n\nThe integration with Virtuals Terminal will significantly enhance transparency and trust in ElizaOS agents by providing a clear and accessible activity log. This feature will be invaluable for monitoring agent performance, auditing behavior, and ensuring alignment with user expectations and Virtuals platform standards.\n\nFor more information on the Virtuals Terminal API, refer to the [official documentation](https://whitepaper.virtuals.io/developer-documents/terminal-api).", "CLOSED", 0, "mikirov", "2025-01-19T15:42:14Z", "2025-03-08T01:15:55Z", "2025-03-08T01:15:54Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mwNzY", 2521, "Agent doesn't reply to new target users tweets, says already responded, skipping", "**Describe the bug**\n\nThe agent doesn't reply to target users' new tweets after a few weeks of it running. It says \"already responded to tweet, skipping\" even though it hasn't replied yet\n\n**To Reproduce**\n\nNot sure, ran 3 agents simultaneously, been replying for a month, after that it stops replying, it says skips new tweets even tho haven't replied to them yet\n\n**Expected behavior**\n\nIt should reply to new tweets of users inside the target users list\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/ad3fbdc5-7bee-4ca7-9660-9918ea075807)\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\n**Additional context**\n\nBuild: v0.1.8+build.1\nAgents running: 3\nDatabase: Sqlite\n", "CLOSED", 0, "medardm", "2025-01-19T14:32:14Z", "2025-03-08T01:17:16Z", "2025-03-08T01:17:16Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mvXM0", 2513, "Issue with Installing @elizaos/plugin-0g", "I am encountering issues while trying to install the @elizaos/plugin-0g package using pnpm. The error message indicates that the package @elizaos/runtime is not found in the registry.\n\nSteps taken:\n\nConfigured .npmrc with the following:\n\n\n@elizaos:registry=https://npm.pkg.github.com/\n//npm.pkg.github.com/:_authToken=MY_PERSONAL_ACCESS_TOKEN\nVerified my token permissions (read:packages scope included).\nChecked the GitHub repository for @elizaos/plugin-0g and its dependencies.\n\nError:\nERR_PNPM_FETCH_404\u2009 GET https://registry.npmjs.org/@elizaos%2Fruntime: Not Found - 404\nCould you confirm if:\n\nThe package @elizaos/plugin-0g and its dependency @elizaos/runtime are correctly published to the GitHub registry?\nThere are any additional steps or permissions required to access these packages?\nThank you!\n\n\n\n\n\n\n\n", "CLOSED", 0, "Aave-Khan", "2025-01-19T05:39:50Z", "2025-03-08T01:15:54Z", "2025-03-08T01:15:54Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mun40", 2511, "database/index.ts file not using CACHE_STORE environment variable", "**Describe the bug**\n\nI could not get better-sql to work, so I tried switching to CACHE_STORE: filesystem in the .env file, but eliza still tried to use the better-sql.  Looking at the database/index.ts file, it looks like it does not respect the setting of CACHE_STORE\n\n**To Reproduce**\n\nset CACHE_STORE: filesystem in .env file\n\n**Expected behavior**\n\nNot use better-sql\n\n**Screenshots**\n\nNone\n\n**Additional context**\n\nHere is the better-sql error if you have any insight on how to fix that as well:\n\n \u26d4 ERRORS\n   Error starting agent for character Eliza: \n   {\"tries\":[\"/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/build/better_sqlite3.node\",\"/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/build/Debug/better_sqlite3.node\",\"/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/build/Release/better_sqlite3.node\",\"/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/out/Debug/better_sqlite3.node\",\"/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/Debug/better_sqlite3.node\",\"/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/out/Release/better_sqlite3.node\",\"/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/Release/better_sqlite3.node\",\"/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/build/default/better_sqlite3.node\",\"/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/compiled/23.3.0/darwin/arm64/better_sqlite3.node\",\"/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/addon-build/release/install-root/better_sqlite3.node\",\"/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/addon-build/debug/install-root/better_sqlite3.node\",\"/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/addon-build/default/install-root/better_sqlite3.node\",\"/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/lib/binding/node-v131-darwin-arm64/better_sqlite3.node\"]} \n\nError: Could not locate the bindings file. Tried:\n \u2192 /Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/build/better_sqlite3.node\n \u2192 /Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/build/Debug/better_sqlite3.node\n \u2192 /Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/build/Release/better_sqlite3.node\n \u2192 /Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/out/Debug/better_sqlite3.node\n \u2192 /Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/Debug/better_sqlite3.node\n \u2192 /Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/out/Release/better_sqlite3.node\n \u2192 /Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/Release/better_sqlite3.node\n \u2192 /Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/build/default/better_sqlite3.node\n \u2192 /Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/compiled/23.3.0/darwin/arm64/better_sqlite3.node\n \u2192 /Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/addon-build/release/install-root/better_sqlite3.node\n \u2192 /Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/addon-build/debug/install-root/better_sqlite3.node\n \u2192 /Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/addon-build/default/install-root/better_sqlite3.node\n \u2192 /Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/lib/binding/node-v131-darwin-arm64/better_sqlite3.node\n    at bindings (/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/bindings@1.5.0/node_modules/bindings/bindings.js:126:9)\n    at new Database (/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/lib/database.js:48:64)\n    at initializeDatabase (file:///Users/rogerbos/Node_HOME/eliza-starter/src/database/index.ts:15:46)\n    at startAgent (file:///Users/rogerbos/Node_HOME/eliza-starter/src/index.ts:55:20)\n    at startAgents (file:///Users/rogerbos/Node_HOME/eliza-starter/src/index.ts:102:19)\n    at file:///Users/rogerbos/Node_HOME/eliza-starter/src/index.ts:128:1 {\n  tries: [\n    '/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/build/better_sqlite3.node',\n    '/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/build/Debug/better_sqlite3.node',\n    '/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/build/Release/better_sqlite3.node',\n    '/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/out/Debug/better_sqlite3.node',\n    '/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/Debug/better_sqlite3.node',\n    '/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/out/Release/better_sqlite3.node',\n    '/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/Release/better_sqlite3.node',\n    '/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/build/default/better_sqlite3.node',\n    '/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/compiled/23.3.0/darwin/arm64/better_sqlite3.node',\n    '/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/addon-build/release/install-root/better_sqlite3.node',\n    '/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/addon-build/debug/install-root/better_sqlite3.node',\n    '/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/addon-build/default/install-root/better_sqlite3.node',\n    '/Users/rogerbos/Node_HOME/eliza-starter/node_modules/.pnpm/better-sqlite3@7.6.2/node_modules/better-sqlite3/lib/binding/node-v131-darwin-arm64/better_sqlite3.node'\n  ]\n}", "CLOSED", 0, "rogerjbos", "2025-01-18T22:11:01Z", "2025-03-08T01:17:16Z", "2025-03-08T01:17:16Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6muGnX", 2509, "Add retry mechanism to RemoteAttestationProvider", "Following up from PR #2508\n\nCurrently, RemoteAttestationProvider lacks retry logic for transient failures. We should:\n\n1. Implement retry mechanism similar to `fetchWithRetry` in WalletProvider\n2. Add exponential backoff for failed attempts\n3. Add test cases to verify retry behavior\n\nRelated PR: #2508\nRelated comment: https://github.com/elizaOS/eliza/pull/2508#discussion_r1921117950\n\ncc @ai16z-demirix", "CLOSED", 0, "coderabbitai", "2025-01-18T17:59:26Z", "2025-03-08T01:17:16Z", "2025-03-08T01:17:15Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mteAQ", 2488, "Client twitter - making agents interact in more natural ways on TWITTER SPACES", "**Is your feature request related to a problem? Please describe.**\n\nCurrently agents hosting twitter spaces can only start processing audio from other human speakers after the speakers are muted. This not only introduces delay in most situations but also makes the conversation flow feel less natural. On the other hand, agents sometimes have very long responses that basically become monologues and there is no way the human speakers can interrupt the agent to change the direction of conversation as needed.\n\n**Describe the solution you'd like**\n\n1. I propose that the agent should be always \"listening\" while others speak, so that the agent can already work on a prompt based on the context of the conversation and relevant knowledge to respond as soon as the others finish speaking or even jump into conversations if needed.\n\n2. Allow the human speaker to use keywords such as stop, halt or anything else to the same effect to essentially tell the agentruntime to stop streaming the audio chunks from elevenlabs and start listening again straightaway.\n\n**Additional context**\n\nI took a first stab at my proposed solutions but didn't have any luck so far.\n\nSome issues I faced\n- I was not able to collect audio data, convert at fixed intervals and temporarily store as well as checking against RAG to get relevance scores which should be the trigger to send the prompt and generate response.\n- The main issue with trying to get the agent to pick out \"stop\" and related keywords was that the audio capture came from both the human speaker and the agent which makes it difficult to recognise the stop request.\n\n\n\n\n**Some failed attempts**\n\n**Listen, search RAG and respond**\n\n```typescript\nprivate async addToQueue(userId: string, text: string) {\n    this.messageQueue.push({\n        userId,\n        text,\n        timestamp: Date.now(),\n        isProcessed: false\n    });\n\n    if (!this.isProcessingQueue) {\n        await this.processQueue();\n    }\n}\n\nprivate async processQueue() {\n    if (this.isProcessingQueue) return;\n    this.isProcessingQueue = true;\n\n    try {\n        // Wait for transcription accumulation window\n        await new Promise(resolve => setTimeout(resolve, this.transcriptionAccumulationTimeMs));\n\n        while (this.messageQueue.length > 0) {\n            // Process all messages that arrived within the last window\n            const now = Date.now();\n            const windowStart = now - this.transcriptionAccumulationTimeMs;\n            const messagesInWindow = this.messageQueue\n                .filter(item => !item.isProcessed && item.timestamp >= windowStart);\n\n            if (messagesInWindow.length === 0) break;\n\n            // Combine all messages in the window\n            const combinedText = messagesInWindow\n                .map(item => item.text)\n                .join(\" \")\n                .trim();\n\n            if (combinedText.length > 0) {\n                const relevanceScore = await this.checkRelevance(combinedText);\n                elizaLogger.info(`[SttTtsPlugin] Processing combined messages: \"${combinedText}\", Score: ${relevanceScore}`);\n\n                if (relevanceScore > 0.3) {\n                    // Check if anyone is currently speaking\n                    const anyActiveSpeakers = Array.from(this.speakerStates.values())\n                        .some(state => state.isSpeaking);\n\n                    if (!anyActiveSpeakers) {\n                        await this.generateAndSpeakResponse(combinedText);\n                        // Mark all processed messages\n                        messagesInWindow.forEach(item => item.isProcessed = true);\n                        // Remove processed messages from queue\n                        this.messageQueue = this.messageQueue.filter(item => !item.isProcessed);\n                        break;\n                    }\n                }\n            }\n\n            // Mark messages as processed\n            messagesInWindow.forEach(item => item.isProcessed = true);\n            // Clean up processed messages\n            this.messageQueue = this.messageQueue.filter(item => !item.isProcessed);\n\n            // Brief pause before next iteration\n            await new Promise(resolve => setTimeout(resolve, 300));\n        }\n    } finally {\n        this.isProcessingQueue = false;\n    }\n}\n\nprivate async checkRelevance(text: string): Promise<number> {\n    try {\n        elizaLogger.info(\"[SttTtsPlugin] Checking relevance for text:\", {\n            text,\n            length: text.length\n        });\n\n        // Respond to very short messages if they might be addressing the agent\n        if (text.length < 5) {\n            // Check if it sounds like \"hey\", \"hi\", \"yo\" etc\n            if (/^(hey|hi|yo|oh|um|uh|you|byte)\\b/i.test(text)) {\n                elizaLogger.info(\"[SttTtsPlugin] Detected greeting/acknowledgment:\", text);\n                return 0.7; // 70% base score for greetings\n            }\n        }\n\n        // Always respond to questions or direct address\n        const isQuestion = text.includes('?') || /^(what|who|where|when|why|how|can|could|would|will|do|does|did|is|are|was|were)\\b/i.test(text);\n        const isDirectAddress = this.agentName ? text.toLowerCase().includes(this.agentName.toLowerCase()) : false;\n\n        if (isQuestion || isDirectAddress) {\n            elizaLogger.info(`[SttTtsPlugin] High priority message detected:`, {\n                text,\n                isQuestion,\n                isDirectAddress,\n                agentName: this.agentName\n            });\n            return 0.9; // 90% base score for questions/direct address\n        }\n\n        // Get relevant knowledge with more detailed logging\n        elizaLogger.info(\"[SttTtsPlugin] Querying RAG knowledge for:\", text);\n        const knowledgeData = await this.runtime.ragKnowledgeManager.getKnowledge({\n            query: text,\n            limit: 3\n        }).catch(err => {\n            elizaLogger.error(\"[SttTtsPlugin] Error getting knowledge:\", err);\n            return [];\n        });\n\n        // Log retrieved knowledge\n        knowledgeData.forEach((k, index) => {\n            elizaLogger.info(`[SttTtsPlugin] RAG Knowledge ${index + 1}:`, {\n                text: k?.content?.text,\n                score: k?.score,\n                source: k?.source\n            });\n        });\n\n        // Calculate relevance score with detailed logging\n        let relevanceScore = 0;\n        const scoreDetails: string[] = [];\n\n        // Base score for any non-empty message\n        if (text.length > 0) {\n            relevanceScore += 0.2;\n            scoreDetails.push(\"+0.2 (non-empty message)\");\n        }\n\n        knowledgeData.forEach((k, index) => {\n            if (!k?.content?.text) return;\n\n            // Check for exact phrase matches\n            if (k.content.text.toLowerCase().includes(text.toLowerCase())) {\n                relevanceScore += 0.4;\n                scoreDetails.push(`+0.4 (exact match in knowledge ${index + 1})`);\n            }\n\n            // Add base score for relevant knowledge\n            relevanceScore += 0.2;\n            scoreDetails.push(`+0.2 (relevant knowledge ${index + 1})`);\n        });\n\n        // Log final relevance calculation\n        elizaLogger.info(\"[SttTtsPlugin] Relevance calculation complete:\", {\n            inputText: text,\n            finalScore: relevanceScore,\n            scoreBreakdown: scoreDetails,\n            knowledgeCount: knowledgeData.length\n        });\n\n        return relevanceScore;\n    } catch (error) {\n        elizaLogger.error(\"[SttTtsPlugin] Error in checkRelevance:\", error);\n        return 0.5; // Default to 50% relevance on error\n    }\n}\n\nprivate async shouldRespondToMessage(text: string): Promise<boolean> {\n    const relevanceScore = await this.checkRelevance(text);\n    const randomChance = Math.random();\n    let shouldRespond = false;\n    let reason = \"\";\n\n    if (relevanceScore > 0.4) {\n        shouldRespond = randomChance < 0.9;\n        reason = \"High relevance (>0.4), 90% chance to respond\";\n    } else if (relevanceScore > 0.2) {\n        shouldRespond = randomChance < 0.7;\n        reason = \"Medium relevance (>0.2), 70% chance to respond\";\n    } else {\n        shouldRespond = randomChance < 0.4;\n        reason = \"Low relevance, 40% chance to respond\";\n    }\n\n    elizaLogger.info(\"[SttTtsPlugin] Response decision:\", {\n        inputText: text,\n        relevanceScore,\n        randomChance,\n        shouldRespond,\n        reason\n    });\n\n    return shouldRespond;\n}\n```\n\n\n\n**Receive stop command**\n```typescript    \nprivate async onAudioData(data: AudioDataWithUser): Promise<void> {\n        // ... existing code ...\n\n        // Quick transcription for stop commands if we're speaking\n        if (this.isSpeaking) {\n            try {\n                const wavBuffer = await this.convertPcmToWavInMemory(data.samples, data.sampleRate);\n                const text = await this.transcriptionService.transcribe(Buffer.from(wavBuffer));\n                \n                if (text) {\n                    const normalizedText = text.toLowerCase().trim();\n                    const isStopCommand = this.stopPhrases.some(phrase => normalizedText.includes(phrase));\n                    \n                    if (isStopCommand) {\n                        elizaLogger.info(\"[SttTtsPlugin] Stop command detected:\", { text });\n                        this.shouldStopSpeaking = true;\n                        this.ttsQueue = []; // Clear pending speech\n                        return;\n                    }\n                }\n            } catch (err) {\n                // Ignore errors in stop detection - don't want to affect main flow\n                elizaLogger.debug(\"[SttTtsPlugin] Error checking for stop command:\", err);\n            }\n        }\n```\n\n\n**Stop playing audio chunks**\n```typescript    \nprivate async streamToJanus(samples: Int16Array, sampleRate: number): Promise<void> {\n        // ... existing code ...\n\n        for (let offset = 0; offset + FRAME_SIZE <= samples.length; offset += FRAME_SIZE) {\n            // Check for stop command\n            if (this.shouldStopSpeaking) {\n                elizaLogger.info(\"[SttTtsPlugin] Interrupting audio stream on request\", {\n                    framesStreamed,\n                    totalFrames,\n                    percentComplete: Math.round((framesStreamed / totalFrames) * 100)\n                });\n                return;\n            }\n            // ... rest of streaming code ...\n        }\n```\n\n\n", "CLOSED", 0, "daniellinuk", "2025-01-18T11:44:55Z", "2025-03-08T01:17:15Z", "2025-03-08T01:17:15Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mtbpI", 2487, "MODULE_NOT_FOUND error when starting the agent", "**Describe the bug**\nI get such error when i use pnpm start for my own agent. I use windows ubuntu wsl.\n\n{\"level\":50,\"time\":1737199046766,\"pid\":44084,\"hostname\":\"XXX\",\"code\":\"MODULE_NOT_FOUND\",\"requireStack\":[\"/mnt/c/Users/XXX/OneDrive/Desktop/final2/eliza/node_modules/body-parser/lib/types/urlencoded.js\",\"/mnt/c/Users/XXX/OneDrive/Desktop/final2/eliza/node_modules/body-parser/index.js\"],\"msg\":\"Unhandled error in startAgents:\"}\n/mnt/c/Users/XXX/OneDrive/Desktop/final2/eliza/agent:\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.9-alpha.1 start: `node --loader ts-node/esm src/index.ts \"--isRoot\" \"--characters=normai.character.json\"`\nExit status 1\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\n\n**Additional context**\n\nI installed all dependecies but still get such error. What is the solution ?\n", "CLOSED", 0, "normaieditor", "2025-01-18T11:23:46Z", "2025-03-08T01:17:15Z", "2025-03-08T01:17:15Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mtbAb", 2486, "Add timeout test coverage for Binance plugin price service", "Add test coverage for API timeout scenarios in the PriceService.\n\nThis enhancement will improve error handling test coverage by validating the behavior when API requests time out.\n\nRelated PR: https://github.com/elizaOS/eliza/pull/2482#discussion_r1921039279", "CLOSED", 0, "coderabbitai", "2025-01-18T11:16:33Z", "2025-03-08T01:15:54Z", "2025-03-08T01:15:54Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mta7Z", 2484, "Docs for the RagKnowledge that was implemented", "I am finding it challenging to understand the implementation of the new RagKnowledge feature for processing PDF files and similar document types. Currently, there is a lack of comprehensive documentation or step-by-step guides for where these files need to be in the project for the character to pull them into the db. This makes it difficult to fully utilize its capabilities, especially for users new to the feature.\n\nI would like to see detailed documentation for the RagKnowledge implementation. This should include:\n\nAn overview of the feature and its purpose.\nStep-by-step instructions for setting up and using RagKnowledge to process PDFs, including sample code.\nExamples of how to integrate it into existing workflows or applications.\nBest practices for optimizing the performance of this feature.\nTroubleshooting common issues and errors related to RagKnowledge.\nDescribe alternatives you've considered\n\nSearching for community tutorials or blog posts about RagKnowledge.\nExperimenting with trial and error to understand the functionality better.\nRequesting assistance from the developer community through forums or social media.\nWhile these alternatives can provide some insights, they are time-consuming and may not provide the depth and reliability that official documentation would offer.\n\nHaving official documentation would not only improve the user experience but also encourage more developers to adopt and implement RagKnowledge in their projects. This could include a dedicated section in the knowledge base, video tutorials, or example repositories on GitHub.", "CLOSED", 0, "KeyesCode", "2025-01-18T11:15:42Z", "2025-03-08T01:10:03Z", "2025-03-08T01:10:03Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6ms-0G", 2478, "WSL 2:onnxruntime package error", "Whether directly through pnpm install or through [eliza-Installer]([HowieDuhzit/Eliza-Installer: Automated Eliza Install Script](https://github.com/HowieDuhzit/Eliza-Installer)), the same issue was encountered.\n\n![Image](https://github.com/user-attachments/assets/807c4568-e8ac-44a0-99c7-704ecdd462de)", "CLOSED", 0, "shichen1iu", "2025-01-18T07:01:01Z", "2025-03-08T01:10:03Z", "2025-03-08T01:10:03Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mraeE", 2466, "telegram client polling is incompatible with blue-green deployments", "**Describe the bug**\nThe telegram client uses long polling. A requirement of this implementation is that only one client can be running at any given moment. This presents a problem for cloud-based deployments where multiple instances may be running during a deployment phase.\n\nThe client throws an error, which crashes the entire runtime instead of gracefully shutting down the telegram client.\n\n**To Reproduce**\n\nRun an agent with telegram clients in two separate terminal windows. Deploy an agent on a blue/green deployment such as Digital Ocean apps, then trigger a new deployment.\n\n**Expected behavior**\n\nGraceful shutdown of telegram client to accommodate blue green deployments\n", "CLOSED", 0, "0xPBIT", "2025-01-17T22:20:25Z", "2025-03-08T01:10:03Z", "2025-03-08T01:10:03Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mqfMd", 2457, "docker-compose-docs.yaml fails to build docs", "**Describe the bug**\n\nI'm trying to build the docs locally, but I'm hitting errors.  `docs/README.md` says to run:\n\n    docker compose -f docker-compose-docs.yaml up --build\n\nbut that results in:\n\n```\n => => transferring context: 208.74MB                                                                                                                               1.2s\n => [docs base 1/4] FROM docker.io/library/node:23.3.0-slim@sha256:8b30809f66a6ea8896b9a5d004b4fe2cc0e8061d981d3784fb0e80a19b86ab9d                                 0.0s\n => CACHED [docs base 2/4] RUN corepack enable                                                                                                                      0.0s\n => CACHED [docs base 3/4] WORKDIR /opt/docusaurus                                                                                                                  0.0s\n => CANCELED [docs base 4/4] RUN apt-get update && apt-get install -y git                                                                                           3.9s\n => CACHED [docs preprod 1/3] WORKDIR /opt/docusaurus                                                                                                               0.0s\n => CACHED [docs preprod 2/3] COPY docs/package.json /opt/docusaurus/package.json                                                                                   0.0s\n => ERROR [docs preprod 3/3] COPY docs/package-lock.json /opt/docusaurus/package-lock.json                                                                          0.0s\n------\n > [docs preprod 3/3] COPY docs/package-lock.json /opt/docusaurus/package-lock.json:\n------\nfailed to solve: failed to compute cache key: failed to calculate checksum of ref d1022e12-69b2-4bd3-ba8f-5726ec569b13::42wphsi865jh0mh5nygohgya3: \"/docs/package-lock.json\": not found\n```\n\nThis is not too surprising because `docs/package-lock.json` doesn't exist in git, and it won't be created unless `npm install` is run; yet `Dockerfile.docs` uses a strange mix of `npm` and `pnpm` but only runs `pnpm install` and never `npm install`.\n\n\n**To Reproduce**\n\nRun:\n\n    docker compose -f docker-compose-docs.yaml up --build\n\n**Expected behavior**\n\nThe command succeeds.\n\n**Screenshots**\n\n<!-- Uploading \"image.png\"... -->\n\n**Additional context**\n\nAfter commenting out that line, it fails with a different error:\n\n```\n => [docs prod 1/5] RUN --mount=type=cache,id=pnpm,target=/pnpm/store pnpm install                                                                                 39.3s\n => ERROR [docs prod 2/5] COPY docs/ /opt/docusaurus/                                                                                                               1.1s\n------\n > [docs prod 2/5] COPY docs/ /opt/docusaurus/:\n------\nfailed to solve: cannot copy to non-directory: /var/lib/docker/btrfs/subvolumes/d23z7lot5eufki4qu5ywr4crp/opt/docusaurus/node_modules/react\n```\n\nbut I guess that's a separate problem - currently looking into it.", "CLOSED", 0, "aspiers", "2025-01-17T19:25:21Z", "2025-03-08T01:15:29Z", "2025-03-08T01:10:02Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mmZS8", 2432, "Cannot find module '@anush008/tokenizers-linux-arm64-gnu' when starting the Docker container on M-based Mac", "Hello, I have a problem when trying to start the Docker container on an M-based Mac.\n\nI build the container with the following command:\n```\ndocker buildx build --platform linux/arm64 -t eliza . \n```\n\nI start the container:\n```\ndocker run --platform linux/arm64 -p 3000:3000 --name eliza eliza\n```\n\nAnd I am getting the following error:\n```\nError: Cannot find module '@anush008/tokenizers-linux-arm64-gnu'\nRequire stack:\n- /app/node_modules/@anush008/tokenizers/index.js\n- /app/node_modules/fastembed/lib/cjs/fastembed.js\n- /app/node_modules/fastembed/lib/cjs/index.js\n    at Function._resolveFilename (node:internal/modules/cjs/loader:1239:15)\n    at Function._load (node:internal/modules/cjs/loader:1064:27)\n    at TracingChannel.traceSync (node:diagnostics_channel:322:14)\n    at wrapModuleLoad (node:internal/modules/cjs/loader:218:24)\n    at Module.require (node:internal/modules/cjs/loader:1325:12)\n    at require (node:internal/modules/helpers:136:16)\n    at Object.<anonymous> (/app/node_modules/@anush008/tokenizers/index.js:219:31)\n    at Module._compile (node:internal/modules/cjs/loader:1546:14)\n    at Object..js (node:internal/modules/cjs/loader:1698:10)\n    at Module.load (node:internal/modules/cjs/loader:1303:32) {\n  code: 'MODULE_NOT_FOUND',\n  requireStack: [\n    '/app/node_modules/@anush008/tokenizers/index.js',\n    '/app/node_modules/fastembed/lib/cjs/fastembed.js',\n    '/app/node_modules/fastembed/lib/cjs/index.js'\n  ]\n}\n```\n\nI am attaching the entire console:\n```\nuser@MacBookPro eliza % docker run --platform linux/arm64 -p 3000:3000 --name eliza eliza\n\n> eliza@ start /app\n> pnpm --filter \"@elizaos/agent\" start --isRoot\n\n\n> @elizaos/agent@0.1.8+build.1 start /app/agent\n> node --loader ts-node/esm src/index.ts \"--isRoot\"\n\n(node:31) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\n(Use `node --trace-warnings ...` to show where the warning was created)\n(node:31) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\n(Use `node --trace-deprecation ...` to show where the warning was created)\nnode:internal/modules/cjs/loader:1239\n  const err = new Error(message);\n              ^\n\nError: Cannot find module '@anush008/tokenizers-linux-arm64-gnu'\nRequire stack:\n- /app/node_modules/@anush008/tokenizers/index.js\n- /app/node_modules/fastembed/lib/cjs/fastembed.js\n- /app/node_modules/fastembed/lib/cjs/index.js\n    at Function._resolveFilename (node:internal/modules/cjs/loader:1239:15)\n    at Function._load (node:internal/modules/cjs/loader:1064:27)\n    at TracingChannel.traceSync (node:diagnostics_channel:322:14)\n    at wrapModuleLoad (node:internal/modules/cjs/loader:218:24)\n    at Module.require (node:internal/modules/cjs/loader:1325:12)\n    at require (node:internal/modules/helpers:136:16)\n    at Object.<anonymous> (/app/node_modules/@anush008/tokenizers/index.js:219:31)\n    at Module._compile (node:internal/modules/cjs/loader:1546:14)\n    at Object..js (node:internal/modules/cjs/loader:1698:10)\n    at Module.load (node:internal/modules/cjs/loader:1303:32) {\n  code: 'MODULE_NOT_FOUND',\n  requireStack: [\n    '/app/node_modules/@anush008/tokenizers/index.js',\n    '/app/node_modules/fastembed/lib/cjs/fastembed.js',\n    '/app/node_modules/fastembed/lib/cjs/index.js'\n  ]\n}\n\nNode.js v23.3.0\n/app/agent:\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.8+build.1 start: `node --loader ts-node/esm src/index.ts \"--isRoot\"`\nExit status 1\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\n```\n", "CLOSED", 0, "krustevalexander", "2025-01-17T10:20:10Z", "2025-03-08T01:10:02Z", "2025-03-08T01:10:02Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mluFp", 2427, "Parsing Error when receiving OpenAI response", "**Describe the bug**\nWhen having a conversation with the trump bot, I got this error.\nError parsing JSON: SyntaxError: Expected ',' or '}' after property value in JSON at position\n\n at JSON.parse (<anonymous>)\n    at parseJsonArrayFromText ()\n\nThe response is an array with multiple objects:\n```json\n [\n{\n    \"claim\": \"Under Trump's leadership, America will become the leader in crypto.\",\n    \"type\": \"opinion\",\n    \"in_bio\": false,\n    \"already_known\": false\n  },\n  {\n    \"claim\": \"Trump is always ready to make America great again, even in the digital world.\",\n    \"type\": \"opinion\",\n    \"in_bio\": false,\n    \"already_known\": false\n  },\n{\n    \"claim\": \"America is dominating the crypto space under Trump's leadership.\",\n    \"type\": \"opinion\",\n    \"in_bio\": false,\n    \"already_known\": false\n  },\n]\n```\n**To Reproduce**\n\nUsing the trump character, use OpenAI model and chat for a while.\n\n\n**Expected behavior**\n\nThe parsing function should be robust enough to handle different responses from OpenAI.\nIt should be error free\n\n\n", "CLOSED", 0, "dantgw", "2025-01-17T08:51:04Z", "2025-03-08T01:10:02Z", "2025-03-08T01:10:01Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mldfq", 2424, "Unexpected Behavior: Bot Ignoring Custom Twitter Target Users", "**Describe the bug**\n\nThe Eliza OS Twitter bot is only retweeting and replying to Elon Musk's tweets, despite having a custom TWITTER_TARGET_USERS list and character configuration.\n\n**To Reproduce**\n\n1. Set up Eliza OS Twitter bot with custom TWITTER_TARGET_USERS list and character configuration\n2. Run the bot\n3. Observe the bot's activity\n\n**Expected behavior**\n\nThe bot should retweet and reply to tweets from all users specified in the TWITTER_TARGET_USERS list, using the custom character configuration.\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/2432719f-6f7e-46f8-89db-4532dd4fbb46)\n\n**Additional context**\n\n- Custom TWITTER_TARGET_USERS list and character configuration have been correctly set up\n- The bot is functioning, but only interacting with Elon Musk's tweets\n- Other specified users in TWITTER_TARGET_USERS are being ignored", "CLOSED", 0, "jeongtai", "2025-01-17T08:11:18Z", "2025-03-08T01:10:01Z", "2025-03-08T01:10:01Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mlIve", 2421, "Package install doesn't work", "\n---\n\n**Describe the bug**\n\nWhen attempting to install the package `@elizaos/runtime` from the GitHub Packages registry using the command `pnpm install @elizaos/runtime --registry=https://npm.pkg.github.com`, the installation fails with a `404 Not Found` error. The error message indicates that the package does not exist under the owner `elizaos`, even though all authentication and configuration steps have been correctly followed.\n\n---\n\n**To Reproduce**\n\n1. Configure `.npmrc` with the following content:\n   ```\n   @elizaos:registry=https://npm.pkg.github.com/\n   //npm.pkg.github.com/:_authToken=YOUR_TOKEN\n   ```\n2. Run the command:\n   ```\n   pnpm install @elizaos/runtime --registry=https://npm.pkg.github.com\n   ```\n3. Observe the error message:\n   ```\n   ERR_PNPM_FETCH_404 GET https://npm.pkg.github.com/@elizaos%2Fruntime: Not Found - 404\n   ```\n\n---\n\n**Expected behavior**\n\nThe package `@elizaos/runtime` should be installed successfully if it exists in the registry and the authentication is correct.\n\n---\n\n**Screenshots**\n\n- Screenshot of the command output:\n  ```\n  curl -H \"Authorization: Bearer YOUR_TOKEN\" https://npm.pkg.github.com/@elizaos/runtime\n  {\"error\":\"npm package \\\"runtime\\\" does not exist under owner \\\"elizaos\\\"\"}\n  ```\n- Screenshot of the `.npmrc` configuration:\n  ```\n  @elizaos:registry=https://npm.pkg.github.com/\n  //npm.pkg.github.com/:_authToken=YOUR_TOKEN\n  ```\n\n---\n\n**Additional context**\n\n- The GitHub token used has the necessary scopes: `read:packages`, `write:packages`, and `repo`.\n- The issue persists across different machines and network configurations.\n- All configurations, including `.npmrc`, were double-checked and confirmed to be accurate.\n- The problem appears to be related to either package visibility settings or misconfiguration in the registry.\n\nLet me know if further clarification is needed or additional steps to verify!\n", "CLOSED", 0, "Aave-Khan", "2025-01-17T07:16:05Z", "2025-03-08T01:10:01Z", "2025-03-08T01:10:01Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mkLpH", 2416, "Error while using <QueryClientProvider />", "**Describe the bug**\nI am getting the error above when i try to load the client app on [port 5173](http://localhost:5173)\n\n**To Reproduce**\n\n1. Clone the latest repo\n2. Follow readme, and eventually run pnpm dev.\n3. go to http://localhost:5173\n\n**Expected behavior**\nI expect the client app to load without errors\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/d298d078-152e-409a-92b7-f331fd01d87f)\n\n**Additional context**\n\n", "CLOSED", 0, "harrisrobin", "2025-01-17T04:13:17Z", "2025-03-08T01:10:00Z", "2025-03-08T01:10:00Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mjFox", 2409, "@elizaos/plugin-image-generation - Issue", "Hey there! \n\nwhen i try to generate an image (I use the together API) I got this error :  [\"\u26d4 TypeError: Cannot read properties of undefined (reading 'name')\"] \n\nFYI I'm using the @elizaos/plugin-image-generation \nThe log from terminal : \n\n[\"\u25ce Generating text...\"] \n\n  INFORMATIONS\n   Generating text with options: \n   {\"modelProvider\":\"openrouter\",\"model\":\"medium\",\"verifiableInference\":false} \n\n \u25ce LOGS\n   Using provider: \n   openrouter \n\n INFORMATIONS\n   Selected model: \n   nousresearch/hermes-3-llama-3.1-405b \n\n \u25ce LOGS\n   Image prompt received: \n   A futuristic robot DJ, vibrant neon lights pulsating in a dark, high-tech nightclub. Deep blues and electric pinks illuminate the scene. Energetic and exhilarating mood, the robot commands attention at center frame, mixing futuristic beats. Sharp angles and sleek lines define the composition in a vibrant, cyberpunk style. \n\n \u25ce LOGS\n   Image settings: \n   {} \n\n \u25ce LOGS\n   Generating image with prompt: \n   A futuristic robot DJ, vibrant neon lights pulsating in a dark, high-tech nightclub. Deep blues and electric pinks illuminate the scene. Energetic and exhilarating mood, the robot commands attention at center frame, mixing futuristic beats. Sharp angles and sleek lines define the composition in a vibrant, cyberpunk style. \n\n [\"\u26d4 TypeError: Cannot read properties of undefined (reading 'name')\"] \n\n\n\nAny help?", "CLOSED", 0, "MustBeSimo", "2025-01-17T01:30:50Z", "2025-03-08T01:10:00Z", "2025-03-08T01:10:00Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mgX2k", 2395, "Cannot figure out how to effectively execute multiple dependent actions in response to a single user message", "Hi everybody!\n\nI watched the dev school videos and i think the framework has a great potential.\n\nI am trying to build an agent focused on crypto trading advice. Its main goal is to answer user queries pulling data from APIs. \n\nI am having trouble in understanding how to be able to execute multiple api calls in response to a single user message. The API calls order is also important because some of them are not independent (i need the results of an API call to be able to call another one). \n\nWhat would be the best way to achieve this behaviour? I was trying to wrap api calls in actions but the issue is that from what i understand the framework only executes a single action per user message.\n\nMaybe it is better to wrap api calls in providers instead of actions? Otherwise should i create an ActionAggregator action that chooses which api calls are needed (and in which order), performs all of them and then sends a response to the user using the API calls results?\n\nI am surprised that the framework does not provide a more straightforward way to handle this type of scenario, which i think is quite common, but maybe i am missing something. Any advice would be greatly appreciated!\n\nAlso i don't know if a github issue is the correct place to ask this type of question, but i did not find anywhere else to ask support.", "CLOSED", 0, "Andrea98Palermo", "2025-01-16T18:47:40Z", "2025-03-08T01:10:00Z", "2025-03-08T01:10:00Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mdJWm", 2381, "A bug in dev.sh - When using \"pnpm dev --character=xx\", the character fails to load", "**Describe the bug**\n\n<!-- A clear and concise description of what the bug is. -->\n\nWhen using the `pnpm dev --character=\"characters/trump.character.json\"` command, the `character` parameter fails to load correctly, resulting in only the default `character` being loaded.\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n\nstep 1:\nopen the `dev.sh` file\n`vim scripts/dev.sh`\n\nstep 2:\n\nadd a new path for WORKING_FOLDERS\n\n```shell\n# List of working folders to watch (relative to $PACKAGES_DIR)\nWORKING_FOLDERS=(\"client-direct\" \"plugin-test\") # Core is handled separately\n```\n\nstep 3:\nrun\n`pnpm dev --character=\"characters/trump.character.json\"`\n\nstep 4:\nWill see that the default character \"Eliza\" has been loaded, instead of the specified \"trump.character.json\"\n\n**Expected behavior**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\nCharacter \"trump\" should be loaded\n\n**Screenshots**\n\n<!-- If applicable, add screenshots to help explain your problem. -->\n\nNo screenshots\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n\nThe reason for this situation is that a wrong symbol was used in `dev.sh`\n\n![Image](https://github.com/user-attachments/assets/4de0cb45-366c-445f-9632-f2fba2c588a0)\n\nShould use `*` instead of `@`\nUsing `@` causes the command to be forcibly wrapped into a new line (and it's an incorrect line break)\n\nThis is the correct code:\n```shell\nCOMMANDS+=(\"nodemon ${WATCH_PATHS[*]} -e js,json,map --delay 2 --exec 'pnpm --dir agent dev -- $*'\")\n```", "CLOSED", 0, "MyJoiT", "2025-01-16T12:48:57Z", "2025-03-08T01:09:59Z", "2025-03-08T01:09:59Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mcdAz", 2376, "RAG/Knowledge for No ascii characters", "**Describe the bug**\r\n\r\nThe knowledge preprocessing function incorrectly removes non-ASCII characters like Chinese text due to an overly restrictive regex pattern that only allows ASCII alphanumeric characters.\r\n\r\n**To Reproduce**\r\n\r\n1. Create a knowledge item with non-ASCII characters like Chinese text\r\n2. Call the preprocess function with this content:\r\n\r\n```\r\nconst input = \"\u4f60\u597d Eliza\";\r\nknowledge.preprocess(input)\r\n```\r\n\r\n3. The Chinese characters are removed from the output\r\n\r\n**Expected behavior**\r\n\r\nThe preprocess function should preserve non-ASCII characters like Chinese text", "CLOSED", 0, "jolestar", "2025-01-16T11:36:49Z", "2025-03-08T01:09:59Z", "2025-03-08T01:09:59Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mXAOd", 2339, "Error invalid schema", "I am trying to develop a plugin and got this error while asking for token creation\r\n\r\n [\"\u25ce Starting CREATE_TOKEN handler...\"] \r\n\r\nError in generateObject: InvalidArgumentError [AI_InvalidArgumentError]: Invalid argument for parameter schema: Schema is required for object output.\r\n\r\n\r\n  cause: undefined,\r\n  parameter: 'schema',\r\n  value: undefined,\r\n  [Symbol(vercel.ai.error)]: true,\r\n  [Symbol(vercel.ai.error.AI_InvalidArgumentError)]: true\r\n}\r\n [\"\u26d4 AI_InvalidArgumentError: Invalid argument for parameter schema: Schema is required for object output.\"] ", "CLOSED", 0, "nidhinakranii", "2025-01-15T22:08:21Z", "2025-03-08T01:09:59Z", "2025-03-08T01:09:59Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mPuQC", 2320, "Fix: [plugin-chainbase] Enhance Query Text Extraction and Validation for QUERY_BLOCKCHAIN_DATA Action", "Title: Enhance Query Text Extraction and Validation for QUERY_BLOCKCHAIN_DATA Action\r\n\r\n**Description**\r\nCurrently in `queryData.ts`, we use a simple string slice method to extract query text:\r\n\r\nWhile this approach works, it has several potential issues:\r\n1. Lacks structured validation for extracted text\r\n2. May contain inappropriate or potentially dangerous content  \r\n3. No explicit query format constraints\r\n\r\n**Proposed Improvements**\r\nConsider implementing the following optimizations:\r\n1. Define query templates or structured formats\r\n2. Add query text validation rules\r\n3. Implement content filtering mechanisms\r\n4. Consider using regex or more structured parsing approaches\r\n\r\n**Implementation Ideas**\r\n1. Create a query template system\r\n2. Add input validation middleware\r\n3. Establish whitelist rules for query text\r\n4. Improve error message accuracy\r\n\r\n**Priority**\r\nMedium - Consider implementing in future releases\r\n", "CLOSED", 0, "lxcong", "2025-01-15T08:27:16Z", "2025-03-08T01:09:58Z", "2025-03-08T01:09:58Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mPUSh", 2316, "Duplicate responses to an action", "Getting duplicate responses on tweets which can possibly trigger actions\r\n\r\nI've created an action which performs token due diligence. Whenever i prompt my agent relating to that action, more than half of the times it sends me double or duplicate responses.\r\n\r\nthe times, when i don't get any duplicate responses, ![image (11)](https://github.com/user-attachments/assets/d756b7bd-3503-49ae-a896-b547d914e587)\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\ncopy and paste [this action](https://gist.github.com/Akshat-Mishra101/36903540911587298201cddc11feccb2) and include it in your agent\r\n\r\nComment out the part regarding the token check logic, and just observe whether the action is being called twice\r\n\r\n**Expected behavior**\r\n\r\nResponds once, to a tweet, reply or mention pertaining to an action\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\nA single response, to my prompt.\r\n\r\n**Additional context**\r\n\r\nI'm using the eliza starter template\r\n\r\n \"@elizaos/client-twitter\": \"^0.1.7\",\r\n\r\n**Screenshots**\r\n\r\n\r\n<img width=\"598\" alt=\"image\" src=\"https://github.com/user-attachments/assets/05e7e232-d115-4525-8d8b-a385ed0e1cb9\" />\r\n\r\n", "CLOSED", 0, "Akshat-Mishra101", "2025-01-15T07:26:45Z", "2025-03-08T01:09:58Z", "2025-03-08T01:09:58Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mPJFa", 2315, "Make ServiceType can be extended without modify package/core", "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, when someone want to create a new service, they must add new type as string to enum ServiceType in packages/core/src/types.\r\n\r\n**Describe the solution you'd like**\r\n\r\nI want to add new service type in my new plugin without modify enum ServiceType in package core. In some case they import packages/cores from node-modules, so they can not edit that enum\r\n\r\n**Describe alternatives you've considered**\r\n\r\nMay be remove that enum, so that getService function in packages/core/src/runtime.ts we can use \r\n```\r\ngetService<T extends Service>(service: string)\r\n```\r\ninstead of\r\n```\r\ngetService<T extends Service>(service: ServiceType)\r\n```", "CLOSED", 0, "fibonacci998", "2025-01-15T06:56:24Z", "2025-03-08T01:09:58Z", "2025-03-08T01:09:58Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mOKj7", 2311, "Low performance issues under parallel requests ?", "**Describe the bug**\r\n\r\nI do a stress testing to `DirectClient`, but low performance. Here's the stress testing report: https://app.artillery.io/share/sh_973944e7b55ad120fef7a5e6c2a71980c176b5ab38b788baa7c3caa2a973f367\r\n\r\nYou can see almost all the requests timeout.\r\n\r\nI guess `generateMessageResponse` will block event loop, so there can only be one concurrent request, but I'm not sure.\r\n\r\nhttps://github.com/elizaOS/eliza/blob/89b6a190449a2e42aaeeef4cb6caec6448442614/packages/core/src/generation.ts#L1270-L1282\r\n\r\n**To Reproduce**\r\n\r\nUse eliza-starter to start DirectClient, set `OPENAI_API_URL` in `.env`:\r\n\r\n```sh\r\nOPENAI_API_URL=http://localhost:5002/v1\r\n```\r\n\r\nuse [mockai](https://github.com/polly3d/mockai) to setup a mockai server, and set `data/contents.txt` to:\r\n```json\r\n{ \"user\": \"agent1\", \"text\": \"Hi\", \"action\": \"IGNORE\" }\r\n```\r\n\r\nstart mockai and eliza-starter, then use artillery to run stress testing. Here's artillery config.yml:\r\n\r\n```yaml\r\nconfig:\r\n  target: \"http://localhost:3000\"\r\n  plugins:\r\n    metrics-by-endpoint:\r\n      useOnlyRequestNames: true\r\n  http:\r\n    timeout: 30\r\n  phases:\r\n    - duration: 120\r\n      arrivalRate: 5\r\n      rampTo: 50\r\n      name: Ramp up load\r\n    - duration: 720\r\n      arrivalRate: 50\r\n      maxVusers: 1000\r\n      name: Sustained load\r\n  variables:\r\n    uuid:\r\n      - 00acb7e1-c8db-0a34-9e4c-b0daadc3775b\r\n      - 0d8ef5f1-d3df-0cbf-8e16-bd5ee0202e7c\r\n      - 83ce34fa-65fa-07fa-926e-73eeb423a589\r\nscenarios:\r\n  - name: \"POST /message\"\r\n    flow:\r\n      - post:\r\n          url: \"/{{uuid}}/message\"\r\n          name: \"POST /mint-request (onchain)\"\r\n          gzip: true\r\n          headers:\r\n            \"Content-Type\": \"application/json\"\r\n          json:\r\n            text: hi\r\n```\r\n\r\nJust post `{\"text\": \"hi\"}` to `http://localhost:3000/{uuid}/message`.\r\n\r\n", "CLOSED", 0, "abcfy2", "2025-01-15T03:05:31Z", "2025-03-08T01:09:57Z", "2025-03-08T01:09:57Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mM9eh", 2306, "Direct Client POST /agents/:agentId/set {character} crashes with Exit status 7 using Postgres", "**Describe the bug**\r\n\r\nI get the following crash error when calling `POST /agents/:agentId/set {character}`\r\n\r\n```\r\n\u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.8+build.1 start: `node --loader ts-node/esm src/index.ts \"--isRoot\"`\r\nExit status 7\r\n```\r\n\r\nThis does not happen when I call `POST /agents/:agentId/set {character}` upon first starting Eliza. That works fine. At this point I am just creating the agent for the first time. I'm not loading the character via the filesystem.\r\n\r\nThis issue only occurs once the service has been running for some time and the agent is happily chatting on Telegram and posting on X, and then I make a call to update the character.\r\n\r\nBTW, I'm running on postgres.\r\n\r\n**To Reproduce**\r\n\r\n- Start Eliza with the default character and using postgresql.\r\n- Create/Start an agent via the Direct Client API with `POST /agents/:agentId/set {character}`\r\n- Give it some time to interact\r\n- Update the agent character via the Direct Client API with `POST /agents/:agentId/set {character}` \r\n\r\n**Expected behavior**\r\n\r\nCharacter updated with no crash\r\n\r\n**Screenshots**\r\n\r\n```\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |  [\"\u25ce Checking Twitter interactions\"]\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |  \u25ce LOGS\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |    Completed checking mentioned tweets:\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |    6\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |  [\"\u25ce No target users configured, processing only mentions\"]\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |  [\"\u25ce Finished checking Twitter interactions\"]\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |  \u25ce LOGS\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |    runtime::stop - requesting\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |    telegram\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |    client stop for\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |    Kekaius Telegram Bot\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |  [\"\u25ce Stopping Telegram bot...\"]\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |  [\"\u25ce Telegram bot stopped\"]\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |  \u25ce LOGS\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |    runtime::stop - requesting\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |    twitter\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |    client stop for\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |    Kekaius Telegram Bot\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |  [\"\u2139 Initializing PostgreSQL connection...\"]\r\neliza_39ff199b2f32439c9980b619fe8eccdb  |\r\neliza_39ff199b2f32439c9980b619fe8eccdb  | /app/node_modules/@primuslabs/zktls-core-sdk/dist/algorithm/client_plugin.js:1\r\neliza_39ff199b2f32439c9980b619fe8eccdb  | var Module=typeof Module!=\"undefined\"?Module:{};var moduleOverrides=Object.assign({},Module);var arguments_=[];var thisProgram=\"./this.program\";var quit_=(status,toThrow)=>{throw toThrow};var ENVIRONMENT_IS_WEB=typeof window==\"object\";var ENVIRONMENT_IS_WORKER=typeof importScripts==\"function\";var ENVIRONMENT_IS_NODE=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\";var ENVIRONMENT_IS_SHELL=!ENVIRONMENT_IS_WEB&&!ENVIRONMENT_IS_NODE&&!ENVIRONMENT_IS_WORKER;if(Module[\"ENVIRONMENT\"]){throw new Error(\"Module.ENVIRONMENT has been deprecated. To force the environment, use the ENVIRONMENT compile-time option (for example, -sENVIRONMENT=web or -sENVIRONMENT=node)\")}var ENVIRONMENT_IS_PTHREAD=Module[\"ENVIRONMENT_IS_PTHREAD\"]||false;var _scriptDir=typeof document!=\"undefined\"&&document.currentScript?document.currentScript.src:undefined;if(ENVIRONMENT_IS_WORKER){_scriptDir=self.location.href}else if(ENVIRONMENT_IS_NODE){_scriptDir=__filename}var scriptDirectory=\"\";function locateFile(path){if(Module[\"locateFile\"]){return Module[\"locateFile\"](path,scriptDirectory)}return scriptDirectory+path}var read_,readAsync,readBinary,setWindowTitle;function logExceptionOnExit(e){if(e instanceof ExitStatus)return;let toLog=e;if(e&&typeof e==\"object\"&&e.stack){toLog=[e,e.stack]}err(\"exiting due to exception: \"+toLog)}if(ENVIRONMENT_IS_NODE){if(typeof process==\"undefined\"||!process.release||process.release.name!==\"node\")throw new Error(\"not compiled for this environment (did you build to HTML and try to run it not on the web, or set ENVIRONMENT to something - like node - and run it someplace else - like on the web?)\");var fs=require(\"fs\");var nodePath=require(\"path\");if(ENVIRONMENT_IS_WORKER){scriptDirectory=nodePath.dirname(scriptDirectory)+\"/\"}else{scriptDirectory=__dirname+\"/\"}read_=(filename,binary)=>{filename=isFileURI(filename)?new URL(filename):nodePath.normalize(filename);return fs.readFileSync(filename,binary?undefined:\"utf8\")};readBinary=filename=>{var ret=read_(filename,true);if(!ret.buffer){ret=new Uint8Array(ret)}assert(ret.buffer);return ret};readAsync=(filename,onload,onerror)=>{filename=isFileURI(filename)?new URL(filename):nodePath.normalize(filename);fs.readFile(filename,function(err,data){if(err)onerror(err);else onload(data.buffer)})};if(process[\"argv\"].length>1){thisProgram=process[\"argv\"][1].replace(/\\\\/g,\"/\")}arguments_=process[\"argv\"].slice(2);if(typeof module!=\"undefined\"){module[\"exports\"]=Module}process[\"on\"](\"uncaughtException\",function(ex){if(!(ex instanceof ExitStatus)){throw ex}});var nodeMajor=process.version.match(/^v(\\d+)\\./)[1];if(nodeMajor<15){process[\"on\"](\"unhandledRejection\",function(reason){throw reason})}quit_=(status,toThrow)=>{if(keepRuntimeAlive()){process[\"exitCode\"]=status;throw toThrow}logExceptionOnExit(toThrow);process[\"exit\"](status)};Module[\"inspect\"]=function(){return\"[Emscripten Module object]\"};let nodeWorkerThreads;try{nodeWorkerThreads=require(\"worker_threads\")}catch(e){console.error('The \"worker_threads\" module is not supported in this node.js build - perhaps a newer version is needed?');throw e}global.Worker=nodeWorkerThreads.Worker}else if(ENVIRONMENT_IS_SHELL){if(typeof process==\"object\"&&typeof require===\"function\"||typeof window==\"object\"||typeof importScripts==\"function\")throw new Error(\"not compiled for this environment (did you build to HTML and try to run it not on the web, or set ENVIRONMENT to something - like node - and run it someplace else - like on the web?)\");if(typeof read!=\"undefined\"){read_=function shell_read(f){return read(f)}}readBinary=function readBinary(f){let data;if(typeof readbuffer==\"function\"){return new Uint8Array(readbuffer(f))}data=read(f,\"binary\");assert(typeof data==\"object\");return data};readAsync=function readAsync(f,onload,onerror){setTimeout(()=>onload(readBinary(f)),0)};if(typeof clearTimeout==\"undefined\"){globalThis.clearTimeout=id=>{}}if(typeof scriptArgs!=\"undefined\"){arguments_=scriptArgs}else if(typeof arguments!=\"undefined\"){arguments_=arguments}if(typeof quit==\"function\"){quit_=(status,toThrow)=>{logExceptionOnExit(toThrow);quit(status)}}if(typeof print!=\"undefined\"){if(typeof console==\"undefined\")console={};console.log=print;console.warn=console.error=typeof printErr!=\"undefined\"?printErr:print}}else if(ENVIRONMENT_IS_WEB||ENVIRONMENT_IS_WORKER){if(ENVIRONMENT_IS_WORKER){scriptDirectory=self.location.href}else if(typeof document!=\"undefined\"&&document.currentScript){scriptDirectory=document.currentScript.src}if(scriptDirectory.indexOf(\"blob:\")!==0){scriptDirectory=scriptDirectory.substr(0,scriptDirectory.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1)}else{scriptDirectory=\"\"}if(!(typeof window==\"object\"||typeof importScripts==\"function\"))throw new Error(\"not compiled for this environment (did you build to HTML and try to run it not on the web, or set ENVIRONMENT to something - like node - and run it someplace else - like on the web?)\");if(!ENVIRONMENT_IS_NODE){read_=url=>{var xhr=new XMLHttpRequest;xhr.open(\"GET\",url,false);xhr.send(null);return xhr.responseText};if(ENVIRONMENT_IS_WORKER){readBinary=url=>{var xhr=new XMLHttpRequest;xhr.open(\"GET\",url,false);xhr.responseType=\"arraybuffer\";xhr.send(null);return new Uint8Array(xhr.response)}}readAsync=(url,onload,onerror)=>{var xhr=new XMLHttpRequest;xhr.open(\"GET\",url,true);xhr.responseType=\"arraybuffer\";xhr.onload=()=>{if(xhr.status==200||xhr.status==0&&xhr.response){onload(xhr.response);return}onerror()};xhr.onerror=onerror;xhr.send(null)}}setWindowTitle=title=>document.title=title}else{throw new Error(\"environment detection error\")}if(ENVIRONMENT_IS_NODE){if(typeof performance==\"undefined\"){global.performance=require(\"perf_hooks\").performance}}var defaultPrint=console.log.bind(console);var defaultPrintErr=console.warn.bind(console);if(ENVIRONMENT_IS_NODE){defaultPrint=str=>fs.writeSync(1,str+\"\\n\");defaultPrintErr=str=>fs.writeSync(2,str+\"\\n\")}var out=Module[\"print\"]||defaultPrint;var err=Module[\"printErr\"]||defaultPrintErr;Object.assign(Module,moduleOverrides);moduleOverrides=null;checkIncomingModuleAPI();if(Module[\"arguments\"])arguments_=Module[\"arguments\"];legacyModuleProp(\"arguments\",\"arguments_\");if(Module[\"thisProgram\"])thisProgram=Module[\"thisProgram\"];legacyModuleProp(\"thisProgram\",\"thisProgram\");if(Module[\"quit\"])quit_=Module[\"quit\"];legacyModuleProp(\"quit\",\"quit_\");assert(typeof Module[\"memoryInitializerPrefixURL\"]==\"undefined\",\"Module.memoryInitializerPrefixURL option was removed, use Module.locateFile instead\");assert(typeof Module[\"pthreadMainPrefixURL\"]==\"undefined\",\"Module.pthreadMainPrefixURL option was removed, use Module.locateFile instead\");assert(typeof Module[\"cdInitializerPrefixURL\"]==\"undefined\",\"Module.cdInitializerPrefixURL option was removed, use Module.locateFile instead\");assert(typeof Module[\"filePackagePrefixURL\"]==\"undefined\",\"Module.filePackagePrefixURL option was removed, use Module.locateFile instead\");assert(typeof Module[\"read\"]==\"undefined\",\"Module.read option was removed (modify read_ in JS)\");assert(typeof Module[\"readAsync\"]==\"undefined\",\"Module.readAsync option was removed (modify readAsync in JS)\");assert(typeof Module[\"readBinary\"]==\"undefined\",\"Module.readBinary option was removed (modify readBinary in JS)\");assert(typeof Module[\"setWindowTitle\"]==\"undefined\",\"Module.setWindowTitle option was removed (modify setWindowTitle in JS)\");assert(typeof Module[\"TOTAL_MEMORY\"]==\"undefined\",\"Module.TOTAL_MEMORY has been renamed Module.INITIAL_MEMORY\");legacyModuleProp(\"read\",\"read_\");legacyModuleProp(\"readAsync\",\"readAsync\");legacyModuleProp(\"readBinary\",\"readBinary\");legacyModuleProp(\"setWindowTitle\",\"setWindowTitle\");assert(ENVIRONMENT_IS_WEB||ENVIRONMENT_IS_WORKER||ENVIRONMENT_IS_NODE,\"Pthreads do not work in this environment yet (need Web Workers, or an alternative to them)\");assert(!ENVIRONMENT_IS_SHELL,\"shell environment detected but not enabled at build time.  Add 'shell' to `-sENVIRONMENT` to enable.\");var dynamicLibraries=Module[\"dynamicLibraries\"]||[];var wasmBinary;if(Module[\"wasmBinary\"])wasmBinary=Module[\"wasmBinary\"];legacyModuleProp(\"wasmBinary\",\"wasmBinary\");var noExitRuntime=Module[\"noExitRuntime\"]||true;legacyModuleProp(\"noExitRuntime\",\"noExitRuntime\");if(typeof WebAssembly!=\"object\"){abort(\"no native wasm support detected\")}var wasmMemory;var wasmModule;var ABORT=false;var EXITSTATUS;function assert(condition,text){if(!condition){abort(\"Assertion failed\"+(text?\": \"+text:\"\"))}}var UTF8Decoder=typeof TextDecoder!=\"undefined\"?new TextDecoder(\"utf8\"):undefined;function UTF8ArrayToString(heapOrArray,idx,maxBytesToRead){var endIdx=idx+maxBytesToRead;var endPtr=idx;while(heapOrArray[endPtr]&&!(endPtr>=endIdx))++endPtr;if(endPtr-idx>16&&heapOrArray.buffer&&UTF8Decoder){return UTF8Decoder.decode(heapOrArray.buffer instanceof SharedArrayBuffer?heapOrArray.slice(idx,endPtr):heapOrArray.subarray(idx,endPtr))}var str=\"\";while(idx<endPtr){var u0=heapOrArray[idx++];if(!(u0&128)){str+=String.fromCharCode(u0);continue}var u1=heapOrArray[idx++]&63;if((u0&224)==192){str+=String.fromCharCode((u0&31)<<6|u1);continue}var u2=heapOrArray[idx++]&63;if((u0&240)==224){u0=(u0&15)<<12|u1<<6|u2}else{if((u0&248)!=240)warnOnce(\"Invalid UTF-8 leading byte \"+ptrToString(u0)+\" encountered when deserializing a UTF-8 string in wasm memory to a JS string!\");u0=(u0&7)<<18|u1<<12|u2<<6|heapOrArray[idx++]&63}if(u0<65536){str+=String.fromCharCode(u0)}else{var ch=u0-65536;str+=String.fromCharCode(55296|ch>>10,56320|ch&1023)}}return str}function UTF8ToString(ptr,maxBytesToRead){return ptr?UTF8ArrayToString(HEAPU8,ptr,maxBytesToRead):\"\"}function stringToUTF8Array(str,heap,outIdx,maxBytesToWrite){if(!(maxBytesToWrite>0))return 0;var startIdx=outIdx;var endIdx=outIdx+maxBytesToWrite-1;for(var i=0;i<str.length;++i){var u=str.charCodeAt(i);if(u>=55296&&u<=57343){var u1=str.charCodeAt(++i);u=65536+((u&1023)<<10)|u1&1023}if(u<=127){if(outIdx>=endIdx)break;heap[outIdx++]=u}else if(u<=2047){if(outIdx+1>=endIdx)break;heap[outIdx++]=192|u>>6;heap[outIdx++]=128|u&63}else if(u<=65535){if(outIdx+2>=endIdx)break;heap[outIdx++]=224|u>>12;heap[outIdx++]=128|u>>6&63;heap[outIdx++]=128|u&63}else{if(outIdx+3>=endIdx)break;if(u>1114111)warnOnce(\"Invalid Unicode code point \"+ptrToString(u)+\" encountered when serializing a JS string to a UTF-8 string in wasm memory! (Valid unicode code points should be in range 0-0x10FFFF).\");heap[outIdx++]=240|u>>18;heap[outIdx++]=128|u>>12&63;heap[outIdx++]=128|u>>6&63;heap[outIdx++]=128|u&63}}heap[outIdx]=0;return outIdx-startIdx}function stringToUTF8(str,outPtr,maxBytesToWrite){assert(typeof maxBytesToWrite==\"number\",\"stringToUTF8(str, outPtr, maxBytesToWrite) is missing the third parameter that specifies the length of the output buffer!\");return stringToUTF8Array(str,HEAPU8,outPtr,maxBytesToWrite)}function lengthBytesUTF8(str){var len=0;for(var i=0;i<str.length;++i){var c=str.charCodeAt(i);if(c<=127){len++}else if(c<=2047){len+=2}else if(c>=55296&&c<=57343){len+=4;++i}else{len+=3}}return len}var HEAP8,HEAPU8,HEAP16,HEAPU16,HEAP32,HEAPU32,HEAPF32,HEAPF64;function updateMemoryViews(){var b=wasmMemory.buffer;Module[\"HEAP8\"]=HEAP8=new Int8Array(b);Module[\"HEAP16\"]=HEAP16=new Int16Array(b);Module[\"HEAP32\"]=HEAP32=new Int32Array(b);Module[\"HEAPU8\"]=HEAPU8=new Uint8Array(b);Module[\"HEAPU16\"]=HEAPU16=new Uint16Array(b);Module[\"HEAPU32\"]=HEAPU32=new Uint32Array(b);Module[\"HEAPF32\"]=HEAPF32=new Float32Array(b);Module[\"HEAPF64\"]=HEAPF64=new Float64Array(b)}assert(!Module[\"STACK_SIZE\"],\"STACK_SIZE can no longer be set at runtime.  Use -sSTACK_SIZE at link time\");assert(typeof Int32Array!=\"undefined\"&&typeof Float64Array!==\"undefined\"&&Int32Array.prototype.subarray!=undefined&&Int32Array.prototype.set!=undefined,\"JS engine does not provide full typed array support\");var INITIAL_MEMORY=Module[\"INITIAL_MEMORY\"]||536870912;legacyModuleProp(\"INITIAL_MEMORY\",\"INITIAL_MEMORY\");assert(INITIAL_MEMORY>=1048576,\"INITIAL_MEMORY should be larger than STACK_SIZE, was \"+INITIAL_MEMORY+\"! (STACK_SIZE=\"+1048576+\")\");if(ENVIRONMENT_IS_PTHREAD){wasmMemory=Module[\"wasmMemory\"]}else{if(Module[\"wasmMemory\"]){wasmMemory=Module[\"wasmMemory\"]}else{wasmMemory=new WebAssembly.Memory({\"initial\":INITIAL_MEMORY/65536,\"maximum\":INITIAL_MEMORY/65536,\"shared\":true});if(!(wasmMemory.buffer instanceof SharedArrayBuffer)){err(\"requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag\");if(ENVIRONMENT_IS_NODE){err(\"(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and/or recent version)\")}throw Error(\"bad memory\")}}}updateMemoryViews();INITIAL_MEMORY=wasmMemory.buffer.byteLength;assert(INITIAL_MEMORY%65536===0);var wasmTable=new WebAssembly.Table({\"initial\":3045,\"element\":\"anyfunc\"});function writeStackCookie(){var max=_emscripten_stack_get_end();assert((max&3)==0);if(max==0){max+=4}HEAPU32[max>>2]=34821223;HEAPU32[max+4>>2]=2310721022;HEAPU32[0]=1668509029}function checkStackCookie(){if(ABORT)return;var max=_emscripten_stack_get_end();if(max==0){max+=4}var cookie1=HEAPU32[max>>2];var cookie2=HEAPU32[max+4>>2];if(cookie1!=34821223||cookie2!=2310721022){abort(\"Stack overflow! Stack cookie has been overwritten at \"+ptrToString(max)+\", expected hex dwords 0x89BACDFE and 0x2135467, but received \"+ptrToString(cookie2)+\" \"+ptrToString(cookie1))}if(HEAPU32[0]!==1668509029){abort(\"Runtime error: The application has corrupted its heap memory area (address zero)!\")}}(function(){var h16=new Int16Array(1);var h8=new Int8Array(h16.buffer);h16[0]=25459;if(h8[0]!==115||h8[1]!==99)throw\"Runtime error: expected the system to be little-endian! (Run with -sSUPPORT_BIG_ENDIAN to bypass)\"})();var __ATPRERUN__=[];var __ATINIT__=[];var __ATMAIN__=[];var __ATPOSTRUN__=[];var __RELOC_FUNCS__=[];var runtimeInitialized=false;function keepRuntimeAlive(){return noExitRuntime}function preRun(){assert(!ENVIRONMENT_IS_PTHREAD);if(Module[\"preRun\"]){if(typeof Module[\"preRun\"]==\"function\")Module[\"preRun\"]=[Module[\"preRun\"]];while(Module[\"preRun\"].length){addOnPreRun(Module[\"preRun\"].shift())}}callRuntimeCallbacks(__ATPRERUN__)}function initRuntime(){assert(!runtimeInitialized);runtimeInitialized=true;if(ENVIRONMENT_IS_PTHREAD)return;checkStackCookie();callRuntimeCallbacks(__RELOC_FUNCS__);if(!Module[\"noFSInit\"]&&!FS.init.initialized)FS.init();FS.ignorePermissions=false;TTY.init();callRuntimeCallbacks(__ATINIT__)}function preMain(){checkStackCookie();if(ENVIRONMENT_IS_PTHREAD)return;callRuntimeCallbacks(__ATMAIN__)}function postRun(){checkStackCookie();if(ENVIRONMENT_IS_PTHREAD)return;if(Module[\"postRun\"]){if(typeof Module[\"postRun\"]==\"function\")Module[\"postRun\"]=[Module[\"postRun\"]];while(Module[\"postRun\"].length){addOnPostRun(Module[\"postRun\"].shift())}}callRuntimeCallbacks(__ATPOSTRUN__)}function addOnPreRun(cb){__ATPRERUN__.unshift(cb)}function addOnInit(cb){__ATINIT__.unshift(cb)}function addOnPostRun(cb){__ATPOSTRUN__.unshift(cb)}assert(Math.imul,\"This browser does not support Math.imul(), build with LEGACY_VM_SUPPORT or POLYFILL_OLD_MATH_FUNCTIONS to add in a polyfill\");assert(Math.fround,\"This browser does not support Math.fround(), build with LEGACY_VM_SUPPORT or POLYFILL_OLD_MATH_FUNCTIONS to add in a polyfill\");assert(Math.clz32,\"This browser does not support Math.clz32(), build with LEGACY_VM_SUPPORT or POLYFILL_OLD_MATH_FUNCTIONS to add in a polyfill\");assert(Math.trunc,\"This browser does not support Math.trunc(), build with LEGACY_VM_SUPPORT or POLYFILL_OLD_MATH_FUNCTIONS to add in a polyfill\");var runDependencies=0;var runDependencyWatcher=null;var dependenciesFulfilled=null;var runDependencyTracking={};function getUniqueRunDependency(id){var orig=id;while(1){if(!runDependencyTracking[id])return id;id=orig+Math.random()}}function addRunDependency(id){runDependencies++;if(Module[\"monitorRunDependencies\"]){Module[\"monitorRunDependencies\"](runDependencies)}if(id){assert(!runDependencyTracking[id]);runDependencyTracking[id]=1;if(runDependencyWatcher===null&&typeof setInterval!=\"undefined\"){runDependencyWatcher=setInterval(function(){if(ABORT){clearInterval(runDependencyWatcher);runDependencyWatcher=null;return}var shown=false;for(var dep in runDependencyTracking){if(!shown){shown=true;err(\"still waiting on run dependencies:\")}err(\"dependency: \"+dep)}if(shown){err(\"(end of list)\")}},1e4)}}else{err(\"warning: run dependency added without ID\")}}function removeRunDependency(id){runDependencies--;if(Module[\"monitorRunDependencies\"]){Module[\"monitorRunDependencies\"](runDependencies)}if(id){assert(runDependencyTracking[id]);delete runDependencyTracking[id]}else{err(\"warning: run dependency removed without ID\")}if(runDependencies==0){if(runDependencyWatcher!==null){clearInterval(runDependencyWatcher);runDependencyWatcher=null}if(dependenciesFulfilled){var callback=dependenciesFulfilled;dependenciesFulfilled=null;callback()}}}function abort(what){if(Module[\"onAbort\"]){Module[\"onAbort\"](what)}what=\"Aborted(\"+what+\")\";err(what);ABORT=true;EXITSTATUS=1;var e=new WebAssembly.RuntimeError(what);throw e}var dataURIPrefix=\"data:application/octet-stream;base64,\";function isDataURI(filename){return filename.startsWith(dataURIPrefix)}function isFileURI(filename){return filename.startsWith(\"file://\")}function createExportWrapper(name,fixedasm){return function(){var displayName=name;var asm=fixedasm;if(!fixedasm){asm=Module[\"asm\"]}assert(runtimeInitialized,\"native function `\"+displayName+\"` called before runtime initialization\");if(!asm[name]){assert(asm[name],\"exported native function `\"+displayName+\"` not found\")}return asm[name].apply(null,arguments)}}var wasmBinaryFile;wasmBinaryFile=\"client_plugin.wasm\";if(!isDataURI(wasmBinaryFile)){wasmBinaryFile=locateFile(wasmBinaryFile)}function getBinary(file){try{if(file==wasmBinaryFile&&wasmBinary){return new Uint8Array(wasmBinary)}if(readBinary){return readBinary(file)}throw\"both async and sync fetching of the wasm failed\"}catch(err){abort(err)}}function getBinaryPromise(){if(!wasmBinary&&(ENVIRONMENT_IS_WEB||ENVIRONMENT_IS_WORKER)){if(typeof fetch==\"function\"){return fetch(wasmBinaryFile,{credentials:\"same-origin\"}).then(function(response){if(!response[\"ok\"]){throw\"failed to load wasm binary file at '\"+wasmBinaryFile+\"'\"}return response[\"arrayBuffer\"]()}).catch(function(){return getBinary(wasmBinaryFile)})}}return Promise.resolve().then(function(){return getBinary(wasmBinaryFile)})}function createWasm(){var info={\"env\":wasmImports,\"wasi_snapshot_preview1\":wasmImports,\"GOT.mem\":new Proxy(wasmImports,GOTHandler),\"GOT.func\":new Proxy(wasmImports,GOTHandler)};function receiveInstance(instance,module){var exports=instance.exports;exports=relocateExports(exports,1024);var metadata=getDylinkMetadata(module);if(metadata.neededDynlibs){dynamicLibraries=metadata.neededDynlibs.concat(dynamicLibraries)}mergeLibSymbols(exports,\"main\");Module[\"asm\"]=exports;registerTLSInit(Module[\"asm\"][\"_emscripten_tls_init\"],instance.exports,metadata);addOnInit(Module[\"asm\"][\"__wasm_call_ctors\"]);__RELOC_FUNCS__.push(Module[\"asm\"][\"__wasm_apply_data_relocs\"]);wasmModule=module;PThread.loadWasmModuleToAllWorkers(()=>removeRunDependency(\"wasm-instantiate\"))}addRunDependency(\"wasm-instantiate\");var trueModule=Module;function receiveInstantiationResult(result){assert(Module===trueModule,\"the Module object should not be replaced during async compilation - perhaps the order of HTML elements is wrong?\");trueModule=null;receiveInstance(result[\"instance\"],result[\"module\"])}function instantiateArrayBuffer(receiver){return getBinaryPromise().then(function(binary){return WebAssembly.instantiate(binary,info)}).then(function(instance){return instance}).then(receiver,function(reason){err(\"failed to asynchronously prepare wasm: \"+reason);if(isFileURI(wasmBinaryFile)){err(\"warning: Loading from a file URI (\"+wasmBinaryFile+\") is not supported in most browsers. See https://emscripten.org/docs/getting_started/FAQ.html#how-do-i-run-a-local-webserver-for-testing-why-does-my-program-stall-in-downloading-or-preparing\")}abort(reason)})}function instantiateAsync(){if(!wasmBinary&&typeof WebAssembly.instantiateStreaming==\"function\"&&!isDataURI(wasmBinaryFile)&&!ENVIRONMENT_IS_NODE&&typeof fetch==\"function\"){return fetch(wasmBinaryFile,{credentials:\"same-origin\"}).then(function(response){var result=WebAssembly.instantiateStreaming(response,info);return result.then(receiveInstantiationResult,function(reason){err(\"wasm streaming compile failed: \"+reason);err(\"falling back to ArrayBuffer instantiation\");return instantiateArrayBuffer(receiveInstantiationResult)})})}else{return instantiateArrayBuffer(receiveInstantiationResult)}}if(Module[\"instantiateWasm\"]){try{var exports=Module[\"instantiateWasm\"](info,receiveInstance);return exports}catch(e){err(\"Module.instantiateWasm callback failed with error: \"+e);return false}}instantiateAsync();return{}}var tempDouble;var tempI64;function legacyModuleProp(prop,newName){if(!Object.getOwnPropertyDescriptor(Module,prop)){Object.defineProperty(Module,prop,{configurable:true,get:function(){abort(\"Module.\"+prop+\" has been replaced with plain \"+newName+\" (the initial value can be provided on Module, but after startup the value is only looked for on a local variable of that name)\")}})}}function ignoredModuleProp(prop){if(Object.getOwnPropertyDescriptor(Module,prop)){abort(\"`Module.\"+prop+\"` was supplied but `\"+prop+\"` not included in INCOMING_MODULE_JS_API\")}}function isExportedByForceFilesystem(name){return name===\"FS_createPath\"||name===\"FS_createDataFile\"||name===\"FS_createPreloadedFile\"||name===\"FS_unlink\"||name===\"addRunDependency\"||name===\"FS_createLazyFile\"||name===\"FS_createDevice\"||name===\"removeRunDependency\"}function missingGlobal(sym,msg){if(typeof globalThis!==\"undefined\"){Object.defineProperty(globalThis,sym,{configurable:true,get:function(){warnOnce(\"`\"+sym+\"` is not longer defined by emscripten. \"+msg);return undefined}})}}missingGlobal(\"buffer\",\"Please use HEAP8.buffer or wasmMemory.buffer\");function missingLibrarySymbol(sym){if(typeof globalThis!==\"undefined\"&&!Object.getOwnPropertyDescriptor(globalThis,sym)){Object.defineProperty(globalThis,sym,{configurable:true,get:function(){var msg=\"`\"+sym+\"` is a library symbol and not included by default; add it to your library.js __deps or to DEFAULT_LIBRARY_FUNCS_TO_INCLUDE on the command line\";var librarySymbol=sym;if(!librarySymbol.startsWith(\"_\")){librarySymbol=\"$\"+sym}msg+=\" (e.g. -sDEFAULT_LIBRARY_FUNCS_TO_INCLUDE=\"+librarySymbol+\")\";if(isExportedByForceFilesystem(sym)){msg+=\". Alternatively, forcing filesystem support (-sFORCE_FILESYSTEM) can export this for you\"}warnOnce(msg);return undefined}})}unexportedRuntimeSymbol(sym)}function unexportedRuntimeSymbol(sym){if(!Object.getOwnPropertyDescriptor(Module,sym)){Object.defineProperty(Module,sym,{configurable:true,get:function(){var msg=\"'\"+sym+\"' was not exported. add it to EXPORTED_RUNTIME_METHODS (see the FAQ)\";if(isExportedByForceFilesystem(sym)){msg+=\". Alternatively, forcing filesystem support (-sFORCE_FILESYSTEM) can export this for you\"}abort(msg)}})}}var ASM_CONSTS={};function ExitStatus(status){this.name=\"ExitStatus\";this.message=\"Program terminated with exit(\"+status+\")\";this.status=status}var GOT={};var CurrentModuleWeakSymbols=new Set([]);var GOTHandler={get:function(obj,symName){var rtn=GOT[symName];if(!rtn){rtn=GOT[symName]=new WebAssembly.Global({\"value\":\"i32\",\"mutable\":true})}if(!CurrentModuleWeakSymbols.has(symName)){rtn.required=true}return rtn}};function killThread(pthread_ptr){assert(!ENVIRONMENT_IS_PTHREAD,\"Internal Error! killThread() can only ever be called from main application thread!\");assert(pthread_ptr,\"Internal Error! Null pthread_ptr in killThread!\");var worker=PThread.pthreads[pthread_ptr];delete PThread.pthreads[pthread_ptr];worker.terminate();__emscripten_thread_free_data(pthread_ptr);PThread.runningWorkers.splice(PThread.runningWorkers.indexOf(worker),1);worker.pthread_ptr=0}function cancelThread(pthread_ptr){assert(!ENVIRONMENT_IS_PTHREAD,\"Internal Error! cancelThread() can only ever be called from main application thread!\");assert(pthread_ptr,\"Internal Error! Null pthread_ptr in cancelThread!\");var worker=PThread.pthreads[pthread_ptr];worker.postMessage({\"cmd\":\"cancel\"})}function cleanupThread(pthread_ptr){assert(!ENVIRONMENT_IS_PTHREAD,\"Internal Error! cleanupThread() can only ever be called from main application thread!\");assert(pthread_ptr,\"Internal Error! Null pthread_ptr in cleanupThread!\");var worker=PThread.pthreads[pthread_ptr];assert(worker);PThread.returnWorkerToPool(worker)}function zeroMemory(address,size){HEAPU8.fill(0,address,address+size);return address}function spawnThread(threadParams){assert(!ENVIRONMENT_IS_PTHREAD,\"Internal Error! spawnThread() can only ever be called from main application thread!\");assert(threadParams.pthread_ptr,\"Internal error, no pthread ptr!\");var worker=PThread.getNewWorker();if(!worker){return 6}assert(!worker.pthread_ptr,\"Internal error!\");PThread.runningWorkers.push(worker);PThread.pthreads[threadParams.pthread_ptr]=worker;worker.pthread_ptr=threadParams.pthread_ptr;var msg={\"cmd\":\"run\",\"start_routine\":threadParams.startRoutine,\"arg\":threadParams.arg,\"pthread_ptr\":threadParams.pthread_ptr};if(ENVIRONMENT_IS_NODE){worker.ref()}worker.postMessage(msg,threadParams.transferList);return 0}var PATH={isAbs:path=>path.charAt(0)===\"/\",splitPath:filename=>{var splitPathRe=/^(\\/?|)([\\s\\S]*?)((?:\\.{1,2}|[^\\/]+?|)(\\.[^.\\/]*|))(?:[\\/]*)$/;return splitPathRe.exec(filename).slice(1)},normalizeArray:(parts,allowAboveRoot)=>{var up=0;for(var i=parts.length-1;i>=0;i--){var last=parts[i];if(last===\".\"){parts.splice(i,1)}else if(last===\"..\"){parts.splice(i,1);up++}else if(up){parts.splice(i,1);up--}}if(allowAboveRoot){for(;up;up--){parts.unshift(\"..\")}}return parts},normalize:path=>{var isAbsolute=PATH.isAbs(path),trailingSlash=path.substr(-1)===\"/\";path=PATH.normalizeArray(path.split(\"/\").filter(p=>!!p),!isAbsolute).join(\"/\");if(!path&&!isAbsolute){path=\".\"}if(path&&trailingSlash){path+=\"/\"}return(isAbsolute?\"/\":\"\")+path},dirname:path=>{var result=PATH.splitPath(path),root=result[0],dir=result[1];if(!root&&!dir){return\".\"}if(dir){dir=dir.substr(0,dir.length-1)}return root+dir},basename:path=>{if(path===\"/\")return\"/\";path=PATH.normalize(path);path=path.replace(/\\/$/,\"\");var lastSlash=path.lastIndexOf(\"/\");if(lastSlash===-1)return path;return path.substr(lastSlash+1)},join:function(){var paths=Array.prototype.slice.call(arguments);return PATH.normalize(paths.join(\"/\"))},join2:(l,r)=>{return PATH.normalize(l+\"/\"+r)}};function getRandomDevice(){if(typeof crypto==\"object\"&&typeof crypto[\"getRandomValues\"]==\"function\"){var randomBuffer=new Uint8Array(1);return()=>{crypto.getRandomValues(randomBuffer);return randomBuffer[0]}}else if(ENVIRONMENT_IS_NODE){try{var crypto_module=require(\"crypto\");return()=>crypto_module[\"randomBytes\"](1)[0]}catch(e){}}return()=>abort(\"no cryptographic support found for randomDevice. consider polyfilling it if you want to use something insecure like Math.random(), e.g. put this in a --pre-js: var crypto = { getRandomValues: function(array) { for (var i = 0; i < array.length; i++) array[i] = (Math.random()*256)|0 } };\")}var PATH_FS={resolve:function(){var resolvedPath=\"\",resolvedAbsolute=false;for(var i=arguments.length-1;i>=-1&&!resolvedAbsolute;i--){var path=i>=0?arguments[i]:FS.cwd();if(typeof path!=\"string\"){throw new TypeError(\"Arguments to path.resolve must be strings\")}else if(!path){return\"\"}resolvedPath=path+\"/\"+resolvedPath;resolvedAbsolute=PATH.isAbs(path)}resolvedPath=PATH.normalizeArray(resolvedPath.split(\"/\").filter(p=>!!p),!resolvedAbsolute).join(\"/\");return(resolvedAbsolute?\"/\":\"\")+resolvedPath||\".\"},relative:(from,to)=>{from=PATH_FS.resolve(from).substr(1);to=PATH_FS.resolve(to).substr(1);function trim(arr){var start=0;for(;start<arr.length;start++){if(arr[start]!==\"\")break}var end=arr.length-1;for(;end>=0;end--){if(arr[end]!==\"\")break}if(start>end)return[];return arr.slice(start,end-start+1)}var fromParts=trim(from.split(\"/\"));var toParts=trim(to.split(\"/\"));var length=Math.min(fromParts.length,toParts.length);var samePartsLength=length;for(var i=0;i<length;i++){if(fromParts[i]!==toParts[i]){samePartsLength=i;break}}var outputParts=[];for(var i=samePartsLength;i<fromParts.length;i++){outputParts.push(\"..\")}outputParts=outputParts.concat(toParts.slice(samePartsLength));return outputParts.join(\"/\")}};function intArrayFromString(stringy,dontAddNull,length){var len=length>0?length:lengthBytesUTF8(stringy)+1;var u8array=new Array(len);var numBytesWritten=stringToUTF8Array(stringy,u8array,0,u8array.length);if(dontAddNull)u8array.length=numBytesWritten;return u8array}var TTY={ttys:[],init:function(){},shutdown:function(){},register:function(dev,ops){TTY.ttys[dev]={input:[],output:[],ops:ops};FS.registerDevice(dev,TTY.stream_ops)},stream_ops:{open:function(stream){var tty=TTY.ttys[stream.node.rdev];if(!tty){throw new FS.ErrnoError(43)}stream.tty=tty;stream.seekable=false},close:function(stream){stream.tty.ops.fsync(stream.tty)},fsync:function(stream){stream.tty.ops.fsync(stream.tty)},read:function(stream,buffer,offset,length,pos){if(!stream.tty||!stream.tty.ops.get_char){throw new FS.ErrnoError(60)}var bytesRead=0;for(var i=0;i<length;i++){var result;try{result=stream.tty.ops.get_char(stream.tty)}catch(e){throw new FS.ErrnoError(29)}if(result===undefined&&bytesRead===0){throw new FS.ErrnoError(6)}if(result===null||result===undefined)break;bytesRead++;buffer[offset+i]=result}if(bytesRead){stream.node.timestamp=Date.now()}return bytesRead},write:function(stream,buffer,offset,length,pos){if(!stream.tty||!stream.tty.ops.put_char){throw new FS.ErrnoError(60)}try{for(var i=0;i<length;i++){stream.tty.ops.put_char(stream.tty,buffer[offset+i])}}catch(e){throw new FS.ErrnoError(29)}if(length){stream.node.timestamp=Date.now()}return i}},default_tty_ops:{get_char:function(tty){if(!tty.input.length){var result=null;if(ENVIRONMENT_IS_NODE){var BUFSIZE=256;var buf=Buffer.alloc(BUFSIZE);var bytesRead=0;try{bytesRead=fs.readSync(process.stdin.fd,buf,0,BUFSIZE,-1)}catch(e){if(e.toString().includes(\"EOF\"))bytesRead=0;else throw e}if(bytesRead>0){result=buf.slice(0,bytesRead).toString(\"utf-8\")}else{result=null}}else if(typeof window!=\"undefined\"&&typeof window.prompt==\"function\"){result=window.prompt(\"Input: \");if(result!==null){result+=\"\\n\"}}else if(typeof readline==\"function\"){result=readline();if(result!==null){result+=\"\\n\"}}if(!result){return null}tty.input=intArrayFromString(result,true)}return tty.input.shift()},put_char:function(tty,val){if(val===null||val===10){out(UTF8ArrayToString(tty.output,0));tty.output=[]}else{if(val!=0)tty.output.push(val)}},fsync:function(tty){if(tty.output&&tty.output.length>0){out(UTF8ArrayToString(tty.output,0));tty.output=[]}}},default_tty1_ops:{put_char:function(tty,val){if(val===null||val===10){err(UTF8ArrayToString(tty.output,0));tty.output=[]}else{if(val!=0)tty.output.push(val)}},fsync:function(tty){if(tty.output&&tty.output.length>0){err(UTF8ArrayToString(tty.output,0));tty.output=[]}}}};function alignMemory(size,alignment){assert(alignment,\"alignment argument is required\");return Math.ceil(size/alignment)*alignment}function mmapAlloc(size){size=alignMemory(size,65536);var ptr=_emscripten_builtin_memalign(65536,size);if(!ptr)return 0;return zeroMemory(ptr,size)}var MEMFS={ops_table:null,mount:function(mount){return MEMFS.createNode(null,\"/\",16384|511,0)},createNode:function(parent,name,mode,dev){if(FS.isBlkdev(mode)||FS.isFIFO(mode)){throw new FS.ErrnoError(63)}if(!MEMFS.ops_table){MEMFS.ops_table={dir:{node:{getattr:MEMFS.node_ops.getattr,setattr:MEMFS.node_ops.setattr,lookup:MEMFS.node_ops.lookup,mknod:MEMFS.node_ops.mknod,rename:MEMFS.node_ops.rename,unlink:MEMFS.node_ops.unlink,rmdir:MEMFS.node_ops.rmdir,readdir:MEMFS.node_ops.readdir,symlink:MEMFS.node_ops.symlink},stream:{llseek:MEMFS.stream_ops.llseek}},file:{node:{getattr:MEMFS.node_ops.getattr,setattr:MEMFS.node_ops.setattr},stream:{llseek:MEMFS.stream_ops.llseek,read:MEMFS.stream_ops.read,write:MEMFS.stream_ops.write,allocate:MEMFS.stream_ops.allocate,mmap:MEMFS.stream_ops.mmap,msync:MEMFS.stream_ops.msync}},link:{node:{getattr:MEMFS.node_ops.getattr,setattr:MEMFS.node_ops.setattr,readlink:MEMFS.node_ops.readlink},stream:{}},chrdev:{node:{getattr:MEMFS.node_ops.getattr,setattr:MEMFS.node_ops.setattr},stream:FS.chrdev_stream_ops}}}var node=FS.createNode(parent,name,mode,dev);if(FS.isDir(node.mode)){node.node_ops=MEMFS.ops_table.dir.node;node.stream_ops=MEMFS.ops_table.dir.stream;node.contents={}}else if(FS.isFile(node.mode)){node.node_ops=MEMFS.ops_table.file.node;node.stream_ops=MEMFS.ops_table.file.stream;node.usedBytes=0;node.contents=null}else if(FS.isLink(node.mode)){node.node_ops=MEMFS.ops_table.link.node;node.stream_ops=MEMFS.ops_table.link.stream}else if(FS.isChrdev(node.mode)){node.node_ops=MEMFS.ops_table.chrdev.node;node.stream_ops=MEMFS.ops_table.chrdev.stream}node.timestamp=Date.now();if(parent){parent.contents[name]=node;parent.timestamp=node.timestamp}return node},getFileDataAsTypedArray:function(node){if(!node.contents)return new Uint8Array(0);if(node.contents.subarray)return node.contents.subarray(0,node.usedBytes);return new Uint8Array(node.contents)},expandFileStorage:function(node,newCapacity){var prevCapacity=node.contents?node.contents.length:0;if(prevCapacity>=newCapacity)return;var CAPACITY_DOUBLING_MAX=1024*1024;newCapacity=Math.max(newCapacity,prevCapacity*(prevCapacity<CAPACITY_DOUBLING_MAX?2:1.125)>>>0);if(prevCapacity!=0)newCapacity=Math.max(newCapacity,256);var oldContents=node.contents;node.contents=new Uint8Array(newCapacity);if(node.usedBytes>0)node.contents.set(oldContents.subarray(0,node.usedBytes),0)},resizeFileStorage:function(node,newSize){if(node.usedBytes==newSize)return;if(newSize==0){node.contents=null;node.usedBytes=0}else{var oldContents=node.contents;node.contents=new Uint8Array(newSize);if(oldContents){node.contents.set(oldContents.subarray(0,Math.min(newSize,node.usedBytes)))}node.usedBytes=newSize}},node_ops:{getattr:function(node){var attr={};attr.dev=FS.isChrdev(node.mode)?node.id:1;attr.ino=node.id;attr.mode=node.mode;attr.nlink=1;attr.uid=0;attr.gid=0;attr.rdev=node.rdev;if(FS.isDir(node.mode)){attr.size=4096}else if(FS.isFile(node.mode)){attr.size=node.usedBytes}else if(FS.isLink(node.mode)){attr.size=node.link.length}else{attr.size=0}attr.atime=new Date(node.timestamp);attr.mtime=new Date(node.timestamp);attr.ctime=new Date(node.timestamp);attr.blksize=4096;attr.blocks=Math.ceil(attr.size/attr.blksize);return attr},setattr:function(node,attr){if(attr.mode!==undefined){node.mode=attr.mode}if(attr.timestamp!==undefined){node.timestamp=attr.timestamp}if(attr.size!==undefined){MEMFS.resizeFileStorage(node,attr.size)}},lookup:function(parent,name){throw FS.genericErrors[44]},mknod:function(parent,name,mode,dev){return MEMFS.createNode(parent,name,mode,dev)},rename:function(old_node,new_dir,new_name){if(FS.isDir(old_node.mode)){var new_node;try{new_node=FS.lookupNode(new_dir,new_name)}catch(e){}if(new_node){for(var i in new_node.contents){throw new FS.ErrnoError(55)}}}delete old_node.parent.contents[old_node.name];old_node.parent.timestamp=Date.now();old_node.name=new_name;new_dir.contents[new_name]=old_node;new_dir.timestamp=old_node.parent.timestamp;old_node.parent=new_dir},unlink:function(parent,name){delete parent.contents[name];parent.timestamp=Date.now()},rmdir:function(parent,name){var node=FS.lookupNode(parent,name);for(var i in node.contents){throw new FS.ErrnoError(55)}delete parent.contents[name];parent.timestamp=Date.now()},readdir:function(node){var entries=[\".\",\"..\"];for(var key in node.contents){if(!node.contents.hasOwnProperty(key)){continue}entries.push(key)}return entries},symlink:function(parent,newname,oldpath){var node=MEMFS.createNode(parent,newname,511|40960,0);node.link=oldpath;return node},readlink:function(node){if(!FS.isLink(node.mode)){throw new FS.ErrnoError(28)}return node.link}},stream_ops:{read:function(stream,buffer,offset,length,position){var contents=stream.node.contents;if(position>=stream.node.usedBytes)return 0;var size=Math.min(stream.node.usedBytes-position,length);assert(size>=0);if(size>8&&contents.subarray){buffer.set(contents.subarray(position,position+size),offset)}else{for(var i=0;i<size;i++)buffer[offset+i]=contents[position+i]}return size},write:function(stream,buffer,offset,length,position,canOwn){assert(!(buffer instanceof ArrayBuffer));if(!length)return 0;var node=stream.node;node.timestamp=Date.now();if(buffer.subarray&&(!node.contents||node.contents.subarray)){if(canOwn){assert(position===0,\"canOwn must imply no weird position inside the file\");node.contents=buffer.subarray(offset,offset+length);node.usedBytes=length;return length}else if(node.usedBytes===0&&position===0){node.contents=buffer.slice(offset,offset+length);node.usedBytes=length;return length}else if(position+length<=node.usedBytes){node.contents.set(buffer.subarray(offset,offset+length),position);return length}}MEMFS.expandFileStorage(node,position+length);if(node.contents.subarray&&buffer.subarray){node.contents.set(buffer.subarray(offset,offset+length),position)}else{for(var i=0;i<length;i++){node.contents[position+i]=buffer[offset+i]}}node.usedBytes=Math.max(node.usedBytes,position+length);return length},llseek:function(stream,offset,whence){var position=offset;if(whence===1){position+=stream.position}else if(whence===2){if(FS.isFile(stream.node.mode)){position+=stream.node.usedBytes}}if(position<0){throw new FS.ErrnoError(28)}return position},allocate:function(stream,offset,length){MEMFS.expandFileStorage(stream.node,offset+length);stream.node.usedBytes=Math.max(stream.node.usedBytes,offset+length)},mmap:function(stream,length,position,prot,flags){if(!FS.isFile(stream.node.mode)){throw new FS.ErrnoError(43)}var ptr;var allocated;var contents=stream.node.contents;if(!(flags&2)&&contents.buffer===HEAP8.buffer){allocated=false;ptr=contents.byteOffset}else{if(position>0||position+length<contents.length){if(contents.subarray){contents=contents.subarray(position,position+length)}else{contents=Array.prototype.slice.call(contents,position,position+length)}}allocated=true;ptr=mmapAlloc(length);if(!ptr){throw new FS.ErrnoError(48)}HEAP8.set(contents,ptr)}return{ptr:ptr,allocated:allocated}},msync:function(stream,buffer,offset,length,mmapFlags){MEMFS.stream_ops.write(stream,buffer,0,length,offset,false);return 0}}};function asyncLoad(url,onload,onerror,noRunDep){var dep=!noRunDep?getUniqueRunDependency(\"al \"+url):\"\";readAsync(url,arrayBuffer=>{assert(arrayBuffer,'Loading data file \"'+url+'\" failed (no arrayBuffer).');onload(new Uint8Array(arrayBuffer));if(dep)removeRunDependency(dep)},event=>{if(onerror){onerror()}else{throw'Loading data file \"'+url+'\" failed.'}});if(dep)addRunDependency(dep)}var ERRNO_MESSAGES={0:\"Success\",1:\"Arg list too long\",2:\"Permission denied\",3:\"Address already in use\",4:\"Address not available\",5:\"Address family not supported by protocol family\",6:\"No more processes\",7:\"Socket already connected\",8:\"Bad file number\",9:\"Trying to read unreadable message\",10:\"Mount device busy\",11:\"Operation canceled\",12:\"No children\",13:\"Connection aborted\",14:\"Connection refused\",15:\"Connection reset by peer\",16:\"File locking deadlock error\",17:\"Destination address required\",18:\"Math arg out of domain of func\",19:\"Quota exceeded\",20:\"File exists\",21:\"Bad address\",22:\"File too large\",23:\"Host is unreachable\",24:\"Identifier removed\",25:\"Illegal byte sequence\",26:\"Connection already in progress\",27:\"Interrupted system call\",28:\"Invalid argument\",29:\"I/O error\",30:\"Socket is already connected\",31:\"Is a directory\",32:\"Too many symbolic links\",33:\"Too many open files\",34:\"Too many links\",35:\"Message too long\",36:\"Multihop attempted\",37:\"File or path name too long\",38:\"Network interface is not configured\",39:\"Connection reset by network\",40:\"Network is unreachable\",41:\"Too many open files in system\",42:\"No buffer space available\",43:\"No such device\",44:\"No such file or directory\",45:\"Exec format error\",46:\"No record locks available\",47:\"The link has been severed\",48:\"Not enough core\",49:\"No message of desired type\",50:\"Protocol not available\",51:\"No space left on device\",52:\"Function not implemented\",53:\"Socket is not connected\",54:\"Not a directory\",55:\"Directory not empty\",56:\"State not recoverable\",57:\"Socket operation on non-socket\",59:\"Not a typewriter\",60:\"No such device or address\",61:\"Value too large for defined data type\",62:\"Previous owner died\",63:\"Not super-user\",64:\"Broken pipe\",65:\"Protocol error\",66:\"Unknown protocol\",67:\"Protocol wrong type for socket\",68:\"Math result not representable\",69:\"Read only file system\",70:\"Illegal seek\",71:\"No such process\",72:\"Stale file handle\",73:\"Connection timed out\",74:\"Text file busy\",75:\"Cross-device link\",100:\"Device not a stream\",101:\"Bad font file fmt\",102:\"Invalid slot\",103:\"Invalid request code\",104:\"No anode\",105:\"Block device required\",106:\"Channel number out of range\",107:\"Level 3 halted\",108:\"Level 3 reset\",109:\"Link number out of range\",110:\"Protocol driver not attached\",111:\"No CSI structure available\",112:\"Level 2 halted\",113:\"Invalid exchange\",114:\"Invalid request descriptor\",115:\"Exchange full\",116:\"No data (for no delay io)\",117:\"Timer expired\",118:\"Out of streams resources\",119:\"Machine is not on the network\",120:\"Package not installed\",121:\"The object is remote\",122:\"Advertise error\",123:\"Srmount error\",124:\"Communication error on send\",125:\"Cross mount point (not really error)\",126:\"Given log. name not unique\",127:\"f.d. invalid for this operation\",128:\"Remote address changed\",129:\"Can   access a needed shared lib\",130:\"Accessing a corrupted shared lib\",131:\".lib section in a.out corrupted\",132:\"Attempting to link in too many libs\",133:\"Attempting to exec a shared library\",135:\"Streams pipe error\",136:\"Too many users\",137:\"Socket type not supported\",138:\"Not supported\",139:\"Protocol family not supported\",140:\"Can't send after socket shutdown\",141:\"Too many references\",142:\"Host is down\",148:\"No medium (in tape drive)\",156:\"Level 2 not synchronized\"};var ERRNO_CODES={};function demangle(func){warnOnce(\"warning: build with -sDEMANGLE_SUPPORT to link in libcxxabi demangling\");return func}function demangleAll(text){var regex=/\\b_Z[\\w\\d_]+/g;return text.replace(regex,function(x){var y=demangle(x);return x===y?x:y+\" [\"+x+\"]\"})}var FS={root:null,mounts:[],devices:{},streams:[],nextInode:1,nameTable:null,currentPath:\"/\",initialized:false,ignorePermissions:true,ErrnoError:null,genericErrors:{},filesystems:null,syncFSRequests:0,lookupPath:(path,opts={})=>{path=PATH_FS.resolve(path);if(!path)return{path:\"\",node:null};var defaults={follow_mount:true,recurse_count:0};opts=Object.assign(defaults,opts);if(opts.recurse_count>8){throw new FS.ErrnoError(32)}var parts=path.split(\"/\").filter(p=>!!p);var current=FS.root;var current_path=\"/\";for(var i=0;i<parts.length;i++){var islast=i===parts.length-1;if(islast&&opts.parent){break}current=FS.lookupNode(current,parts[i]);current_path=PATH.join2(current_path,parts[i]);if(FS.isMountpoint(current)){if(!islast||islast&&opts.follow_mount){current=current.mounted.root}}if(!islast||opts.follow){var count=0;while(FS.isLink(current.mode)){var link=FS.readlink(current_path);current_path=PATH_FS.resolve(PATH.dirname(current_path),link);var lookup=FS.lookupPath(current_path,{recurse_count:opts.recurse_count+1});current=lookup.node;if(count++>40){throw new FS.ErrnoError(32)}}}}return{path:current_path,node:current}},getPath:node=>{var path;while(true){if(FS.isRoot(node)){var mount=node.mount.mountpoint;if(!path)return mount;return mount[mount.length-1]!==\"/\"?mount+\"/\"+path:mount+path}path=path?node.name+\"/\"+path:node.name;node=node.parent}},hashName:(parentid,name)=>{var hash=0;for(var i=0;i<name.length;i++){hash=(hash<<5)-hash+name.charCodeAt(i)|0}return(parentid+hash>>>0)%FS.nameTable.length},hashAddNode:node=>{var hash=FS.hashName(node.parent.id,node.name);node.name_next=FS.nameTable[hash];FS.nameTable[hash]=node},hashRemoveNode:node=>{var hash=FS.hashName(node.parent.id,node.name);if(FS.nameTable[hash]===node){FS.nameTable[hash]=node.name_next}else{var current=FS.nameTable[hash];while(current){if(current.name_next===node){current.name_next=node.name_next;break}current=current.name_next}}},lookupNode:(parent,name)=>{var errCode=FS.mayLookup(parent);if(errCode){throw new FS.ErrnoError(errCode,parent)}var hash=FS.hashName(parent.id,name);for(var node=FS.nameTable[hash];node;node=node.name_next){var nodeName=node.name;if(node.parent.id===parent.id&&nodeName===name){return node}}return FS.lookup(parent,name)},createNode:(parent,name,mode,rdev)=>{assert(typeof parent==\"object\");var node=new FS.FSNode(parent,name,mode,rdev);FS.hashAddNode(node);return node},destroyNode:node=>{FS.hashRemoveNode(node)},isRoot:node=>{return node===node.parent},isMountpoint:node=>{return!!node.mounted},isFile:mode=>{return(mode&61440)===32768},isDir:mode=>{return(mode&61440)===16384},isLink:mode=>{return(mode&61440)===40960},isChrdev:mode=>{return(mode&61440)===8192},isBlkdev:mode=>{return(mode&61440)===24576},isFIFO:mode=>{return(mode&61440)===4096},isSocket:mode=>{return(mode&49152)===49152},flagModes:{\"r\":0,\"r+\":2,\"w\":577,\"w+\":578,\"a\":1089,\"a+\":1090},modeStringToFlags:str=>{var flags=FS.flagModes[str];if(typeof flags==\"undefined\"){throw new Error(\"Unknown file open mode: \"+str)}return flags},flagsToPermissionString:flag=>{var perms=[\"r\",\"w\",\"rw\"][flag&3];if(flag&512){perms+=\"w\"}return perms},nodePermissions:(node,perms)=>{if(FS.ignorePermissions){return 0}if(perms.includes(\"r\")&&!(node.mode&292)){return 2}else if(perms.includes(\"w\")&&!(node.mode&146)){return 2}else if(perms.includes(\"x\")&&!(node.mode&73)){return 2}return 0},mayLookup:dir=>{var errCode=FS.nodePermissions(dir,\"x\");if(errCode)return errCode;if(!dir.node_ops.lookup)return 2;return 0},mayCreate:(dir,name)=>{try{var node=FS.lookupNode(dir,name);return 20}catch(e){}return FS.nodePermissions(dir,\"wx\")},mayDelete:(dir,name,isdir)=>{var node;try{node=FS.lookupNode(dir,name)}catch(e){return e.errno}var errCode=FS.nodePermissions(dir,\"wx\");if(errCode){return errCode}if(isdir){if(!FS.isDir(node.mode)){return 54}if(FS.isRoot(node)||FS.getPath(node)===FS.cwd()){return 10}}else{if(FS.isDir(node.mode)){return 31}}return 0},mayOpen:(node,flags)=>{if(!node){return 44}if(FS.isLink(node.mode)){return 32}else if(FS.isDir(node.mode)){if(FS.flagsToPermissionString(flags)!==\"r\"||flags&512){return 31}}return FS.nodePermissions(node,FS.flagsToPermissionString(flags))},MAX_OPEN_FDS:4096,nextfd:(fd_start=0,fd_end=FS.MAX_OPEN_FDS)=>{for(var fd=fd_start;fd<=fd_end;fd++){if(!FS.streams[fd]){return fd}}throw new FS.ErrnoError(33)},getStream:fd=>FS.streams[fd],createStream:(stream,fd_start,fd_end)=>{if(!FS.FSStream){FS.FSStream=function(){this.shared={}};FS.FSStream.prototype={};Object.defineProperties(FS.FSStream.prototype,{object:{get:function(){return this.node},set:function(val){this.node=val}},isRead:{get:function(){return(this.flags&2097155)!==1}},isWrite:{get:function(){return(this.flags&2097155)!==0}},isAppend:{get:function(){return this.flags&1024}},flags:{get:function(){return this.shared.flags},set:function(val){this.shared.flags=val}},position:{get:function(){return this.shared.position},set:function(val){this.shared.position=val}}})}stream=Object.assign(new FS.FSStream,stream);var fd=FS.nextfd(fd_start,fd_end);stream.fd=fd;FS.streams[fd]=stream;return stream},closeStream:fd=>{FS.streams[fd]=null},chrdev_stream_ops:{open:stream=>{var device=FS.getDevice(stream.node.rdev);stream.stream_ops=device.stream_ops;if(stream.stream_ops.open){stream.stream_ops.open(stream)}},llseek:()=>{throw new FS.ErrnoError(70)}},major:dev=>dev>>8,minor:dev=>dev&255,makedev:(ma,mi)=>ma<<8|mi,registerDevice:(dev,ops)=>{FS.devices[dev]={stream_ops:ops}},getDevice:dev=>FS.devices[dev],getMounts:mount=>{var mounts=[];var check=[mount];while(check.length){var m=check.pop();mounts.push(m);check.push.apply(check,m.mounts)}return mounts},syncfs:(populate,callback)=>{if(typeof populate==\"function\"){callback=populate;populate=false}FS.syncFSRequests++;if(FS.syncFSRequests>1){err(\"warning: \"+FS.syncFSRequests+\" FS.syncfs operations in flight at once, probably just doing extra work\")}var mounts=FS.getMounts(FS.root.mount);var completed=0;function doCallback(errCode){assert(FS.syncFSRequests>0);FS.syncFSRequests--;return callback(errCode)}function done(errCode){if(errCode){if(!done.errored){done.errored=true;return doCallback(errCode)}return}if(++completed>=mounts.length){doCallback(null)}}mounts.forEach(mount=>{if(!mount.type.syncfs){return done(null)}mount.type.syncfs(mount,populate,done)})},mount:(type,opts,mountpoint)=>{if(typeof type==\"string\"){throw type}var root=mountpoint===\"/\";var pseudo=!mountpoint;var node;if(root&&FS.root){throw new FS.ErrnoError(10)}else if(!root&&!pseudo){var lookup=FS.lookupPath(mountpoint,{follow_mount:false});mountpoint=lookup.path;node=lookup.node;if(FS.isMountpoint(node)){throw new FS.ErrnoError(10)}if(!FS.isDir(node.mode)){throw new FS/app/agent:\r\neliza_39ff199b2f32439c9980b619fe8eccdb  | \u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.8+build.1 start: `node --loader ts-node/esm src/index.ts \"--isRoot\"`\r\neliza_39ff199b2f32439c9980b619fe8eccdb  | Exit status 7\r\neliza_39ff199b2f32439c9980b619fe8eccdb  | \u2009ELIFECYCLE\u2009 Command failed with exit code 7.\r\neliza_39ff199b2f32439c9980b619fe8eccdb exited with code 7\r\n```\r\n\r\n**Additional context**\r\n\r\nThis only started happening once I switched to using Postgres. It's works fine with SQLite\r\n ", "CLOSED", 0, "jason51553262", "2025-01-14T22:39:26Z", "2025-03-08T01:09:57Z", "2025-03-08T01:09:57Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mL-U2", 2304, "Trying to find how to run Eliza locally with two graphical cards. ", "**Is your feature request related to a problem? Please describe.**\r\nI would like to have more information concerning how to run Eliza locally with multiple graphical cards. \r\n\r\n**Describe the solution you'd like**\r\nI don't really know where to start with solving this issue, for example, I am not sure if the problem comes from my installation, or a necessary modification of the Eliza code.  \r\nThe ideal solution would be to have notes in the documentation on the subject. \r\n\r\n**Describe alternatives you've considered**\r\nI asked on the Discord if anybody was aware of a solution, but unfortunately, nobody could help. \r\n\r\n**Additional context**\r\nI run the system on a Debian. The two graphical cards are NVIDIA ones, but of different generations. \r\nEliza works properly using a single card with CUDA, cuBLAS, cuDNN and node-llama-cpp installed, but I am not certain of the necessary installation to run the second card. \r\nnividia-detect and nvidia-smi show both my cards. \r\n\r\nAlso, I was not certain that it was the right place to post, but as it is not related to a bug or a security issue, I figured that \"Features request\" would be my best bet. \r\n\r\nThanks in advance.\r\n\r\n", "CLOSED", 0, "Nautilusera", "2025-01-14T19:48:59Z", "2025-03-08T01:09:56Z", "2025-03-08T01:09:56Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mLrfY", 2302, "farcaster-client fails to embed", "**Describe the bug**\r\n\r\nI'm brand new to this so forgive me, but it seems all incoming memories (from mentions) are using an empty vector when trying to embed. Is this desired, or should it embed the text from the cast?\r\n\r\nI see this in the code for memory processing:\r\n\r\nhttps://github.com/elizaOS/eliza/blob/d55c86c961960b4b34528c358eb34b2ff4b34d87/packages/client-farcaster/src/memory.ts#L45C8-L45C45\r\n\r\n```\r\nembedding: getEmbeddingZeroVector(),\r\n```\r\n\r\nIt looks to be hardcoded to always be empty.\r\n\r\nI'm using 0.1.7\r\n\r\n**To Reproduce**\r\n\r\nConnect farcaster client and get inbound messages from replies. See these log messages:\r\n\r\n\u25ce LOGS\r\n   Creating Memory\r\n   c749dce0-4f97-0878-870f-ae92d34be101\r\n   @agentpaddington why is it so hard\r\n\r\n \u26a0 WARNINGS\r\n   Invalid embedding input:\r\n   {\"input\":\"\",\"type\":\"string\",\"length\":0}\r\n\r\n\r\n\r\n**Expected behavior**\r\n\r\nActual embedding of the memories. \r\n", "CLOSED", 0, "CryptoGraffe", "2025-01-14T19:05:24Z", "2025-03-08T01:09:56Z", "2025-03-08T01:09:56Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mGcn8", 2282, "feat: add ntf-starter and nft-generator", "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, agents' data (character configuration and memory) are stored locally, making it difficult to share, transfer, or authorize agents between different users and systems. There's no standardized way to manage agent ownership and data sharing.\r\n\r\n**Describe the solution you'd like**\r\n\r\nImplement Agent NFT following [ERC-7857](https://github.com/0glabs/ERCs/blob/master/ERCS/erc-7857.md) standard to:\r\n1. Store agent data (character configuration and SQLite memory) on the [0G storage](https://docs.0g.ai/0g-storage)\r\n2. Provide ownership management through NFTs\r\n3. Enable agent data transfer, cloning, and authorization\r\n4. Allow starting agents from existing NFTs with proper ownership validation\r\n\r\nKey components:\r\n1. AgentNFTClient for smart contract interaction\r\n2. Generate NFT functionality with local agent data\r\n3. NFT-based agent startup with data validation and retrieval\r\n\r\n**Describe alternatives you've considered**\r\n\r\n1. Traditional database storage with access control\r\n2. Centralized cloud storage solutions\r\n3. Custom token implementation without NFT standard\r\n4. Local file sharing and manual authorization\r\n\r\n**Additional context**\r\n\r\nThe implementation requires:\r\n1. Integration with [0G](https://0g.ai/) blockchain\r\n2. [ERC-7857](https://github.com/0glabs/ERCs/blob/master/ERCS/erc-7857.md) smart contract deployment\r\n\r\nEnvironment configuration:\r\n1. ZEROG_RPC_URL\r\n2. ZEROG_INDEXER_RPC_URL\r\n3. ZEROG_PRIVATE_KEY\r\n4. ZEROG_AGENT_NFT_CONTRACT_ADDRESS\r\n\r\nFor more details:\r\n1. [ERC-7857](https://github.com/0glabs/ERCs/blob/master/ERCS/erc-7857.md)\r\n2. [0G-Agent-NFT](https://github.com/0glabs/0g-agent-nft/tree/eip-7857-draft) \r\n", "CLOSED", 0, "Wilbert957", "2025-01-14T09:53:15Z", "2025-03-08T01:09:56Z", "2025-03-08T01:09:56Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6mGNj0", 2279, "got compilation runtime error when running pnpm start command (Wasm SIMD unsupported) ", "OS version: ubuntu 22\r\nnode version: 23.3.0\r\n\r\nevery step is running good except running the command:\r\npnpm start --character=\"characters/trump.character.json\"\r\n\r\n![4171601](https://github.com/user-attachments/assets/e94aec45-ed12-4add-9b22-136863fbb52f)\r\n", "CLOSED", 0, "holiccoder", "2025-01-14T09:23:09Z", "2025-03-08T01:09:55Z", "2025-03-08T01:09:55Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6l_JNB", 2252, "Multiple remote server character files", "**Is your feature request related to a problem? Please describe.**\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\nAllow multiple characters to also be loaded from a remote server instead of only through file paths\r\n\r\n**Describe the solution you'd like**\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\nFrom within the `loadCharacters` function, instead of only accepting character file paths, accept `URL`s where you are able to fetch character data and load characters from the cloud.\r\n\r\nEditted Requirement: Multiple urls are a must, and should be allowed to be used in conjuction with the `character(s)` or alone", "CLOSED", 0, "leeran7", "2025-01-13T17:55:14Z", "2025-03-08T01:09:55Z", "2025-03-08T01:09:55Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6l5gP9", 2233, "Agent Execution Halts", "Hello,\r\n\r\nI've encountered an issue where the agent execution halts unexpectedly. Until two weeks ago, everything worked well, and agents were running without any problems.\r\n\r\nCurrently, when I attempt to start the agent using the following command:\r\n\r\npnpm start --character=\"characters/trump.character.json\"\r\n\r\nI receive the following warnings:\r\n\r\nExperimentalWarning: --experimental-loader may be removed in the future; instead use register()\r\n[DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\r\nAfter these warnings, the process seems to stop without any further progress or error messages.\r\n\r\nUntil two weeks ago, I had no issues running agents this way. \r\n\r\nEnvironment Details:\r\nNode.js version: v23.3.0\r\npnpm version: 9.15.3\r\nOperating System: Windows 10/11, 64-bit operating system, x64-based processor\r\nRunning via: WSL (Windows Subsystem for Linux)\r\n\r\nThank you for looking into this! Let me know if you need further information or logs.", "CLOSED", 0, "Herrsosa", "2025-01-13T08:26:35Z", "2025-03-08T01:08:59Z", "2025-03-08T01:08:59Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6l3BkY", 2214, "ragKnowledge error when launching character", "**Describe the bug**\r\n\r\n ```\r\n[\"\u25ce` Initializing AwsS3Service\"] \r\n\r\n [\"\u2713 Service aws_s3 initialized successfully\"] \r\n\r\n [\"\u25ce Initializing ImageDescriptionService\"] \r\n\r\n [\"\u2139 Initializing LlamaService...\"] \r\n\r\n [\"\u25ce CUDA not detected. Transcription will run on CPU.\"] \r\n\r\n [\"\u25ce Initializing AwsS3Service\"] \r\n\r\n \u26d4 ERRORS\r\n   Error starting agent for character Shokami: \r\n   {} \r\n\r\n [\"\u26d4 TypeError: Cannot read properties of undefined (reading 'ragKnowledge')\"] \r\n\r\n \u26d4 ERRORS\r\n   Error starting agents: \r\n   {} \r\n```\r\n\r\n**To Reproduce**\r\n\r\npnpm start --characters=\"characters/mycharacter.character.json\"\r\n\r\n**Expected behavior**\r\n\r\nlaunches character without crashing", "CLOSED", 0, "confluent-1", "2025-01-12T19:55:17Z", "2025-03-03T07:15:41Z", "2025-01-12T20:59:47Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6kefBP", 1460, "Broken Docker image on fresh build", "**Describe the bug**\r\n\r\nBuilt Docker image (`pnpm docker:run`) fails to start - exits with the following error:\r\n```\r\n2024-12-26 07:24:12 /app/agent:\r\n2024-12-26 07:24:12 \u2009ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL\u2009 @elizaos/agent@0.1.7-alpha.1 start: `node --loader ts-node/esm src/index.ts \"--isRoot\"`\r\n2024-12-26 07:24:12 Exit status 1\r\n2024-12-26 07:24:12 \u2009WARN\u2009  Local package.json exists, but node_modules missing, did you mean to install?\r\n2024-12-26 07:24:12 (node:31) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\r\n2024-12-26 07:24:12 --import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\r\n2024-12-26 07:24:12 (Use `node --trace-warnings ...` to show where the warning was created)\r\n2024-12-26 07:24:12 (node:31) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\r\n2024-12-26 07:24:12 (Use `node --trace-deprecation ...` to show where the warning was created)\r\n2024-12-26 07:24:12 \r\n2024-12-26 07:24:12 node:internal/modules/run_main:122\r\n2024-12-26 07:24:12     triggerUncaughtException(\r\n2024-12-26 07:24:12     ^\r\n2024-12-26 07:24:12 Error: Cannot find package '@elizaos/adapter-postgres' imported from /app/agent/src/index.ts\r\n2024-12-26 07:24:12     at packageResolve (/app/node_modules/ts-node/dist-raw/node-internal-modules-esm-resolve.js:757:9)\r\n2024-12-26 07:24:12     at moduleResolve (/app/node_modules/ts-node/dist-raw/node-internal-modules-esm-resolve.js:798:18)\r\n2024-12-26 07:24:12     at Object.defaultResolve (/app/node_modules/ts-node/dist-raw/node-internal-modules-esm-resolve.js:912:11)\r\n2024-12-26 07:24:12     at /app/node_modules/ts-node/src/esm.ts:218:35\r\n2024-12-26 07:24:12     at entrypointFallback (/app/node_modules/ts-node/src/esm.ts:168:34)\r\n2024-12-26 07:24:12     at /app/node_modules/ts-node/src/esm.ts:217:14\r\n2024-12-26 07:24:12     at addShortCircuitFlag (/app/node_modules/ts-node/src/esm.ts:409:21)\r\n2024-12-26 07:24:12     at resolve (/app/node_modules/ts-node/src/esm.ts:197:12)\r\n2024-12-26 07:24:12     at nextResolve (node:internal/modules/esm/hooks:748:28)\r\n2024-12-26 07:24:12     at Hooks.resolve (node:internal/modules/esm/hooks:240:30)\r\n2024-12-26 07:24:12 \r\n2024-12-26 07:24:12 Node.js v23.3.0\r\n2024-12-26 07:24:12 \u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n```\r\n\r\nYou can fix this issue by running `pnpm install --no-frozen-lockfile` before executing `pnpm docker:build` but the installed dependencies should not affect the image build process.\r\n\r\n**To Reproduce**\r\nPrerequisites:\r\n- Ubuntu/Debian\r\n- Docker installed\r\n- PNPM installed\r\n- Repo cloned\r\n- `main` branch checked out\r\n\r\n1. `pnpm clean`\r\n2. `pnpm docker:build`\r\n3. `pnpm docker:run`\r\n4. `docker logs eliza`\r\n\r\n**Expected behavior**\r\n\r\nThe container should not exit with a dependency error and should start as normal regardless of whether `pnpm install` was executed before `pnpm docker:build`.\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\nPossibly related to: https://github.com/elizaOS/eliza/pull/1120 and https://github.com/elizaOS/eliza/pull/1352\r\n", "CLOSED", 0, "timolegros", "2024-12-26T08:20:50Z", "2025-03-06T01:43:38Z", "2025-01-12T11:03:57Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6jSoPb", 1059, "Unexpected token 'A', \"Agent not found\" is not valid JSON", "**Describe the bug**\r\n\r\nWhen \"llama_local\" is set as the modelProvider in the character.json file, a prompt returns this error: \r\n\r\n```\r\nError fetching response: SyntaxError: Unexpected token 'A', \"Agent not found\" is not valid JSON\r\n    at JSON.parse (<anonymous>)\r\n    at parseJSONFromBytes (node:internal/deps/undici/undici:5731:19)\r\n    at successSteps (node:internal/deps/undici/undici:5712:27)\r\n    at fullyReadBody (node:internal/deps/undici/undici:4609:9)\r\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\r\n    at async consumeBody (node:internal/deps/undici/undici:5721:7)\r\n    at async handleUserInput (file:///home/cipher/cipher/agent/src/index.ts:454:22)\r\n    at async file:///home/cipher/cipher/agent/src/index.ts:420:13\r\n```\r\n\r\n**To Reproduce**\r\n\r\n1. In any character.json file, set the modelProvider to \"llama_local\"\r\n2. Initialize your character\r\n3. Send a prompt, such as \"hello\"\r\n\r\n**Expected behavior**\r\n\r\nI expected the character to respond back with a greeting such as hi, hello, how are you, etc.\r\n\r\n**Screenshots**\r\n\r\n![image](https://github.com/user-attachments/assets/f871b6f0-1b64-413a-bf7f-63139e67f643)\r\n\r\n**Additional context**\r\n\r\nUsing WSL with release: https://github.com/ai16z/eliza/releases/tag/v0.1.5-alpha.5\r\n", "CLOSED", 0, "cipherkilledit", "2024-12-14T05:00:17Z", "2025-04-19T12:38:28Z", "2024-12-14T08:23:06Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6iuP9p", 970, "Need to add media file upload for posting tweets with image from imageGenerationPlugin. Currently only discord has this implemented", "Need add media upload to twitter and later to telegram. And implement Eliza's common agent function \"processAttachments\" for imageGenerationPlugin.\r\n\r\nThis agent has media upload\r\nhttps://github.com/ai16z/agent-twitter-client\r\n\r\nI use twitter and telegram and in Character \"modelProvider\": \"heurist\", \"secrets\": {\t\"HEURIST_API_KEY\": \"xxx\" }\r\n    }, \r\nI wrote \"Generate an AI image from text: cats on street\" and get only text \"...\"\r\n![image](https://github.com/user-attachments/assets/29e83a8b-3885-4f78-8dc6-bb8016162e46)\r\nBut file uploaded and logs say same\r\n![image](https://github.com/user-attachments/assets/1cdef8ce-df2b-44ac-8686-84e567f72fad)\r\n![image](https://github.com/user-attachments/assets/ebc32cf5-9e0c-4f13-94cb-97372bcb92f0)\r\n\r\nHere we get attachments.\r\nimageGenerationPlugin\r\n![image](https://github.com/user-attachments/assets/07f8a466-c165-43d8-8dea-b6d0678c2202)\r\nhttps://github.com/ai16z/eliza/blob/622000ef19fc7805f1f8d3d86530d883353ac01f/packages/plugin-image-generation/src/index.ts#L200\r\n\r\nMust be implemented function \"processAttachments\" for Twitter and Telegram.\r\nhttps://github.com/ai16z/eliza/blob/main/docs/docs/packages/clients.md#message-handling\r\n![image](https://github.com/user-attachments/assets/5b501fbd-01c3-40f0-804b-836599a47b44)\r\n\r\n\"processAttachments\" implemented in Discord\r\nhttps://github.com/ai16z/eliza/blob/622000ef19fc7805f1f8d3d86530d883353ac01f/packages/client-discord/src/attachments.ts#L67\r\n![image](https://github.com/user-attachments/assets/e9c421c5-01f8-45d5-afdf-de0f8c1ca71b)\r\n\r\nAnd current agents may post only text, only Discord can images, audio and other", "CLOSED", 0, "Endytech", "2024-12-10T12:47:22Z", "2025-03-04T22:57:51Z", "2025-02-27T01:28:33Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6cUmnl", 79, "Dependency Dashboard", "This issue lists Renovate updates and detected dependencies. Read the [Dependency Dashboard](https://docs.renovatebot.com/key-concepts/dashboard/) docs to learn more.<br>[View this repository on the Mend.io Web Portal](https://developer.mend.io/github/elizaOS/eliza).\n\n## Pending Approval\n\nThese branches will be created by Renovate only once you click their checkbox below.\n\n - [ ] <!-- approve-branch=renovate/testing-frameworks -->chore(deps): pin dependencies (`@types/jest`, `jest`)\n - [ ] <!-- approve-branch=renovate/react-monorepo -->chore(deps): pin dependencies (`@types/react`, `@types/react-dom`)\n - [ ] <!-- approve-branch=renovate/eslint-and-formatting -->chore(deps): pin dependencies (`eslint`, `eslint-import-resolver-typescript`, `eslint-plugin-import`, `eslint-plugin-jsx-a11y`, `eslint-plugin-react`, `eslint-plugin-react-hooks`, `eslint-plugin-react-refresh`)\n - [ ] <!-- approve-branch=renovate/rollup-and-plugins -->chore(deps): pin dependency rollup-plugin-visualizer to 5.14.0\n - [ ] <!-- approve-branch=renovate/pin-dependencies -->fix(deps): pin dependencies (`@biomejs/biome`, `@deepgram/sdk`, `@docusaurus/plugin-ideal-image`, `@electric-sql/pglite`, `@eslint/js`, `@injectivelabs/sdk-ts`, `@jest/globals`, `@langchain/openai`, `@octokit/plugin-paginate-rest@>=1.0.0 <11.4.1`, `@octokit/request-error@>=1.0.0 <5.1.1`, `@octokit/request@>=1.0.0 <9.2.1`, `@octokit/rest`, `@radix-ui/react-avatar`, `@radix-ui/react-collapsible`, `@radix-ui/react-dialog`, `@radix-ui/react-label`, `@radix-ui/react-separator`, `@radix-ui/react-slot`, `@radix-ui/react-tabs`, `@radix-ui/react-toast`, `@radix-ui/react-tooltip`, `@react-spring/web`, `@supabase/supabase-js`, `@tanstack/react-query`, `@types/multer`, `@types/node`, `@types/semver`, `@uidotdev/usehooks`, `@vitejs/plugin-react-swc`, `@vitest/coverage-v8`, `aiofiles`, `anthropic`, `asyncio`, `autoprefixer`, `axios@>=0.8.1 <0.28.0`, `class-variance-authority`, `clsx`, `commander`, `dayjs`, `deepseek`, `dompurify@<3.2.4`, `dotenv`, `esbuild@<=0.24.2`, `esprima`, `globals`, `graphviz`, `handlebars`, `isort`, `jschema-to-python`, `langchain`, `langdetect`, `lizard`, `lodash`, `lucide-react`, `markdown`, `markitdown`, `mypy`, `node`, `nodeenv`, `path-to-regexp`, `path-to-regexp@<0.1.12`, `phidata`, `pino`, `pino-pretty`, `postcss`, `pydantic`, `pytest`, `pytest-asyncio`, `python`, `radon`, `react`, `react-aiwriter`, `react-dom`, `react-router`, `react-router-dom`, `rich`, `semgrep`, `semver`, `sql.js`, `tailwind-merge`, `tailwindcss`, `tailwindcss-animate`, `termcolor`, `textual`, `tsup`, `typer`, `typescript-eslint`, `undici@>=6.0.0 <6.21.1`, `vite-plugin-compression`, `vite-tsconfig-paths`, `vitest`, `yaml`, `zod`)\n - [ ] <!-- approve-branch=renovate/typescript-and-related -->fix(deps): pin dependencies (`@typescript-eslint/eslint-plugin`, `@typescript-eslint/parser`, `@typescript-eslint/types`, `@typescript-eslint/typescript-estree`, `ts-jest`, `ts-node`, `typescript`)\n - [ ] <!-- approve-branch=renovate/aiml-packages -->fix(deps): pin dependencies\n - [ ] <!-- approve-branch=renovate/docker-build-push-action-digest -->chore(deps): update docker/build-push-action digest to 471d1dc\n - [ ] <!-- approve-branch=renovate/docker-login-action-digest -->chore(deps): update docker/login-action digest to 327cd5a\n - [ ] <!-- approve-branch=renovate/docker-metadata-action-digest -->chore(deps): update docker/metadata-action digest to 902fa8e\n - [ ] <!-- approve-branch=renovate/ai-sdk-provider-1.x -->chore(deps): update dependency @ai-sdk/provider to v1.0.10\n - [ ] <!-- approve-branch=renovate/ai-sdk-provider-utils-2.x -->chore(deps): update dependency @ai-sdk/provider-utils to v2.1.11\n - [ ] <!-- approve-branch=renovate/concurrently-9.x -->chore(deps): update dependency concurrently to v9.1.2\n - [ ] <!-- approve-branch=renovate/cookie-0.x -->chore(deps): update dependency cookie to v0.7.2\n - [ ] <!-- approve-branch=renovate/nodemon-3.x -->chore(deps): update dependency nodemon to v3.1.9\n - [ ] <!-- approve-branch=renovate/vite-5.x -->chore(deps): update dependency vite to v5.4.14\n - [ ] <!-- approve-branch=renovate/vitest-monorepo -->chore(deps): update vitest monorepo to ^3.0.7 (`@vitest/coverage-v8`, `vitest`)\n - [ ] <!-- approve-branch=renovate/0glabs-0g-ts-sdk-0.x -->fix(deps): update dependency @0glabs/0g-ts-sdk to v0.2.6\n - [ ] <!-- approve-branch=renovate/ai-sdk-anthropic-1.x -->fix(deps): update dependency @ai-sdk/anthropic to v1.1.15\n - [ ] <!-- approve-branch=renovate/ai-sdk-google-1.x -->fix(deps): update dependency @ai-sdk/google to v1.1.20\n - [ ] <!-- approve-branch=renovate/ai-sdk-groq-1.x -->fix(deps): update dependency @ai-sdk/groq to v1.1.12\n - [ ] <!-- approve-branch=renovate/ai-sdk-mistral-1.x -->fix(deps): update dependency @ai-sdk/mistral to v1.1.15\n - [ ] <!-- approve-branch=renovate/deepgram-sdk-3.x -->fix(deps): update dependency @deepgram/sdk to ^3.11.1\n - [ ] <!-- approve-branch=renovate/fal-ai-client-1.x -->fix(deps): update dependency @fal-ai/client to v1.2.3\n - [ ] <!-- approve-branch=renovate/octokit-monorepo -->fix(deps): update dependency @octokit/rest to ^21.1.0\n - [ ] <!-- approve-branch=renovate/node-20.x -->fix(deps): update dependency @types/node to ^20.17.12\n - [ ] <!-- approve-branch=renovate/ai-4.x -->fix(deps): update dependency ai to v4.1.54\n - [ ] <!-- approve-branch=renovate/bs58-4.x -->fix(deps): update dependency bs58 to v4.0.1\n - [ ] <!-- approve-branch=renovate/dotenv-16.x -->fix(deps): update dependency dotenv to v16.4.7\n - [ ] <!-- approve-branch=renovate/express-4.x -->fix(deps): update dependency express to v4.21.2\n - [ ] <!-- approve-branch=renovate/glob-11.x -->fix(deps): update dependency glob to v11.0.1\n - [ ] <!-- approve-branch=renovate/js-tiktoken-1.x -->fix(deps): update dependency js-tiktoken to v1.0.19\n - [ ] <!-- approve-branch=renovate/langchain-0.x -->fix(deps): update dependency langchain to ^0.3.11\n - [ ] <!-- approve-branch=renovate/markitdown-0.x -->fix(deps): update dependency markitdown to ^0.0.2\n - [ ] <!-- approve-branch=renovate/ws-8.x -->fix(deps): update dependency ws to v8.18.1\n - [ ] <!-- approve-branch=renovate/zod-3.x -->fix(deps): update dependency zod to v3.24.2\n - [ ] <!-- approve-branch=renovate/pnpm-9.x -->fix(deps): update pnpm to v9.15.7\n - [ ] <!-- approve-branch=renovate/coral-xyz-anchor-0.x -->chore(deps): update dependency @coral-xyz/anchor to v0.30.1\n - [ ] <!-- approve-branch=renovate/vitejs-plugin-react-swc-3.x -->chore(deps): update dependency @vitejs/plugin-react-swc to ^3.8.0\n - [ ] <!-- approve-branch=renovate/docusaurus-plugin-typedoc-1.x -->chore(deps): update dependency docusaurus-plugin-typedoc to v1.2.3\n - [ ] <!-- approve-branch=renovate/lerna-monorepo -->chore(deps): update dependency lerna to v8.2.1\n - [ ] <!-- approve-branch=renovate/onnxruntime-node-1.x -->chore(deps): update dependency onnxruntime-node to v1.21.0\n - [ ] <!-- approve-branch=renovate/postcss-8.x -->chore(deps): update dependency postcss to ^8.5.3\n - [ ] <!-- approve-branch=renovate/pytest-asyncio-0.x -->chore(deps): update dependency pytest-asyncio to ^0.25.0\n - [ ] <!-- approve-branch=renovate/tsup-8.x -->chore(deps): update dependency tsup to v8.4.0\n - [ ] <!-- approve-branch=renovate/typedoc-0.x -->chore(deps): update dependency typedoc to v0.27.9\n - [ ] <!-- approve-branch=renovate/typedoc-plugin-markdown-4.x -->chore(deps): update dependency typedoc-plugin-markdown to v4.4.2\n - [ ] <!-- approve-branch=renovate/typescript-eslint-monorepo -->chore(deps): update dependency typescript-eslint to ^8.26.0\n - [ ] <!-- approve-branch=renovate/node-23.x -->chore(deps): update node.js to v23.9.0\n - [ ] <!-- approve-branch=renovate/solana-packages -->chore(deps): update solana packages to v1.98.0 (`@solana/web3.js@1.95.5`, `@solana/web3.js@1.95.8`)\n - [ ] <!-- approve-branch=renovate/ai-sdk-openai-1.x -->fix(deps): update dependency @ai-sdk/openai to v1.2.1\n - [ ] <!-- approve-branch=renovate/coinbase-coinbase-sdk-0.x -->fix(deps): update dependency @coinbase/coinbase-sdk to v0.21.0\n - [ ] <!-- approve-branch=renovate/docusaurus-monorepo -->fix(deps): update dependency @docusaurus/plugin-ideal-image to ^3.7.0\n - [ ] <!-- approve-branch=renovate/langchain-openai-0.x -->fix(deps): update dependency @langchain/openai to ^0.4.0\n - [ ] <!-- approve-branch=renovate/mdx-monorepo -->fix(deps): update dependency @mdx-js/react to v3.1.0\n - [ ] <!-- approve-branch=renovate/tanstack-query-monorepo -->fix(deps): update dependency @tanstack/react-query to ^5.67.2\n - [ ] <!-- approve-branch=renovate/vitest-eslint-plugin-1.x -->fix(deps): update dependency @vitest/eslint-plugin to v1.1.36\n - [ ] <!-- approve-branch=renovate/anthropic-0.x -->fix(deps): update dependency anthropic to ^0.49.0\n - [ ] <!-- approve-branch=renovate/docusaurus-lunr-search-3.x -->fix(deps): update dependency docusaurus-lunr-search to v3.6.0\n - [ ] <!-- approve-branch=renovate/lucide-monorepo -->fix(deps): update dependency lucide-react to ^0.479.0\n - [ ] <!-- approve-branch=renovate/prism-react-renderer-2.x -->fix(deps): update dependency prism-react-renderer to v2.4.1\n - [ ] <!-- approve-branch=renovate/react-router-monorepo -->fix(deps): update dependency react-router-dom to v6.30.0\n - [ ] <!-- approve-branch=renovate/textual-0.x -->fix(deps): update dependency textual to ^0.89.0\n - [ ] <!-- approve-branch=renovate/together-ai-0.x -->fix(deps): update dependency together-ai to v0.13.0\n - [ ] <!-- approve-branch=renovate/typer-0.x -->fix(deps): update dependency typer to ^0.15.0\n - [ ] <!-- approve-branch=renovate/uuid-11.x -->fix(deps): update dependency uuid to v11.1.0\n - [ ] <!-- approve-branch=renovate/viem-2.x -->fix(deps): update dependency viem to v2.23.8\n - [ ] <!-- approve-branch=renovate/actions-attest-build-provenance-2.x -->chore(deps): update actions/attest-build-provenance action to v2\n - [ ] <!-- approve-branch=renovate/actions-stale-9.x -->chore(deps): update actions/stale action to v9\n - [ ] <!-- approve-branch=renovate/major-commitlint-monorepo -->chore(deps): update commitlint monorepo to v19 (major) (`@commitlint/cli`, `@commitlint/config-conventional`)\n - [ ] <!-- approve-branch=renovate/polkadot-keyring-13.x -->chore(deps): update dependency @polkadot/keyring to v13\n - [ ] <!-- approve-branch=renovate/polkadot-types-codec-15.x -->chore(deps): update dependency @polkadot/types-codec to v15\n - [ ] <!-- approve-branch=renovate/polkadot-types-create-15.x -->chore(deps): update dependency @polkadot/types-create to v15\n - [ ] <!-- approve-branch=renovate/polkadot-util-13.x -->chore(deps): update dependency @polkadot/util to v13\n - [ ] <!-- approve-branch=renovate/polkadot-util-crypto-13.x -->chore(deps): update dependency @polkadot/util-crypto to v13\n - [ ] <!-- approve-branch=renovate/express-5.x -->chore(deps): update dependency @types/express to v5\n - [ ] <!-- approve-branch=renovate/cookie-1.x -->chore(deps): update dependency cookie to v1\n - [ ] <!-- approve-branch=renovate/globals-16.x -->chore(deps): update dependency globals to v16\n - [ ] <!-- approve-branch=renovate/isort-6.x -->chore(deps): update dependency isort to v6\n - [ ] <!-- approve-branch=renovate/pytest-8.x -->chore(deps): update dependency pytest to v8\n - [ ] <!-- approve-branch=renovate/major-tailwindcss-monorepo -->chore(deps): update dependency tailwindcss to v4\n - [ ] <!-- approve-branch=renovate/vite-6.x -->chore(deps): update dependency vite to v6\n - [ ] <!-- approve-branch=renovate/whatwg-url-14.x -->chore(deps): update dependency whatwg-url to v14\n - [ ] <!-- approve-branch=renovate/ai-sdk-amazon-bedrock-2.x -->fix(deps): update dependency @ai-sdk/amazon-bedrock to v2\n - [ ] <!-- approve-branch=renovate/node-22.x -->fix(deps): update dependency @types/node to v22.13.10\n - [ ] <!-- approve-branch=renovate/aiofiles-24.x -->fix(deps): update dependency aiofiles to v24\n - [ ] <!-- approve-branch=renovate/bs58-6.x -->fix(deps): update dependency bs58 to v6\n - [ ] <!-- approve-branch=renovate/ollama-ai-provider-1.x -->fix(deps): update dependency ollama-ai-provider to v1\n - [ ] <!-- approve-branch=renovate/path-to-regexp-8.x -->fix(deps): update dependency path-to-regexp to v8\n - [ ] <!-- approve-branch=renovate/major-react-router-monorepo -->fix(deps): update dependency react-router-dom to v7\n - [ ] <!-- approve-branch=renovate/tailwind-merge-3.x -->fix(deps): update dependency tailwind-merge to v3\n - [ ] <!-- approve-branch=renovate/textual-2.x -->fix(deps): update dependency textual to v2\n - [ ] <!-- approve-branch=renovate/pnpm-10.x -->fix(deps): update pnpm to v10\n - [ ] <!-- approve-branch=renovate/major-react-monorepo -->fix(deps): update react monorepo to v19 (major) (`@types/react`, `@types/react-dom`, `react`, `react-dom`)\n - [ ] <!-- approve-branch=renovate/major-typescript-and-related -->fix(deps): update typescript and related to v8 (major) (`@typescript-eslint/eslint-plugin`, `@typescript-eslint/parser`, `@typescript-eslint/types`, `@typescript-eslint/typescript-estree`)\n - [x] <!-- approve-all-pending-prs -->\ud83d\udd10 **Create all pending approval PRs at once** \ud83d\udd10\n\n## Other Branches\n\nThese updates are pending. To force PRs open, click the checkbox below.\n\n - [x] <!-- other-branch=renovate/npm-vite-vulnerability -->chore(deps): update dependency vite to v6.0.9 [security]\n\n## Ignored or Blocked\n\nThese are blocked by an existing closed PR and will not be recreated unless you click a checkbox below.\n\n - [x] <!-- recreate-branch=renovate/pypi-black-vulnerability -->[chore(deps): update dependency black to v24 [security]](../pull/2758)\n\n## Detected dependencies\n\n<details><summary>docker-compose</summary>\n<blockquote>\n\n<details><summary>docker-compose-docs.yaml</summary>\n\n\n</details>\n\n<details><summary>docker-compose.yaml</summary>\n\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>dockerfile</summary>\n<blockquote>\n\n<details><summary>.devcontainer/Dockerfile</summary>\n\n\n</details>\n\n<details><summary>Dockerfile</summary>\n\n - `node 23.3.0-slim`\n - `node 23.3.0-slim`\n\n</details>\n\n<details><summary>Dockerfile.docs</summary>\n\n - `docker/dockerfile 1`\n - `node 23.3.0-slim`\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>github-actions</summary>\n<blockquote>\n\n<details><summary>.github/workflows/ci.yaml</summary>\n\n - `actions/checkout v4`\n - `actions/setup-node v4`\n - `biomejs/setup-biome v2`\n - `codecov/codecov-action v5`\n\n</details>\n\n<details><summary>.github/workflows/codeql.yml</summary>\n\n - `actions/checkout v4`\n - `github/codeql-action v3`\n - `github/codeql-action v3`\n\n</details>\n\n<details><summary>.github/workflows/generate-changelog.yml</summary>\n\n - `actions/checkout v4`\n - `stefanzweifel/git-auto-commit-action v5`\n\n</details>\n\n<details><summary>.github/workflows/generate-readme-translations.yml</summary>\n\n - `actions/checkout v4`\n - `0xjord4n/aixion v1.2.1`\n - `actions/upload-artifact v4`\n - `actions/checkout v4`\n - `actions/download-artifact v4`\n - `stefanzweifel/git-auto-commit-action v5`\n\n</details>\n\n<details><summary>.github/workflows/greetings.yml</summary>\n\n\n</details>\n\n<details><summary>.github/workflows/image.yaml</summary>\n\n - `actions/checkout v4`\n - `docker/login-action 65b78e6e13532edd9afa3aa52ac7964289d1a9c1`\n - `docker/metadata-action 9ec57ed1fcdbf14dcef7dfbe97b2010124a938b7`\n - `docker/build-push-action f2a1d5e99d037542a71f64918e516c093c6f3fc4`\n - `actions/attest-build-provenance v1`\n\n</details>\n\n<details><summary>.github/workflows/integrationTests.yaml</summary>\n\n - `actions/checkout v4`\n - `actions/setup-node v4`\n\n</details>\n\n<details><summary>.github/workflows/jsdoc-automation.yml</summary>\n\n - `actions/checkout v4`\n - `actions/setup-node v4`\n\n</details>\n\n<details><summary>.github/workflows/minimal-merge-queue.yml</summary>\n\n\n</details>\n\n<details><summary>.github/workflows/pnpm-lockfile-check.yml</summary>\n\n - `actions/checkout v4`\n - `actions/setup-node v4`\n - `actions/github-script v7`\n\n</details>\n\n<details><summary>.github/workflows/pr.yaml</summary>\n\n - `actions/checkout v4`\n\n</details>\n\n<details><summary>.github/workflows/pre-release.yml</summary>\n\n - `actions/checkout v4`\n - `actions/setup-node v4`\n - `actions/create-release v1`\n\n</details>\n\n<details><summary>.github/workflows/release.yaml</summary>\n\n - `actions/checkout v4`\n - `actions/setup-node v4`\n\n</details>\n\n<details><summary>.github/workflows/require-develop.yml</summary>\n\n\n</details>\n\n<details><summary>.github/workflows/smoke-tests.yml</summary>\n\n - `actions/checkout v4`\n - `actions/setup-node v4`\n\n</details>\n\n<details><summary>.github/workflows/stale.yml</summary>\n\n - `actions/stale v5`\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>npm</summary>\n<blockquote>\n\n<details><summary>agent/package.json</summary>\n\n - `@types/node ^22.13.5`\n - `json5 2.2.3`\n - `ts-node ^10.9.2`\n - `yargs 17.7.2`\n - `@jest/globals ^29.7.0`\n - `@types/jest ^29.5.14`\n - `jest ^29.7.0`\n - `ts-jest ^29.2.6`\n\n</details>\n\n<details><summary>client/package.json</summary>\n\n - `@radix-ui/react-avatar ^1.1.2`\n - `@radix-ui/react-collapsible ^1.1.2`\n - `@radix-ui/react-dialog ^1.1.4`\n - `@radix-ui/react-label ^2.1.1`\n - `@radix-ui/react-separator ^1.1.1`\n - `@radix-ui/react-slot ^1.1.1`\n - `@radix-ui/react-tabs ^1.1.2`\n - `@radix-ui/react-toast ^1.2.4`\n - `@radix-ui/react-tooltip ^1.1.6`\n - `@react-spring/web ^9.7.5`\n - `@tanstack/react-query ^5.63.0`\n - `@uidotdev/usehooks ^2.4.1`\n - `class-variance-authority ^0.7.1`\n - `clsx 2.1.1`\n - `dayjs ^1.11.13`\n - `lucide-react ^0.469.0`\n - `react ^19.0.0`\n - `react-aiwriter ^1.0.0`\n - `react-dom ^19.0.0`\n - `react-router ^7.1.1`\n - `react-router-dom ^7.1.1`\n - `semver ^7.6.3`\n - `tailwind-merge ^2.6.0`\n - `tailwindcss-animate ^1.0.7`\n - `vite-plugin-compression ^0.5.1`\n - `@eslint/js ^9.17.0`\n - `@types/node ^22.10.5`\n - `@types/react ^19.0.3`\n - `@types/react-dom ^19.0.2`\n - `@types/semver ^7.5.8`\n - `@typescript-eslint/eslint-plugin ^8.19.1`\n - `@typescript-eslint/parser ^8.19.1`\n - `@vitejs/plugin-react-swc ^3.5.0`\n - `autoprefixer ^10.4.19`\n - `eslint ^9.17.0`\n - `eslint-import-resolver-typescript ^3.6.1`\n - `eslint-plugin-import ^2.28.1`\n - `eslint-plugin-jsx-a11y ^6.7.1`\n - `eslint-plugin-react ^7.33.2`\n - `eslint-plugin-react-hooks ^5.0.0`\n - `eslint-plugin-react-refresh ^0.4.16`\n - `globals ^15.14.0`\n - `postcss ^8.4.38`\n - `rollup-plugin-visualizer ^5.14.0`\n - `tailwindcss ^3.4.4`\n - `typescript ~5.6.3`\n - `typescript-eslint ^8.18.2`\n - `vite ^6.0.5`\n - `vite-tsconfig-paths ^5.1.4`\n\n</details>\n\n<details><summary>docs/package.json</summary>\n\n - `@docusaurus/core 3.7.0`\n - `@docusaurus/plugin-content-blog 3.7.0`\n - `@docusaurus/plugin-content-docs 3.7.0`\n - `@docusaurus/plugin-ideal-image ^3.0.0`\n - `@docusaurus/preset-classic 3.7.0`\n - `@docusaurus/theme-common 3.7.0`\n - `@docusaurus/theme-mermaid 3.7.0`\n - `clsx ^2.1.1`\n - `@mdx-js/react 3.0.1`\n - `docusaurus-lunr-search 3.5.0`\n - `dotenv ^16.4.7`\n - `lodash ^4.17.21`\n - `lunr 2.3.9`\n - `prism-react-renderer 2.3.1`\n - `react 18.3.1`\n - `react-dom 18.3.1`\n - `react-router-dom 6.22.1`\n - `@docusaurus/module-type-aliases 3.7.0`\n - `@docusaurus/types 3.7.0`\n - `docusaurus-plugin-typedoc 1.0.5`\n - `typedoc 0.26.11`\n - `typedoc-plugin-markdown 4.2.10`\n - `node 23.3.0`\n - `pnpm 9.4.0`\n\n</details>\n\n<details><summary>package.json</summary>\n\n - `@0glabs/0g-ts-sdk 0.2.1`\n - `@coinbase/coinbase-sdk 0.10.0`\n - `@deepgram/sdk ^3.9.0`\n - `@injectivelabs/sdk-ts ^1.14.33`\n - `@vitest/eslint-plugin 1.0.1`\n - `amqplib 0.10.5`\n - `bs58 4.0.0`\n - `csv-parse 5.6.0`\n - `langdetect ^0.2.1`\n - `ollama-ai-provider 0.16.1`\n - `optional 0.1.4`\n - `pnpm 9.15.0`\n - `sharp 0.33.5`\n - `ws 8.18.0`\n - `zod 3.24.1`\n - `@biomejs/biome ^1.9.4`\n - `@commitlint/cli 18.6.1`\n - `@commitlint/config-conventional 18.6.3`\n - `@types/jest ^29.5.11`\n - `concurrently 9.1.0`\n - `cross-env 7.0.3`\n - `husky 9.1.7`\n - `jest ^29.7.0`\n - `lerna 8.1.5`\n - `nodemon 3.1.7`\n - `only-allow 1.2.1`\n - `turbo 2.4.4`\n - `typedoc 0.26.11`\n - `typescript 5.6.3`\n - `viem 2.21.58`\n - `vite 5.4.12`\n - `vitest 3.0.5`\n - `node 23.3.0`\n - `pnpm 9.15.0`\n - `onnxruntime-node 1.20.1`\n - `@solana/web3.js@1.95.5 1.95.5`\n - `@solana/web3.js@1.95.8 1.95.8`\n - `@solana/web3.js@2 2.0.0`\n - `viem 2.21.58`\n - `@polkadot/util 12.6.2`\n - `@polkadot/util-crypto 12.6.2`\n - `@polkadot/types-create 10.13.1`\n - `@polkadot/types-codec 10.13.1`\n - `@polkadot/keyring 12.6.2`\n - `@ai-sdk/provider 1.0.6`\n - `@ai-sdk/provider-utils 2.1.6`\n - `cookie 0.7.0`\n - `bs58 5.0.0`\n - `@coral-xyz/anchor 0.28.0`\n - `axios@>=0.8.1 <0.28.0 >=0.28.0`\n - `undici@>=6.0.0 <6.21.1 >=6.21.1`\n - `path-to-regexp@<0.1.12 >=0.1.12`\n - `secp256k1 5.0.1`\n - `@octokit/request-error@>=1.0.0 <5.1.1 >=5.1.1`\n - `dompurify@<3.2.4 >=3.2.4`\n - `@octokit/request@>=1.0.0 <9.2.1 >=9.2.1`\n - `@octokit/plugin-paginate-rest@>=1.0.0 <11.4.1 >=11.4.1`\n - `esbuild@<=0.24.2 >=0.25.0`\n\n</details>\n\n<details><summary>packages/adapter-sqlite/package.json</summary>\n\n - `@types/better-sqlite3 7.6.12`\n - `better-sqlite3 11.8.1`\n - `sqlite-vec 0.1.6`\n - `uuid 11.0.5`\n - `@types/uuid 10.0.0`\n - `tsup 8.3.5`\n - `vitest ^3.0.2`\n - `@vitest/coverage-v8 ^3.0.2`\n - `whatwg-url 7.1.0`\n\n</details>\n\n<details><summary>packages/cli/package.json</summary>\n\n - `commander ^13.1.0`\n\n</details>\n\n<details><summary>packages/client-direct/package.json</summary>\n\n - `@types/body-parser 1.19.5`\n - `@types/cors 2.8.17`\n - `body-parser 1.20.3`\n - `cors 2.8.5`\n - `express 4.21.1`\n - `multer 1.4.5-lts.1`\n - `openai 4.73.0`\n - `path-to-regexp ^1.7.0`\n - `zod ^3.24.2`\n - `@types/express 4.17.21`\n - `@types/multer ^1.4.12`\n - `tsup 8.3.5`\n - `whatwg-url 7.1.0`\n\n</details>\n\n<details><summary>packages/core/package.json</summary>\n\n - `@ai-sdk/amazon-bedrock 1.1.6`\n - `@ai-sdk/anthropic 1.1.6`\n - `@ai-sdk/google 1.1.0`\n - `@ai-sdk/groq 1.1.7`\n - `@ai-sdk/mistral 1.1.6`\n - `@ai-sdk/openai 1.1.9`\n - `@electric-sql/pglite ^0.2.17`\n - `@fal-ai/client 1.2.0`\n - `@supabase/supabase-js ^2.49.1`\n - `@types/uuid 10.0.0`\n - `ai 4.1.16`\n - `better-sqlite3 11.8.1`\n - `bignumber.js 9.1.2`\n - `dotenv 16.4.5`\n - `fastembed 1.14.1`\n - `glob 11.0.0`\n - `handlebars ^4.7.8`\n - `js-sha1 0.7.0`\n - `js-tiktoken 1.0.15`\n - `ollama-ai-provider 0.16.1`\n - `openai 4.82.0`\n - `pino ^9.6.0`\n - `pino-pretty ^13.0.0`\n - `sql.js ^1.12.0`\n - `together-ai 0.7.0`\n - `unique-names-generator 4.7.1`\n - `uuid 11.0.3`\n - `viem 2.21.58`\n - `vitest ^3.0.5`\n - `zod ^3.24.2`\n - `@types/node 22.8.4`\n - `tsup 8.3.5`\n - `typescript 5.6.3`\n\n</details>\n\n<details><summary>packages/dynamic-imports/package.json</summary>\n\n\n</details>\n\n<details><summary>packages/plugin-bootstrap/package.json</summary>\n\n - `@types/node ^22.10.5`\n - `tsup 8.3.5`\n - `whatwg-url 7.1.0`\n\n</details>\n\n<details><summary>pnpm-workspace.yaml</summary>\n\n\n</details>\n\n<details><summary>scripts/bug_hunt/package.json</summary>\n\n - `@biomejs/biome 1.9.4`\n - `@types/node ^20.11.5`\n - `node >=18.0.0`\n\n</details>\n\n<details><summary>scripts/jsdoc-automation/package.json</summary>\n\n - `@langchain/openai ^0.3.16`\n - `@octokit/rest ^21.0.2`\n - `@types/node ^20.11.0`\n - `@typescript-eslint/parser 6.18.1`\n - `@typescript-eslint/types 6.18.1`\n - `@typescript-eslint/typescript-estree 6.18.1`\n - `dotenv ^16.4.7`\n - `langchain ^0.3.7`\n - `yaml ^2.3.4`\n - `ts-node ^10.9.2`\n - `tsup ^8.3.5`\n - `typescript 5.3.3`\n\n</details>\n\n<details><summary>scripts/jsdoc-automation/pnpm-workspace.yaml</summary>\n\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>nvm</summary>\n<blockquote>\n\n<details><summary>.nvmrc</summary>\n\n - `node v23.3.0`\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>pep621</summary>\n<blockquote>\n\n<details><summary>scripts/bug_hunt/pyproject.toml</summary>\n\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>poetry</summary>\n<blockquote>\n\n<details><summary>scripts/bug_hunt/pyproject.toml</summary>\n\n - `python ^3.11`\n - `rich ^13.7.0`\n - `termcolor ^2.4.0`\n - `typer ^0.9.0`\n - `pydantic ^2.5.3`\n - `aiofiles ^23.2.1`\n - `asyncio ^3.4.3`\n - `textual ^0.47.1`\n - `nodeenv ^1.8.0`\n - `esprima ^4.0.1`\n - `lizard ^1.17.10`\n - `radon ^6.0.1`\n - `semgrep ^1.65.0`\n - `jschema-to-python ^1.2.3`\n - `graphviz ^0.20.1`\n - `phidata ^2.7.9`\n - `openai ^1.60.0`\n - `deepseek ^1.0.0`\n - `anthropic ^0.45.0`\n - `markdown ^3.7`\n - `markitdown ^0.0.1a3`\n - `black ^23.12.1`\n - `isort ^5.13.2`\n - `mypy ^1.8.0`\n - `pytest ^7.4.4`\n - `pytest-asyncio ^0.23.3`\n\n</details>\n\n</blockquote>\n</details>\n\n---\n\n- [ ] <!-- manual job -->Check this box to trigger a request for Renovate to run again on this repository\n\n", "CLOSED", 0, "renovate", "2024-10-30T01:34:59Z", "2025-03-08T20:24:30Z", "2025-03-08T20:24:30Z", "elizaos/eliza", "2025-04-14 21:54:46"]
["I_kwDOMT5cIs6vTCqe", 4050, "Need help with client-twitter, How do I let eliza post images along with tweets??", "I am trying to create a twitter agent that does basic work like tweeting and replying to tweets, now how do I enable it to post/tweet images too???\n\nPlease help!!", "OPEN", 0, "Quanta-Naut", "2025-03-23T07:53:49Z", "2025-03-23T07:54:12Z", null, "elizaos/eliza", "2025-04-14 21:55:06"]
["I_kwDOMT5cIs6vRd0n", 4048, "Husky pre commit error", "**Describe the bug**\n\n.husky/pre-commit: line 3: node_modules/.bin/bun: cannot execute binary file: Exec format error\nhusky - pre-commit script failed (code 126)\n\n\n**To Reproduce**\n\ngit commit produces the error in git bash\n\n**Expected behavior**\n\nexpected the commit to go through\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/50f4ee05-b604-4ce4-9ebc-11840df48ce5)\n\n**Additional context**\n\ncurrent error when trying to pull latest changes\n", "OPEN", 0, "Deadsg", "2025-03-22T19:42:55Z", "2025-03-22T20:29:16Z", null, "elizaos/eliza", "2025-04-14 21:55:06"]
["I_kwDOMT5cIs6u_kqB", 4023, "Version is 1 point behind in client\u00a0GH #4009", "In the client, the version is copied and built when the client is built, but the version is changed on publish. We need to split our setup so we version, build, publish in that order.", "CLOSED", 0, "linear", "2025-03-20T15:37:29Z", "2025-03-20T15:40:47Z", "2025-03-20T15:40:47Z", "elizaos/eliza", "2025-04-14 21:55:06"]
["I_kwDOMT5cIs6u_kH7", 4022, "npx elizaos agent list fetch failed\u00a0GH #4020", "npx elizaos agent list<br>\\[2025-03-20 11:18:26\\] USERLVL: An error occurred:<br>\\[2025-03-20 11:18:26\\] USERLVL: Error details: fetch failed<br>\\[2025-03-20 11:18:26\\] USERLVL: Stack trace: TypeError: fetch failed<br>at node:internal/deps/undici/undici:13484:13<br>at process.processTicksAndRejections (node:internal/process/task_queues:105:5)<br>at async getAgents (file:///Users/alexander/Sources/eliza/liza/node_modules/@elizaos/cli/dist/chunk-NXPHQUQ5.js:106:20)<br>at async \\_Command. (file:///Users/alexander/Sources/eliza/liza/node_modules/@elizaos/cli/dist/chunk-NXPHQUQ5.js:132:20)<br>at async \\_Command.parseAsync (file:///Users/alexander/Sources/eliza/liza/node_modules/@elizaos/cli/dist/chunk-5LH7NKB4.js:1721:9)<br>at async main (file:///Users/alexander/Sources/eliza/liza/node_modules/@elizaos/cli/dist/index.js:148:3)", "CLOSED", 0, "linear", "2025-03-20T15:36:44Z", "2025-03-20T15:40:47Z", "2025-03-20T15:40:47Z", "elizaos/eliza", "2025-04-14 21:55:06"]
["I_kwDOMT5cIs6u36kr", 4009, "Version is 1 point behind in client", "In the client, the version is copied and built when the client is built, but the version is changed on publish. We need to split our setup so we version, build, publish in that order.", "OPEN", 0, "lalalune", "2025-03-20T03:11:11Z", "2025-04-19T18:32:33Z", null, "elizaos/eliza", "2025-04-14 21:55:06"]
["I_kwDOMT5cIs6ueCLj", 3981, "Check if this is a plugin (package.json contains 'eliza' section with type='plugin')?", "can you please show me examples of where to find plugins as defined here?\nhttps://github.com/elizaOS/eliza/blob/9834bbd06128356b44b091f022fc2a2d024a875e/packages/cli/src/commands/start.ts#L346\n\n```\n// Check if this is a plugin (package.json contains 'eliza' section with type='plugin')\n      if (packageJson.eliza?.type && packageJson.eliza.type === 'plugin') {\n        isPlugin = true;\n        logger.info('Found Eliza plugin in current directory');\n      }\n\n      // Check if this is a project (package.json contains 'eliza' section with type='project')\n      if (packageJson.eliza?.type && packageJson.eliza.type === 'project') {\n        isProject = true;\n        logger.info('Found Eliza project in current directory');\n      }\n```", "OPEN", 0, "jmikedupont2", "2025-03-18T04:45:01Z", "2025-04-17T18:34:24Z", null, "elizaos/eliza", "2025-04-14 21:55:06"]
["I_kwDOMT5cIs6uOvZG", 3956, "V2 preflight check", "I would like a CLI tool to list the current chars and do a preflight check for them,\n1. check if the llm is working (write one text)\n2. check if the twitter login works (login and write a tweet)\n3. check if the discord is working\n4. check if all the plugins are loading and needed\n\n\nCurrently the start command takes some time to check everything and generate a tweet so it would be great\nto check everything.\n", "OPEN", 0, "jmikedupont2", "2025-03-16T14:28:23Z", "2025-04-17T18:34:27Z", null, "elizaos/eliza", "2025-04-14 21:55:06"]
["I_kwDOMT5cIs6uOXR_", 3955, "opus.node", "on branch https://github.com/meta-introspector/cloud-deployment-eliza/pull/54/commits/beebca40341a7d7ad6069c055ae9d0136d0711a5\n```\n[2025-03-16 12:33:01] INFO: Initializing platform detection...\n 7 |       return data;\n 8 |     } catch (e) {\n 9 |       errorLog.push(e);\n10 |     }\n11 |   }\n12 |   throw new Error(errorLog.join('\\n'));\n             ^\nerror: ResolveMessage: Cannot find module '/mnt/data1/nix/time/2025/01/13/cloud-deployment-eliza/node_modules/prism-media/node_modules/@discordjs/opus/prebuild/node-v127-napi-v3-linux-x64-glibc-2.29/opus.node' from '/mnt/data1/nix/time/2025/01/13/cloud-deployment-eliza/node_modules/prism-media/node_modules/@discordjs/opus/lib/index.js'\nResolveMessage: Cannot find package 'node-opus' from '/mnt/data1/nix/time/2025/01/13/cloud-deployment-eliza/node_modules/prism-media/src/util/loader.js'\nResolveMessage: Cannot find package 'opusscript' from '/mnt/data1/nix/time/2025/01/13/cloud-deployment-eliza/node_modules/prism-media/src/util/loader.js'\n      at loader (/mnt/data1/nix/time/2025/01/13/cloud-deployment-eliza/node_modules/prism-media/src/util/loader.js:12:9)\n      at loadOpus (/mnt/data1/nix/time/2025/01/13/cloud-deployment-eliza/node_modules/prism-media/src/opus/Opus.js:17:17)\n      at new OpusStream (/mnt/data1/nix/time/2025/01/13/cloud-deployment-eliza/node_modules/prism-media/src/opus/Opus.js:46:10)\n      at new Decoder (1:23)\n      at <anonymous> (/mnt/data1/nix/time/2025/01/13/cloud-deployment-eliza/packages/plugin-discord/dist/index.js:2772:25)\n      at monitorMember (/mnt/data1/nix/time/2025/01/13/cloud-deployment-eliza/packages/plugin-discord/dist/index.js:2760:23)\n      at <anonymous> (/mnt/data1/nix/time/2025/01/13/cloud-deployment-eliza/packages/plugin-discord/dist/index.js:2722:16)\n      at <anonymous> (/mnt/data1/nix/time/2025/01/13/cloud-deployment-eliza/packages/plugin-discord/dist/index.js:2712:55)\n      at emit (node:events:89:22)\n      at onPacket (/mnt/data1/nix/time/2025/01/13/cloud-deployment-eliza/node_modules/@discordjs/voice/dist/index.mjs:1435:12)\n      at onUdpMessage (/mnt/data1/nix/time/2025/01/13/cloud-deployment-eliza/node_modules/@discordjs/voice/dist/index.mjs:1571:19)\n      at emit (node:events:89:22)\n      at onMessage (/mnt/data1/nix/time/2025/01/13/cloud-deployment-eliza/node_modules/@discordjs/voice/dist/index.mjs:273:10)\n      at emit (node:events:92:22)\n      at <anonymous> (node:dgram:170:22)\n```\n", "CLOSED", 0, "jmikedupont2", "2025-03-16T12:37:39Z", "2025-03-21T07:42:49Z", "2025-03-21T07:42:48Z", "elizaos/eliza", "2025-04-14 21:55:06"]
["I_kwDOMT5cIs6uMI_z", 3949, "Twitter Client Not Initializing with Agent", "The twitter clients work with the eliza-starter, but not with the main Eliza install. That's pretty much it, and I can't figure out why. Not sure why there are two different repos like this either.", "CLOSED", 0, "small-talk", "2025-03-15T18:21:26Z", "2025-03-20T01:10:38Z", "2025-03-20T01:10:38Z", "elizaos/eliza", "2025-04-14 21:55:06"]
["I_kwDOMT5cIs6uI5im", 3936, "feat: upload .env file to webui configurator", "ability to upload / drag and drop a .env file to automatically populate secrets with", "CLOSED", 0, "madjin", "2025-03-15T01:11:24Z", "2025-04-18T09:05:42Z", "2025-04-18T09:05:42Z", "elizaos/eliza", "2025-04-14 21:55:06"]
["I_kwDOMT5cIs6t65cr", 3914, "Usage of typebox for safety", "Feature Request: Adopt TypeBox for Type Safety in elizaos/eliza\nIs your feature request related to a problem? Please describe.\nYes, this feature request addresses the challenge of ensuring data integrity when handling dynamic inputs in elizaos/eliza, such as API responses, user inputs, or LLM-generated JSON. Without proper validation, malformed data can lead to runtime errors, inconsistent behavior, or bugs that are hard to debug. For example, if eliza processes a JSON response expecting a confidence field as a number between 0 and 1, but receives a string or out-of-range value, it could cause unexpected failures or incorrect logic.\nDescribe the solution you'd like\nI propose integrating TypeBox, a lightweight TypeScript library, to introduce type safety into eliza. TypeBox combines JSON schema validation with TypeScript type inference, providing both compile-time and runtime safety. Here\u2019s how it could work:\nDefine Schemas: Create TypeBox schemas for key data structures, such as API responses:\ntypescript\n\nimport { Type, Static } from '@sinclair/typebox';\n\nconst ElizaResponseSchema = Type.Object({\n  intent: Type.String(),\n  confidence: Type.Number({ minimum: 0, maximum: 1 }),\n  entities: Type.Array(Type.String())\n});\n\ntype ElizaResponse = Static<typeof ElizaResponseSchema>;\n\nValidate Data: Use TypeBox to validate incoming data at runtime:\ntypescript\n\nfunction validateElizaResponse(json: unknown): ElizaResponse {\n  const result = ElizaResponseSchema.safeParse(json);\n  if (!result.success) throw new Error(`Validation failed: ${result.error.message}`);\n  return result.data;\n}\n\nIntegrate: Apply this to a small component (e.g., API response parsing) to start, ensuring data integrity without disrupting existing workflows.\n\nThis solution ensures eliza processes data safely, reducing errors and improving reliability.\nDescribe alternatives you've considered  \nZod: Another popular schema validation library for TypeScript. While Zod offers similar features (type inference, runtime validation), it has a slightly larger footprint and a different syntax that might feel less JSON Schema-like compared to TypeBox. TypeBox\u2019s alignment with JSON Schema standards makes it more interoperable with existing systems.\n\nManual Type Guards: Writing custom type guards in TypeScript (e.g., isElizaResponse functions) can provide some safety but lacks the robustness of schema-based validation and doesn\u2019t scale well for complex data structures.\n\nNo Validation: Continuing without validation risks runtime errors, especially as eliza scales to handle more dynamic data sources, which could degrade user experience or system stability.\n\nAdditional Context\nTypeBox is lightweight (minimal overhead), widely used, and well-documented, making it an easy adoption for the Eliza team. It provides immediate benefits\u2014error prevention, improved developer productivity through TypeScript integration, and a foundation for scaling to more advanced validation or formal methods in the future. Starting with a small integration allows the team to evaluate its impact with minimal risk, paving the way for broader adoption across elizaos/eliza.\n\n", "CLOSED", 0, "jmikedupont2", "2025-03-13T17:15:46Z", "2025-03-20T02:26:21Z", "2025-03-20T02:26:21Z", "elizaos/eliza", "2025-04-14 21:55:06"]
["I_kwDOMT5cIs6qNs3D", 3514, "Port scanning error on Render", "Hi eveyone,\n\nI currently have a twitter Eliza agent working perfectly on the localhost but on render is returns a No Ports found error.\nI have try the following:\n- Change the SERVER_PORT to PORT in .env and render environment.... same error\n- added both SERVER_PORT and PORT to the environment variable, updated the index.ts to include process.env.PORT || SERVER_PORT || '3000'... same error.\n-I'd appreciate any help i can get or alternative for render deployment.", "CLOSED", 0, "Etette", "2025-02-15T21:11:52Z", "2025-03-20T09:51:02Z", "2025-03-20T09:51:02Z", "elizaos/eliza", "2025-04-14 21:55:06"]
["I_kwDOMT5cIs6pk8Ke", 3440, "RagKnowledge is cleaned up on runtime initialization", "**Is your feature request related to a problem? Please describe.**\n\nOur team developed a service to manage agent RagKnowledge, it interacts with the RagKnowledge instance under agent runtime directly\n\nwe support loading a txt/pdf file from a remote URL, and creating knowledge via ragKnowledge#processFile, at the moment we set the content.metadata.source to be the URL string, here is how the content file in db looks like in our case\n\n```json\n{\n   \"text\":\"I like txt file, because it's plain\\n\",\n   \"metadata\":{\n      \"type\":\"txt\",\n      \"source\":\"https://........./knowledge/test.txt\",\n      \"isShared\":false\n   }\n}\n```\n\nHowever we found in the recent change, that there is a cleanup operation to remove knowledge that's missing local source file \nhttps://github.com/elizaOS/eliza/blob/main/packages/core/src/runtime.ts#L560\n\nand this will clean up all the rag-knowledge that created from a remote file\n\n**Describe the solution you'd like**\n\nCan we either set some flag in the knowledge metadata or detect the source string format to prevent cleaning up such remote sourced knowledge, so that there is more flexibility in knowledge management\n\n**Describe alternatives you've considered**\n\n- we have considered touching a fake file or removing the source string from the metadata to bypass the cleanup, but none of those is an elegant or robust way\n\nI would like to hear what's your thoughts on this, or if there is some way to avoid such knowledge from being cleaned up without changing the current logic, cheers\n", "CLOSED", 0, "JustinFeng", "2025-02-11T10:58:04Z", "2025-03-20T02:30:56Z", "2025-03-20T02:30:55Z", "elizaos/eliza", "2025-04-14 21:55:06"]
["I_kwDOMT5cIs6o-1wJ", 3318, "Add template system documentation to docs", "**Is your feature request related to a problem? Please describe.**\nTemplate system and hydrating it seems to be part of the core challenges of building AI agents but atm there's little to no documentation about it.\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\nAdd new page to docs about template system. What standard is it following if any,  what kind of macros are available OOB. How to expand macros and maybe add a couple of examples to there or where to find out more. \n**Describe the solution you'd like**\n\n<!-- A clear and concise description of what you want to happen. -->\n\n**Describe alternatives you've considered**\n\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\n\n**Additional context**\n\n<!-- Add any other context or screenshots about the feature request here. -->\n", "OPEN", 0, "yaruno", "2025-02-06T09:50:47Z", "2025-04-18T18:34:00Z", null, "elizaos/eliza", "2025-04-14 21:55:06"]
["I_kwDOMT5cIs6lPYEE", 1949, "New plugins/actions not available to existing users", "**Describe the bug**\r\n\r\nAdding a new plugin (e.g. web-search) requires to delete the sqlite database for the plugin actions to be visible to existing users.\r\n\r\n\r\n**To Reproduce**\r\n\r\n- Start a fresh project with eliza-starter\r\n- Interact with the character\r\n- Enable a new plugin (e.g. web-search)\r\n- Although the action is registered, the agent complains it can't search the web\r\n- Delete the sqllite database and restart\r\n- Now the agent is happy to search the web\r\n\r\n**Expected behavior**\r\n\r\nI'd expect that the plugin would be available to all users after a service restart.\r\n", "CLOSED", 0, "eschnou", "2025-01-07T09:00:19Z", "2025-03-22T08:18:54Z", "2025-01-12T10:45:00Z", "elizaos/eliza", "2025-04-14 21:55:06"]
["I_kwDOMT5cIs6wSIzm", 4105, "quickstart guide instructions inaccurate/outdated", "Describe the bug\n\ndependency not found\uff08npm error notarget No matching version found for @elizaos/plugin-sql@^0.25.6.\uff09\n\nuse fellow cmd\uff1a\nnpm install -g @elizaos/cli@latest\n\nget error\uff1a\nnpm install -g @elizaos/cli@latest\n\nTo Reproduce\n\nExpected behavior\n\nScreenshots\n\nAdditional context\n\nA user pointed out that You need to use @beta on the package name to solve this bug. This should be updated on the quickstart guide on eliza.how", "CLOSED", 0, "sw2347", "2025-03-29T00:06:15Z", "2025-03-29T20:21:04Z", "2025-03-29T20:21:03Z", "elizaos/eliza", "2025-04-14 21:55:21"]
["I_kwDOMT5cIs6wE0yD", 4094, "not building on windows", "\n```\n@elizaos/client:build: $ bun run extract-version && vite build\n@elizaos/client:build: $ bash ./version.sh\n@elizaos/client:build: bun: command not found: bash\n@elizaos/client:build: error: script \"extract-version\" exited with code 1\n@elizaos/client:build: error: script \"build\" exited with code 1\n```", "OPEN", 0, "jmikedupont2", "2025-03-27T18:22:08Z", "2025-03-27T18:27:25Z", null, "elizaos/eliza", "2025-04-14 21:55:21"]
["I_kwDOMT5cIs6v3wyP", 4086, "Twitter: Authorization: Status is a duplicate.", "It appears that eliza is producing duplicate tweets and getting bounced but the error message is confusing\nand it should not produce duplicates.\n\n```\n[2025-03-26 19:28:25] ERROR: Error sending tweet; Bad response:\n    errors: [\n      {\n        \"message\": \"Authorization: Status is a duplicate. (187)\",\n        \"locations\": [\n          {\n            \"line\": 18,\n            \"column\": 3\n          }\n        ],\n        \"path\": [\n          \"create_tweet\"\n        ],\n        \"extensions\": {\n          \"name\": \"AuthorizationError\",\n          \"source\": \"Client\",\n          \"code\": 187,\n          \"kind\": \"Permissions\",\n          \"tracing\": {\n            \"trace_id\": \"70abb4ef4d29f118\"\n          }\n        },\n        \"code\": 187,\n        \"kind\": \"Permissions\",\n        \"name\": \"AuthorizationError\",\n        \"source\": \"Client\",\n        \"tracing\": {\n          \"trace_id\": \"70abb4ef4d29f118\"\n        }\n      }\n    ]\n    data: {}\n[2025-03-26 19:28:25] ERROR: Error posting tweet:\n    message: \"(TypeError) Cannot read properties of null (reading 'rest_id')\"\n    stack: [\n      \"TypeError: Cannot read properties of null (reading 'rest_id')\",\n      \"at callback (file:///mnt/data1/nix/time/2025/03/14/cloud-deployment-eliza/packages/plugin-twitter/dist/index.js:8646:34)\",\n      \"at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\",\n      \"at async postGeneratedHandler (file:///mnt/data1/nix/time/2025/03/14/cloud-deployment-eliza/packages/cli/dist/chunk-RSA7S755.js:26649:5)\",\n      \"at async events (file:///mnt/data1/nix/time/2025/03/14/cloud-deployment-eliza/packages/cli/dist/chunk-RSA7S755.js:26781:7)\",\n      \"at async Promise.all (index 0)\",\n      \"at async AgentRuntime.emitEvent (file:///mnt/data1/nix/time/2025/03/14/cloud-deployment-eliza/packages/cli/dist/chunk-RSA7S755.js:27963:9)\"\n    ]\n\n```", "CLOSED", 0, "jmikedupont2", "2025-03-26T19:37:46Z", "2025-03-29T16:44:58Z", "2025-03-29T16:44:58Z", "elizaos/eliza", "2025-04-14 21:55:21"]
["I_kwDOMT5cIs6vsQe5", 4074, "\"Authorization: Status is a duplicate. (187)\",", "```\n2025-03-25 19:50:37] INFO: No settings state found for server 1883025815090372608\n[2025-03-25 19:50:37] ERROR: Error sending tweet; Bad response:\n    errors: [\n      {\n        \"message\": \"Authorization: Status is a duplicate. (187)\",\n        \"locations\": [\n          {\n            \"line\": 18,\n            \"column\": 3\n          }\n        ],\n        \"path\": [\n          \"create_tweet\"\n        ],\n        \"extensions\": {\n          \"name\": \"AuthorizationError\",\n          \"source\": \"Client\",\n          \"code\": 187,\n          \"kind\": \"Permissions\",\n          \"tracing\": {\n            \"trace_id\": \"04b712740fc18d04\"\n          }\n        },\n        \"code\": 187,\n        \"kind\": \"Permissions\",\n        \"name\": \"AuthorizationError\",\n        \"source\": \"Client\",\n        \"tracing\": {\n          \"trace_id\": \"04b712740fc18d04\"\n        }\n      }\n    ]\n    data: {}\n[2025-03-25 19:50:37] ERROR: Error posting tweet:\n    message: \"(TypeError) Cannot read properties of null (reading 'rest_id')\"\n    stack: [\n      \"TypeError: Cannot read properties of null (reading 'rest_id')\",\n      \"at callback (file:///app/packages/plugin-twitter/dist/index.js:8649:34)\",\n      \"at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\",\n      \"at async postGeneratedHandler (file:///app/packages/cli/dist/chunk-ZQLMO6Y7.js:26597:5)\",\n      \"at async events (file:///app/packages/cli/dist/chunk-ZQLMO6Y7.js:26728:7)\",\n      \"at async Promise.all (index 0)\",\n      \"at async AgentRuntime.emitEvent (file:///app/packages/cli/dist/chunk-ZQLMO6Y7.js:27910:9)\"\n    ]\n```", "CLOSED", 0, "jmikedupont2", "2025-03-25T19:53:45Z", "2025-03-26T17:46:45Z", "2025-03-26T17:46:44Z", "elizaos/eliza", "2025-04-14 21:55:21"]
["I_kwDOMT5cIs6vrCSB", 4070, "Cannot type spaces in GUI room name field during room creation", "", "CLOSED", 0, "tcm390", "2025-03-25T17:37:34Z", "2025-03-26T01:15:47Z", "2025-03-26T01:15:47Z", "elizaos/eliza", "2025-04-14 21:55:21"]
["I_kwDOMT5cIs6vrBsE", 4069, "Agent statuses are not updating in GUI room", "", "CLOSED", 0, "tcm390", "2025-03-25T17:36:37Z", "2025-03-26T01:15:40Z", "2025-03-26T01:15:40Z", "elizaos/eliza", "2025-04-14 21:55:21"]
["I_kwDOMT5cIs6vWTK6", 4054, "Twitter agent is not replying to some of the accounts mentioned in TWITTER_TARGET_USERS  in .env file", "I have a list of 52 twitter accounts mentioned in TWITTER_TARGET_USERS .env variable. but the twitter agent only replies to only 15-20 of them. can anyone help me to solve this?", "OPEN", 0, "JimiPatel2023", "2025-03-24T03:13:39Z", "2025-03-24T03:14:09Z", null, "elizaos/eliza", "2025-04-14 21:55:21"]
["I_kwDOMT5cIs6vSLDI", 4049, "AI_LoadAPIKeyError: Anthropic API key is missing. Pass it using the 'apiKey' parameter or the ANTHROPIC_API_KEY", "```\n2025-03-22 22:45:31] INFO: [useModel] TEXT_EMBEDDING completed in 0.03ms\nJoining channel: General\nError selecting or joining a voice channel: 1416 |   get voiceAdapterCreator() {\n1417 |     return methods => {\n1418 |       this.client.voice.adapters.set(this.id, methods);\n1419 |       return {\n1420 |         sendPayload: data => {\n1421 |           if (this.shard.status !== Status.Ready) return false;\n                          ^\nTypeError: undefined is not an object (evaluating 'this.shard.status')\n      at sendPayload (/app/node_modules/discord.js/src/structures/Guild.js:1421:20)\n      at createVoiceConnection (/app/node_modules/@discordjs/voice/dist/index.mjs:2078:102)\n      at <anonymous> (/app/packages/plugin-discord/dist/index.js:2658:24)\n      at joinChannel (/app/packages/plugin-discord/dist/index.js:2647:21)\n      at <anonymous> (/app/packages/plugin-discord/dist/index.js:3148:20)\n\n[2025-03-22 22:45:32] INFO: Successfully started 1 agents from project\nServing static assets from the client dist path\n[2025-03-22 22:45:32] INFO: Client build path: /app/packages/cli/dist\n[2025-03-22 22:45:32] INFO: Server started at http://localhost:3000\n[2025-03-22 22:45:32] INFO (Str Introspector $SOLFUNMEME): Creating world:\n    id: \"ee07ef86-47e3-068b-afd1-a1336dba76db\"\n    serverId: \"1029599029258108998\"\n    agentId: \"1ee9e4ad-f1a9-0946-8498-edce550b222c\"\n[2025-03-22 22:45:32] INFO: World ee07ef86-47e3-068b-afd1-a1336dba76db created successfully.\n[2025-03-22 22:45:33] INFO: Handling server sync event for server: Str Introspector $SOLFUNMEME\n[2025-03-22 22:45:35] INFO: Initialized settings config for server 1029599029258108998\n[2025-03-22 22:47:01] INFO: [useModel] TEXT_EMBEDDING completed in 0.03ms\n[2025-03-22 22:47:01] ERROR: OpenAI API error: 401 - Unauthorized\n[2025-03-22 22:47:01] INFO: [useModel] TEXT_EMBEDDING completed in 102.35ms\n14 |   constructor({\n15 |     name: name14,\n16 |     message,\n17 |     cause\n18 |   }) {\n19 |     super(message);\n         ^\nAI_LoadAPIKeyError: Anthropic API key is missing. Pass it using the 'apiKey' parameter or the ANTHROPIC_API_KEY environment variable.\n      cause: undefined,\n vercel.ai.error: true,\n vercel.ai.error.AI_LoadAPIKeyError: true,\n\n      at new _AISDKError (/app/node_modules/@ai-sdk/provider/dist/index.mjs:19:5)\n[2025-03-22 22:47:01] WARN: PROVIDERS Provider took 3ms to respond\n[2025-03-22 22:47:01] WARN: ENTITIES Provider took 14ms to respond\n```", "OPEN", 0, "jmikedupont2", "2025-03-22T22:49:05Z", "2025-03-25T04:08:09Z", null, "elizaos/eliza", "2025-04-14 21:55:21"]
["I_kwDOMT5cIs6vE46c", 4034, "Golang port", "Eliza is awesome idea but I think nodejs have some issue with performance, so if you have any plan to build another version of eliza in golang maybe I can help.", "CLOSED", 0, "imduchuyyy", "2025-03-21T05:17:24Z", "2025-03-25T16:58:48Z", "2025-03-25T04:17:11Z", "elizaos/eliza", "2025-04-14 21:55:21"]
["I_kwDOMT5cIs6uqvPI", 3989, "fix: Getting started instruction issues", "## `npm install -g @elizaos/cli`\n\n### Where Found\n\n- https://eliza.how/docs/quickstart\n- https://eliza.how/docs/faq\n- https://eliza.how/docs/intro\n\n```\neliza-v2/test \u00bb npm install -g @elizaos/cli\nnpm error code ETARGET\nnpm error notarget No matching version found for @elizaos/plugin-sql@^0.25.6.\nnpm error notarget In most cases you or one of your dependencies are requesting\nnpm error notarget a package version that doesn't exist.\nnpm error A complete log of this run can be found in: /home/jin/.npm/_logs/2025-03-19T04_34_02_115Z-debug-0.log\n```\n\n> Note, tested this too: eliza-v2/test \u00bb bun install -g @elizaos/cli\n> bun add v1.2.5 (013fdddc)\n> error: No version matching \"^0.25.6\" found for specifier \"@elizaos/plugin-sql\" (but package exists)\n> error: @elizaos/plugin-sql@^0.25.6 failed to resolve\n\nTest on machine 2 (debian bookworm)\n\n```\n\u279c  test2 npm install -g @elizaos/cli\nnpm error code ETARGET\nnpm error notarget No matching version found for @elizaos/plugin-sql@^0.25.6.\nnpm error notarget In most cases you or one of your dependencies are requesting\nnpm error notarget a package version that doesn't exist.\nnpm error A complete log of this run can be found in: /home/jintern/.npm/_logs/2025-03-19T04_41_19_499Z-debug-0.log\n```\n\n---\n\n## `npx elizaos start`\n\n### Where Found\n\n- https://eliza.how/docs/quickstart\n- https://eliza.how/docs/faq\n- https://eliza.how/docs/intro\n\n\n```\ncode/eliza-v2 \u00bb npx elizaos start\n\nVersion: 1.0.0-beta.0\nStartup successful!\nGo to the dashboard at http://localhost:3000\n\n[2025-03-19 04:13:50] INFO: Using default Eliza character with all plugins\n[2025-03-19 04:13:51] INFO: Plugin @elizaos/plugin-local-ai not installed, installing into /home/jin/code/eliza-v2...\nbun add v1.2.5 (013fdddc)\n  \ud83d\udd0d Resolving [1/66] [2025-03-19 04:13:51] INFO: Installing plugin: @elizaos/plugin-local-ai\n\ninstalled @elizaos/plugin-local-ai@1.0.0-beta.0\n\n410 packages installed [3.78s]\n\nBlocked 3 postinstalls. Run `bun pm untrusted` for details.\n{\"level\":50,\"time\":1742357635302,\"pid\":970489,\"hostname\":\"tank\",\"code\":\"ERR_MODULE_NOT_FOUND\",\"msg\":\"Failed to import plugin: @elizaos/plugin-local-ai\"}\n[2025-03-19 04:13:55] ERROR: Failed to run database migrations:\n```\n\neither that or:\n\n`npm error could not determine executable to run`\n\nfull error:\n\n```\n8 verbose argv \"exec\" \"--\" \"elizaos\" \"start\"\n9 verbose logfile logs-max:10 dir:/home/jintern/.npm/_logs/2025-03-19T04_39_54_057Z-\n10 verbose logfile /home/jintern/.npm/_logs/2025-03-19T04_39_54_057Z-debug-0.log\n11 silly logfile start cleaning logs, removing 2 files\n12 silly packumentCache heap:2197815296 maxSize:549453824 maxEntrySize:274726912\n13 silly logfile done cleaning log files\n14 http fetch GET 200 https://registry.npmjs.org/elizaos 209ms (cache updated)\n15 verbose stack Error: could not determine executable to run\n15 verbose stack     at getBinFromManifest (/home/jintern/.nvm/versions/node/v23.7.0/lib/node_modules/npm/node_modules/libnpmexec/lib/get-bin-from-manifest.js:17:23)\n15 verbose stack     at exec (/home/jintern/.nvm/versions/node/v23.7.0/lib/node_modules/npm/node_modules/libnpmexec/lib/index.js:202:15)\n15 verbose stack     at async Npm.exec (/home/jintern/.nvm/versions/node/v23.7.0/lib/node_modules/npm/lib/npm.js:207:9)\n15 verbose stack     at async module.exports (/home/jintern/.nvm/versions/node/v23.7.0/lib/node_modules/npm/lib/cli/entry.js:74:5)\n16 verbose pkgid elizaos@0.25.6-alpha.1\n17 error could not determine executable to run\n18 verbose cwd /home/jintern/Documents/v2/test\n```\n\nusing node 23", "CLOSED", 0, "madjin", "2025-03-19T04:46:31Z", "2025-03-29T20:23:18Z", "2025-03-29T20:23:16Z", "elizaos/eliza", "2025-04-14 21:55:21"]
["I_kwDOMT5cIs6uclKL", 3978, "How to debug remotely v2", "Here is how I debugged on v2\n\nbash\n`bun --verbose --inspect-brk=192.168.1.90:9229 ../cli/dist/index.js start`\n\njson\n```\n{\n  \"url\": \"ws://192.168.1.90:9229/hiva4rzuydf\",\n  \"name\": \"Attach bun\",\n  \"type\": \"bun\",\n  \"request\": \"attach\"\n}\n```\n", "OPEN", 0, "jmikedupont2", "2025-03-18T00:42:15Z", "2025-03-25T04:19:27Z", null, "elizaos/eliza", "2025-04-14 21:55:21"]
["I_kwDOMT5cIs6uVQ8k", 3972, "Raw newLine characters in tweets", "Agent creates tweets/Tweets reply/quotes with a raw '\\n'\n\nsee for instance\nhttps://x.com/CadmosThalia/status/1901603473935737323\nhttps://x.com/CadmosThalia/status/1901410605619392982\n", "OPEN", 0, "NBFinanceTech", "2025-03-17T12:01:24Z", "2025-03-24T14:09:13Z", null, "elizaos/eliza", "2025-04-14 21:55:21"]
["I_kwDOMT5cIs6uNMoS", 3952, "Discord Messages disappearing randomly", "**Describe the bug**\n\nMessages randomly disappear after they are sent to Discord using callback().\n\n**To Reproduce**\n\nJust send about 2-4 messages back to back, and you'd see some of those disappearing. Happens to me.\n\n**Expected behavior**\n\nAll messages to stay in chat.\n\n**Screenshots**\n\n[issue demonstration](https://drive.google.com/file/d/1BgjRX4UCPKi4Mk73WG7gnyfq--AdIxhm/view?usp=sharing)\n\n**Additional context**\n\n<!-- Add any other context about the problem here. -->\n", "OPEN", 0, "D3nii", "2025-03-16T01:39:40Z", "2025-03-25T04:11:47Z", null, "elizaos/eliza", "2025-04-14 21:55:21"]
["I_kwDOMT5cIs6t5BnL", 3912, "v2/autodoc fileUsageDoc is missing context", "The usage doc is only passing in the file name and the ai is hallucinating the rest. \n\n```\nDetermine multiple use cases for the provided code, and give examples of how to use the code:\n\n### Common Use Cases\n1. [First use case with code example]\n2. [Second use case with code example]\n\n### Best Practices\n- [Best practice 1]\n- [Best practice 2]\n\nFormat in markdown without adding any additional headers.\n\nFor file: actions/unfollowRoom.ts\n\nWith components:\n```\n\n", "OPEN", 0, "jmikedupont2", "2025-03-13T14:40:18Z", "2025-03-24T13:44:11Z", null, "elizaos/eliza", "2025-04-14 21:55:21"]
["I_kwDOMT5cIs6tRAji", 3885, "\u4e2d\u6587AI Agent \u793e\u533a\u4ea4\u6d41\u7fa4", "![Image](https://github.com/user-attachments/assets/1c9aaa31-227e-4568-9c5a-3cd24161e500)", "CLOSED", 0, "aiqubits", "2025-03-10T11:12:25Z", "2025-04-21T09:49:16Z", "2025-03-20T15:32:42Z", "elizaos/eliza", "2025-04-14 21:55:21"]
["I_kwDOMT5cIs6yaiIG", 4285, "Clarify contributing guide in docs vs for using framework", "we probably need to clarify in docs\nthat if you're looking to contribute to elizaos then people should install monorepo etc but they are just wanting to work on their agent etc; they should stick to using elizaos start / cli", "OPEN", 0, "wtfsayo", "2025-04-14T14:42:39Z", "2025-04-14T14:43:09Z", null, "elizaos/eliza", "2025-04-14 21:56:00"]
["I_kwDOMT5cIs6yV2X8", 4282, "V2 - `LOG_LEVEL=` env not responding", "**Describe the bug**\n\nWhen updating the .env `LOG_LEVEL`, the program does not change it's logging. Both in the .env file and the character secrets.\n\nTried `fatal`, `trace`, and `debug` with no luck.\n\n**To Reproduce**\n\nUpdated .env `LOG_LEVEL`\n\n**Additional context**\n\nVersion:\n\nBranch: v2-develop - `53132d264da8367d50a0370095a367cdefc25218`", "OPEN", 0, "Titan-Node", "2025-04-14T06:54:26Z", "2025-04-14T06:54:26Z", null, "elizaos/eliza", "2025-04-14 21:56:00"]
["I_kwDOMT5cIs6yy4Mz", 4303, "Ensure USE_LOCAL_AI is always true", "Hi team,\nI am wondering about \" Ensure USE_LOCAL_AI is always true\" in v2,\nin my small version I don't want to have local ai loaded.\nIf the user sets it to false, we should respect that.\n\n", "OPEN", 0, "jmikedupont2", "2025-04-16T13:34:31Z", "2025-04-16T15:40:00Z", null, "elizaos/eliza", "2025-04-16 23:03:54"]
["I_kwDOMT5cIs6yyqVg", 4302, "Task.World is redundant", "The world already is referenced from room and task references room, so we dont need to have world in task.\npackages/plugin-sql/src/schema/tasks.ts\n```\n worldId: uuid('world_id').references(() => worldTable.id, {\n   onDelete: 'cascade',\n }),\n\n```", "OPEN", 0, "jmikedupont2", "2025-04-16T13:14:06Z", "2025-04-16T15:41:02Z", null, "elizaos/eliza", "2025-04-16 23:03:54"]
["I_kwDOMT5cIs6yxIb9", 4299, "How can i handle the content response from the modell?", "i am getting the content from the prompt using llama_local model, but i don't want to use that content again in my future prompts based on {recentMessages}, e.g i said i want to swap 0.0001 Eth to USDT on Ethereum chain, the model give me content based on the swapTemplate but when i again prompt like just please swap it gives me the same content, from the recentMessages, how can i restrict the model so that it should not give content based on previous messages? here is the swapTemplate and action code:\n\n```\nexport const swapTemplate = `Respond with a JSON markdown block containing only the extracted values\n- Use default | null for any values that cannot be determined.\n\n{{recentMessages}}\n\n{{walletInfo}}\n\nGiven the recent messages and wallet info, extract the following information about the requested token swap in same chain:\n- Input token symbol.\n- Output token symbol.\n- Input token address. If the address is provided, it must be a valid Ethereum address starting with \"0x\" (the token being sold), default 0x0000000000000000000000000000000000000000.\n- Output token address. If the address is provided, it must be a valid Ethereum address starting with \"0x\" (the token being bought), default 0x0000000000000000000000000000000000000000.\n- Amount to swap: Must be a string representing the amount in ether (only number without coin symbol, e.g., \"0.1\")\n- Chain from chain to execute on swap\n- Slippage percentage value in numbers: default is 0.5\n\nRespond with a JSON markdown block containing only the extracted values. \nIf any field is not provided, use the default value. If no default value is specified, use null.\n \n\\`\\`\\`json\n{   \n    \"inputTokenSymbol\": string,\n    \"outputTokenSymbol\": string,\n    \"amount\": string,\n    \"chain\": \"ethereum\" | \"bsc\" | \"polygon\" | \"optimism\" | \"base\" | \"mode\" | \"zora\" | \"aurora\" | \"gnosis\" | \"mantle\" | \"avalanche\" | \"linea\" | \"blast\" | \"scroll\" | \"arbitrum\" | \"zksync era\" | \"polygon zkevm\" | \"moonriver\" | \"moonbeam\" | \"boba\" | \"fantom\" | \"metis\" | \"sei\" | \"taiko\" | \"fraxtal\" | \"celo\" | \"rootstock\" | \"gravity\" | \"klatyn\" | \"cronos\" | \"world chain\" | \"ink\" | \"lisk\" | \"abstract\" | \"unichain\" | \"b3\" | \"berachain\" | \"nirvana\" | \"sagaevm\" | \"maria chain\";\n    \"slippage\": number\n}\n\\`\\`\\`\n`;\n\n```\n\n```\nimport {\n    composeContext,\n    elizaLogger,\n    type HandlerCallback,\n    ModelClass,\n    type IAgentRuntime,\n    type Memory,\n    type State,\n    generateObjectDeprecated,\n} from \"@elizaos/core\";\nimport {\n    decodeFunctionData,\n    erc20Abi,\n    formatUnits,\n    parseUnits,\n    zeroAddress,\n    type Hex,\n} from \"viem\";\n\nimport {\n    evmWalletProvider,\n    initWalletProvider,\n    type WalletProvider,\n} from \"../providers/evmWallet\";\n\nimport { swapTemplate } from \"../templates\";\nimport { QuotePayload, RoutePayload, SupportedChain, SwapParams, SwapResponse } from \"../types\";\nimport { PonderAPIProvider } from \"../providers/ponder\";\nimport { swapExamplesSingleToken } from \"../utils/examples\";\nexport { swapTemplate };\n\nexport class SwapAction {\n    constructor(private walletProvider: WalletProvider) {}\n\n    async swapSingle(params: SwapParams): Promise<SwapResponse | string> {\n        elizaLogger.info(\"Single swap params same chain:\", params);\n        const fromAddress = this.walletProvider.getAddress();\n\n        const requiredFields = await this.checkRequiredParams(params);\n\n        if (requiredFields.length > 0) {\n            return requiredFields;\n        }\n\n        const requiredParams = await this.validateParams(params)\n\n        if (requiredParams.length > 0) {\n            return requiredParams;\n        }\n\n        const ponderProvider = new PonderAPIProvider();\n        const chains = await ponderProvider.getChains();\n\n        const blockExplorer = chains.find((chain) => chain.name.toLowerCase() === params.chain.toLowerCase())?.blockExplorer;\n\n        const inputChainId = String(await ponderProvider.getChainId(params.chain, chains));\n        const outputChainId = String(await ponderProvider.getChainId(params.chain, chains));\n\n        const resp: SwapResponse = {\n           fromChain: params.chain as SupportedChain,\n           toChain: params.chain as SupportedChain,\n           fromTokenSymbol: params.inputTokenSymbol,\n           toTokenSymbol: params.outputTokenSymbol,\n           fromToken: params.inputToken,\n           toToken: params.outputToken,\n           txHash: blockExplorer + \"tx/\",\n           recipient:fromAddress,\n           fromAmount: params.amount,\n           toAmount: \"\"\n        }\n\n        const publicClient = this.walletProvider.getPublicClient(\n            params.chain\n        );\n\n        let decimals;\n\n        if (params.inputToken === zeroAddress) {\n            decimals = 18;\n        } else {\n            decimals = await publicClient.readContract({\n                address: params.inputToken as `0x${string}`,\n                abi: erc20Abi,\n                functionName: \"decimals\",\n            });\n        }\n\n        params.amount = parseUnits(params.amount, decimals).toString();\n        \n        this.walletProvider.switchChain(params.chain);\n\n        const quotePayload: QuotePayload = {\n            fromChain: inputChainId,\n            toChain: outputChainId,\n            fromToken: [params.inputToken],\n            toToken: [params.outputToken],\n            fromAmount: [params.amount],\n            slippage: 0.5, //TODO: slippage fix now returning \"null\" in string form\n            fromAddress: fromAddress,\n            toAddress: fromAddress,\n            provider: \"\"\n        }\n\n        const quote = await ponderProvider.getQuote(quotePayload);\n        \n        if (!quote) {\n            throw new Error(\"No quote found for the given input\");\n        }\n\n        const routePayload: RoutePayload = {\n            fromChain: inputChainId,\n            toChain: outputChainId,\n            fromToken: [params.inputToken],\n            toToken: [params.outputToken],\n            fromAmount: [params.amount],\n            slippage: params.slippage,\n            fromAddress: fromAddress,\n            provider: quote.protocol,\n            routeId: quote.routeId\n        }\n\n        let route = await ponderProvider.getRoute(routePayload);\n\n        if (!route) {\n            throw new Error(\"No route found for the given quote\");\n        }\n\n        if (route.approvalTx) {\n            const approveAmount = BigInt(params.amount)\n            const token = await this.walletProvider.formatAddress(params.inputToken)\n\n            const { args } = decodeFunctionData({\n                abi: erc20Abi,\n                data: route.approvalTx[0].data\n              })\n\n            const spender = await this.walletProvider.formatAddress(args[0] as string)\n\n            const allowance = await this.walletProvider.checkERC20Allowance(\n                params.chain,\n                token,\n                fromAddress,\n                spender\n            );\n            if (allowance < approveAmount) {\n                elizaLogger.info(\n                    `Increasing ERC20 token ${params.inputTokenSymbol} allowance for ${route.protocol}. ${approveAmount - allowance} more needed`\n                );\n                const txHash = await this.walletProvider.approveERC20(\n                    params.chain,\n                    token,\n                    spender,\n                    approveAmount\n                );\n                await publicClient.waitForTransactionReceipt({\n                    hash: txHash,\n                });\n\n                elizaLogger.info(`successfully approved ${params.inputTokenSymbol} for swap`);\n            }\n        }\n\n        route = await ponderProvider.getRoute(routePayload);\n\n        if (!route.executionTx) {\n            throw new Error(\"No execution data found for the given route\");\n        }\n\n        const options: { gas?: bigint; gasPrice?: bigint; data?: Hex } = {}\n        \n        options.gas = BigInt(route.executionTx.gasLimit);\n        options.gasPrice = BigInt(route.executionTx.gasPrice);\n        options.data = route.executionTx.data;\n\n        const txHash = await this.walletProvider.swapToken(params.chain, route.executionTx.to, BigInt(route.executionTx.value), options)\n\n        if (!txHash || txHash === \"0x\") {\n            throw new Error(\"Get transaction hash failed\");\n        }\n\n        // wait for the transaction to be confirmed\n        await publicClient.waitForTransactionReceipt({\n            hash: txHash,\n        });\n\n        const toAmount = formatUnits(quote.transactionDetails[0].toToken[0].toAmount,  quote.transactionDetails[0].toToken[0].decimals);\n\n        resp.toAmount = toAmount.toString(); \n        resp.txHash = resp.txHash + txHash;\n\n        return resp;\n\n    }\n\n    async checkRequiredParams(params: SwapParams): Promise<string> {\n\n        let requiredFieldsText = \"\";\n\n        if (!params.inputTokenSymbol) {\n            requiredFieldsText += `- inputTokenSymbol: Symbol of the input token, like ETH\\n`\n        }\n\n        if (!params.outputTokenSymbol) {\n            requiredFieldsText += `- outputTokenSymbol: Symbol of the output token, like USDT\\n`\n        }\n\n        if (!params.inputToken) {\n            requiredFieldsText += `- inputToken: Address of the input token\\n`\n        }\n\n        if (!params.outputToken) {\n            requiredFieldsText += `- outputToken: Address of the output token\\n`\n        }\n\n        if (!params.amount) {\n            requiredFieldsText += `- amount: Amount of input token to swap\\n`\n        }\n\n        if (!params.chain) {\n            requiredFieldsText += `- chain: Chain to swap on\\n`\n        }\n\n        return requiredFieldsText;\n\n    }\n\n    async validateParams(params: SwapParams): Promise<string> {\n\n        let notValidParamsText = \"\"; \n\n        const nativeToken = this.walletProvider.chains[params.chain].nativeCurrency.symbol;\n\n        if (params.inputTokenSymbol.toLowerCase() === params.outputTokenSymbol.toLowerCase()) {\n            notValidParamsText = 'Cannot Swap Same Token, symbols are same'\n            return notValidParamsText;\n        }\n\n        if (params.inputTokenSymbol.toLowerCase() !== nativeToken.toLowerCase() && params.inputToken.toLowerCase() === zeroAddress) {\n            notValidParamsText = `- inputToken: Address of the input token\\n`\n            return notValidParamsText;\n        }\n\n        if (params.outputTokenSymbol.toLowerCase() !== nativeToken.toLowerCase() && params.outputToken.toLowerCase() === zeroAddress) {\n            notValidParamsText = `- outputToken: Address of the output token\\n`\n            return notValidParamsText;\n        }\n\n        return notValidParamsText;\n\n    }\n}\n\nexport const swapSingleAction = {\n    name: \"SWAP_SINGLE\",\n    description: \"Use this action when user swap from evm chain to evm chain, from chain and to chain should not be solana or movement chain.\",\n    handler: async (\n        runtime: IAgentRuntime,\n        message: Memory,\n        state: State,\n        _options: Record<string, unknown>,\n        callback?: HandlerCallback\n    ) => {\n        elizaLogger.info(\"Starting swap action...\");\n\n        if (message.content.source === \"direct\") {\n            // continue\n        } else {\n            callback?.({\n                text: \"i can't do that for you.\",\n                content: { error: \"Swap single not allowed\" },\n            });\n            return false;\n        }\n\n        \n        // Initialize or update state\n        let currentState = state;\n        if (!currentState) {\n            currentState = (await runtime.composeState(message)) as State;\n        } else {\n            currentState = await runtime.updateRecentMessageState(currentState);\n        }\n        state.walletInfo = await evmWalletProvider.get(\n            runtime,\n            message,\n            currentState\n        );\n\n        // Compose swap context\n        const swapContext = composeContext({\n            state: currentState,\n            template: swapTemplate,\n        });\n        const content = await generateObjectDeprecated({\n            runtime,\n            context: swapContext,\n            modelClass: ModelClass.LARGE,\n        });\n\n        elizaLogger.debug(\"Swap evm single token on same chain content:\", content);\n\n        const slippage = (!content?.slippage || content.slippage === null || content.slippage === \"null\") ? 0.5 : Number(content.slippage);\n\n        const walletProvider = initWalletProvider(runtime);\n        const action = new SwapAction(walletProvider);\n        const swapParams: SwapParams = {\n            inputTokenSymbol: content.inputTokenSymbol,\n            outputTokenSymbol: content.outputTokenSymbol,\n            inputToken: content.inputToken,\n            outputToken: content.outputToken,\n            amount: content.amount,\n            chain: content.chain,\n            slippage: slippage,\n        };\n        try {\n            const swapResp = await action.swapSingle(swapParams);\n\n            if (typeof swapResp === \"string\") {\n                callback?.({\n                    text: `You are trying to do token swap on same evm chain, but following fields are missing or not correct:\\n${swapResp}`,\n                    content: { error: swapResp }\n                });\n                return false;\n            }\n\n            callback?.({\n                text: `Successfully swapped ${swapResp.fromAmount} ${swapResp.fromTokenSymbol} to ${swapResp.toAmount} ${swapResp.toTokenSymbol} to receipent address ${swapResp.recipient} on ${swapResp.toChain} chain\\nTransaction Hash: ${swapResp.txHash}`,\n                content: { ...swapResp },\n            });\n\n            return true;\n        } catch (error) {\n            elizaLogger.error(\"Error during single token swap:\", error.message);\n            callback?.({\n                text: `Swap failed: ${error.message}`,\n                content: { error: error.message }\n            });\n            return false;\n        }\n    },\n    template: swapTemplate,\n    \n    validate: async (runtime: IAgentRuntime) => {\n        const privateKey = runtime.getSetting(\"WALLET_PRIVATE_KEY\");\n        return typeof privateKey === \"string\" && privateKey.startsWith(\"0x\");\n    },\n    examples: swapExamplesSingleToken,\n    similes: [\"SWAP\", \"TOKEN_SWAP\", \"SWAP_TOKEN\", \"SWAP_FUND\", \"CONVERT\", \"EXCHANGE_TOKEN\", \"TOKEN_CONVERSION\"]\n\n};\n\n\n```", "OPEN", 0, "transformer98", "2025-04-16T10:37:20Z", "2025-04-16T16:43:55Z", null, "elizaos/eliza", "2025-04-16 23:03:54"]
["I_kwDOMT5cIs6yu0eY", 4298, "Unable to use GOAT Plugin", "**Describe the bug**\n\n<!-- A clear and concise description of what the bug is. -->\nThe GOAT plugin https://github.com/elizaos-plugins/plugin-goat doesnt work after eliza separation of plugins .\n\n**To Reproduce**\n\n<!-- Steps to reproduce the behavior. -->\n```\n1. Install the goat plugin in current stable version of elizaos -> npx elizaos plugins install @elizaos-plugins/plugin-goat\n2. Add \"plugins\": [\"@elizaos-plugins/plugin-goat\"] to the characterfile and provide appropriate secrets.\n3. Run the eliza with the character file. Even though the plugin is activated, the actions are not triggered.\n\n```\n\nThe reason i found was with GOAT plugin returning a async function instead of a json structure.\nhttps://github.com/elizaos-plugins/plugin-goat/blob/main/src/index.ts#L5.\n\nBecause of this https://github.com/elizaOS/eliza/blob/main/agent/src/index.ts#L390 the current elizaos logic doesnt handle this plugin properly.\nThis type of async exported plugins can work if in eliza, the code changes to \n```\nawait importedPlugin.default(secrets) instead of importedPlugin.default in above mentioned line L390\n```\n\n**Expected behavior**\n\nPlugins with Async exported functions has to work.\n\n", "OPEN", 0, "praveen-kaia", "2025-04-16T06:41:11Z", "2025-04-16T08:08:30Z", null, "elizaos/eliza", "2025-04-16 23:03:54"]
["I_kwDOMT5cIs6y7eAK", 4309, "tried on a real ubuntu (not vm)", "```\nbun install && bun run build\nbun install v1.2.10 (db2e7d7f)\n  \ud83d\ude9a @babel/plugin-bugfix-firefox-class-in-computed-class-key..\n  \ud83d\ude9a @babel/plugin-bugfix-safari-class-field-initializer-scope.\n  \ud83d\ude9a @babel/plugin-bugfix-v8-spread-parameters-in-optional-chai\n  \u2699\ufe0f  youtube-dl-execnux-x64-cuda... node:internal/deps/undici/undici:13484\n      Error.captureStackTrace(err);\n            ^\n\nTypeError: fetch failed\n    at node:internal/deps/undici/undici:13484:13\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async getBinary (/home/xkcdhat/Documents/Github/eliza/node_modules/youtube-dl-exec/scripts/postinstall.js:24:18)\n    at async Promise.all (index 0)\n    at async installBinary (/home/xkcdhat/Documents/Github/eliza/node_modules/youtube-dl-exec/scripts/postinstall.js:37:20) {\n  [cause]: ConnectTimeoutError: Connect Timeout Error (attempted address: api.github.com:443, timeout: 10000ms)\n      at onConnectTimeout (node:internal/deps/undici/undici:2602:28)\n      at Immediate._onImmediate (node:internal/deps/undici/undici:2583:11)\n      at process.processImmediate (node:internal/timers:511:21) {\n    code: 'UND_ERR_CONNECT_TIMEOUT'\n  }\n}\n\nNode.js v23.3.0\n\nerror: postinstall script from \"youtube-dl-exec\" exited with 1\n```", "OPEN", 0, "wtfsayo", "2025-04-17T09:22:53Z", "2025-04-17T09:22:53Z", null, "elizaos/eliza", "2025-04-17 23:04:00"]
["I_kwDOMT5cIs6zHnkA", 4319, "Image analysis fails with OpenAI API 404 error in @elizaos/plugin-openai using discord", "Describe the bug\n\nWhen trying to analyze an image using the @elizaos/plugin-openai, the process fails with a 404 error from the OpenAI API. This appears during image attachment processing in a Discord plugin.\n\n\u2e3b\n\nTo Reproduce\n\t1.\tStart the ElizaOS agent with the Discord plugin enabled.\n\t2.\tSend an image to the Discord channel monitored by the agent.\n\t3.\tObserve the error logs in the console.\n\n\u2e3b\n\nExpected behavior\n\nThe image should be successfully processed by the plugin using the OpenAI API, and the result should be handled or displayed accordingly.\n\nAdditional context\n\t\u2022\tPlugin versions:\n\t\u2022\t@elizaos/plugin-openai@1.0.0-beta.32\n\t\u2022\t@elizaos/plugin-discord@1.0.0-beta.32\n\t\u2022\tRuntime: ElizaOS Agent via @elizaos/cli@1.0.0-beta.32\n\t\u2022\tPossibly related to a deprecated or incorrect endpoint in the image analysis feature (IMAGE_DESCRIPTION)\n\t\u2022\tThe error may indicate a missing route on OpenAI\u2019s side, or a wrong model/feature is being called.\n\n\nI'm using the 4o model", "CLOSED", 0, "standujar", "2025-04-18T14:52:47Z", "2025-04-18T15:14:05Z", "2025-04-18T15:14:05Z", "elizaos/eliza", "2025-04-18 19:38:30"]
["I_kwDOMT5cIs6zEmua", 4316, "Blue dot remains after skipping onboarding via close button", "When I close the onboarding instructions from the GUI without completing them step by step, a persistent blue dot appears on top of the interface. \n\n<img width=\"834\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d0daa604-2e4d-4492-ac71-eba0bcc63632\" />", "CLOSED", 0, "tcm390", "2025-04-18T08:01:18Z", "2025-04-18T08:35:36Z", "2025-04-18T08:35:36Z", "elizaos/eliza", "2025-04-18 19:38:30"]
["I_kwDOMT5cIs6zEVIk", 4315, "V2 - Group chat not working", "**Describe the bug**\nCannot use group chat, getting this js error.\n\n```\nUncaught TypeError: crypto.randomUUID is not a function\n    at handleSendMessage (room.tsx:369:18)\n```\n\nIf you delete this line and rebuild it works.\nhttps://github.com/elizaOS/eliza/blob/e8e4bd0585999e68daf09e0c65e4520041a0b077/packages/client/src/components/room.tsx#L369\n\n", "OPEN", 0, "Titan-Node", "2025-04-18T07:26:14Z", "2025-04-18T08:34:50Z", null, "elizaos/eliza", "2025-04-18 19:38:30"]
