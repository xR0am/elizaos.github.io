[
  {
    "contributor": "lalalune",
    "score": 0,
    "summary": "Lalalune is actively developing the project, focusing on integrating new features and collaborations from other repositories such as 'eliza' by ai16z and 'farcaster-neynar-client' by sayangel/eliza. Recent commits include merging pull requests, adding lock files for version control, and branch management to streamline the development process.",
    "avatar_url": "https://avatars.githubusercontent.com/u/18633264?u=8f2bca0a3cef958bd405ea89680a9b9a0ff38f06&v=4",
    "activity": {
      "code": {
        "total_commits": 6,
        "total_prs": 0,
        "commits": [
          {
            "sha": "ebd65c273a66189dc3740fdb8bed4f02eac01e4f",
            "message": "Merge pull request #874 from btspoony/tbh/plugin-flow\n\nfeat: Add Flow Blockchain plugin",
            "created_at": "2024-12-07T03:37:06Z",
            "additions": 4626,
            "deletions": 4,
            "changed_files": 41
          },
          {
            "sha": "42c8b7b6594e4b6125735447f10d6b566339cbf0",
            "message": "v0.1.5-alpha.5",
            "created_at": "2024-12-07T00:34:45Z",
            "additions": 37,
            "deletions": 38,
            "changed_files": 34
          },
          {
            "sha": "0f714abb9a51f2a124e32fbe1c39e045171fcb80",
            "message": "Merge branch 'main-add-lockfile'",
            "created_at": "2024-12-07T00:32:51Z",
            "additions": 266,
            "deletions": 89,
            "changed_files": 1
          },
          {
            "sha": "b478f82c4be2ae545818b352eb4fee77b6fc2535",
            "message": "Merge branch 'main' of https://github.com/ai16z/eliza",
            "created_at": "2024-12-07T00:32:47Z",
            "additions": 45081,
            "deletions": 7729,
            "changed_files": 669
          },
          {
            "sha": "c1c4456e4b4fcea5d980230c5e6836f2db85870c",
            "message": "add lock file",
            "created_at": "2024-12-07T00:32:23Z",
            "additions": 266,
            "deletions": 89,
            "changed_files": 1
          },
          {
            "sha": "cec95acb24b65bf3f2b2bd861cc7aeb57f40011e",
            "message": "Merge branch 'farcaster-neynar-client' of https://github.com/sayangel/eliza into HEAD",
            "created_at": "2024-12-07T00:17:16Z",
            "additions": 1771,
            "deletions": 235,
            "changed_files": 16
          }
        ],
        "pull_requests": []
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "renovate",
    "score": 0,
    "summary": "Renovate is actively updating AI/ML package dependencies, as evidenced by multiple pull requests focused on this task within the last 90 days. Additionally, there has been a chore-related update to the @rollup/plugin-terser dependency, ensuring that project dependencies remain current and optimized for performance.",
    "avatar_url": "https://avatars.githubusercontent.com/in/2740?v=4",
    "activity": {
      "code": {
        "total_commits": 0,
        "total_prs": 4,
        "commits": [],
        "pull_requests": [
          {
            "number": 886,
            "title": "fix(deps): update ai/ml packages",
            "state": "CLOSED",
            "merged": false,
            "created_at": "2024-12-07T03:05:48Z",
            "updated_at": "2024-12-07T06:13:55Z",
            "body": "This PR contains the following updates:\n\n| Package | Change | Age | Adoption | Passing | Confidence |\n|---|---|---|---|---|---|\n| [@anthropic-ai/sdk](https://redirect.github.com/anthropics/anthropic-sdk-typescript) | [`0.30.1` -> `0.32.1`](https://renovatebot.com/diffs/npm/@anthropic-ai%2fsdk/0.30.1/0.32.1) | [![age](https://developer.mend.io/api/mc/badges/age/npm/@anthropic-ai%2fsdk/0.32.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![adoption](https://developer.mend.io/api/mc/badges/adoption/npm/@anthropic-ai%2fsdk/0.32.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![passing](https://developer.mend.io/api/mc/badges/compatibility/npm/@anthropic-ai%2fsdk/0.30.1/0.32.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![confidence](https://developer.mend.io/api/mc/badges/confidence/npm/@anthropic-ai%2fsdk/0.30.1/0.32.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) |\n| [@huggingface/transformers](https://redirect.github.com/huggingface/transformers.js) | [`3.0.2` -> `3.1.1`](https://renovatebot.com/diffs/npm/@huggingface%2ftransformers/3.0.2/3.1.1) | [![age](https://developer.mend.io/api/mc/badges/age/npm/@huggingface%2ftransformers/3.1.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![adoption](https://developer.mend.io/api/mc/badges/adoption/npm/@huggingface%2ftransformers/3.1.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![passing](https://developer.mend.io/api/mc/badges/compatibility/npm/@huggingface%2ftransformers/3.0.2/3.1.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![confidence](https://developer.mend.io/api/mc/badges/confidence/npm/@huggingface%2ftransformers/3.0.2/3.1.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) |\n| [openai](https://redirect.github.com/openai/openai-node) | [`4.73.0` -> `4.76.0`](https://renovatebot.com/diffs/npm/openai/4.73.0/4.76.0) | [![age](https://developer.mend.io/api/mc/badges/age/npm/openai/4.76.0?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![adoption](https://developer.mend.io/api/mc/badges/adoption/npm/openai/4.76.0?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![passing](https://developer.mend.io/api/mc/badges/compatibility/npm/openai/4.73.0/4.76.0?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![confidence](https://developer.mend.io/api/mc/badges/confidence/npm/openai/4.73.0/4.76.0?slim=true)](https://docs.renovatebot.com/merge-confidence/) |\n\n---\n\n### Release Notes\n\n<details>\n<summary>anthropics/anthropic-sdk-typescript (@&#8203;anthropic-ai/sdk)</summary>\n\n### [`v0.32.1`](https://redirect.github.com/anthropics/anthropic-sdk-typescript/blob/HEAD/CHANGELOG.md#0321-2024-11-05)\n\nFull Changelog: [sdk-v0.32.0...sdk-v0.32.1](https://redirect.github.com/anthropics/anthropic-sdk-typescript/compare/sdk-v0.32.0...sdk-v0.32.1)\n\n##### Bug Fixes\n\n-   **bedrock:** don't mutate request body inputs ([f83b535](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/f83b53520262219229cecc388f95d92be83c09d5))\n-   **vertex:** don't mutate request body inputs ([e9a82e5](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/e9a82e56f0d7fff956c2ebd19e103a190f8beb83))\n\n### [`v0.32.0`](https://redirect.github.com/anthropics/anthropic-sdk-typescript/blob/HEAD/CHANGELOG.md#0320-2024-11-04)\n\nFull Changelog: [sdk-v0.31.0...sdk-v0.32.0](https://redirect.github.com/anthropics/anthropic-sdk-typescript/compare/sdk-v0.31.0...sdk-v0.32.0)\n\n##### Features\n\n-   **api:** add new haiku model ([#&#8203;587](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/587)) ([983b13c](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/983b13c9e4f55b832fc4fddfd46bed89756d745e))\n\n##### Bug Fixes\n\n-   don't require deno to run build-deno ([#&#8203;586](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/586)) ([0e431d6](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/0e431d61ec318aae09687dee0bfb922ccb8ddd15))\n-   **types:** add missing token-counting-2024-11-01 ([#&#8203;583](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/583)) ([13d629c](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/13d629c9b444a32b69729df7792199556a2b95f2))\n\n##### Chores\n\n-   remove unused build-deno condition ([#&#8203;585](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/585)) ([491e8fe](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/491e8fe28745aeb55217809f94ad4e37900f4675))\n\n### [`v0.31.0`](https://redirect.github.com/anthropics/anthropic-sdk-typescript/blob/HEAD/CHANGELOG.md#0310-2024-11-01)\n\nFull Changelog: [sdk-v0.30.1...sdk-v0.31.0](https://redirect.github.com/anthropics/anthropic-sdk-typescript/compare/sdk-v0.30.1...sdk-v0.31.0)\n\n##### Features\n\n-   **api:** add message token counting & PDFs support ([#&#8203;582](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/582)) ([b593837](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/b593837ae2d320414a26b5ec53aa6d3f30a3e6bc))\n\n##### Bug Fixes\n\n-   **countTokens:** correctly set beta header ([1680757](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/16807572af923831e384869a0a6ccccaa8dbec84))\n-   **internal:** support pnpm git installs ([#&#8203;579](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/579)) ([86bb102](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/86bb102ce33346930a8b0a553a909fcc7d964a36))\n-   **types:** add missing token-counting-2024-11-01 ([aff1546](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/aff1546cd84ce50a52d17bcdcaba54e60e92955a))\n\n##### Reverts\n\n-   disable isolatedModules and change imports ([#&#8203;575](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/575)) ([2c3b176](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/2c3b176fc551c21abef240b4fa6a98d33ca52048))\n\n##### Chores\n\n-   **internal:** update spec version ([#&#8203;571](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/571)) ([5760012](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/576001245f0b5222cb9b17fafb8619f68d51bec3))\n\n##### Documentation\n\n-   **readme:** minor typo fixes ([#&#8203;577](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/577)) ([8412854](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/8412854c05837cdb8b8ff898bef2a4e0dbb23cd2))\n\n##### Refactors\n\n-   enable isolatedModules and change imports ([#&#8203;573](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/573)) ([9068b4b](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/9068b4b0a0a08a69a9330ce03418135e11aa539e))\n-   use type imports for type-only imports ([#&#8203;580](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/580)) ([2c8a337](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/2c8a337033e850b7282d35b37c3ce36d5b0dabbe))\n\n</details>\n\n<details>\n<summary>huggingface/transformers.js (@&#8203;huggingface/transformers)</summary>\n\n### [`v3.1.1`](https://redirect.github.com/huggingface/transformers.js/releases/tag/3.1.1)\n\n[Compare Source](https://redirect.github.com/huggingface/transformers.js/compare/3.1.0...3.1.1)\n\n#### \ud83e\udd16 New models\n\n-   Add support for Idefics3 (SmolVLM) in [https://github.com/huggingface/transformers.js/pull/1059](https://redirect.github.com/huggingface/transformers.js/pull/1059)\n\n    ```js\n    import {\n      AutoProcessor,\n      AutoModelForVision2Seq,\n      load_image,\n    } from \"@&#8203;huggingface/transformers\";\n\n    // Initialize processor and model\n    const model_id = \"HuggingFaceTB/SmolVLM-Instruct\";\n    const processor = await AutoProcessor.from_pretrained(model_id);\n    const model = await AutoModelForVision2Seq.from_pretrained(model_id, {\n      dtype: {\n        embed_tokens: \"fp16\", // \"fp32\", \"fp16\", \"q8\"\n        vision_encoder: \"q4\", // \"fp32\", \"fp16\", \"q8\", \"q4\", \"q4f16\"\n        decoder_model_merged: \"q4\", // \"q8\", \"q4\", \"q4f16\"\n      }\n    });\n\n    // Load images\n    const image1 = await load_image(\"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\");\n    const image2 = await load_image(\"https://huggingface.co/spaces/merve/chameleon-7b/resolve/main/bee.jpg\");\n\n    // Create input messages\n    const messages = [\n      {\n        role: \"user\",\n        content: [\n          { type: \"image\" },\n          { type: \"image\" },\n          { type: \"text\", text: \"Can you describe the two images?\" },\n        ],\n      },\n    ];\n\n    // Prepare inputs\n    const text = processor.apply_chat_template(messages, { add_generation_prompt: true });\n    const inputs = await processor(text, [image1, image2], {\n      // Set `do_image_splitting: true` to split images into multiple patches.\n      // NOTE: This uses more memory, but can provide more accurate results.\n      do_image_splitting: false,\n    });\n\n    // Generate outputs\n    const generated_ids = await model.generate({\n      ...inputs,\n      max_new_tokens: 500,\n    });\n    const generated_texts = processor.batch_decode(\n      generated_ids.slice(null, [inputs.input_ids.dims.at(-1), null]),\n      { skip_special_tokens: true },\n    );\n    console.log(generated_texts[0]);\n    // ' In the first image, there is a green statue of liberty on a pedestal in the middle of the water. The water is surrounded by trees and buildings in the background. In the second image, there are pink and red flowers with a bee on the pink flower.'\n    ```\n\n#### \ud83d\udc1b Bug fixes\n\n-   Fix repetition penalty logits processor in [https://github.com/huggingface/transformers.js/pull/1062](https://redirect.github.com/huggingface/transformers.js/pull/1062)\n-   Fix optional chaining for batch size calculation in PreTrainedModel by [@&#8203;emojiiii](https://redirect.github.com/emojiiii) in [https://github.com/huggingface/transformers.js/pull/1063](https://redirect.github.com/huggingface/transformers.js/pull/1063)\n\n#### \ud83d\udcdd Documentation improvements\n\n-   Add an example and type enhancement for TextStreamer by [@&#8203;seonglae](https://redirect.github.com/seonglae) in [https://github.com/huggingface/transformers.js/pull/1066](https://redirect.github.com/huggingface/transformers.js/pull/1066)\n-   The smallest typo fix for webgpu.md by [@&#8203;JoramMillenaar](https://redirect.github.com/JoramMillenaar) in [https://github.com/huggingface/transformers.js/pull/1068](https://redirect.github.com/huggingface/transformers.js/pull/1068)\n\n#### \ud83d\udee0\ufe0f Other improvements\n\n-   Only log warning if type not explicitly set to \"custom\" in [https://github.com/huggingface/transformers.js/pull/1061](https://redirect.github.com/huggingface/transformers.js/pull/1061)\n-   Improve browser vs. webworker detection in [https://github.com/huggingface/transformers.js/pull/1067](https://redirect.github.com/huggingface/transformers.js/pull/1067)\n\n#### \ud83e\udd17 New contributors\n\n-   [@&#8203;emojiiii](https://redirect.github.com/emojiiii) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1063](https://redirect.github.com/huggingface/transformers.js/pull/1063)\n-   [@&#8203;seonglae](https://redirect.github.com/seonglae) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1066](https://redirect.github.com/huggingface/transformers.js/pull/1066)\n-   [@&#8203;JoramMillenaar](https://redirect.github.com/JoramMillenaar) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1068](https://redirect.github.com/huggingface/transformers.js/pull/1068)\n\n**Full Changelog**: https://github.com/huggingface/transformers.js/compare/3.1.0...3.1.1\n\n### [`v3.1.0`](https://redirect.github.com/huggingface/transformers.js/releases/tag/3.1.0)\n\n[Compare Source](https://redirect.github.com/huggingface/transformers.js/compare/3.0.2...3.1.0)\n\n### \ud83d\ude80 Transformers.js v3.1 \u2014 any-to-any, text-to-image, image-to-text, pose estimation, time series forecasting, and more!\n\nTable of contents:\n\n-   [\ud83e\udd16 New models: Janus, Qwen2-VL, JinaCLIP, LLaVA-OneVision, ViTPose, MGP-STR, PatchTST, PatchTSMixer.](#new-models)\n    -   [**Janus**: Any-to-Any generation](#janus)\n    -   [**Qwen2-VL**: Image-Text-to-Text](#qwen2vl)\n    -   [**JinaCLIP**: Multimodal embeddings](#jina_clip)\n    -   [**LLaVA-OneVision**: Image-Text-to-Text](#llava_onevision)\n    -   [**ViTPose**: Pose-estimation](#vitpose)\n    -   [**MGP-STR**: Optical Character Recognition (OCR)](#mgp-str)\n    -   [**PatchTST and PatchTSMixer**: Time series forecasting.](#patchtst-and-patchtsmixer)\n-   [\ud83d\udc1b Bug fixes](#bug-fixes)\n-   [\ud83d\udcdd Documentation improvements](#documentation-improvements)\n-   [\ud83d\udee0\ufe0f Other improvements](#other-improvements)\n-   [\ud83e\udd17 New contributors](#new-contributors)\n\n<h2 id=\"new-models\">\ud83e\udd16 New models: Janus, Qwen2-VL, JinaCLIP, LLaVA-OneVision, ViTPose, MGP-STR, PatchTST, PatchTSMixer.</h2>\n\n<h3 id=\"janus\">Janus for Any-to-Any generation (e.g., image-to-text and text-to-image)</h3>\n\nFirst of all, this release adds support for Janus, a novel autoregressive framework that unifies multimodal understanding and generation. The most popular model, [deepseek-ai/Janus-1.3B](https://huggingface.co/deepseek-ai/Janus-1.3B), is tagged as an \"any-to-any\" model, and has specifically been trained for the following tasks:\n\n**Example:** Image-Text-to-Text\n\n```js\nimport { AutoProcessor, MultiModalityCausalLM } from \"@&#8203;huggingface/transformers\";\n\n// Load processor and model\nconst model_id = \"onnx-community/Janus-1.3B-ONNX\";\nconst processor = await AutoProcessor.from_pretrained(model_id);\nconst model = await MultiModalityCausalLM.from_pretrained(model_id);\n\n// Prepare inputs\nconst conversation = [\n  {\n    role: \"User\",\n    content: \"<image_placeholder>\\nConvert the formula into latex code.\",\n    images: [\"https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/quadratic_formula.png\"],\n  },\n];\nconst inputs = await processor(conversation);\n\n// Generate response\nconst outputs = await model.generate({\n  ...inputs,\n  max_new_tokens: 150,\n  do_sample: false,\n});\n\n// Decode output\nconst new_tokens = outputs.slice(null, [inputs.input_ids.dims.at(-1), null]);\nconst decoded = processor.batch_decode(new_tokens, { skip_special_tokens: true });\nconsole.log(decoded[0]);\n```\n\nSample output:\n\n    Sure, here is the LaTeX code for the given formula:\n\n    ```\n    x = \\frac{-b \\pm \\sqrt{b^2 - 4a c}}{2a}\n    ```\n\n    This code represents the mathematical expression for the variable \\( x \\).\n\n**Example:** Text-to-Image\n\n```js\nimport { AutoProcessor, MultiModalityCausalLM } from \"@&#8203;huggingface/transformers\";\n\n// Load processor and model\nconst model_id = \"onnx-community/Janus-1.3B-ONNX\";\nconst processor = await AutoProcessor.from_pretrained(model_id);\nconst model = await MultiModalityCausalLM.from_pretrained(model_id);\n\n// Prepare inputs\nconst conversation = [\n  {\n    role: \"User\",\n    content: \"A cute and adorable baby fox with big brown eyes, autumn leaves in the background enchanting,immortal,fluffy, shiny mane,Petals,fairyism,unreal engine 5 and Octane Render,highly detailed, photorealistic, cinematic, natural colors.\",\n  },\n];\nconst inputs = await processor(conversation, { chat_template: \"text_to_image\" });\n\n// Generate response\nconst num_image_tokens = processor.num_image_tokens;\nconst outputs = await model.generate_images({\n  ...inputs,\n  min_new_tokens: num_image_tokens,\n  max_new_tokens: num_image_tokens,\n  do_sample: true,\n});\n\n// Save the generated image\nawait outputs[0].save(\"test.png\");\n```\n\nSample outputs:\n\n|  ![fox\\_1](https://redirect.github.com/user-attachments/assets/c8a4f588-655f-440e-bd55-79d19505edae)  | ![fox\\_2](https://redirect.github.com/user-attachments/assets/88b5003a-82de-4ef9-8315-6cb59aee607d) | ![fox\\_3](https://redirect.github.com/user-attachments/assets/f92ed498-4a32-4757-86de-cac37bc8fbf6) | ![fox\\_4](https://redirect.github.com/user-attachments/assets/51b9d0a6-c737-499d-983e-d89ff023282d) |\n|---|---|---|---|\n| ![fox\\_5](https://redirect.github.com/user-attachments/assets/8876ebb0-fea2-4443-b458-fdd6c035a69f) | ![fox\\_6](https://redirect.github.com/user-attachments/assets/1989f128-5fd4-4b0c-83b4-dc5f33b388c2) | ![fox\\_7](https://redirect.github.com/user-attachments/assets/1fa9ac58-ca14-4ee3-84ca-47e69de2589c) | ![fox\\_8](https://redirect.github.com/user-attachments/assets/20a20642-a336-4277-9056-f45d7ddb3bbe) |\n\nWhat to play around with the model? Check out our [online WebGPU demo](https://huggingface.co/spaces/webml-community/Janus-1.3B-WebGPU)! \ud83d\udc47\n\nhttps://github.com/user-attachments/assets/513b3119-ba8c-4a2d-b5fe-6869be47abfa\n\n<h3 id=\"qwen2vl\">Qwen2-VL for Image-Text-to-Text</h3>\n\n**Example:** Image-Text-to-Text\n\nNext, we added support for Qwen2-VL, the multimodal large language model series developed by Qwen team, Alibaba Cloud. It introduces the Naive Dynamic Resolution mechanism, allowing the model to process images of varying resolutions and leading to more efficient and accurate visual representations.\n\n```js\nimport { AutoProcessor, Qwen2VLForConditionalGeneration, RawImage } from \"@&#8203;huggingface/transformers\";\n\n// Load processor and model\nconst model_id = \"onnx-community/Qwen2-VL-2B-Instruct\";\nconst processor = await AutoProcessor.from_pretrained(model_id);\nconst model = await Qwen2VLForConditionalGeneration.from_pretrained(model_id);\n\n// Prepare inputs\nconst url = \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\";\nconst image = await (await RawImage.read(url)).resize(448, 448);\nconst conversation = [\n  {\n    role: \"user\",\n    content: [\n      { type: \"image\" },\n      { type: \"text\", text: \"Describe this image.\" },\n    ],\n  },\n];\nconst text = processor.apply_chat_template(conversation, { add_generation_prompt: true });\nconst inputs = await processor(text, image);\n\n// Perform inference\nconst outputs = await model.generate({\n  ...inputs,\n  max_new_tokens: 128,\n});\n\n// Decode output\nconst decoded = processor.batch_decode(\n  outputs.slice(null, [inputs.input_ids.dims.at(-1), null]),\n  { skip_special_tokens: true },\n);\nconsole.log(decoded[0]);\n// The image depicts a serene beach scene with a woman and a dog. The woman is sitting on the sand, wearing a plaid shirt, and appears to be engaged in a playful interaction with the dog. The dog, which is a large breed, is sitting on its hind legs and appears to be reaching out to the woman, possibly to give her a high-five or a paw. The background shows the ocean with gentle waves, and the sky is clear, suggesting it might be either sunrise or sunset. The overall atmosphere is calm and relaxed, capturing a moment of connection between the woman and the dog.\n```\n\n<h3 id=\"jina_clip\">JinaCLIP for multimodal embeddings</h3>\n\nJinaCLIP is a series of general-purpose multilingual multimodal embedding models for text & images, created by Jina AI.\n\n**Example:** Compute text and/or image embeddings with `jinaai/jina-clip-v2`:\n\n```js\nimport { AutoModel, AutoProcessor, RawImage, matmul } from \"@&#8203;huggingface/transformers\";\n\n// Load processor and model\nconst model_id = \"jinaai/jina-clip-v2\";\nconst processor = await AutoProcessor.from_pretrained(model_id);\nconst model = await AutoModel.from_pretrained(model_id, { dtype: \"q4\" /* e.g., \"fp16\", \"q8\", or \"q4\" */ });\n\n// Prepare inputs\nconst urls = [\"https://i.ibb.co/nQNGqL0/beach1.jpg\", \"https://i.ibb.co/r5w8hG8/beach2.jpg\"];\nconst images = await Promise.all(urls.map(url => RawImage.read(url)));\nconst sentences = [\n    \"\u063a\u0631\u0648\u0628 \u062c\u0645\u064a\u0644 \u0639\u0644\u0649 \u0627\u0644\u0634\u0627\u0637\u0626\", // Arabic\n    \"\u6d77\u6ee9\u4e0a\u7f8e\u4e3d\u7684\u65e5\u843d\", // Chinese\n    \"Un beau coucher de soleil sur la plage\", // French\n    \"Ein wundersch\u00f6ner Sonnenuntergang am Strand\", // German\n    \"\u0388\u03bd\u03b1 \u03cc\u03bc\u03bf\u03c1\u03c6\u03bf \u03b7\u03bb\u03b9\u03bf\u03b2\u03b1\u03c3\u03af\u03bb\u03b5\u03bc\u03b1 \u03c0\u03ac\u03bd\u03c9 \u03b1\u03c0\u03cc \u03c4\u03b7\u03bd \u03c0\u03b1\u03c1\u03b1\u03bb\u03af\u03b1\", // Greek\n    \"\u0938\u092e\u0941\u0926\u094d\u0930 \u0924\u091f \u092a\u0930 \u090f\u0915 \u0916\u0942\u092c\u0938\u0942\u0930\u0924 \u0938\u0942\u0930\u094d\u092f\u093e\u0938\u094d\u0924\", // Hindi\n    \"Un bellissimo tramonto sulla spiaggia\", // Italian\n    \"\u6d5c\u8fba\u306b\u6c88\u3080\u7f8e\u3057\u3044\u5915\u65e5\", // Japanese\n    \"\ud574\ubcc0 \uc704\ub85c \uc544\ub984\ub2e4\uc6b4 \uc77c\ubab0\", // Korean\n];\n\n// Encode text and images\nconst inputs = await processor(sentences, images, { padding: true, truncation: true });\nconst { l2norm_text_embeddings, l2norm_image_embeddings } = await model(inputs);\n\n// Encode query (text-only)\nconst query_prefix = \"Represent the query for retrieving evidence documents: \";\nconst query_inputs = await processor(query_prefix + \"beautiful sunset over the beach\");\nconst { l2norm_text_embeddings: query_embeddings } = await model(query_inputs);\n\n// Compute text-image similarity scores\nconst text_to_image_scores = await matmul(query_embeddings, l2norm_image_embeddings.transpose(1, 0));\nconsole.log(\"text-image similarity scores\", text_to_image_scores.tolist()[0]); // [0.29530206322669983, 0.3183615803718567]\n\n// Compute image-image similarity scores\nconst image_to_image_score = await matmul(l2norm_image_embeddings[0], l2norm_image_embeddings[1]);\nconsole.log(\"image-image similarity score\", image_to_image_score.item()); // 0.9344457387924194\n\n// Compute text-text similarity scores\nconst text_to_text_scores = await matmul(query_embeddings, l2norm_text_embeddings.transpose(1, 0));\nconsole.log(\"text-text similarity scores\", text_to_text_scores.tolist()[0]); // [0.5566609501838684, 0.7028406858444214, 0.582255482673645, 0.6648036241531372, 0.5462006330490112, 0.6791588068008423, 0.6192430257797241, 0.6258729100227356, 0.6453716158866882]\n```\n\n<h3 id=\"llava_onevision\">LLaVA-OneVision for Image-Text-to-Text</h3>\n\nLLaVA-OneVision is a Vision-Language Model that can generate text conditioned on one or several images/videos. The model consists of SigLIP vision encoder and a Qwen2 language backbone.\n\n**Example:** Multi-round conversations w/ PKV caching\n\n```js\nimport { AutoProcessor, AutoTokenizer, LlavaOnevisionForConditionalGeneration, RawImage } from '@&#8203;huggingface/transformers';\n\n// Load tokenizer, processor and model\nconst model_id = 'llava-hf/llava-onevision-qwen2-0.5b-ov-hf';\n\nconst tokenizer = await AutoTokenizer.from_pretrained(model_id);\nconst processor = await AutoProcessor.from_pretrained(model_id);\nconst model = await LlavaOnevisionForConditionalGeneration.from_pretrained(model_id, {\n    dtype: {\n        embed_tokens: 'fp16', // or 'fp32' or 'q8'\n        vision_encoder: 'fp16', // or 'fp32' or 'q8'\n        decoder_model_merged: 'q4', // or 'q8'\n    },\n    // device: 'webgpu',\n});\n\n// Prepare text inputs\nconst prompt = 'What does the text say?';\nconst messages = [\n    { role: 'system', content: 'Answer the question.' },\n    { role: 'user', content: `<image>\\n${prompt}` }\n]\nconst text = tokenizer.apply_chat_template(messages, { tokenize: false, add_generation_prompt: true });\nconst text_inputs = tokenizer(text);\n\n// Prepare vision inputs\nconst url = 'https://huggingface.co/qnguyen3/nanoLLaVA/resolve/main/example_1.png';\nconst image = await RawImage.fromURL(url);\nconst vision_inputs = await processor(image);\n\n// Generate response\nconst { past_key_values, sequences } = await model.generate({\n    ...text_inputs,\n    ...vision_inputs,\n    do_sample: false,\n    max_new_tokens: 64,\n    return_dict_in_generate: true,\n});\n\n// Decode output\nconst answer = tokenizer.decode(\n    sequences.slice(0, [text_inputs.input_ids.dims[1], null]),\n    { skip_special_tokens: true },\n);\nconsole.log(answer);\n// The text says \"small but mighty\" in a playful font.\n\nconst new_messages = [\n    ...messages,\n    { role: 'assistant', content: answer },\n    { role: 'user', content: 'How does the text correlate to the context of the image?' }\n]\nconst new_text = tokenizer.apply_chat_template(new_messages, { tokenize: false, add_generation_prompt: true });\nconst new_text_inputs = tokenizer(new_text);\n\n// Generate another response\nconst output = await model.generate({\n    ...new_text_inputs,\n    past_key_values,\n    do_sample: false,\n    max_new_tokens: 256,\n});\nconst new_answer = tokenizer.decode(\n    output.slice(0, [new_text_inputs.input_ids.dims[1], null]),\n    { skip_special_tokens: true },\n);\nconsole.log(new_answer);\n// The text \"small but mighty\" is likely a playful or humorous reference to the image of the blue mouse with the orange dumbbell. It could be used as a motivational phrase or a playful way to express the idea that even small things can be impressive or powerful.\n```\n\n<h3 id=\"vitpose\">ViTPose for pose-estimation</h3>\n\nA state-of-the-art pose estimation model which employs a standard, non-hierarchical vision transformer as a backbone for the task of keypoint estimation (combined with a simple decoder head to predict heatmaps from a given image).\n\n**Example:** Pose estimation w/ `onnx-community/vitpose-base-simple`.\n\n```js\nimport { AutoModel, AutoImageProcessor, RawImage } from '@&#8203;huggingface/transformers';\n\n// Load model and processor\nconst model_id = 'onnx-community/vitpose-base-simple';\nconst model = await AutoModel.from_pretrained(model_id);\nconst processor = await AutoImageProcessor.from_pretrained(model_id);\n\n// Load image and prepare inputs\nconst url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/ryan-gosling.jpg';\nconst image = await RawImage.read(url);\nconst inputs = await processor(image);\n\n// Predict heatmaps\nconst { heatmaps } = await model(inputs);\n\n// Post-process heatmaps to get keypoints and scores\nconst boxes = [[[0, 0, image.width, image.height]]];\nconst results = processor.post_process_pose_estimation(heatmaps, boxes)[0][0];\nconsole.log(results);\n```\n\n<details>\n\n<summary>Optionally, visualize the outputs (Node.js usage shown here, using the node-canvas library):</summary>\n\n```js\nimport { createCanvas, createImageData } from 'canvas';\n\n// Create canvas and draw image\nconst canvas = createCanvas(image.width, image.height);\nconst ctx = canvas.getContext('2d');\nconst imageData = createImageData(image.rgba().data, image.width, image.height);\nctx.putImageData(imageData, 0, 0);\n\n// Draw edges between keypoints\nconst points = results.keypoints;\nctx.lineWidth = 4;\nctx.strokeStyle = 'blue';\nfor (const [i, j] of model.config.edges) {\n    const [x1, y1] = points[i];\n    const [x2, y2] = points[j];\n    ctx.beginPath();\n    ctx.moveTo(x1, y1);\n    ctx.lineTo(x2, y2);\n    ctx.stroke();\n}\n\n// Draw circle at each keypoint\nctx.fillStyle = 'red';\nfor (const [x, y] of points) {\n    ctx.beginPath();\n    ctx.arc(x, y, 8, 0, 2 * Math.PI);\n    ctx.fill();\n}\n\n// Save image to file\nimport fs from 'fs';\nconst out = fs.createWriteStream('pose.png');\nconst stream = canvas.createPNGStream();\nstream.pipe(out)\nout.on('finish', () =>  console.log('The PNG file was created.'));\n```\n\n</details>\n\n| Input image | Output image |\n| :----------:|:------------:|\n| ![image/jpeg](https://cdn-uploads.huggingface.co/production/uploads/61b253b7ac5ecaae3d1efe0c/QpXlLNyLDKZUxXjokbUyy.jpeg) | ![image/png](https://cdn-uploads.huggingface.co/production/uploads/61b253b7ac5ecaae3d1efe0c/xj0jaKo9aAOux-NSU8U7S.png) |\n\n<h3 id=\"mgp-str\">MGP-STR for Optical Character Recognition (OCR)</h3>\n\nA simple yet powerful vision scene text recognition model, built upon the vision transformer (ViT).\n\n**Example:** Optical Character Recognition (OCR) w/ `onnx-community/mgp-str-base`\n\n```js\nimport { MgpstrForSceneTextRecognition, MgpstrProcessor, RawImage } from '@&#8203;huggingface/transformers';\n\nconst model_id = 'onnx-community/mgp-str-base';\nconst model = await MgpstrForSceneTextRecognition.from_pretrained(model_id);\nconst processor = await MgpstrProcessor.from_pretrained(model_id);\n\n// Load image from the IIIT-5k dataset\nconst url = \"https://i.postimg.cc/ZKwLg2Gw/367-14.png\";\nconst image = await RawImage.read(url);\n\n// Preprocess the image\nconst result = await processor(image);\n\n// Perform inference\nconst outputs = await model(result);\n\n// Decode the model outputs\nconst generated_text = processor.batch_decode(outputs.logits).generated_text;\nconsole.log(generated_text); // [ 'ticket' ]\n```\n\n<h3 id=\"patchtst-and-patchtsmixer\">PatchTST and PatchTSMixer for time series forecasting.</h3>\n\n**Example:** Time series forecasting w/ `onnx-community/granite-timeseries-patchtst`\n\nModels which can be used for multivariate time series forecasting.\n\n```js\nimport { PatchTSTForPrediction, Tensor } from \"@&#8203;huggingface/transformers\";\n\nconst model_id = \"onnx-community/granite-timeseries-patchtst\";\nconst model = await PatchTSTForPrediction.from_pretrained(model_id, { dtype: \"fp32\" });\n\nconst dims = [64, 512, 7];\nconst prod = dims.reduce((a, b) => a * b, 1);\nconst past_values = new Tensor('float32',\n    Float32Array.from({ length: prod }, (_, i) => i / prod),\n    dims,\n);\nconst { prediction_outputs } = await model({ past_values });\nconsole.log(prediction_outputs);\n```\n\n**Example:** Time series forecasting w/ `onnx-community/granite-timeseries-patchtsmixer`\n\n```js\nimport { PatchTSMixerForPrediction, Tensor } from \"@&#8203;huggingface/transformers\";\n\nconst model_id = \"onnx-community/granite-timeseries-patchtsmixer\";\nconst model = await PatchTSMixerForPrediction.from_pretrained(model_id, { dtype: \"fp32\" });\n\nconst dims = [64, 512, 7];\nconst prod = dims.reduce((a, b) => a * b, 1);\nconst past_values = new Tensor('float32',\n    Float32Array.from({ length: prod }, (_, i) => i / prod),\n    dims,\n);\nconst { prediction_outputs } = await model({ past_values });\nconsole.log(prediction_outputs);\n```\n\n<h2 id=\"bug-fixes\">\ud83d\udc1b Bug fixes</h2>\n\n-   When padding an image, the dimensions get stretched by [@&#8203;BritishWerewolf](https://redirect.github.com/BritishWerewolf) in [https://github.com/huggingface/transformers.js/pull/1015](https://redirect.github.com/huggingface/transformers.js/pull/1015)\n-   fix(scale): add missing scale element by [@&#8203;tosinamuda](https://redirect.github.com/tosinamuda) in [https://github.com/huggingface/transformers.js/pull/1017](https://redirect.github.com/huggingface/transformers.js/pull/1017)\n\n<h2 id=\"documentation-improvements\">\ud83d\udcdd Documentation improvements</h2>\n\n-   Updated link to sentence similarity models. by [@&#8203;uzyn](https://redirect.github.com/uzyn) in [https://github.com/huggingface/transformers.js/pull/893](https://redirect.github.com/huggingface/transformers.js/pull/893)\n-   fix(docs): fixed a broken link to quantization guide by [@&#8203;ThomasWT](https://redirect.github.com/ThomasWT) in [https://github.com/huggingface/transformers.js/pull/1014](https://redirect.github.com/huggingface/transformers.js/pull/1014)\n-   fix(docs): Fixed Typos in README and docs/snippets/6\\_supported-models.snippet by [@&#8203;hitchhiker3010](https://redirect.github.com/hitchhiker3010) in [https://github.com/huggingface/transformers.js/pull/1030](https://redirect.github.com/huggingface/transformers.js/pull/1030)\n\n<h2 id=\"other-improvements\">\ud83d\udee0\ufe0f Other improvements</h2>\n\n-   Add option to maintain aspect ratio on resize by [@&#8203;BritishWerewolf](https://redirect.github.com/BritishWerewolf) in [https://github.com/huggingface/transformers.js/pull/971](https://redirect.github.com/huggingface/transformers.js/pull/971)\n-   Add functionality to split RawImage into channels; Update slice documentation and tests by [@&#8203;BritishWerewolf](https://redirect.github.com/BritishWerewolf) in [https://github.com/huggingface/transformers.js/pull/978](https://redirect.github.com/huggingface/transformers.js/pull/978)\n-   Avoid resizing images when they already have the desired size by [@&#8203;nemphys](https://redirect.github.com/nemphys) in [https://github.com/huggingface/transformers.js/pull/1027](https://redirect.github.com/huggingface/transformers.js/pull/1027)\n-   Add support for Split pretokenizer w/ `behavior=removed` & `invert=false` by [@&#8203;xenova](https://redirect.github.com/xenova) in [https://github.com/huggingface/transformers.js/pull/1033](https://redirect.github.com/huggingface/transformers.js/pull/1033)\n-   Add type declaration for `progress_callback` by [@&#8203;ocavue](https://redirect.github.com/ocavue) in [https://github.com/huggingface/transformers.js/pull/1034](https://redirect.github.com/huggingface/transformers.js/pull/1034)\n-   Add support for op_block_list by [@&#8203;pdufour](https://redirect.github.com/pdufour) in [https://github.com/huggingface/transformers.js/pull/1036](https://redirect.github.com/huggingface/transformers.js/pull/1036)\n\n<h2 id=\"new-contributors\">\ud83e\udd17 New contributors</h2>\n\n-   [@&#8203;uzyn](https://redirect.github.com/uzyn) made their first contribution in [https://github.com/huggingface/transformers.js/pull/893](https://redirect.github.com/huggingface/transformers.js/pull/893)\n-   [@&#8203;ThomasWT](https://redirect.github.com/ThomasWT) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1014](https://redirect.github.com/huggingface/transformers.js/pull/1014)\n-   [@&#8203;tosinamuda](https://redirect.github.com/tosinamuda) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1017](https://redirect.github.com/huggingface/transformers.js/pull/1017)\n-   [@&#8203;nemphys](https://redirect.github.com/nemphys) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1027](https://redirect.github.com/huggingface/transformers.js/pull/1027)\n-   [@&#8203;hitchhiker3010](https://redirect.github.com/hitchhiker3010) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1030](https://redirect.github.com/huggingface/transformers.js/pull/1030)\n-   [@&#8203;pdufour](https://redirect.github.com/pdufour) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1036](https://redirect.github.com/huggingface/transformers.js/pull/1036)\n\n**Full Changelog**: https://github.com/huggingface/transformers.js/compare/3.0.2...3.1.0\n\n</details>\n\n<details>\n<summary>openai/openai-node (openai)</summary>\n\n### [`v4.76.0`](https://redirect.github.com/openai/openai-node/blob/HEAD/CHANGELOG.md#4760-2024-12-05)\n\n[Compare Source](https://redirect.github.com/openai/openai-node/compare/v4.75.0...v4.76.0)\n\nFull Changelog: [v4.75.0...v4.76.0](https://redirect.github.com/openai/openai-node/compare/v4.75.0...v4.76.0)\n\n##### Features\n\n-   **api:** updates ([#&#8203;1212](https://redirect.github.com/openai/openai-node/issues/1212)) ([e0fedf2](https://redirect.github.com/openai/openai-node/commit/e0fedf2c5a91d0c03d8dad6854b366f77eab4923))\n\n##### Chores\n\n-   bump openapi url ([#&#8203;1210](https://redirect.github.com/openai/openai-node/issues/1210)) ([3fa95a4](https://redirect.github.com/openai/openai-node/commit/3fa95a429d4b2adecce35a7b96b73f6d5e88eeeb))\n\n### [`v4.75.0`](https://redirect.github.com/openai/openai-node/blob/HEAD/CHANGELOG.md#4750-2024-12-03)\n\n[Compare Source](https://redirect.github.com/openai/openai-node/compare/v4.74.0...v4.75.0)\n\nFull Changelog: [v4.74.0...v4.75.0](https://redirect.github.com/openai/openai-node/compare/v4.74.0...v4.75.0)\n\n##### Features\n\n-   improve docs for jsr README.md ([#&#8203;1208](https://redirect.github.com/openai/openai-node/issues/1208)) ([338527e](https://redirect.github.com/openai/openai-node/commit/338527e40361e2de899a63f280d4ec2db5e87f3c))\n\n### [`v4.74.0`](https://redirect.github.com/openai/openai-node/blob/HEAD/CHANGELOG.md#4740-2024-12-02)\n\n[Compare Source](https://redirect.github.com/openai/openai-node/compare/v4.73.1...v4.74.0)\n\nFull Changelog: [v4.73.1...v4.74.0](https://redirect.github.com/openai/openai-node/compare/v4.73.1...v4.74.0)\n\n##### Features\n\n-   **internal:** make git install file structure match npm ([#&#8203;1204](https://redirect.github.com/openai/openai-node/issues/1204)) ([e7c4c6d](https://redirect.github.com/openai/openai-node/commit/e7c4c6d23adbe52300053a8d35db6e341c438703))\n\n### [`v4.73.1`](https://redirect.github.com/openai/openai-node/blob/HEAD/CHANGELOG.md#4731-2024-11-25)\n\n[Compare Source](https://redirect.github.com/openai/openai-node/compare/v4.73.0...v4.73.1)\n\nFull Changelog: [v4.73.0...v4.73.1](https://redirect.github.com/openai/openai-node/compare/v4.73.0...v4.73.1)\n\n##### Documentation\n\n-   **readme:** mention `.withResponse()` for streaming request ID ([#&#8203;1202](https://redirect.github.com/openai/openai-node/issues/1202)) ([b6800d4](https://redirect.github.com/openai/openai-node/commit/b6800d4dea2729fe3b0864171ce8fb3b2cc1b21c))\n\n</details>\n\n---\n\n### Configuration\n\n\ud83d\udcc5 **Schedule**: Branch creation - \"every weekend\" in timezone UTC, Automerge - At any time (no schedule defined).\n\n\ud83d\udea6 **Automerge**: Disabled by config. Please merge this manually once you are satisfied.\n\n\u267b **Rebasing**: Whenever PR becomes conflicted, or you tick the rebase/retry checkbox.\n\n\ud83d\udc7b **Immortal**: This PR will be recreated if closed unmerged. Get [config help](https://redirect.github.com/renovatebot/renovate/discussions) if that's undesired.\n\n---\n\n - [ ] <!-- rebase-check -->If you want to rebase/retry this PR, check this box\n\n---\n\nThis PR was generated by [Mend Renovate](https://mend.io/renovate/). View the [repository job log](https://developer.mend.io/github/ai16z/eliza).\n<!--renovate-debug:eyJjcmVhdGVkSW5WZXIiOiIzOS40Mi40IiwidXBkYXRlZEluVmVyIjoiMzkuNDIuNCIsInRhcmdldEJyYW5jaCI6Im1haW4iLCJsYWJlbHMiOltdfQ==-->\n",
            "files": [
              {
                "path": "packages/core/package.json",
                "additions": 2,
                "deletions": 2
              },
              {
                "path": "packages/plugin-node/package.json",
                "additions": 1,
                "deletions": 1
              },
              {
                "path": "pnpm-lock.yaml",
                "additions": 39,
                "deletions": 44
              }
            ],
            "reviews": [],
            "comments": []
          },
          {
            "number": 885,
            "title": "fix(deps): update ai/ml packages",
            "state": "CLOSED",
            "merged": false,
            "created_at": "2024-12-07T03:01:13Z",
            "updated_at": "2024-12-07T03:04:07Z",
            "body": "This PR contains the following updates:\n\n| Package | Change | Age | Adoption | Passing | Confidence |\n|---|---|---|---|---|---|\n| [@anthropic-ai/sdk](https://redirect.github.com/anthropics/anthropic-sdk-typescript) | [`0.30.1` -> `0.32.1`](https://renovatebot.com/diffs/npm/@anthropic-ai%2fsdk/0.30.1/0.32.1) | [![age](https://developer.mend.io/api/mc/badges/age/npm/@anthropic-ai%2fsdk/0.32.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![adoption](https://developer.mend.io/api/mc/badges/adoption/npm/@anthropic-ai%2fsdk/0.32.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![passing](https://developer.mend.io/api/mc/badges/compatibility/npm/@anthropic-ai%2fsdk/0.30.1/0.32.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![confidence](https://developer.mend.io/api/mc/badges/confidence/npm/@anthropic-ai%2fsdk/0.30.1/0.32.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) |\n| [@huggingface/transformers](https://redirect.github.com/huggingface/transformers.js) | [`3.0.2` -> `3.1.1`](https://renovatebot.com/diffs/npm/@huggingface%2ftransformers/3.0.2/3.1.1) | [![age](https://developer.mend.io/api/mc/badges/age/npm/@huggingface%2ftransformers/3.1.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![adoption](https://developer.mend.io/api/mc/badges/adoption/npm/@huggingface%2ftransformers/3.1.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![passing](https://developer.mend.io/api/mc/badges/compatibility/npm/@huggingface%2ftransformers/3.0.2/3.1.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![confidence](https://developer.mend.io/api/mc/badges/confidence/npm/@huggingface%2ftransformers/3.0.2/3.1.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) |\n| [openai](https://redirect.github.com/openai/openai-node) | [`4.73.0` -> `4.76.0`](https://renovatebot.com/diffs/npm/openai/4.73.0/4.76.0) | [![age](https://developer.mend.io/api/mc/badges/age/npm/openai/4.76.0?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![adoption](https://developer.mend.io/api/mc/badges/adoption/npm/openai/4.76.0?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![passing](https://developer.mend.io/api/mc/badges/compatibility/npm/openai/4.73.0/4.76.0?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![confidence](https://developer.mend.io/api/mc/badges/confidence/npm/openai/4.73.0/4.76.0?slim=true)](https://docs.renovatebot.com/merge-confidence/) |\n\n---\n\n### Release Notes\n\n<details>\n<summary>anthropics/anthropic-sdk-typescript (@&#8203;anthropic-ai/sdk)</summary>\n\n### [`v0.32.1`](https://redirect.github.com/anthropics/anthropic-sdk-typescript/blob/HEAD/CHANGELOG.md#0321-2024-11-05)\n\nFull Changelog: [sdk-v0.32.0...sdk-v0.32.1](https://redirect.github.com/anthropics/anthropic-sdk-typescript/compare/sdk-v0.32.0...sdk-v0.32.1)\n\n##### Bug Fixes\n\n-   **bedrock:** don't mutate request body inputs ([f83b535](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/f83b53520262219229cecc388f95d92be83c09d5))\n-   **vertex:** don't mutate request body inputs ([e9a82e5](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/e9a82e56f0d7fff956c2ebd19e103a190f8beb83))\n\n### [`v0.32.0`](https://redirect.github.com/anthropics/anthropic-sdk-typescript/blob/HEAD/CHANGELOG.md#0320-2024-11-04)\n\nFull Changelog: [sdk-v0.31.0...sdk-v0.32.0](https://redirect.github.com/anthropics/anthropic-sdk-typescript/compare/sdk-v0.31.0...sdk-v0.32.0)\n\n##### Features\n\n-   **api:** add new haiku model ([#&#8203;587](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/587)) ([983b13c](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/983b13c9e4f55b832fc4fddfd46bed89756d745e))\n\n##### Bug Fixes\n\n-   don't require deno to run build-deno ([#&#8203;586](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/586)) ([0e431d6](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/0e431d61ec318aae09687dee0bfb922ccb8ddd15))\n-   **types:** add missing token-counting-2024-11-01 ([#&#8203;583](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/583)) ([13d629c](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/13d629c9b444a32b69729df7792199556a2b95f2))\n\n##### Chores\n\n-   remove unused build-deno condition ([#&#8203;585](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/585)) ([491e8fe](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/491e8fe28745aeb55217809f94ad4e37900f4675))\n\n### [`v0.31.0`](https://redirect.github.com/anthropics/anthropic-sdk-typescript/blob/HEAD/CHANGELOG.md#0310-2024-11-01)\n\nFull Changelog: [sdk-v0.30.1...sdk-v0.31.0](https://redirect.github.com/anthropics/anthropic-sdk-typescript/compare/sdk-v0.30.1...sdk-v0.31.0)\n\n##### Features\n\n-   **api:** add message token counting & PDFs support ([#&#8203;582](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/582)) ([b593837](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/b593837ae2d320414a26b5ec53aa6d3f30a3e6bc))\n\n##### Bug Fixes\n\n-   **countTokens:** correctly set beta header ([1680757](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/16807572af923831e384869a0a6ccccaa8dbec84))\n-   **internal:** support pnpm git installs ([#&#8203;579](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/579)) ([86bb102](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/86bb102ce33346930a8b0a553a909fcc7d964a36))\n-   **types:** add missing token-counting-2024-11-01 ([aff1546](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/aff1546cd84ce50a52d17bcdcaba54e60e92955a))\n\n##### Reverts\n\n-   disable isolatedModules and change imports ([#&#8203;575](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/575)) ([2c3b176](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/2c3b176fc551c21abef240b4fa6a98d33ca52048))\n\n##### Chores\n\n-   **internal:** update spec version ([#&#8203;571](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/571)) ([5760012](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/576001245f0b5222cb9b17fafb8619f68d51bec3))\n\n##### Documentation\n\n-   **readme:** minor typo fixes ([#&#8203;577](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/577)) ([8412854](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/8412854c05837cdb8b8ff898bef2a4e0dbb23cd2))\n\n##### Refactors\n\n-   enable isolatedModules and change imports ([#&#8203;573](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/573)) ([9068b4b](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/9068b4b0a0a08a69a9330ce03418135e11aa539e))\n-   use type imports for type-only imports ([#&#8203;580](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/580)) ([2c8a337](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/2c8a337033e850b7282d35b37c3ce36d5b0dabbe))\n\n</details>\n\n<details>\n<summary>huggingface/transformers.js (@&#8203;huggingface/transformers)</summary>\n\n### [`v3.1.1`](https://redirect.github.com/huggingface/transformers.js/releases/tag/3.1.1)\n\n[Compare Source](https://redirect.github.com/huggingface/transformers.js/compare/3.1.0...3.1.1)\n\n#### \ud83e\udd16 New models\n\n-   Add support for Idefics3 (SmolVLM) in [https://github.com/huggingface/transformers.js/pull/1059](https://redirect.github.com/huggingface/transformers.js/pull/1059)\n\n    ```js\n    import {\n      AutoProcessor,\n      AutoModelForVision2Seq,\n      load_image,\n    } from \"@&#8203;huggingface/transformers\";\n\n    // Initialize processor and model\n    const model_id = \"HuggingFaceTB/SmolVLM-Instruct\";\n    const processor = await AutoProcessor.from_pretrained(model_id);\n    const model = await AutoModelForVision2Seq.from_pretrained(model_id, {\n      dtype: {\n        embed_tokens: \"fp16\", // \"fp32\", \"fp16\", \"q8\"\n        vision_encoder: \"q4\", // \"fp32\", \"fp16\", \"q8\", \"q4\", \"q4f16\"\n        decoder_model_merged: \"q4\", // \"q8\", \"q4\", \"q4f16\"\n      }\n    });\n\n    // Load images\n    const image1 = await load_image(\"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\");\n    const image2 = await load_image(\"https://huggingface.co/spaces/merve/chameleon-7b/resolve/main/bee.jpg\");\n\n    // Create input messages\n    const messages = [\n      {\n        role: \"user\",\n        content: [\n          { type: \"image\" },\n          { type: \"image\" },\n          { type: \"text\", text: \"Can you describe the two images?\" },\n        ],\n      },\n    ];\n\n    // Prepare inputs\n    const text = processor.apply_chat_template(messages, { add_generation_prompt: true });\n    const inputs = await processor(text, [image1, image2], {\n      // Set `do_image_splitting: true` to split images into multiple patches.\n      // NOTE: This uses more memory, but can provide more accurate results.\n      do_image_splitting: false,\n    });\n\n    // Generate outputs\n    const generated_ids = await model.generate({\n      ...inputs,\n      max_new_tokens: 500,\n    });\n    const generated_texts = processor.batch_decode(\n      generated_ids.slice(null, [inputs.input_ids.dims.at(-1), null]),\n      { skip_special_tokens: true },\n    );\n    console.log(generated_texts[0]);\n    // ' In the first image, there is a green statue of liberty on a pedestal in the middle of the water. The water is surrounded by trees and buildings in the background. In the second image, there are pink and red flowers with a bee on the pink flower.'\n    ```\n\n#### \ud83d\udc1b Bug fixes\n\n-   Fix repetition penalty logits processor in [https://github.com/huggingface/transformers.js/pull/1062](https://redirect.github.com/huggingface/transformers.js/pull/1062)\n-   Fix optional chaining for batch size calculation in PreTrainedModel by [@&#8203;emojiiii](https://redirect.github.com/emojiiii) in [https://github.com/huggingface/transformers.js/pull/1063](https://redirect.github.com/huggingface/transformers.js/pull/1063)\n\n#### \ud83d\udcdd Documentation improvements\n\n-   Add an example and type enhancement for TextStreamer by [@&#8203;seonglae](https://redirect.github.com/seonglae) in [https://github.com/huggingface/transformers.js/pull/1066](https://redirect.github.com/huggingface/transformers.js/pull/1066)\n-   The smallest typo fix for webgpu.md by [@&#8203;JoramMillenaar](https://redirect.github.com/JoramMillenaar) in [https://github.com/huggingface/transformers.js/pull/1068](https://redirect.github.com/huggingface/transformers.js/pull/1068)\n\n#### \ud83d\udee0\ufe0f Other improvements\n\n-   Only log warning if type not explicitly set to \"custom\" in [https://github.com/huggingface/transformers.js/pull/1061](https://redirect.github.com/huggingface/transformers.js/pull/1061)\n-   Improve browser vs. webworker detection in [https://github.com/huggingface/transformers.js/pull/1067](https://redirect.github.com/huggingface/transformers.js/pull/1067)\n\n#### \ud83e\udd17 New contributors\n\n-   [@&#8203;emojiiii](https://redirect.github.com/emojiiii) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1063](https://redirect.github.com/huggingface/transformers.js/pull/1063)\n-   [@&#8203;seonglae](https://redirect.github.com/seonglae) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1066](https://redirect.github.com/huggingface/transformers.js/pull/1066)\n-   [@&#8203;JoramMillenaar](https://redirect.github.com/JoramMillenaar) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1068](https://redirect.github.com/huggingface/transformers.js/pull/1068)\n\n**Full Changelog**: https://github.com/huggingface/transformers.js/compare/3.1.0...3.1.1\n\n### [`v3.1.0`](https://redirect.github.com/huggingface/transformers.js/releases/tag/3.1.0)\n\n[Compare Source](https://redirect.github.com/huggingface/transformers.js/compare/3.0.2...3.1.0)\n\n### \ud83d\ude80 Transformers.js v3.1 \u2014 any-to-any, text-to-image, image-to-text, pose estimation, time series forecasting, and more!\n\nTable of contents:\n\n-   [\ud83e\udd16 New models: Janus, Qwen2-VL, JinaCLIP, LLaVA-OneVision, ViTPose, MGP-STR, PatchTST, PatchTSMixer.](#new-models)\n    -   [**Janus**: Any-to-Any generation](#janus)\n    -   [**Qwen2-VL**: Image-Text-to-Text](#qwen2vl)\n    -   [**JinaCLIP**: Multimodal embeddings](#jina_clip)\n    -   [**LLaVA-OneVision**: Image-Text-to-Text](#llava_onevision)\n    -   [**ViTPose**: Pose-estimation](#vitpose)\n    -   [**MGP-STR**: Optical Character Recognition (OCR)](#mgp-str)\n    -   [**PatchTST and PatchTSMixer**: Time series forecasting.](#patchtst-and-patchtsmixer)\n-   [\ud83d\udc1b Bug fixes](#bug-fixes)\n-   [\ud83d\udcdd Documentation improvements](#documentation-improvements)\n-   [\ud83d\udee0\ufe0f Other improvements](#other-improvements)\n-   [\ud83e\udd17 New contributors](#new-contributors)\n\n<h2 id=\"new-models\">\ud83e\udd16 New models: Janus, Qwen2-VL, JinaCLIP, LLaVA-OneVision, ViTPose, MGP-STR, PatchTST, PatchTSMixer.</h2>\n\n<h3 id=\"janus\">Janus for Any-to-Any generation (e.g., image-to-text and text-to-image)</h3>\n\nFirst of all, this release adds support for Janus, a novel autoregressive framework that unifies multimodal understanding and generation. The most popular model, [deepseek-ai/Janus-1.3B](https://huggingface.co/deepseek-ai/Janus-1.3B), is tagged as an \"any-to-any\" model, and has specifically been trained for the following tasks:\n\n**Example:** Image-Text-to-Text\n\n```js\nimport { AutoProcessor, MultiModalityCausalLM } from \"@&#8203;huggingface/transformers\";\n\n// Load processor and model\nconst model_id = \"onnx-community/Janus-1.3B-ONNX\";\nconst processor = await AutoProcessor.from_pretrained(model_id);\nconst model = await MultiModalityCausalLM.from_pretrained(model_id);\n\n// Prepare inputs\nconst conversation = [\n  {\n    role: \"User\",\n    content: \"<image_placeholder>\\nConvert the formula into latex code.\",\n    images: [\"https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/quadratic_formula.png\"],\n  },\n];\nconst inputs = await processor(conversation);\n\n// Generate response\nconst outputs = await model.generate({\n  ...inputs,\n  max_new_tokens: 150,\n  do_sample: false,\n});\n\n// Decode output\nconst new_tokens = outputs.slice(null, [inputs.input_ids.dims.at(-1), null]);\nconst decoded = processor.batch_decode(new_tokens, { skip_special_tokens: true });\nconsole.log(decoded[0]);\n```\n\nSample output:\n\n    Sure, here is the LaTeX code for the given formula:\n\n    ```\n    x = \\frac{-b \\pm \\sqrt{b^2 - 4a c}}{2a}\n    ```\n\n    This code represents the mathematical expression for the variable \\( x \\).\n\n**Example:** Text-to-Image\n\n```js\nimport { AutoProcessor, MultiModalityCausalLM } from \"@&#8203;huggingface/transformers\";\n\n// Load processor and model\nconst model_id = \"onnx-community/Janus-1.3B-ONNX\";\nconst processor = await AutoProcessor.from_pretrained(model_id);\nconst model = await MultiModalityCausalLM.from_pretrained(model_id);\n\n// Prepare inputs\nconst conversation = [\n  {\n    role: \"User\",\n    content: \"A cute and adorable baby fox with big brown eyes, autumn leaves in the background enchanting,immortal,fluffy, shiny mane,Petals,fairyism,unreal engine 5 and Octane Render,highly detailed, photorealistic, cinematic, natural colors.\",\n  },\n];\nconst inputs = await processor(conversation, { chat_template: \"text_to_image\" });\n\n// Generate response\nconst num_image_tokens = processor.num_image_tokens;\nconst outputs = await model.generate_images({\n  ...inputs,\n  min_new_tokens: num_image_tokens,\n  max_new_tokens: num_image_tokens,\n  do_sample: true,\n});\n\n// Save the generated image\nawait outputs[0].save(\"test.png\");\n```\n\nSample outputs:\n\n|  ![fox\\_1](https://redirect.github.com/user-attachments/assets/c8a4f588-655f-440e-bd55-79d19505edae)  | ![fox\\_2](https://redirect.github.com/user-attachments/assets/88b5003a-82de-4ef9-8315-6cb59aee607d) | ![fox\\_3](https://redirect.github.com/user-attachments/assets/f92ed498-4a32-4757-86de-cac37bc8fbf6) | ![fox\\_4](https://redirect.github.com/user-attachments/assets/51b9d0a6-c737-499d-983e-d89ff023282d) |\n|---|---|---|---|\n| ![fox\\_5](https://redirect.github.com/user-attachments/assets/8876ebb0-fea2-4443-b458-fdd6c035a69f) | ![fox\\_6](https://redirect.github.com/user-attachments/assets/1989f128-5fd4-4b0c-83b4-dc5f33b388c2) | ![fox\\_7](https://redirect.github.com/user-attachments/assets/1fa9ac58-ca14-4ee3-84ca-47e69de2589c) | ![fox\\_8](https://redirect.github.com/user-attachments/assets/20a20642-a336-4277-9056-f45d7ddb3bbe) |\n\nWhat to play around with the model? Check out our [online WebGPU demo](https://huggingface.co/spaces/webml-community/Janus-1.3B-WebGPU)! \ud83d\udc47\n\nhttps://github.com/user-attachments/assets/513b3119-ba8c-4a2d-b5fe-6869be47abfa\n\n<h3 id=\"qwen2vl\">Qwen2-VL for Image-Text-to-Text</h3>\n\n**Example:** Image-Text-to-Text\n\nNext, we added support for Qwen2-VL, the multimodal large language model series developed by Qwen team, Alibaba Cloud. It introduces the Naive Dynamic Resolution mechanism, allowing the model to process images of varying resolutions and leading to more efficient and accurate visual representations.\n\n```js\nimport { AutoProcessor, Qwen2VLForConditionalGeneration, RawImage } from \"@&#8203;huggingface/transformers\";\n\n// Load processor and model\nconst model_id = \"onnx-community/Qwen2-VL-2B-Instruct\";\nconst processor = await AutoProcessor.from_pretrained(model_id);\nconst model = await Qwen2VLForConditionalGeneration.from_pretrained(model_id);\n\n// Prepare inputs\nconst url = \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\";\nconst image = await (await RawImage.read(url)).resize(448, 448);\nconst conversation = [\n  {\n    role: \"user\",\n    content: [\n      { type: \"image\" },\n      { type: \"text\", text: \"Describe this image.\" },\n    ],\n  },\n];\nconst text = processor.apply_chat_template(conversation, { add_generation_prompt: true });\nconst inputs = await processor(text, image);\n\n// Perform inference\nconst outputs = await model.generate({\n  ...inputs,\n  max_new_tokens: 128,\n});\n\n// Decode output\nconst decoded = processor.batch_decode(\n  outputs.slice(null, [inputs.input_ids.dims.at(-1), null]),\n  { skip_special_tokens: true },\n);\nconsole.log(decoded[0]);\n// The image depicts a serene beach scene with a woman and a dog. The woman is sitting on the sand, wearing a plaid shirt, and appears to be engaged in a playful interaction with the dog. The dog, which is a large breed, is sitting on its hind legs and appears to be reaching out to the woman, possibly to give her a high-five or a paw. The background shows the ocean with gentle waves, and the sky is clear, suggesting it might be either sunrise or sunset. The overall atmosphere is calm and relaxed, capturing a moment of connection between the woman and the dog.\n```\n\n<h3 id=\"jina_clip\">JinaCLIP for multimodal embeddings</h3>\n\nJinaCLIP is a series of general-purpose multilingual multimodal embedding models for text & images, created by Jina AI.\n\n**Example:** Compute text and/or image embeddings with `jinaai/jina-clip-v2`:\n\n```js\nimport { AutoModel, AutoProcessor, RawImage, matmul } from \"@&#8203;huggingface/transformers\";\n\n// Load processor and model\nconst model_id = \"jinaai/jina-clip-v2\";\nconst processor = await AutoProcessor.from_pretrained(model_id);\nconst model = await AutoModel.from_pretrained(model_id, { dtype: \"q4\" /* e.g., \"fp16\", \"q8\", or \"q4\" */ });\n\n// Prepare inputs\nconst urls = [\"https://i.ibb.co/nQNGqL0/beach1.jpg\", \"https://i.ibb.co/r5w8hG8/beach2.jpg\"];\nconst images = await Promise.all(urls.map(url => RawImage.read(url)));\nconst sentences = [\n    \"\u063a\u0631\u0648\u0628 \u062c\u0645\u064a\u0644 \u0639\u0644\u0649 \u0627\u0644\u0634\u0627\u0637\u0626\", // Arabic\n    \"\u6d77\u6ee9\u4e0a\u7f8e\u4e3d\u7684\u65e5\u843d\", // Chinese\n    \"Un beau coucher de soleil sur la plage\", // French\n    \"Ein wundersch\u00f6ner Sonnenuntergang am Strand\", // German\n    \"\u0388\u03bd\u03b1 \u03cc\u03bc\u03bf\u03c1\u03c6\u03bf \u03b7\u03bb\u03b9\u03bf\u03b2\u03b1\u03c3\u03af\u03bb\u03b5\u03bc\u03b1 \u03c0\u03ac\u03bd\u03c9 \u03b1\u03c0\u03cc \u03c4\u03b7\u03bd \u03c0\u03b1\u03c1\u03b1\u03bb\u03af\u03b1\", // Greek\n    \"\u0938\u092e\u0941\u0926\u094d\u0930 \u0924\u091f \u092a\u0930 \u090f\u0915 \u0916\u0942\u092c\u0938\u0942\u0930\u0924 \u0938\u0942\u0930\u094d\u092f\u093e\u0938\u094d\u0924\", // Hindi\n    \"Un bellissimo tramonto sulla spiaggia\", // Italian\n    \"\u6d5c\u8fba\u306b\u6c88\u3080\u7f8e\u3057\u3044\u5915\u65e5\", // Japanese\n    \"\ud574\ubcc0 \uc704\ub85c \uc544\ub984\ub2e4\uc6b4 \uc77c\ubab0\", // Korean\n];\n\n// Encode text and images\nconst inputs = await processor(sentences, images, { padding: true, truncation: true });\nconst { l2norm_text_embeddings, l2norm_image_embeddings } = await model(inputs);\n\n// Encode query (text-only)\nconst query_prefix = \"Represent the query for retrieving evidence documents: \";\nconst query_inputs = await processor(query_prefix + \"beautiful sunset over the beach\");\nconst { l2norm_text_embeddings: query_embeddings } = await model(query_inputs);\n\n// Compute text-image similarity scores\nconst text_to_image_scores = await matmul(query_embeddings, l2norm_image_embeddings.transpose(1, 0));\nconsole.log(\"text-image similarity scores\", text_to_image_scores.tolist()[0]); // [0.29530206322669983, 0.3183615803718567]\n\n// Compute image-image similarity scores\nconst image_to_image_score = await matmul(l2norm_image_embeddings[0], l2norm_image_embeddings[1]);\nconsole.log(\"image-image similarity score\", image_to_image_score.item()); // 0.9344457387924194\n\n// Compute text-text similarity scores\nconst text_to_text_scores = await matmul(query_embeddings, l2norm_text_embeddings.transpose(1, 0));\nconsole.log(\"text-text similarity scores\", text_to_text_scores.tolist()[0]); // [0.5566609501838684, 0.7028406858444214, 0.582255482673645, 0.6648036241531372, 0.5462006330490112, 0.6791588068008423, 0.6192430257797241, 0.6258729100227356, 0.6453716158866882]\n```\n\n<h3 id=\"llava_onevision\">LLaVA-OneVision for Image-Text-to-Text</h3>\n\nLLaVA-OneVision is a Vision-Language Model that can generate text conditioned on one or several images/videos. The model consists of SigLIP vision encoder and a Qwen2 language backbone.\n\n**Example:** Multi-round conversations w/ PKV caching\n\n```js\nimport { AutoProcessor, AutoTokenizer, LlavaOnevisionForConditionalGeneration, RawImage } from '@&#8203;huggingface/transformers';\n\n// Load tokenizer, processor and model\nconst model_id = 'llava-hf/llava-onevision-qwen2-0.5b-ov-hf';\n\nconst tokenizer = await AutoTokenizer.from_pretrained(model_id);\nconst processor = await AutoProcessor.from_pretrained(model_id);\nconst model = await LlavaOnevisionForConditionalGeneration.from_pretrained(model_id, {\n    dtype: {\n        embed_tokens: 'fp16', // or 'fp32' or 'q8'\n        vision_encoder: 'fp16', // or 'fp32' or 'q8'\n        decoder_model_merged: 'q4', // or 'q8'\n    },\n    // device: 'webgpu',\n});\n\n// Prepare text inputs\nconst prompt = 'What does the text say?';\nconst messages = [\n    { role: 'system', content: 'Answer the question.' },\n    { role: 'user', content: `<image>\\n${prompt}` }\n]\nconst text = tokenizer.apply_chat_template(messages, { tokenize: false, add_generation_prompt: true });\nconst text_inputs = tokenizer(text);\n\n// Prepare vision inputs\nconst url = 'https://huggingface.co/qnguyen3/nanoLLaVA/resolve/main/example_1.png';\nconst image = await RawImage.fromURL(url);\nconst vision_inputs = await processor(image);\n\n// Generate response\nconst { past_key_values, sequences } = await model.generate({\n    ...text_inputs,\n    ...vision_inputs,\n    do_sample: false,\n    max_new_tokens: 64,\n    return_dict_in_generate: true,\n});\n\n// Decode output\nconst answer = tokenizer.decode(\n    sequences.slice(0, [text_inputs.input_ids.dims[1], null]),\n    { skip_special_tokens: true },\n);\nconsole.log(answer);\n// The text says \"small but mighty\" in a playful font.\n\nconst new_messages = [\n    ...messages,\n    { role: 'assistant', content: answer },\n    { role: 'user', content: 'How does the text correlate to the context of the image?' }\n]\nconst new_text = tokenizer.apply_chat_template(new_messages, { tokenize: false, add_generation_prompt: true });\nconst new_text_inputs = tokenizer(new_text);\n\n// Generate another response\nconst output = await model.generate({\n    ...new_text_inputs,\n    past_key_values,\n    do_sample: false,\n    max_new_tokens: 256,\n});\nconst new_answer = tokenizer.decode(\n    output.slice(0, [new_text_inputs.input_ids.dims[1], null]),\n    { skip_special_tokens: true },\n);\nconsole.log(new_answer);\n// The text \"small but mighty\" is likely a playful or humorous reference to the image of the blue mouse with the orange dumbbell. It could be used as a motivational phrase or a playful way to express the idea that even small things can be impressive or powerful.\n```\n\n<h3 id=\"vitpose\">ViTPose for pose-estimation</h3>\n\nA state-of-the-art pose estimation model which employs a standard, non-hierarchical vision transformer as a backbone for the task of keypoint estimation (combined with a simple decoder head to predict heatmaps from a given image).\n\n**Example:** Pose estimation w/ `onnx-community/vitpose-base-simple`.\n\n```js\nimport { AutoModel, AutoImageProcessor, RawImage } from '@&#8203;huggingface/transformers';\n\n// Load model and processor\nconst model_id = 'onnx-community/vitpose-base-simple';\nconst model = await AutoModel.from_pretrained(model_id);\nconst processor = await AutoImageProcessor.from_pretrained(model_id);\n\n// Load image and prepare inputs\nconst url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/ryan-gosling.jpg';\nconst image = await RawImage.read(url);\nconst inputs = await processor(image);\n\n// Predict heatmaps\nconst { heatmaps } = await model(inputs);\n\n// Post-process heatmaps to get keypoints and scores\nconst boxes = [[[0, 0, image.width, image.height]]];\nconst results = processor.post_process_pose_estimation(heatmaps, boxes)[0][0];\nconsole.log(results);\n```\n\n<details>\n\n<summary>Optionally, visualize the outputs (Node.js usage shown here, using the node-canvas library):</summary>\n\n```js\nimport { createCanvas, createImageData } from 'canvas';\n\n// Create canvas and draw image\nconst canvas = createCanvas(image.width, image.height);\nconst ctx = canvas.getContext('2d');\nconst imageData = createImageData(image.rgba().data, image.width, image.height);\nctx.putImageData(imageData, 0, 0);\n\n// Draw edges between keypoints\nconst points = results.keypoints;\nctx.lineWidth = 4;\nctx.strokeStyle = 'blue';\nfor (const [i, j] of model.config.edges) {\n    const [x1, y1] = points[i];\n    const [x2, y2] = points[j];\n    ctx.beginPath();\n    ctx.moveTo(x1, y1);\n    ctx.lineTo(x2, y2);\n    ctx.stroke();\n}\n\n// Draw circle at each keypoint\nctx.fillStyle = 'red';\nfor (const [x, y] of points) {\n    ctx.beginPath();\n    ctx.arc(x, y, 8, 0, 2 * Math.PI);\n    ctx.fill();\n}\n\n// Save image to file\nimport fs from 'fs';\nconst out = fs.createWriteStream('pose.png');\nconst stream = canvas.createPNGStream();\nstream.pipe(out)\nout.on('finish', () =>  console.log('The PNG file was created.'));\n```\n\n</details>\n\n| Input image | Output image |\n| :----------:|:------------:|\n| ![image/jpeg](https://cdn-uploads.huggingface.co/production/uploads/61b253b7ac5ecaae3d1efe0c/QpXlLNyLDKZUxXjokbUyy.jpeg) | ![image/png](https://cdn-uploads.huggingface.co/production/uploads/61b253b7ac5ecaae3d1efe0c/xj0jaKo9aAOux-NSU8U7S.png) |\n\n<h3 id=\"mgp-str\">MGP-STR for Optical Character Recognition (OCR)</h3>\n\nA simple yet powerful vision scene text recognition model, built upon the vision transformer (ViT).\n\n**Example:** Optical Character Recognition (OCR) w/ `onnx-community/mgp-str-base`\n\n```js\nimport { MgpstrForSceneTextRecognition, MgpstrProcessor, RawImage } from '@&#8203;huggingface/transformers';\n\nconst model_id = 'onnx-community/mgp-str-base';\nconst model = await MgpstrForSceneTextRecognition.from_pretrained(model_id);\nconst processor = await MgpstrProcessor.from_pretrained(model_id);\n\n// Load image from the IIIT-5k dataset\nconst url = \"https://i.postimg.cc/ZKwLg2Gw/367-14.png\";\nconst image = await RawImage.read(url);\n\n// Preprocess the image\nconst result = await processor(image);\n\n// Perform inference\nconst outputs = await model(result);\n\n// Decode the model outputs\nconst generated_text = processor.batch_decode(outputs.logits).generated_text;\nconsole.log(generated_text); // [ 'ticket' ]\n```\n\n<h3 id=\"patchtst-and-patchtsmixer\">PatchTST and PatchTSMixer for time series forecasting.</h3>\n\n**Example:** Time series forecasting w/ `onnx-community/granite-timeseries-patchtst`\n\nModels which can be used for multivariate time series forecasting.\n\n```js\nimport { PatchTSTForPrediction, Tensor } from \"@&#8203;huggingface/transformers\";\n\nconst model_id = \"onnx-community/granite-timeseries-patchtst\";\nconst model = await PatchTSTForPrediction.from_pretrained(model_id, { dtype: \"fp32\" });\n\nconst dims = [64, 512, 7];\nconst prod = dims.reduce((a, b) => a * b, 1);\nconst past_values = new Tensor('float32',\n    Float32Array.from({ length: prod }, (_, i) => i / prod),\n    dims,\n);\nconst { prediction_outputs } = await model({ past_values });\nconsole.log(prediction_outputs);\n```\n\n**Example:** Time series forecasting w/ `onnx-community/granite-timeseries-patchtsmixer`\n\n```js\nimport { PatchTSMixerForPrediction, Tensor } from \"@&#8203;huggingface/transformers\";\n\nconst model_id = \"onnx-community/granite-timeseries-patchtsmixer\";\nconst model = await PatchTSMixerForPrediction.from_pretrained(model_id, { dtype: \"fp32\" });\n\nconst dims = [64, 512, 7];\nconst prod = dims.reduce((a, b) => a * b, 1);\nconst past_values = new Tensor('float32',\n    Float32Array.from({ length: prod }, (_, i) => i / prod),\n    dims,\n);\nconst { prediction_outputs } = await model({ past_values });\nconsole.log(prediction_outputs);\n```\n\n<h2 id=\"bug-fixes\">\ud83d\udc1b Bug fixes</h2>\n\n-   When padding an image, the dimensions get stretched by [@&#8203;BritishWerewolf](https://redirect.github.com/BritishWerewolf) in [https://github.com/huggingface/transformers.js/pull/1015](https://redirect.github.com/huggingface/transformers.js/pull/1015)\n-   fix(scale): add missing scale element by [@&#8203;tosinamuda](https://redirect.github.com/tosinamuda) in [https://github.com/huggingface/transformers.js/pull/1017](https://redirect.github.com/huggingface/transformers.js/pull/1017)\n\n<h2 id=\"documentation-improvements\">\ud83d\udcdd Documentation improvements</h2>\n\n-   Updated link to sentence similarity models. by [@&#8203;uzyn](https://redirect.github.com/uzyn) in [https://github.com/huggingface/transformers.js/pull/893](https://redirect.github.com/huggingface/transformers.js/pull/893)\n-   fix(docs): fixed a broken link to quantization guide by [@&#8203;ThomasWT](https://redirect.github.com/ThomasWT) in [https://github.com/huggingface/transformers.js/pull/1014](https://redirect.github.com/huggingface/transformers.js/pull/1014)\n-   fix(docs): Fixed Typos in README and docs/snippets/6\\_supported-models.snippet by [@&#8203;hitchhiker3010](https://redirect.github.com/hitchhiker3010) in [https://github.com/huggingface/transformers.js/pull/1030](https://redirect.github.com/huggingface/transformers.js/pull/1030)\n\n<h2 id=\"other-improvements\">\ud83d\udee0\ufe0f Other improvements</h2>\n\n-   Add option to maintain aspect ratio on resize by [@&#8203;BritishWerewolf](https://redirect.github.com/BritishWerewolf) in [https://github.com/huggingface/transformers.js/pull/971](https://redirect.github.com/huggingface/transformers.js/pull/971)\n-   Add functionality to split RawImage into channels; Update slice documentation and tests by [@&#8203;BritishWerewolf](https://redirect.github.com/BritishWerewolf) in [https://github.com/huggingface/transformers.js/pull/978](https://redirect.github.com/huggingface/transformers.js/pull/978)\n-   Avoid resizing images when they already have the desired size by [@&#8203;nemphys](https://redirect.github.com/nemphys) in [https://github.com/huggingface/transformers.js/pull/1027](https://redirect.github.com/huggingface/transformers.js/pull/1027)\n-   Add support for Split pretokenizer w/ `behavior=removed` & `invert=false` by [@&#8203;xenova](https://redirect.github.com/xenova) in [https://github.com/huggingface/transformers.js/pull/1033](https://redirect.github.com/huggingface/transformers.js/pull/1033)\n-   Add type declaration for `progress_callback` by [@&#8203;ocavue](https://redirect.github.com/ocavue) in [https://github.com/huggingface/transformers.js/pull/1034](https://redirect.github.com/huggingface/transformers.js/pull/1034)\n-   Add support for op_block_list by [@&#8203;pdufour](https://redirect.github.com/pdufour) in [https://github.com/huggingface/transformers.js/pull/1036](https://redirect.github.com/huggingface/transformers.js/pull/1036)\n\n<h2 id=\"new-contributors\">\ud83e\udd17 New contributors</h2>\n\n-   [@&#8203;uzyn](https://redirect.github.com/uzyn) made their first contribution in [https://github.com/huggingface/transformers.js/pull/893](https://redirect.github.com/huggingface/transformers.js/pull/893)\n-   [@&#8203;ThomasWT](https://redirect.github.com/ThomasWT) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1014](https://redirect.github.com/huggingface/transformers.js/pull/1014)\n-   [@&#8203;tosinamuda](https://redirect.github.com/tosinamuda) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1017](https://redirect.github.com/huggingface/transformers.js/pull/1017)\n-   [@&#8203;nemphys](https://redirect.github.com/nemphys) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1027](https://redirect.github.com/huggingface/transformers.js/pull/1027)\n-   [@&#8203;hitchhiker3010](https://redirect.github.com/hitchhiker3010) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1030](https://redirect.github.com/huggingface/transformers.js/pull/1030)\n-   [@&#8203;pdufour](https://redirect.github.com/pdufour) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1036](https://redirect.github.com/huggingface/transformers.js/pull/1036)\n\n**Full Changelog**: https://github.com/huggingface/transformers.js/compare/3.0.2...3.1.0\n\n</details>\n\n<details>\n<summary>openai/openai-node (openai)</summary>\n\n### [`v4.76.0`](https://redirect.github.com/openai/openai-node/blob/HEAD/CHANGELOG.md#4760-2024-12-05)\n\n[Compare Source](https://redirect.github.com/openai/openai-node/compare/v4.75.0...v4.76.0)\n\nFull Changelog: [v4.75.0...v4.76.0](https://redirect.github.com/openai/openai-node/compare/v4.75.0...v4.76.0)\n\n##### Features\n\n-   **api:** updates ([#&#8203;1212](https://redirect.github.com/openai/openai-node/issues/1212)) ([e0fedf2](https://redirect.github.com/openai/openai-node/commit/e0fedf2c5a91d0c03d8dad6854b366f77eab4923))\n\n##### Chores\n\n-   bump openapi url ([#&#8203;1210](https://redirect.github.com/openai/openai-node/issues/1210)) ([3fa95a4](https://redirect.github.com/openai/openai-node/commit/3fa95a429d4b2adecce35a7b96b73f6d5e88eeeb))\n\n### [`v4.75.0`](https://redirect.github.com/openai/openai-node/blob/HEAD/CHANGELOG.md#4750-2024-12-03)\n\n[Compare Source](https://redirect.github.com/openai/openai-node/compare/v4.74.0...v4.75.0)\n\nFull Changelog: [v4.74.0...v4.75.0](https://redirect.github.com/openai/openai-node/compare/v4.74.0...v4.75.0)\n\n##### Features\n\n-   improve docs for jsr README.md ([#&#8203;1208](https://redirect.github.com/openai/openai-node/issues/1208)) ([338527e](https://redirect.github.com/openai/openai-node/commit/338527e40361e2de899a63f280d4ec2db5e87f3c))\n\n### [`v4.74.0`](https://redirect.github.com/openai/openai-node/blob/HEAD/CHANGELOG.md#4740-2024-12-02)\n\n[Compare Source](https://redirect.github.com/openai/openai-node/compare/v4.73.1...v4.74.0)\n\nFull Changelog: [v4.73.1...v4.74.0](https://redirect.github.com/openai/openai-node/compare/v4.73.1...v4.74.0)\n\n##### Features\n\n-   **internal:** make git install file structure match npm ([#&#8203;1204](https://redirect.github.com/openai/openai-node/issues/1204)) ([e7c4c6d](https://redirect.github.com/openai/openai-node/commit/e7c4c6d23adbe52300053a8d35db6e341c438703))\n\n### [`v4.73.1`](https://redirect.github.com/openai/openai-node/blob/HEAD/CHANGELOG.md#4731-2024-11-25)\n\n[Compare Source](https://redirect.github.com/openai/openai-node/compare/v4.73.0...v4.73.1)\n\nFull Changelog: [v4.73.0...v4.73.1](https://redirect.github.com/openai/openai-node/compare/v4.73.0...v4.73.1)\n\n##### Documentation\n\n-   **readme:** mention `.withResponse()` for streaming request ID ([#&#8203;1202](https://redirect.github.com/openai/openai-node/issues/1202)) ([b6800d4](https://redirect.github.com/openai/openai-node/commit/b6800d4dea2729fe3b0864171ce8fb3b2cc1b21c))\n\n</details>\n\n---\n\n### Configuration\n\n\ud83d\udcc5 **Schedule**: Branch creation - \"every weekend\" in timezone UTC, Automerge - At any time (no schedule defined).\n\n\ud83d\udea6 **Automerge**: Disabled by config. Please merge this manually once you are satisfied.\n\n\u267b **Rebasing**: Whenever PR becomes conflicted, or you tick the rebase/retry checkbox.\n\n\ud83d\udc7b **Immortal**: This PR will be recreated if closed unmerged. Get [config help](https://redirect.github.com/renovatebot/renovate/discussions) if that's undesired.\n\n---\n\n - [ ] <!-- rebase-check -->If you want to rebase/retry this PR, check this box\n\n---\n\nThis PR was generated by [Mend Renovate](https://mend.io/renovate/). View the [repository job log](https://developer.mend.io/github/ai16z/eliza).\n<!--renovate-debug:eyJjcmVhdGVkSW5WZXIiOiIzOS40Mi40IiwidXBkYXRlZEluVmVyIjoiMzkuNDIuNCIsInRhcmdldEJyYW5jaCI6Im1haW4iLCJsYWJlbHMiOltdfQ==-->\n",
            "files": [
              {
                "path": "packages/core/package.json",
                "additions": 2,
                "deletions": 2
              },
              {
                "path": "packages/plugin-node/package.json",
                "additions": 1,
                "deletions": 1
              },
              {
                "path": "pnpm-lock.yaml",
                "additions": 305,
                "deletions": 133
              }
            ],
            "reviews": [],
            "comments": []
          },
          {
            "number": 879,
            "title": "fix(deps): update ai/ml packages",
            "state": "CLOSED",
            "merged": false,
            "created_at": "2024-12-07T00:33:21Z",
            "updated_at": "2024-12-07T03:00:31Z",
            "body": "This PR contains the following updates:\n\n| Package | Change | Age | Adoption | Passing | Confidence |\n|---|---|---|---|---|---|\n| [@anthropic-ai/sdk](https://redirect.github.com/anthropics/anthropic-sdk-typescript) | [`0.30.1` -> `0.32.1`](https://renovatebot.com/diffs/npm/@anthropic-ai%2fsdk/0.30.1/0.32.1) | [![age](https://developer.mend.io/api/mc/badges/age/npm/@anthropic-ai%2fsdk/0.32.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![adoption](https://developer.mend.io/api/mc/badges/adoption/npm/@anthropic-ai%2fsdk/0.32.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![passing](https://developer.mend.io/api/mc/badges/compatibility/npm/@anthropic-ai%2fsdk/0.30.1/0.32.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![confidence](https://developer.mend.io/api/mc/badges/confidence/npm/@anthropic-ai%2fsdk/0.30.1/0.32.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) |\n| [@huggingface/transformers](https://redirect.github.com/huggingface/transformers.js) | [`3.0.2` -> `3.1.1`](https://renovatebot.com/diffs/npm/@huggingface%2ftransformers/3.0.2/3.1.1) | [![age](https://developer.mend.io/api/mc/badges/age/npm/@huggingface%2ftransformers/3.1.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![adoption](https://developer.mend.io/api/mc/badges/adoption/npm/@huggingface%2ftransformers/3.1.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![passing](https://developer.mend.io/api/mc/badges/compatibility/npm/@huggingface%2ftransformers/3.0.2/3.1.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![confidence](https://developer.mend.io/api/mc/badges/confidence/npm/@huggingface%2ftransformers/3.0.2/3.1.1?slim=true)](https://docs.renovatebot.com/merge-confidence/) |\n| [openai](https://redirect.github.com/openai/openai-node) | [`4.73.0` -> `4.76.0`](https://renovatebot.com/diffs/npm/openai/4.73.0/4.76.0) | [![age](https://developer.mend.io/api/mc/badges/age/npm/openai/4.76.0?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![adoption](https://developer.mend.io/api/mc/badges/adoption/npm/openai/4.76.0?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![passing](https://developer.mend.io/api/mc/badges/compatibility/npm/openai/4.73.0/4.76.0?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![confidence](https://developer.mend.io/api/mc/badges/confidence/npm/openai/4.73.0/4.76.0?slim=true)](https://docs.renovatebot.com/merge-confidence/) |\n\n---\n\n### Release Notes\n\n<details>\n<summary>anthropics/anthropic-sdk-typescript (@&#8203;anthropic-ai/sdk)</summary>\n\n### [`v0.32.1`](https://redirect.github.com/anthropics/anthropic-sdk-typescript/blob/HEAD/CHANGELOG.md#0321-2024-11-05)\n\nFull Changelog: [sdk-v0.32.0...sdk-v0.32.1](https://redirect.github.com/anthropics/anthropic-sdk-typescript/compare/sdk-v0.32.0...sdk-v0.32.1)\n\n##### Bug Fixes\n\n-   **bedrock:** don't mutate request body inputs ([f83b535](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/f83b53520262219229cecc388f95d92be83c09d5))\n-   **vertex:** don't mutate request body inputs ([e9a82e5](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/e9a82e56f0d7fff956c2ebd19e103a190f8beb83))\n\n### [`v0.32.0`](https://redirect.github.com/anthropics/anthropic-sdk-typescript/blob/HEAD/CHANGELOG.md#0320-2024-11-04)\n\nFull Changelog: [sdk-v0.31.0...sdk-v0.32.0](https://redirect.github.com/anthropics/anthropic-sdk-typescript/compare/sdk-v0.31.0...sdk-v0.32.0)\n\n##### Features\n\n-   **api:** add new haiku model ([#&#8203;587](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/587)) ([983b13c](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/983b13c9e4f55b832fc4fddfd46bed89756d745e))\n\n##### Bug Fixes\n\n-   don't require deno to run build-deno ([#&#8203;586](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/586)) ([0e431d6](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/0e431d61ec318aae09687dee0bfb922ccb8ddd15))\n-   **types:** add missing token-counting-2024-11-01 ([#&#8203;583](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/583)) ([13d629c](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/13d629c9b444a32b69729df7792199556a2b95f2))\n\n##### Chores\n\n-   remove unused build-deno condition ([#&#8203;585](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/585)) ([491e8fe](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/491e8fe28745aeb55217809f94ad4e37900f4675))\n\n### [`v0.31.0`](https://redirect.github.com/anthropics/anthropic-sdk-typescript/blob/HEAD/CHANGELOG.md#0310-2024-11-01)\n\nFull Changelog: [sdk-v0.30.1...sdk-v0.31.0](https://redirect.github.com/anthropics/anthropic-sdk-typescript/compare/sdk-v0.30.1...sdk-v0.31.0)\n\n##### Features\n\n-   **api:** add message token counting & PDFs support ([#&#8203;582](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/582)) ([b593837](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/b593837ae2d320414a26b5ec53aa6d3f30a3e6bc))\n\n##### Bug Fixes\n\n-   **countTokens:** correctly set beta header ([1680757](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/16807572af923831e384869a0a6ccccaa8dbec84))\n-   **internal:** support pnpm git installs ([#&#8203;579](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/579)) ([86bb102](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/86bb102ce33346930a8b0a553a909fcc7d964a36))\n-   **types:** add missing token-counting-2024-11-01 ([aff1546](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/aff1546cd84ce50a52d17bcdcaba54e60e92955a))\n\n##### Reverts\n\n-   disable isolatedModules and change imports ([#&#8203;575](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/575)) ([2c3b176](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/2c3b176fc551c21abef240b4fa6a98d33ca52048))\n\n##### Chores\n\n-   **internal:** update spec version ([#&#8203;571](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/571)) ([5760012](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/576001245f0b5222cb9b17fafb8619f68d51bec3))\n\n##### Documentation\n\n-   **readme:** minor typo fixes ([#&#8203;577](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/577)) ([8412854](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/8412854c05837cdb8b8ff898bef2a4e0dbb23cd2))\n\n##### Refactors\n\n-   enable isolatedModules and change imports ([#&#8203;573](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/573)) ([9068b4b](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/9068b4b0a0a08a69a9330ce03418135e11aa539e))\n-   use type imports for type-only imports ([#&#8203;580](https://redirect.github.com/anthropics/anthropic-sdk-typescript/issues/580)) ([2c8a337](https://redirect.github.com/anthropics/anthropic-sdk-typescript/commit/2c8a337033e850b7282d35b37c3ce36d5b0dabbe))\n\n</details>\n\n<details>\n<summary>huggingface/transformers.js (@&#8203;huggingface/transformers)</summary>\n\n### [`v3.1.1`](https://redirect.github.com/huggingface/transformers.js/releases/tag/3.1.1)\n\n[Compare Source](https://redirect.github.com/huggingface/transformers.js/compare/3.1.0...3.1.1)\n\n#### \ud83e\udd16 New models\n\n-   Add support for Idefics3 (SmolVLM) in [https://github.com/huggingface/transformers.js/pull/1059](https://redirect.github.com/huggingface/transformers.js/pull/1059)\n\n    ```js\n    import {\n      AutoProcessor,\n      AutoModelForVision2Seq,\n      load_image,\n    } from \"@&#8203;huggingface/transformers\";\n\n    // Initialize processor and model\n    const model_id = \"HuggingFaceTB/SmolVLM-Instruct\";\n    const processor = await AutoProcessor.from_pretrained(model_id);\n    const model = await AutoModelForVision2Seq.from_pretrained(model_id, {\n      dtype: {\n        embed_tokens: \"fp16\", // \"fp32\", \"fp16\", \"q8\"\n        vision_encoder: \"q4\", // \"fp32\", \"fp16\", \"q8\", \"q4\", \"q4f16\"\n        decoder_model_merged: \"q4\", // \"q8\", \"q4\", \"q4f16\"\n      }\n    });\n\n    // Load images\n    const image1 = await load_image(\"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\");\n    const image2 = await load_image(\"https://huggingface.co/spaces/merve/chameleon-7b/resolve/main/bee.jpg\");\n\n    // Create input messages\n    const messages = [\n      {\n        role: \"user\",\n        content: [\n          { type: \"image\" },\n          { type: \"image\" },\n          { type: \"text\", text: \"Can you describe the two images?\" },\n        ],\n      },\n    ];\n\n    // Prepare inputs\n    const text = processor.apply_chat_template(messages, { add_generation_prompt: true });\n    const inputs = await processor(text, [image1, image2], {\n      // Set `do_image_splitting: true` to split images into multiple patches.\n      // NOTE: This uses more memory, but can provide more accurate results.\n      do_image_splitting: false,\n    });\n\n    // Generate outputs\n    const generated_ids = await model.generate({\n      ...inputs,\n      max_new_tokens: 500,\n    });\n    const generated_texts = processor.batch_decode(\n      generated_ids.slice(null, [inputs.input_ids.dims.at(-1), null]),\n      { skip_special_tokens: true },\n    );\n    console.log(generated_texts[0]);\n    // ' In the first image, there is a green statue of liberty on a pedestal in the middle of the water. The water is surrounded by trees and buildings in the background. In the second image, there are pink and red flowers with a bee on the pink flower.'\n    ```\n\n#### \ud83d\udc1b Bug fixes\n\n-   Fix repetition penalty logits processor in [https://github.com/huggingface/transformers.js/pull/1062](https://redirect.github.com/huggingface/transformers.js/pull/1062)\n-   Fix optional chaining for batch size calculation in PreTrainedModel by [@&#8203;emojiiii](https://redirect.github.com/emojiiii) in [https://github.com/huggingface/transformers.js/pull/1063](https://redirect.github.com/huggingface/transformers.js/pull/1063)\n\n#### \ud83d\udcdd Documentation improvements\n\n-   Add an example and type enhancement for TextStreamer by [@&#8203;seonglae](https://redirect.github.com/seonglae) in [https://github.com/huggingface/transformers.js/pull/1066](https://redirect.github.com/huggingface/transformers.js/pull/1066)\n-   The smallest typo fix for webgpu.md by [@&#8203;JoramMillenaar](https://redirect.github.com/JoramMillenaar) in [https://github.com/huggingface/transformers.js/pull/1068](https://redirect.github.com/huggingface/transformers.js/pull/1068)\n\n#### \ud83d\udee0\ufe0f Other improvements\n\n-   Only log warning if type not explicitly set to \"custom\" in [https://github.com/huggingface/transformers.js/pull/1061](https://redirect.github.com/huggingface/transformers.js/pull/1061)\n-   Improve browser vs. webworker detection in [https://github.com/huggingface/transformers.js/pull/1067](https://redirect.github.com/huggingface/transformers.js/pull/1067)\n\n#### \ud83e\udd17 New contributors\n\n-   [@&#8203;emojiiii](https://redirect.github.com/emojiiii) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1063](https://redirect.github.com/huggingface/transformers.js/pull/1063)\n-   [@&#8203;seonglae](https://redirect.github.com/seonglae) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1066](https://redirect.github.com/huggingface/transformers.js/pull/1066)\n-   [@&#8203;JoramMillenaar](https://redirect.github.com/JoramMillenaar) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1068](https://redirect.github.com/huggingface/transformers.js/pull/1068)\n\n**Full Changelog**: https://github.com/huggingface/transformers.js/compare/3.1.0...3.1.1\n\n### [`v3.1.0`](https://redirect.github.com/huggingface/transformers.js/releases/tag/3.1.0)\n\n[Compare Source](https://redirect.github.com/huggingface/transformers.js/compare/3.0.2...3.1.0)\n\n### \ud83d\ude80 Transformers.js v3.1 \u2014 any-to-any, text-to-image, image-to-text, pose estimation, time series forecasting, and more!\n\nTable of contents:\n\n-   [\ud83e\udd16 New models: Janus, Qwen2-VL, JinaCLIP, LLaVA-OneVision, ViTPose, MGP-STR, PatchTST, PatchTSMixer.](#new-models)\n    -   [**Janus**: Any-to-Any generation](#janus)\n    -   [**Qwen2-VL**: Image-Text-to-Text](#qwen2vl)\n    -   [**JinaCLIP**: Multimodal embeddings](#jina_clip)\n    -   [**LLaVA-OneVision**: Image-Text-to-Text](#llava_onevision)\n    -   [**ViTPose**: Pose-estimation](#vitpose)\n    -   [**MGP-STR**: Optical Character Recognition (OCR)](#mgp-str)\n    -   [**PatchTST and PatchTSMixer**: Time series forecasting.](#patchtst-and-patchtsmixer)\n-   [\ud83d\udc1b Bug fixes](#bug-fixes)\n-   [\ud83d\udcdd Documentation improvements](#documentation-improvements)\n-   [\ud83d\udee0\ufe0f Other improvements](#other-improvements)\n-   [\ud83e\udd17 New contributors](#new-contributors)\n\n<h2 id=\"new-models\">\ud83e\udd16 New models: Janus, Qwen2-VL, JinaCLIP, LLaVA-OneVision, ViTPose, MGP-STR, PatchTST, PatchTSMixer.</h2>\n\n<h3 id=\"janus\">Janus for Any-to-Any generation (e.g., image-to-text and text-to-image)</h3>\n\nFirst of all, this release adds support for Janus, a novel autoregressive framework that unifies multimodal understanding and generation. The most popular model, [deepseek-ai/Janus-1.3B](https://huggingface.co/deepseek-ai/Janus-1.3B), is tagged as an \"any-to-any\" model, and has specifically been trained for the following tasks:\n\n**Example:** Image-Text-to-Text\n\n```js\nimport { AutoProcessor, MultiModalityCausalLM } from \"@&#8203;huggingface/transformers\";\n\n// Load processor and model\nconst model_id = \"onnx-community/Janus-1.3B-ONNX\";\nconst processor = await AutoProcessor.from_pretrained(model_id);\nconst model = await MultiModalityCausalLM.from_pretrained(model_id);\n\n// Prepare inputs\nconst conversation = [\n  {\n    role: \"User\",\n    content: \"<image_placeholder>\\nConvert the formula into latex code.\",\n    images: [\"https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/quadratic_formula.png\"],\n  },\n];\nconst inputs = await processor(conversation);\n\n// Generate response\nconst outputs = await model.generate({\n  ...inputs,\n  max_new_tokens: 150,\n  do_sample: false,\n});\n\n// Decode output\nconst new_tokens = outputs.slice(null, [inputs.input_ids.dims.at(-1), null]);\nconst decoded = processor.batch_decode(new_tokens, { skip_special_tokens: true });\nconsole.log(decoded[0]);\n```\n\nSample output:\n\n    Sure, here is the LaTeX code for the given formula:\n\n    ```\n    x = \\frac{-b \\pm \\sqrt{b^2 - 4a c}}{2a}\n    ```\n\n    This code represents the mathematical expression for the variable \\( x \\).\n\n**Example:** Text-to-Image\n\n```js\nimport { AutoProcessor, MultiModalityCausalLM } from \"@&#8203;huggingface/transformers\";\n\n// Load processor and model\nconst model_id = \"onnx-community/Janus-1.3B-ONNX\";\nconst processor = await AutoProcessor.from_pretrained(model_id);\nconst model = await MultiModalityCausalLM.from_pretrained(model_id);\n\n// Prepare inputs\nconst conversation = [\n  {\n    role: \"User\",\n    content: \"A cute and adorable baby fox with big brown eyes, autumn leaves in the background enchanting,immortal,fluffy, shiny mane,Petals,fairyism,unreal engine 5 and Octane Render,highly detailed, photorealistic, cinematic, natural colors.\",\n  },\n];\nconst inputs = await processor(conversation, { chat_template: \"text_to_image\" });\n\n// Generate response\nconst num_image_tokens = processor.num_image_tokens;\nconst outputs = await model.generate_images({\n  ...inputs,\n  min_new_tokens: num_image_tokens,\n  max_new_tokens: num_image_tokens,\n  do_sample: true,\n});\n\n// Save the generated image\nawait outputs[0].save(\"test.png\");\n```\n\nSample outputs:\n\n|  ![fox\\_1](https://redirect.github.com/user-attachments/assets/c8a4f588-655f-440e-bd55-79d19505edae)  | ![fox\\_2](https://redirect.github.com/user-attachments/assets/88b5003a-82de-4ef9-8315-6cb59aee607d) | ![fox\\_3](https://redirect.github.com/user-attachments/assets/f92ed498-4a32-4757-86de-cac37bc8fbf6) | ![fox\\_4](https://redirect.github.com/user-attachments/assets/51b9d0a6-c737-499d-983e-d89ff023282d) |\n|---|---|---|---|\n| ![fox\\_5](https://redirect.github.com/user-attachments/assets/8876ebb0-fea2-4443-b458-fdd6c035a69f) | ![fox\\_6](https://redirect.github.com/user-attachments/assets/1989f128-5fd4-4b0c-83b4-dc5f33b388c2) | ![fox\\_7](https://redirect.github.com/user-attachments/assets/1fa9ac58-ca14-4ee3-84ca-47e69de2589c) | ![fox\\_8](https://redirect.github.com/user-attachments/assets/20a20642-a336-4277-9056-f45d7ddb3bbe) |\n\nWhat to play around with the model? Check out our [online WebGPU demo](https://huggingface.co/spaces/webml-community/Janus-1.3B-WebGPU)! \ud83d\udc47\n\nhttps://github.com/user-attachments/assets/513b3119-ba8c-4a2d-b5fe-6869be47abfa\n\n<h3 id=\"qwen2vl\">Qwen2-VL for Image-Text-to-Text</h3>\n\n**Example:** Image-Text-to-Text\n\nNext, we added support for Qwen2-VL, the multimodal large language model series developed by Qwen team, Alibaba Cloud. It introduces the Naive Dynamic Resolution mechanism, allowing the model to process images of varying resolutions and leading to more efficient and accurate visual representations.\n\n```js\nimport { AutoProcessor, Qwen2VLForConditionalGeneration, RawImage } from \"@&#8203;huggingface/transformers\";\n\n// Load processor and model\nconst model_id = \"onnx-community/Qwen2-VL-2B-Instruct\";\nconst processor = await AutoProcessor.from_pretrained(model_id);\nconst model = await Qwen2VLForConditionalGeneration.from_pretrained(model_id);\n\n// Prepare inputs\nconst url = \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\";\nconst image = await (await RawImage.read(url)).resize(448, 448);\nconst conversation = [\n  {\n    role: \"user\",\n    content: [\n      { type: \"image\" },\n      { type: \"text\", text: \"Describe this image.\" },\n    ],\n  },\n];\nconst text = processor.apply_chat_template(conversation, { add_generation_prompt: true });\nconst inputs = await processor(text, image);\n\n// Perform inference\nconst outputs = await model.generate({\n  ...inputs,\n  max_new_tokens: 128,\n});\n\n// Decode output\nconst decoded = processor.batch_decode(\n  outputs.slice(null, [inputs.input_ids.dims.at(-1), null]),\n  { skip_special_tokens: true },\n);\nconsole.log(decoded[0]);\n// The image depicts a serene beach scene with a woman and a dog. The woman is sitting on the sand, wearing a plaid shirt, and appears to be engaged in a playful interaction with the dog. The dog, which is a large breed, is sitting on its hind legs and appears to be reaching out to the woman, possibly to give her a high-five or a paw. The background shows the ocean with gentle waves, and the sky is clear, suggesting it might be either sunrise or sunset. The overall atmosphere is calm and relaxed, capturing a moment of connection between the woman and the dog.\n```\n\n<h3 id=\"jina_clip\">JinaCLIP for multimodal embeddings</h3>\n\nJinaCLIP is a series of general-purpose multilingual multimodal embedding models for text & images, created by Jina AI.\n\n**Example:** Compute text and/or image embeddings with `jinaai/jina-clip-v2`:\n\n```js\nimport { AutoModel, AutoProcessor, RawImage, matmul } from \"@&#8203;huggingface/transformers\";\n\n// Load processor and model\nconst model_id = \"jinaai/jina-clip-v2\";\nconst processor = await AutoProcessor.from_pretrained(model_id);\nconst model = await AutoModel.from_pretrained(model_id, { dtype: \"q4\" /* e.g., \"fp16\", \"q8\", or \"q4\" */ });\n\n// Prepare inputs\nconst urls = [\"https://i.ibb.co/nQNGqL0/beach1.jpg\", \"https://i.ibb.co/r5w8hG8/beach2.jpg\"];\nconst images = await Promise.all(urls.map(url => RawImage.read(url)));\nconst sentences = [\n    \"\u063a\u0631\u0648\u0628 \u062c\u0645\u064a\u0644 \u0639\u0644\u0649 \u0627\u0644\u0634\u0627\u0637\u0626\", // Arabic\n    \"\u6d77\u6ee9\u4e0a\u7f8e\u4e3d\u7684\u65e5\u843d\", // Chinese\n    \"Un beau coucher de soleil sur la plage\", // French\n    \"Ein wundersch\u00f6ner Sonnenuntergang am Strand\", // German\n    \"\u0388\u03bd\u03b1 \u03cc\u03bc\u03bf\u03c1\u03c6\u03bf \u03b7\u03bb\u03b9\u03bf\u03b2\u03b1\u03c3\u03af\u03bb\u03b5\u03bc\u03b1 \u03c0\u03ac\u03bd\u03c9 \u03b1\u03c0\u03cc \u03c4\u03b7\u03bd \u03c0\u03b1\u03c1\u03b1\u03bb\u03af\u03b1\", // Greek\n    \"\u0938\u092e\u0941\u0926\u094d\u0930 \u0924\u091f \u092a\u0930 \u090f\u0915 \u0916\u0942\u092c\u0938\u0942\u0930\u0924 \u0938\u0942\u0930\u094d\u092f\u093e\u0938\u094d\u0924\", // Hindi\n    \"Un bellissimo tramonto sulla spiaggia\", // Italian\n    \"\u6d5c\u8fba\u306b\u6c88\u3080\u7f8e\u3057\u3044\u5915\u65e5\", // Japanese\n    \"\ud574\ubcc0 \uc704\ub85c \uc544\ub984\ub2e4\uc6b4 \uc77c\ubab0\", // Korean\n];\n\n// Encode text and images\nconst inputs = await processor(sentences, images, { padding: true, truncation: true });\nconst { l2norm_text_embeddings, l2norm_image_embeddings } = await model(inputs);\n\n// Encode query (text-only)\nconst query_prefix = \"Represent the query for retrieving evidence documents: \";\nconst query_inputs = await processor(query_prefix + \"beautiful sunset over the beach\");\nconst { l2norm_text_embeddings: query_embeddings } = await model(query_inputs);\n\n// Compute text-image similarity scores\nconst text_to_image_scores = await matmul(query_embeddings, l2norm_image_embeddings.transpose(1, 0));\nconsole.log(\"text-image similarity scores\", text_to_image_scores.tolist()[0]); // [0.29530206322669983, 0.3183615803718567]\n\n// Compute image-image similarity scores\nconst image_to_image_score = await matmul(l2norm_image_embeddings[0], l2norm_image_embeddings[1]);\nconsole.log(\"image-image similarity score\", image_to_image_score.item()); // 0.9344457387924194\n\n// Compute text-text similarity scores\nconst text_to_text_scores = await matmul(query_embeddings, l2norm_text_embeddings.transpose(1, 0));\nconsole.log(\"text-text similarity scores\", text_to_text_scores.tolist()[0]); // [0.5566609501838684, 0.7028406858444214, 0.582255482673645, 0.6648036241531372, 0.5462006330490112, 0.6791588068008423, 0.6192430257797241, 0.6258729100227356, 0.6453716158866882]\n```\n\n<h3 id=\"llava_onevision\">LLaVA-OneVision for Image-Text-to-Text</h3>\n\nLLaVA-OneVision is a Vision-Language Model that can generate text conditioned on one or several images/videos. The model consists of SigLIP vision encoder and a Qwen2 language backbone.\n\n**Example:** Multi-round conversations w/ PKV caching\n\n```js\nimport { AutoProcessor, AutoTokenizer, LlavaOnevisionForConditionalGeneration, RawImage } from '@&#8203;huggingface/transformers';\n\n// Load tokenizer, processor and model\nconst model_id = 'llava-hf/llava-onevision-qwen2-0.5b-ov-hf';\n\nconst tokenizer = await AutoTokenizer.from_pretrained(model_id);\nconst processor = await AutoProcessor.from_pretrained(model_id);\nconst model = await LlavaOnevisionForConditionalGeneration.from_pretrained(model_id, {\n    dtype: {\n        embed_tokens: 'fp16', // or 'fp32' or 'q8'\n        vision_encoder: 'fp16', // or 'fp32' or 'q8'\n        decoder_model_merged: 'q4', // or 'q8'\n    },\n    // device: 'webgpu',\n});\n\n// Prepare text inputs\nconst prompt = 'What does the text say?';\nconst messages = [\n    { role: 'system', content: 'Answer the question.' },\n    { role: 'user', content: `<image>\\n${prompt}` }\n]\nconst text = tokenizer.apply_chat_template(messages, { tokenize: false, add_generation_prompt: true });\nconst text_inputs = tokenizer(text);\n\n// Prepare vision inputs\nconst url = 'https://huggingface.co/qnguyen3/nanoLLaVA/resolve/main/example_1.png';\nconst image = await RawImage.fromURL(url);\nconst vision_inputs = await processor(image);\n\n// Generate response\nconst { past_key_values, sequences } = await model.generate({\n    ...text_inputs,\n    ...vision_inputs,\n    do_sample: false,\n    max_new_tokens: 64,\n    return_dict_in_generate: true,\n});\n\n// Decode output\nconst answer = tokenizer.decode(\n    sequences.slice(0, [text_inputs.input_ids.dims[1], null]),\n    { skip_special_tokens: true },\n);\nconsole.log(answer);\n// The text says \"small but mighty\" in a playful font.\n\nconst new_messages = [\n    ...messages,\n    { role: 'assistant', content: answer },\n    { role: 'user', content: 'How does the text correlate to the context of the image?' }\n]\nconst new_text = tokenizer.apply_chat_template(new_messages, { tokenize: false, add_generation_prompt: true });\nconst new_text_inputs = tokenizer(new_text);\n\n// Generate another response\nconst output = await model.generate({\n    ...new_text_inputs,\n    past_key_values,\n    do_sample: false,\n    max_new_tokens: 256,\n});\nconst new_answer = tokenizer.decode(\n    output.slice(0, [new_text_inputs.input_ids.dims[1], null]),\n    { skip_special_tokens: true },\n);\nconsole.log(new_answer);\n// The text \"small but mighty\" is likely a playful or humorous reference to the image of the blue mouse with the orange dumbbell. It could be used as a motivational phrase or a playful way to express the idea that even small things can be impressive or powerful.\n```\n\n<h3 id=\"vitpose\">ViTPose for pose-estimation</h3>\n\nA state-of-the-art pose estimation model which employs a standard, non-hierarchical vision transformer as a backbone for the task of keypoint estimation (combined with a simple decoder head to predict heatmaps from a given image).\n\n**Example:** Pose estimation w/ `onnx-community/vitpose-base-simple`.\n\n```js\nimport { AutoModel, AutoImageProcessor, RawImage } from '@&#8203;huggingface/transformers';\n\n// Load model and processor\nconst model_id = 'onnx-community/vitpose-base-simple';\nconst model = await AutoModel.from_pretrained(model_id);\nconst processor = await AutoImageProcessor.from_pretrained(model_id);\n\n// Load image and prepare inputs\nconst url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/ryan-gosling.jpg';\nconst image = await RawImage.read(url);\nconst inputs = await processor(image);\n\n// Predict heatmaps\nconst { heatmaps } = await model(inputs);\n\n// Post-process heatmaps to get keypoints and scores\nconst boxes = [[[0, 0, image.width, image.height]]];\nconst results = processor.post_process_pose_estimation(heatmaps, boxes)[0][0];\nconsole.log(results);\n```\n\n<details>\n\n<summary>Optionally, visualize the outputs (Node.js usage shown here, using the node-canvas library):</summary>\n\n```js\nimport { createCanvas, createImageData } from 'canvas';\n\n// Create canvas and draw image\nconst canvas = createCanvas(image.width, image.height);\nconst ctx = canvas.getContext('2d');\nconst imageData = createImageData(image.rgba().data, image.width, image.height);\nctx.putImageData(imageData, 0, 0);\n\n// Draw edges between keypoints\nconst points = results.keypoints;\nctx.lineWidth = 4;\nctx.strokeStyle = 'blue';\nfor (const [i, j] of model.config.edges) {\n    const [x1, y1] = points[i];\n    const [x2, y2] = points[j];\n    ctx.beginPath();\n    ctx.moveTo(x1, y1);\n    ctx.lineTo(x2, y2);\n    ctx.stroke();\n}\n\n// Draw circle at each keypoint\nctx.fillStyle = 'red';\nfor (const [x, y] of points) {\n    ctx.beginPath();\n    ctx.arc(x, y, 8, 0, 2 * Math.PI);\n    ctx.fill();\n}\n\n// Save image to file\nimport fs from 'fs';\nconst out = fs.createWriteStream('pose.png');\nconst stream = canvas.createPNGStream();\nstream.pipe(out)\nout.on('finish', () =>  console.log('The PNG file was created.'));\n```\n\n</details>\n\n| Input image | Output image |\n| :----------:|:------------:|\n| ![image/jpeg](https://cdn-uploads.huggingface.co/production/uploads/61b253b7ac5ecaae3d1efe0c/QpXlLNyLDKZUxXjokbUyy.jpeg) | ![image/png](https://cdn-uploads.huggingface.co/production/uploads/61b253b7ac5ecaae3d1efe0c/xj0jaKo9aAOux-NSU8U7S.png) |\n\n<h3 id=\"mgp-str\">MGP-STR for Optical Character Recognition (OCR)</h3>\n\nA simple yet powerful vision scene text recognition model, built upon the vision transformer (ViT).\n\n**Example:** Optical Character Recognition (OCR) w/ `onnx-community/mgp-str-base`\n\n```js\nimport { MgpstrForSceneTextRecognition, MgpstrProcessor, RawImage } from '@&#8203;huggingface/transformers';\n\nconst model_id = 'onnx-community/mgp-str-base';\nconst model = await MgpstrForSceneTextRecognition.from_pretrained(model_id);\nconst processor = await MgpstrProcessor.from_pretrained(model_id);\n\n// Load image from the IIIT-5k dataset\nconst url = \"https://i.postimg.cc/ZKwLg2Gw/367-14.png\";\nconst image = await RawImage.read(url);\n\n// Preprocess the image\nconst result = await processor(image);\n\n// Perform inference\nconst outputs = await model(result);\n\n// Decode the model outputs\nconst generated_text = processor.batch_decode(outputs.logits).generated_text;\nconsole.log(generated_text); // [ 'ticket' ]\n```\n\n<h3 id=\"patchtst-and-patchtsmixer\">PatchTST and PatchTSMixer for time series forecasting.</h3>\n\n**Example:** Time series forecasting w/ `onnx-community/granite-timeseries-patchtst`\n\nModels which can be used for multivariate time series forecasting.\n\n```js\nimport { PatchTSTForPrediction, Tensor } from \"@&#8203;huggingface/transformers\";\n\nconst model_id = \"onnx-community/granite-timeseries-patchtst\";\nconst model = await PatchTSTForPrediction.from_pretrained(model_id, { dtype: \"fp32\" });\n\nconst dims = [64, 512, 7];\nconst prod = dims.reduce((a, b) => a * b, 1);\nconst past_values = new Tensor('float32',\n    Float32Array.from({ length: prod }, (_, i) => i / prod),\n    dims,\n);\nconst { prediction_outputs } = await model({ past_values });\nconsole.log(prediction_outputs);\n```\n\n**Example:** Time series forecasting w/ `onnx-community/granite-timeseries-patchtsmixer`\n\n```js\nimport { PatchTSMixerForPrediction, Tensor } from \"@&#8203;huggingface/transformers\";\n\nconst model_id = \"onnx-community/granite-timeseries-patchtsmixer\";\nconst model = await PatchTSMixerForPrediction.from_pretrained(model_id, { dtype: \"fp32\" });\n\nconst dims = [64, 512, 7];\nconst prod = dims.reduce((a, b) => a * b, 1);\nconst past_values = new Tensor('float32',\n    Float32Array.from({ length: prod }, (_, i) => i / prod),\n    dims,\n);\nconst { prediction_outputs } = await model({ past_values });\nconsole.log(prediction_outputs);\n```\n\n<h2 id=\"bug-fixes\">\ud83d\udc1b Bug fixes</h2>\n\n-   When padding an image, the dimensions get stretched by [@&#8203;BritishWerewolf](https://redirect.github.com/BritishWerewolf) in [https://github.com/huggingface/transformers.js/pull/1015](https://redirect.github.com/huggingface/transformers.js/pull/1015)\n-   fix(scale): add missing scale element by [@&#8203;tosinamuda](https://redirect.github.com/tosinamuda) in [https://github.com/huggingface/transformers.js/pull/1017](https://redirect.github.com/huggingface/transformers.js/pull/1017)\n\n<h2 id=\"documentation-improvements\">\ud83d\udcdd Documentation improvements</h2>\n\n-   Updated link to sentence similarity models. by [@&#8203;uzyn](https://redirect.github.com/uzyn) in [https://github.com/huggingface/transformers.js/pull/893](https://redirect.github.com/huggingface/transformers.js/pull/893)\n-   fix(docs): fixed a broken link to quantization guide by [@&#8203;ThomasWT](https://redirect.github.com/ThomasWT) in [https://github.com/huggingface/transformers.js/pull/1014](https://redirect.github.com/huggingface/transformers.js/pull/1014)\n-   fix(docs): Fixed Typos in README and docs/snippets/6\\_supported-models.snippet by [@&#8203;hitchhiker3010](https://redirect.github.com/hitchhiker3010) in [https://github.com/huggingface/transformers.js/pull/1030](https://redirect.github.com/huggingface/transformers.js/pull/1030)\n\n<h2 id=\"other-improvements\">\ud83d\udee0\ufe0f Other improvements</h2>\n\n-   Add option to maintain aspect ratio on resize by [@&#8203;BritishWerewolf](https://redirect.github.com/BritishWerewolf) in [https://github.com/huggingface/transformers.js/pull/971](https://redirect.github.com/huggingface/transformers.js/pull/971)\n-   Add functionality to split RawImage into channels; Update slice documentation and tests by [@&#8203;BritishWerewolf](https://redirect.github.com/BritishWerewolf) in [https://github.com/huggingface/transformers.js/pull/978](https://redirect.github.com/huggingface/transformers.js/pull/978)\n-   Avoid resizing images when they already have the desired size by [@&#8203;nemphys](https://redirect.github.com/nemphys) in [https://github.com/huggingface/transformers.js/pull/1027](https://redirect.github.com/huggingface/transformers.js/pull/1027)\n-   Add support for Split pretokenizer w/ `behavior=removed` & `invert=false` by [@&#8203;xenova](https://redirect.github.com/xenova) in [https://github.com/huggingface/transformers.js/pull/1033](https://redirect.github.com/huggingface/transformers.js/pull/1033)\n-   Add type declaration for `progress_callback` by [@&#8203;ocavue](https://redirect.github.com/ocavue) in [https://github.com/huggingface/transformers.js/pull/1034](https://redirect.github.com/huggingface/transformers.js/pull/1034)\n-   Add support for op_block_list by [@&#8203;pdufour](https://redirect.github.com/pdufour) in [https://github.com/huggingface/transformers.js/pull/1036](https://redirect.github.com/huggingface/transformers.js/pull/1036)\n\n<h2 id=\"new-contributors\">\ud83e\udd17 New contributors</h2>\n\n-   [@&#8203;uzyn](https://redirect.github.com/uzyn) made their first contribution in [https://github.com/huggingface/transformers.js/pull/893](https://redirect.github.com/huggingface/transformers.js/pull/893)\n-   [@&#8203;ThomasWT](https://redirect.github.com/ThomasWT) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1014](https://redirect.github.com/huggingface/transformers.js/pull/1014)\n-   [@&#8203;tosinamuda](https://redirect.github.com/tosinamuda) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1017](https://redirect.github.com/huggingface/transformers.js/pull/1017)\n-   [@&#8203;nemphys](https://redirect.github.com/nemphys) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1027](https://redirect.github.com/huggingface/transformers.js/pull/1027)\n-   [@&#8203;hitchhiker3010](https://redirect.github.com/hitchhiker3010) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1030](https://redirect.github.com/huggingface/transformers.js/pull/1030)\n-   [@&#8203;pdufour](https://redirect.github.com/pdufour) made their first contribution in [https://github.com/huggingface/transformers.js/pull/1036](https://redirect.github.com/huggingface/transformers.js/pull/1036)\n\n**Full Changelog**: https://github.com/huggingface/transformers.js/compare/3.0.2...3.1.0\n\n</details>\n\n<details>\n<summary>openai/openai-node (openai)</summary>\n\n### [`v4.76.0`](https://redirect.github.com/openai/openai-node/blob/HEAD/CHANGELOG.md#4760-2024-12-05)\n\n[Compare Source](https://redirect.github.com/openai/openai-node/compare/v4.75.0...v4.76.0)\n\nFull Changelog: [v4.75.0...v4.76.0](https://redirect.github.com/openai/openai-node/compare/v4.75.0...v4.76.0)\n\n##### Features\n\n-   **api:** updates ([#&#8203;1212](https://redirect.github.com/openai/openai-node/issues/1212)) ([e0fedf2](https://redirect.github.com/openai/openai-node/commit/e0fedf2c5a91d0c03d8dad6854b366f77eab4923))\n\n##### Chores\n\n-   bump openapi url ([#&#8203;1210](https://redirect.github.com/openai/openai-node/issues/1210)) ([3fa95a4](https://redirect.github.com/openai/openai-node/commit/3fa95a429d4b2adecce35a7b96b73f6d5e88eeeb))\n\n### [`v4.75.0`](https://redirect.github.com/openai/openai-node/blob/HEAD/CHANGELOG.md#4750-2024-12-03)\n\n[Compare Source](https://redirect.github.com/openai/openai-node/compare/v4.74.0...v4.75.0)\n\nFull Changelog: [v4.74.0...v4.75.0](https://redirect.github.com/openai/openai-node/compare/v4.74.0...v4.75.0)\n\n##### Features\n\n-   improve docs for jsr README.md ([#&#8203;1208](https://redirect.github.com/openai/openai-node/issues/1208)) ([338527e](https://redirect.github.com/openai/openai-node/commit/338527e40361e2de899a63f280d4ec2db5e87f3c))\n\n### [`v4.74.0`](https://redirect.github.com/openai/openai-node/blob/HEAD/CHANGELOG.md#4740-2024-12-02)\n\n[Compare Source](https://redirect.github.com/openai/openai-node/compare/v4.73.1...v4.74.0)\n\nFull Changelog: [v4.73.1...v4.74.0](https://redirect.github.com/openai/openai-node/compare/v4.73.1...v4.74.0)\n\n##### Features\n\n-   **internal:** make git install file structure match npm ([#&#8203;1204](https://redirect.github.com/openai/openai-node/issues/1204)) ([e7c4c6d](https://redirect.github.com/openai/openai-node/commit/e7c4c6d23adbe52300053a8d35db6e341c438703))\n\n### [`v4.73.1`](https://redirect.github.com/openai/openai-node/blob/HEAD/CHANGELOG.md#4731-2024-11-25)\n\n[Compare Source](https://redirect.github.com/openai/openai-node/compare/v4.73.0...v4.73.1)\n\nFull Changelog: [v4.73.0...v4.73.1](https://redirect.github.com/openai/openai-node/compare/v4.73.0...v4.73.1)\n\n##### Documentation\n\n-   **readme:** mention `.withResponse()` for streaming request ID ([#&#8203;1202](https://redirect.github.com/openai/openai-node/issues/1202)) ([b6800d4](https://redirect.github.com/openai/openai-node/commit/b6800d4dea2729fe3b0864171ce8fb3b2cc1b21c))\n\n</details>\n\n---\n\n### Configuration\n\n\ud83d\udcc5 **Schedule**: Branch creation - \"every weekend\" in timezone UTC, Automerge - At any time (no schedule defined).\n\n\ud83d\udea6 **Automerge**: Disabled by config. Please merge this manually once you are satisfied.\n\n\u267b **Rebasing**: Whenever PR becomes conflicted, or you tick the rebase/retry checkbox.\n\n\ud83d\udc7b **Immortal**: This PR will be recreated if closed unmerged. Get [config help](https://redirect.github.com/renovatebot/renovate/discussions) if that's undesired.\n\n---\n\n - [ ] <!-- rebase-check -->If you want to rebase/retry this PR, check this box\n\n---\n\nThis PR was generated by [Mend Renovate](https://mend.io/renovate/). View the [repository job log](https://developer.mend.io/github/ai16z/eliza).\n<!--renovate-debug:eyJjcmVhdGVkSW5WZXIiOiIzOS40Mi40IiwidXBkYXRlZEluVmVyIjoiMzkuNDIuNCIsInRhcmdldEJyYW5jaCI6Im1haW4iLCJsYWJlbHMiOltdfQ==-->\n",
            "files": [
              {
                "path": "packages/core/package.json",
                "additions": 2,
                "deletions": 2
              },
              {
                "path": "packages/plugin-node/package.json",
                "additions": 1,
                "deletions": 1
              },
              {
                "path": "pnpm-lock.yaml",
                "additions": 305,
                "deletions": 133
              }
            ],
            "reviews": [],
            "comments": []
          },
          {
            "number": 878,
            "title": "chore(deps): update dependency @rollup/plugin-terser to v0.4.4",
            "state": "CLOSED",
            "merged": false,
            "created_at": "2024-12-07T00:32:14Z",
            "updated_at": "2024-12-07T03:01:12Z",
            "body": "This PR contains the following updates:\n\n| Package | Change | Age | Adoption | Passing | Confidence |\n|---|---|---|---|---|---|\n| [@rollup/plugin-terser](https://redirect.github.com/rollup/plugins/tree/master/packages/terser#readme) ([source](https://redirect.github.com/rollup/plugins/tree/HEAD/packages/terser)) | [`0.1.0` -> `0.4.4`](https://renovatebot.com/diffs/npm/@rollup%2fplugin-terser/0.1.0/0.4.4) | [![age](https://developer.mend.io/api/mc/badges/age/npm/@rollup%2fplugin-terser/0.4.4?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![adoption](https://developer.mend.io/api/mc/badges/adoption/npm/@rollup%2fplugin-terser/0.4.4?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![passing](https://developer.mend.io/api/mc/badges/compatibility/npm/@rollup%2fplugin-terser/0.1.0/0.4.4?slim=true)](https://docs.renovatebot.com/merge-confidence/) | [![confidence](https://developer.mend.io/api/mc/badges/confidence/npm/@rollup%2fplugin-terser/0.1.0/0.4.4?slim=true)](https://docs.renovatebot.com/merge-confidence/) |\n\n---\n\n### Release Notes\n\n<details>\n<summary>rollup/plugins (@&#8203;rollup/plugin-terser)</summary>\n\n### [`v0.4.4`](https://redirect.github.com/rollup/plugins/blob/HEAD/packages/terser/CHANGELOG.md#v044)\n\n[Compare Source](https://redirect.github.com/rollup/plugins/compare/a9fa1b5f2a29455a8a4043a79d96d44ddb3dd8fb...841a0391c1dd11fed16771a202e6eff97cf4139b)\n\n*2023-10-05*\n\n##### Bugfixes\n\n-   fix: ensure rollup 4 compatibility [#&#8203;1595](https://redirect.github.com/rollup/plugins/pull/1595)\n\n### [`v0.4.3`](https://redirect.github.com/rollup/plugins/blob/HEAD/packages/terser/CHANGELOG.md#v043)\n\n[Compare Source](https://redirect.github.com/rollup/plugins/compare/8fa358e0168418ffc93b9a38e4809199ac913484...a9fa1b5f2a29455a8a4043a79d96d44ddb3dd8fb)\n\n*2023-05-17*\n\n##### Bugfixes\n\n-   fix: bump dependencies [#&#8203;1501](https://redirect.github.com/rollup/plugins/pull/1501)\n\n### [`v0.4.2`](https://redirect.github.com/rollup/plugins/blob/HEAD/packages/terser/CHANGELOG.md#v042)\n\n[Compare Source](https://redirect.github.com/rollup/plugins/compare/007acf15c7605e4ebe77afc7f4e6f3c0c8e6a1b1...8fa358e0168418ffc93b9a38e4809199ac913484)\n\n*2023-05-16*\n\n##### Bugfixes\n\n-   fix: don't assume code is running in worker created by the worker pool [#&#8203;1483](https://redirect.github.com/rollup/plugins/pull/1483)\n\n### [`v0.4.1`](https://redirect.github.com/rollup/plugins/blob/HEAD/packages/terser/CHANGELOG.md#v041)\n\n[Compare Source](https://redirect.github.com/rollup/plugins/compare/5452bf266ac76e5c519f1b240679d11674e30284...007acf15c7605e4ebe77afc7f4e6f3c0c8e6a1b1)\n\n*2023-04-09*\n\n##### Bugfixes\n\n-   fix: expose extended terser options interface [#&#8203;1477](https://redirect.github.com/rollup/plugins/pull/1477)\n\n### [`v0.4.0`](https://redirect.github.com/rollup/plugins/blob/HEAD/packages/terser/CHANGELOG.md#v040)\n\n[Compare Source](https://redirect.github.com/rollup/plugins/compare/60972fc60d3e76522cda2cc067e4cb7375e9876b...5452bf266ac76e5c519f1b240679d11674e30284)\n\n*2023-01-23*\n\n##### Features\n\n-   feat: Update WorkerPool to reuse Workers [#&#8203;1409](https://redirect.github.com/rollup/plugins/pull/1409)\n\n### [`v0.3.0`](https://redirect.github.com/rollup/plugins/blob/HEAD/packages/terser/CHANGELOG.md#v030)\n\n[Compare Source](https://redirect.github.com/rollup/plugins/compare/13ab91f36ea9f1addf2c155e7e2edcf3a9775a2b...60972fc60d3e76522cda2cc067e4cb7375e9876b)\n\n*2023-01-06*\n\n##### Features\n\n-   feat: emit source map [#&#8203;1383](https://redirect.github.com/rollup/plugins/pull/1383)\n\n### [`v0.2.1`](https://redirect.github.com/rollup/plugins/blob/HEAD/packages/terser/CHANGELOG.md#v021)\n\n[Compare Source](https://redirect.github.com/rollup/plugins/compare/074e8fa8252f198983b74f3947e4b05fbd32cec6...13ab91f36ea9f1addf2c155e7e2edcf3a9775a2b)\n\n*2022-12-21*\n\n##### Bugfixes\n\n-   fix: \\__filename not defined [#&#8203;1367](https://redirect.github.com/rollup/plugins/pull/1367)\n\n### [`v0.2.0`](https://redirect.github.com/rollup/plugins/blob/HEAD/packages/terser/CHANGELOG.md#v020)\n\n[Compare Source](https://redirect.github.com/rollup/plugins/compare/818420618275b53eac89def776502c9a7bef43e2...074e8fa8252f198983b74f3947e4b05fbd32cec6)\n\n*2022-12-05*\n\n##### Features\n\n-   feat: parallel execution [#&#8203;1341](https://redirect.github.com/rollup/plugins/pull/1341)\n\n</details>\n\n---\n\n### Configuration\n\n\ud83d\udcc5 **Schedule**: Branch creation - \"every weekend\" in timezone UTC, Automerge - At any time (no schedule defined).\n\n\ud83d\udea6 **Automerge**: Disabled by config. Please merge this manually once you are satisfied.\n\n\u267b **Rebasing**: Whenever PR becomes conflicted, or you tick the rebase/retry checkbox.\n\n\ud83d\udd15 **Ignore**: Close this PR and you won't be reminded about this update again.\n\n---\n\n - [ ] <!-- rebase-check -->If you want to rebase/retry this PR, check this box\n\n---\n\nThis PR was generated by [Mend Renovate](https://mend.io/renovate/). View the [repository job log](https://developer.mend.io/github/ai16z/eliza).\n<!--renovate-debug:eyJjcmVhdGVkSW5WZXIiOiIzOS40Mi40IiwidXBkYXRlZEluVmVyIjoiMzkuNDIuNCIsInRhcmdldEJyYW5jaCI6Im1haW4iLCJsYWJlbHMiOltdfQ==-->\n",
            "files": [
              {
                "path": "packages/core/package.json",
                "additions": 1,
                "deletions": 1
              },
              {
                "path": "pnpm-lock.yaml",
                "additions": 13,
                "deletions": 6
              }
            ],
            "reviews": [],
            "comments": [
              {
                "author": "renovate",
                "body": "### Renovate Ignore Notification\n\nBecause you closed this PR without merging, Renovate will ignore this update (`0.4.4`). You will get a PR once a newer version is released. To ignore this dependency forever, add it to the `ignoreDeps` array of your Renovate config.\n\nIf you accidentally closed this PR, or if you changed your mind: rename this PR to get a fresh replacement PR."
              }
            ]
          }
        ]
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "shakkernerd",
    "score": 0,
    "summary": "Shakkernerd is actively enhancing the development workflow by improving the `dev.sh` script, focusing on performance improvements and adding helpful messages to commands. They have also streamlined the build command by disabling documentation building for efficiency. Overall, their recent work has resulted in a more user-friendly and optimized plugin development experience.",
    "avatar_url": "https://avatars.githubusercontent.com/u/165377636?u=5560dd9f2d310e1ba61dbba864006a951391a582&v=4",
    "activity": {
      "code": {
        "total_commits": 9,
        "total_prs": 4,
        "commits": [
          {
            "sha": "e713ed1aeecd12c952755dd56c6f041f5865f562",
            "message": "Merge pull request #892 from ai16z/dev_command\n\nchore: improved dev command",
            "created_at": "2024-12-07T06:39:41Z",
            "additions": 8,
            "deletions": 3,
            "changed_files": 2
          },
          {
            "sha": "1656ce786d1b0a9be1efccd3f2f82af2db4077b1",
            "message": "chore: add a delay to the help message",
            "created_at": "2024-12-07T06:34:47Z",
            "additions": 7,
            "deletions": 1,
            "changed_files": 1
          },
          {
            "sha": "e094cce9f1282f8c06fb7c2d4eff4b98c9799c62",
            "message": "chore: remove redundant dev:build command",
            "created_at": "2024-12-07T06:28:16Z",
            "additions": 1,
            "deletions": 2,
            "changed_files": 2
          },
          {
            "sha": "9bc29635ed8674aa8e2c1e99a389cfab0b9ee6dd",
            "message": "Merge pull request #891 from ai16z/dev_command\n\nchore: added more help message to the important notice text.",
            "created_at": "2024-12-07T05:18:24Z",
            "additions": 20,
            "deletions": 0,
            "changed_files": 1
          },
          {
            "sha": "849bd177c63fba68c1626a15f24def2888d525cb",
            "message": "chore: added more help message to the important notice text.",
            "created_at": "2024-12-07T05:12:43Z",
            "additions": 20,
            "deletions": 0,
            "changed_files": 1
          },
          {
            "sha": "bebc7e1830f968b23a4102c20cb0c6d4a6d70311",
            "message": "Merge pull request #887 from ai16z/dev_command\n\nchore: enhance dev script, performance improvement and add help message",
            "created_at": "2024-12-07T04:50:14Z",
            "additions": 48,
            "deletions": 21,
            "changed_files": 1
          },
          {
            "sha": "2785135d8524045f65c78ad724b077299033b238",
            "message": "chore: enhance dev script, performance improvement and add help message",
            "created_at": "2024-12-07T04:37:02Z",
            "additions": 48,
            "deletions": 21,
            "changed_files": 1
          },
          {
            "sha": "cdde3d9365b49b5e3714841b4024bd922ebabb0e",
            "message": "Merge pull request #884 from ai16z/build_command\n\nchore: disable building docs on build command",
            "created_at": "2024-12-07T03:03:52Z",
            "additions": 1,
            "deletions": 1,
            "changed_files": 1
          },
          {
            "sha": "8f30f26dd8063d76ec3158ab58d38f8ad165e9dd",
            "message": "perf: disable building docs on build command",
            "created_at": "2024-12-07T02:57:35Z",
            "additions": 1,
            "deletions": 1,
            "changed_files": 1
          }
        ],
        "pull_requests": [
          {
            "number": 892,
            "title": "chore: improved dev command",
            "state": "MERGED",
            "merged": true,
            "created_at": "2024-12-07T06:36:03Z",
            "updated_at": "2024-12-07T06:39:43Z",
            "body": "",
            "files": [
              {
                "path": "package.json",
                "additions": 0,
                "deletions": 1
              },
              {
                "path": "scripts/dev.sh",
                "additions": 8,
                "deletions": 2
              }
            ],
            "reviews": [],
            "comments": []
          },
          {
            "number": 891,
            "title": "chore: added more help message to the important notice text.",
            "state": "MERGED",
            "merged": true,
            "created_at": "2024-12-07T05:14:55Z",
            "updated_at": "2024-12-07T05:18:26Z",
            "body": "",
            "files": [
              {
                "path": "scripts/dev.sh",
                "additions": 20,
                "deletions": 0
              }
            ],
            "reviews": [
              {
                "author": "monilpat",
                "state": "APPROVED",
                "body": "LGTM! "
              }
            ],
            "comments": []
          },
          {
            "number": 887,
            "title": "chore: enhance dev script, performance improvement and add help message",
            "state": "MERGED",
            "merged": true,
            "created_at": "2024-12-07T04:40:39Z",
            "updated_at": "2024-12-07T04:50:15Z",
            "body": "Improvement to the dev script.\r\n\r\n<img width=\"778\" alt=\"image\" src=\"https://github.com/user-attachments/assets/4555fa59-b84d-4a08-a8e7-ad8be7debc26\">\r\n",
            "files": [
              {
                "path": "scripts/dev.sh",
                "additions": 48,
                "deletions": 21
              }
            ],
            "reviews": [],
            "comments": [
              {
                "author": "shakkernerd",
                "body": "Implementing #888 "
              }
            ]
          },
          {
            "number": 884,
            "title": "chore: disable building docs on build command",
            "state": "MERGED",
            "merged": true,
            "created_at": "2024-12-07T02:57:59Z",
            "updated_at": "2024-12-07T03:03:54Z",
            "body": "",
            "files": [
              {
                "path": "package.json",
                "additions": 1,
                "deletions": 1
              }
            ],
            "reviews": [],
            "comments": []
          }
        ]
      },
      "issues": {
        "total_opened": 1,
        "opened": [
          {
            "number": 888,
            "title": "Improve `dev.sh` Script to Enhance Plugin Development Workflow",
            "state": "CLOSED",
            "created_at": "2024-12-07T04:48:39Z",
            "updated_at": "2024-12-07T04:53:29Z",
            "body": "This issue documents the improvements made to the `dev.sh` script to enhance the plugin development workflow. The changes are designed to guide users on integrating their plugins efficiently and ensuring the script handles core and additional plugins effectively.\r\n\r\n## Summary of Changes\r\n\r\n1. **Big User Notice:**\r\n   - Added a detailed notice displayed to users when running the script, instructing them to:\r\n     - Navigate to the `scripts` directory.\r\n     - Edit the `dev.sh` file to integrate their plugin into the workflow.\r\n     - Add the `dev` command to the plugin's `package.json`.\r\n     - Update the `WORKING_FOLDERS` list to include the plugin's directory.\r\n\r\n2. **Working Folders Implementation:**\r\n   - Replaced excluded folder logic with a `WORKING_FOLDERS` list.\r\n   - Process only the folders explicitly listed in `WORKING_FOLDERS`.\r\n",
            "labels": [
              {
                "name": "enhancement",
                "color": "a2eeef",
                "description": "New feature or request"
              }
            ],
            "comments": []
          }
        ]
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "monilpat",
    "score": 0,
    "summary": "Monilpat is actively working on enhancing trading capabilities, focusing on testing and implementing advanced features. Over the past 90 days, they have made a single commit that resulted in a net increase of code changes by +259 lines added and -51 lines removed. Despite these developments, there has been no progress on pull requests or issues during this period.",
    "avatar_url": "https://avatars.githubusercontent.com/u/15067321?u=1271e57605b48029307547127c90e1bd5e4f3f39&v=4",
    "activity": {
      "code": {
        "total_commits": 1,
        "total_prs": 0,
        "commits": [
          {
            "sha": "0a6fb9108eef02c288f4b7114916a5e5e0415577",
            "message": "testing and getting advanced trading working",
            "created_at": "2024-12-07T06:31:25Z",
            "additions": 259,
            "deletions": 51,
            "changed_files": 7
          }
        ],
        "pull_requests": []
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "cygaar",
    "score": 0,
    "summary": "Cygaar is actively contributing to the project by improving evaluation JSON parsing and ensuring Twitter actions trigger correctly, as evidenced by two merged pull requests addressing these issues within the last 90 days. With a total of five commits resulting in +113/-65 code changes across packages, cygaar's work has significantly enhanced functionality and reliability.",
    "avatar_url": "https://avatars.githubusercontent.com/u/97691933?u=45e66309f3fd41536b48a58f3c949b9e4e90789a&v=4",
    "activity": {
      "code": {
        "total_commits": 5,
        "total_prs": 2,
        "commits": [
          {
            "sha": "216e3127ca77060bebc3765a032f96b9a441e4ab",
            "message": "Merge pull request #907 from cygaar/fix_evaulation_parsing\n\nfix: evaluation json parsing",
            "created_at": "2024-12-07T22:18:27Z",
            "additions": 15,
            "deletions": 9,
            "changed_files": 2
          },
          {
            "sha": "af7591b42b4418444b7e3b8f4c10bcf6a4e201d6",
            "message": "fix: evaluation json parsing",
            "created_at": "2024-12-07T21:51:27Z",
            "additions": 15,
            "deletions": 9,
            "changed_files": 2
          },
          {
            "sha": "7bd0892cca037a8baa69f2cf592ec4e91b2ad12f",
            "message": "Merge pull request #890 from oxSaturn/patch-1\n\nchore: update models for groq",
            "created_at": "2024-12-07T16:40:16Z",
            "additions": 3,
            "deletions": 3,
            "changed_files": 2
          },
          {
            "sha": "6ccf25b762823e584acc6543b825aec885f53b52",
            "message": "Merge pull request #903 from cygaar/improve_twitter_actions\n\nfix: twitter actions not triggering",
            "created_at": "2024-12-07T16:37:40Z",
            "additions": 40,
            "deletions": 22,
            "changed_files": 2
          },
          {
            "sha": "613c001d9d59df92f6f55f2067bbfb1eda15a0ff",
            "message": "fix: twitter actions not triggering",
            "created_at": "2024-12-07T16:15:59Z",
            "additions": 40,
            "deletions": 22,
            "changed_files": 2
          }
        ],
        "pull_requests": [
          {
            "number": 907,
            "title": "fix: evaluation json parsing",
            "state": "MERGED",
            "merged": true,
            "created_at": "2024-12-07T21:53:54Z",
            "updated_at": "2024-12-07T22:18:30Z",
            "body": "<!-- Use this template by filling in information and copy and pasting relevant items out of the html comments. -->\r\n\r\n# Relates to:\r\n\r\nRight now the call to `parseJsonArrayFromText` in `evaluate` fails at times because the result passed in looks like:\r\n\r\n````\r\n```json\r\n[\r\n  'EXTRACT_RECOMMENDATIONS'\r\n]\r\n```\r\n````\r\n\r\nIn order to fix this, we need to fix the parsing function to convert the single quotes to double quotes.\r\n\r\n# Risks\r\n\r\nLow\r\n\r\n# Background\r\n\r\n## What does this PR do?\r\n\r\n## What kind of change is this?\r\n\r\n<!--\r\nBug fixes (non-breaking change which fixes an issue)\r\nImprovements (misc. changes to existing features)\r\nFeatures (non-breaking change which adds functionality)\r\nUpdates (new versions of included code)\r\n-->\r\n\r\n<!-- This \"Why\" section is most relevant if there is no linked issue explaining why. If there is a related issue it might make sense to skip this why section. -->\r\n<!--\r\n## Why are we doing this? Any context or related work?\r\n-->\r\n\r\n# Documentation changes needed?\r\n\r\n<!--\r\nMy changes do not require a change to the project documentation.\r\nMy changes require a change to the project documentation.\r\nIf a docs change is needed: I have updated the documentation accordingly.\r\n-->\r\n\r\n<!-- Please show how you tested the PR. This will really help if the PR needs to be retested, and probably help the PR get merged quicker. -->\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\n\r\n## Detailed testing steps\r\n\r\n<!--\r\nNone, automated tests are fine.\r\n-->\r\n\r\n<!--\r\n- As [anon/admin], go to [link]\r\n\u00a0 - [do action]\r\n\u00a0 - verify [result]\r\n-->\r\n\r\n<!-- If there is a UI change, please include before and after screenshots or videos. This will speed up PRs being merged. It is extra nice to annotate screenshots with arrows or boxes pointing out the differences. -->\r\n<!--\r\n## Screenshots\r\n### Before\r\n### After\r\n-->\r\n\r\n<!-- If there is anything about the deploy, please make a note. -->\r\n<!--\r\n# Deploy Notes\r\n-->\r\n\r\n<!-- \u00a0Copy and paste commandline output. -->\r\n<!--\r\n## Database changes\r\n-->\r\n\r\n<!-- \u00a0If there is something more than the automated steps, please specifiy deploy instructions. -->\r\n<!--\r\n## Deployment instructions\r\n-->\r\n\r\n<!-- If you are on Discord, please join https://discord.gg/ai16z and state your Discord username here for contribute role and join us in #development-feed -->\r\n<!--\r\n## Discord username\r\n\r\n-->\r\n",
            "files": [
              {
                "path": "packages/client-twitter/src/interactions.ts",
                "additions": 1,
                "deletions": 1
              },
              {
                "path": "packages/core/src/parsing.ts",
                "additions": 14,
                "deletions": 8
              }
            ],
            "reviews": [],
            "comments": []
          },
          {
            "number": 903,
            "title": "fix: twitter actions not triggering",
            "state": "MERGED",
            "merged": true,
            "created_at": "2024-12-07T16:16:57Z",
            "updated_at": "2024-12-07T16:37:43Z",
            "body": "<!-- Use this template by filling in information and copy and pasting relevant items out of the html comments. -->\r\n\r\n# Relates to:\r\n\r\nI was having issues triggering issues on the twitter client. This PR improves the prompt for getting an action.\r\n\r\nAdditionally, for the OpenAI image generation, we will use the openai api key rather than the provided api key.\r\n\r\n# Risks\r\n\r\n<!--\r\nLow, medium, large. List what kind of risks, and what could be effected.\r\n-->\r\n\r\n# Background\r\n\r\n## What does this PR do?\r\n\r\n## What kind of change is this?\r\n\r\n<!--\r\nBug fixes (non-breaking change which fixes an issue)\r\nImprovements (misc. changes to existing features)\r\nFeatures (non-breaking change which adds functionality)\r\nUpdates (new versions of included code)\r\n-->\r\n\r\n<!-- This \"Why\" section is most relevant if there is no linked issue explaining why. If there is a related issue it might make sense to skip this why section. -->\r\n<!--\r\n## Why are we doing this? Any context or related work?\r\n-->\r\n\r\n# Documentation changes needed?\r\n\r\n<!--\r\nMy changes do not require a change to the project documentation.\r\nMy changes require a change to the project documentation.\r\nIf a docs change is needed: I have updated the documentation accordingly.\r\n-->\r\n\r\n<!-- Please show how you tested the PR. This will really help if the PR needs to be retested, and probably help the PR get merged quicker. -->\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\n\r\n## Detailed testing steps\r\n\r\n<!--\r\nNone, automated tests are fine.\r\n-->\r\n\r\n<!--\r\n- As [anon/admin], go to [link]\r\n\u00a0 - [do action]\r\n\u00a0 - verify [result]\r\n-->\r\n\r\n<!-- If there is a UI change, please include before and after screenshots or videos. This will speed up PRs being merged. It is extra nice to annotate screenshots with arrows or boxes pointing out the differences. -->\r\n<!--\r\n## Screenshots\r\n### Before\r\n### After\r\n-->\r\n\r\n<!-- If there is anything about the deploy, please make a note. -->\r\n<!--\r\n# Deploy Notes\r\n-->\r\n\r\n<!-- \u00a0Copy and paste commandline output. -->\r\n<!--\r\n## Database changes\r\n-->\r\n\r\n<!-- \u00a0If there is something more than the automated steps, please specifiy deploy instructions. -->\r\n<!--\r\n## Deployment instructions\r\n-->\r\n\r\n<!-- If you are on Discord, please join https://discord.gg/ai16z and state your Discord username here for contribute role and join us in #development-feed -->\r\n<!--\r\n## Discord username\r\n\r\n-->\r\n",
            "files": [
              {
                "path": "packages/client-twitter/src/interactions.ts",
                "additions": 4,
                "deletions": 1
              },
              {
                "path": "packages/core/src/generation.ts",
                "additions": 36,
                "deletions": 21
              }
            ],
            "reviews": [],
            "comments": []
          }
        ]
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "oxSaturn",
    "score": 0,
    "summary": "oxSaturn is actively engaged in updating models for Groq, as evidenced by a recent merge pull request and two commits related to this task. The developer's efforts have resulted in an equal number of additions and deletions within the packages code area over the past 90 days.",
    "avatar_url": "https://avatars.githubusercontent.com/u/126733611?v=4",
    "activity": {
      "code": {
        "total_commits": 2,
        "total_prs": 1,
        "commits": [
          {
            "sha": "753564ce63ab4331da152a4785870f413e860461",
            "message": "fix models test",
            "created_at": "2024-12-07T05:33:26Z",
            "additions": 1,
            "deletions": 1,
            "changed_files": 1
          },
          {
            "sha": "368848bc105e64f3cd857d06b1f09d9167397c09",
            "message": "chore: update models for groq\n\nhttps://console.groq.com/docs/deprecations",
            "created_at": "2024-12-07T05:01:43Z",
            "additions": 2,
            "deletions": 2,
            "changed_files": 1
          }
        ],
        "pull_requests": [
          {
            "number": 890,
            "title": "chore: update models for groq",
            "state": "MERGED",
            "merged": true,
            "created_at": "2024-12-07T05:03:06Z",
            "updated_at": "2024-12-07T23:19:01Z",
            "body": "https://console.groq.com/docs/deprecations\r\n\r\n<!-- Use this template by filling in information and copy and pasting relevant items out of the html comments. -->\r\n\r\n# Relates to:\r\n\r\n<!-- LINK TO ISSUE OR TICKET -->\r\n\r\n<!-- This risks section is to be filled out before final review and merge. -->\r\n\r\n# Risks\r\n\r\n<!--\r\nLow, medium, large. List what kind of risks, and what could be effected.\r\n-->\r\n\r\n# Background\r\n\r\n## What does this PR do?\r\n\r\nUpdate models for groq as some will be deprecated per https://console.groq.com/docs/deprecations.\r\n\r\n![Screenshot-co879gyV@2x](https://github.com/user-attachments/assets/400b58a7-b76e-4de2-bf5c-c8dc1e9ac4c9)\r\n\r\n![Screenshot-e1nmXZFW@2x](https://github.com/user-attachments/assets/fa100aca-9166-4c07-b1ba-0c363502a5e8)\r\n\r\n\r\n## What kind of change is this?\r\n\r\n<!--\r\nBug fixes (non-breaking change which fixes an issue)\r\nImprovements (misc. changes to existing features)\r\nFeatures (non-breaking change which adds functionality)\r\nUpdates (new versions of included code)\r\n-->\r\n\r\n<!-- This \"Why\" section is most relevant if there is no linked issue explaining why. If there is a related issue it might make sense to skip this why section. -->\r\n<!--\r\n## Why are we doing this? Any context or related work?\r\n-->\r\n\r\n# Documentation changes needed?\r\n\r\n<!--\r\nMy changes do not require a change to the project documentation.\r\nMy changes require a change to the project documentation.\r\nIf a docs change is needed: I have updated the documentation accordingly.\r\n-->\r\n\r\n<!-- Please show how you tested the PR. This will really help if the PR needs to be retested, and probably help the PR get merged quicker. -->\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\n\r\n## Detailed testing steps\r\n\r\n<!--\r\nNone, automated tests are fine.\r\n-->\r\n\r\n<!--\r\n- As [anon/admin], go to [link]\r\n\u00a0 - [do action]\r\n\u00a0 - verify [result]\r\n-->\r\n\r\n<!-- If there is a UI change, please include before and after screenshots or videos. This will speed up PRs being merged. It is extra nice to annotate screenshots with arrows or boxes pointing out the differences. -->\r\n<!--\r\n## Screenshots\r\n### Before\r\n### After\r\n-->\r\n\r\n<!-- If there is anything about the deploy, please make a note. -->\r\n<!--\r\n# Deploy Notes\r\n-->\r\n\r\n<!-- \u00a0Copy and paste commandline output. -->\r\n<!--\r\n## Database changes\r\n-->\r\n\r\n<!-- \u00a0If there is something more than the automated steps, please specifiy deploy instructions. -->\r\n<!--\r\n## Deployment instructions\r\n-->\r\n\r\n<!-- If you are on Discord, please join https://discord.gg/ai16z and state your Discord username here for contribute role and join us in #development-feed -->\r\n<!--\r\n## Discord username\r\n\r\n-->\r\n",
            "files": [
              {
                "path": "packages/core/src/models.ts",
                "additions": 2,
                "deletions": 2
              },
              {
                "path": "packages/core/src/tests/models.test.ts",
                "additions": 1,
                "deletions": 1
              }
            ],
            "reviews": [
              {
                "author": "monilpat",
                "state": "CHANGES_REQUESTED",
                "body": "Outside of the test fix looks good "
              },
              {
                "author": "cygaar",
                "state": "APPROVED",
                "body": ""
              }
            ],
            "comments": [
              {
                "author": "monilpat",
                "body": "Thanks for adding this - Looks like the test is failing "
              }
            ]
          }
        ]
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "HashWarlock",
    "score": 0,
    "summary": "HashWarlock is actively enhancing documentation by adding an overview and a tutorial for Eliza in TEE mode, as well as integrating new features into the main branch. Despite no pull requests or issues being addressed during this period, there has been significant code activity with 3 commits resulting in a net increase of +9864 lines of code.",
    "avatar_url": "https://avatars.githubusercontent.com/u/64296537?u=3aba9462fb28d3b01bdc8ac888817386b6bf3266&v=4",
    "activity": {
      "code": {
        "total_commits": 3,
        "total_prs": 0,
        "commits": [
          {
            "sha": "29689d108ece7751fa6776e87870b3c9458fd735",
            "message": "Merge branch 'main' into add-tee-mode",
            "created_at": "2024-12-07T23:13:30Z",
            "additions": 14433,
            "deletions": 4858,
            "changed_files": 276
          },
          {
            "sha": "ba18167001109f931b1637e02671b1af0c28a41c",
            "message": "docs: add overview",
            "created_at": "2024-12-07T23:09:26Z",
            "additions": 12,
            "deletions": 1,
            "changed_files": 1
          },
          {
            "sha": "d052002a94a018f9876198e583a5d5ab3b0143aa",
            "message": "docs: add tutorial for Eliza in TEE",
            "created_at": "2024-12-07T22:59:31Z",
            "additions": 282,
            "deletions": 4,
            "changed_files": 2
          }
        ],
        "pull_requests": []
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "snobbee",
    "score": 0,
    "summary": "snobbee is currently focused on enhancing the CI workflow by re-enabling coverage report uploads to Codecov, as evidenced by a recent commit and merged pull request. This activity indicates an emphasis on improving code quality monitoring within their projects.",
    "avatar_url": "https://avatars.githubusercontent.com/u/125891987?u=ba9ca14b922f8fb73f38ba0981d157247af3dd03&v=4",
    "activity": {
      "code": {
        "total_commits": 1,
        "total_prs": 1,
        "commits": [
          {
            "sha": "3d9b78486f99b518480fe37b5f24267a230ec668",
            "message": "ci: re-enable coverage report upload to Codecov in CI workflow",
            "created_at": "2024-12-07T01:14:48Z",
            "additions": 4,
            "deletions": 4,
            "changed_files": 1
          }
        ],
        "pull_requests": [
          {
            "number": 880,
            "title": "fix: re-enable coverage report upload to Codecov in CI workflow",
            "state": "MERGED",
            "merged": true,
            "created_at": "2024-12-07T01:19:07Z",
            "updated_at": "2024-12-12T21:11:07Z",
            "body": "# Relates to:\r\nContinuous Integration workflow improvements\r\n\r\n# Risks\r\nLow - Changes to CI workflow configuration only. Main risk would be potential CI pipeline failures if any configuration is incorrect.\r\n\r\n# Background\r\n\r\n## What does this PR do?\r\nUpdates the GitHub Actions CI workflow configuration with the following changes:\r\n- Adds code coverage reporting to Codecov\r\n\r\n## What kind of change is this?\r\nImprovements (misc. changes to existing features)\r\n- Enhances the existing CI pipeline with better package management and test coverage reporting\r\n\r\n# Documentation changes needed?\r\nMy changes do not require a change to the project documentation.\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\n1. Review the .github/workflows/ci.yaml file\r\n2. Check the workflow runs on both push to main and pull requests\r\n3. Verify all job steps are properly configured\r\n\r\n## Detailed testing steps\r\n1. Create a test PR to verify the workflow triggers correctly\r\n2. Ensure all steps complete successfully:\r\n   - PNPM installation\r\n   - Dependencies installation\r\n   - Prettier checks\r\n   - Linting\r\n   - Test environment setup\r\n   - Test execution\r\n   - Package building\r\n   - Code coverage reporting\r\n3. Verify Codecov integration is working by checking coverage reports\r\n\r\nThe automated CI workflow will validate all changes.\r\n\r\n# Deploy Notes\r\nNo special deployment needed - changes only affect CI pipeline configuration.\r\n",
            "files": [
              {
                "path": ".github/workflows/ci.yaml",
                "additions": 4,
                "deletions": 4
              }
            ],
            "reviews": [
              {
                "author": "monilpat",
                "state": "APPROVED",
                "body": "LGTM!"
              },
              {
                "author": "jkbrooks",
                "state": "APPROVED",
                "body": ""
              }
            ],
            "comments": []
          }
        ]
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "YoungPhlo",
    "score": 0,
    "summary": "YoungPhlo is actively enhancing documentation, focusing on weekly summaries and metadata improvements within the project's codebase. Recently, they have successfully merged a pull request that adds 'What Did You Get Done This Week #4' summaries along with timestamps to the documentation.",
    "avatar_url": "https://avatars.githubusercontent.com/u/90307961?u=2e7b36c41a4576a4720529da97a57280df102b28&v=4",
    "activity": {
      "code": {
        "total_commits": 2,
        "total_prs": 1,
        "commits": [
          {
            "sha": "83dffb4f17476b7d596950ba5d637deff177a357",
            "message": "wdygdtw 4 notes + docs metadata",
            "created_at": "2024-12-07T12:34:55Z",
            "additions": 187,
            "deletions": 0,
            "changed_files": 3
          },
          {
            "sha": "561bd3ff9dc86036711bb9c00a7f614fc7e6a74c",
            "message": "rename file correct date",
            "created_at": "2024-12-07T11:23:39Z",
            "additions": 0,
            "deletions": 0,
            "changed_files": 1
          }
        ],
        "pull_requests": [
          {
            "number": 895,
            "title": "docs: Add What Did You Get Done This Week #4 summaries and timestamps",
            "state": "MERGED",
            "merged": true,
            "created_at": "2024-12-07T12:50:12Z",
            "updated_at": "2024-12-08T02:37:19Z",
            "body": "# Relates to:\r\nN/A - Documentation update\r\n\r\n# Risks\r\nLow - Documentation only changes\r\n\r\n# Background\r\n\r\n## What does this PR do?\r\n- Adds frontmatter metadata (title, description, sidebar position) to existing stream docs\r\n- Adds detailed notes and timestamps for \"What Did You Get Done This Week? #4\" stream\r\n- Fixes date in filename from 2024-12-06 to 2024-12-05\r\n\r\n## What kind of change is this?\r\nImprovements (adding metadata to existing docs and new stream notes)\r\n\r\n# Documentation changes needed?\r\nMy changes are documentation changes themselves.\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\n1. Check the frontmatter metadata added to existing stream docs\r\n2. Review the new stream notes file for accuracy and formatting\r\n3. Verify the file date correction from 12-06 to 12-05\r\n\r\n## Detailed testing steps\r\n- Verify frontmatter metadata in:\r\n  - `docs/community/Streams/12-2024/2024-12-03.md`\r\n  - `docs/community/Streams/12-2024/2024-12-05.md`\r\n- Check that the new stream notes are properly formatted with:\r\n  - Correct timestamps and YouTube links\r\n  - Complete summary section\r\n  - \"Hot Takes\" section with quotes\r\n- Confirm the file rename from `2024-12-06.md` to `2024-12-05.md` was successful\r\n\r\n<!-- If you are on Discord, please join https://discord.gg/ai16z and state your Discord username here for contribute role and join us in #development-feed -->\r\n<!--\r\n## Discord username\r\nYoungPhlo\r\n-->\r\n",
            "files": [
              {
                "path": "docs/community/Streams/12-2024/2024-12-03.md",
                "additions": 6,
                "deletions": 0
              },
              {
                "path": "docs/community/Streams/12-2024/2024-12-05.md",
                "additions": 104,
                "deletions": 0
              },
              {
                "path": "docs/community/Streams/12-2024/2024-12-06.md",
                "additions": 157,
                "deletions": 80
              }
            ],
            "reviews": [
              {
                "author": "madjin",
                "state": "APPROVED",
                "body": "Good updates overall, super useful having timestamps + who was speaker!"
              }
            ],
            "comments": []
          }
        ]
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "jkbrooks",
    "score": 0,
    "summary": "jkbrooks is currently focused on enhancing the code coverage reporting system, as evidenced by a recent merge pull request (#880) from snobbee/ci/re-enable-codecov-reporting. This activity indicates an effort to improve project transparency and quality assurance processes within their GitHub repository.",
    "avatar_url": "https://avatars.githubusercontent.com/u/129074?u=4cd0bf499a885dd922e04d57e805c88f7c6dd4f9&v=4",
    "activity": {
      "code": {
        "total_commits": 1,
        "total_prs": 0,
        "commits": [
          {
            "sha": "fad561b04f439a9ce307a2a73e62195f6e1cda42",
            "message": "Merge pull request #880 from snobbee/ci/re-enable-codecov-reporting\n\nfix: re-enable coverage report upload to Codecov in CI workflow",
            "created_at": "2024-12-07T02:07:14Z",
            "additions": 4,
            "deletions": 4,
            "changed_files": 1
          }
        ],
        "pull_requests": []
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "0xaguspunk",
    "score": 0,
    "summary": "0xaguspunk is actively working on enhancing the GOAT setup process by passing environment variables for improved configuration flexibility. They have made significant progress, including updating the chain base and refining code within packages and agent areas, as evidenced by their recent commits and merged pull request.",
    "avatar_url": "https://avatars.githubusercontent.com/u/6149085?u=9f6af2484a7452d042a0c24d50e9d760284c689b&v=4",
    "activity": {
      "code": {
        "total_commits": 2,
        "total_prs": 1,
        "commits": [
          {
            "sha": "acc2a451812392c468fb10e0c7fe3bf50509f9bf",
            "message": "Update chain to base",
            "created_at": "2024-12-07T14:22:20Z",
            "additions": 2,
            "deletions": 2,
            "changed_files": 1
          },
          {
            "sha": "ef60886fe901c109f94b35737a0d1edb1b89b86c",
            "message": "Pass env variables when setting up GOAT",
            "created_at": "2024-12-07T14:10:53Z",
            "additions": 131,
            "deletions": 124,
            "changed_files": 6
          }
        ],
        "pull_requests": [
          {
            "number": 898,
            "title": "chore: pass env variables when setting up GOAT and update GOAT readme",
            "state": "MERGED",
            "merged": true,
            "created_at": "2024-12-07T14:21:50Z",
            "updated_at": "2024-12-10T18:35:58Z",
            "body": "# Risks\r\n\r\nLow\r\n\r\n# Background\r\n\r\n## What does this PR do?\r\n\r\nThis PR aims to easily pass secrets to the GOAT plugin as well as improve its readme.\r\n\r\nProblem: \r\nCurrenlty secrets can only be used by plugins when calling an action or a provider. If a plugin requires an initial setup such as setting up a wallet or a GOAT plugin (e.g adding Polymarket or Uniswap plugins) there is no way to achieve this.\r\n\r\nSolution:\r\nUpdate the GOAT plugin to get passed a `getSecrets` function for the specific character it is adding actions to. This allows GOAT to check the secrets/env variables and configure its plugins accordingly when being initialized.\r\n\r\n## What kind of change is this?\r\n\r\nImprovements: This change allows developers to install GOAT plugins easily such as Polymarket, Uniswap and Coingecko. It also makes it easier to update the plugin to support multi-chain.\r\n\r\n# Documentation changes needed?\r\n\r\nMy changes do not require a change to the project documentation.\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\n1. Go to `plugin-goat`\r\n\r\n## Detailed testing steps\r\n1. Make sure you have an `EVM_PRIVATE_KEY` and `EVM_PROVIDER_URL` for Base set\r\n2. Comment out `evmPlugin` in `src/agent.ts`\r\n3. Run the agent and prompt it with: What's the USDC balance of `0x18Bead774f927Af586F86F6d054C269416E163DD`\r\n4. Should give you the balance of `0x18Bead774f927Af586F86F6d054C269416E163DD`\r\n\r\nTo test actions on Base Sepolia simply:\r\n1. Go to `plugin-goat/src/wallet.ts` and change\r\n```typescript\r\nconst chain = base \r\n```\r\nto\r\n```typescript\r\nconst chain = sepolia\r\n```\r\n2. Make sure `EVM_PROVIDER_URL` works for Sepolia\r\n3. Run the agent!\r\n\r\n\r\n## Discord username\r\naguspunk\r\n",
            "files": [
              {
                "path": "agent/src/index.ts",
                "additions": 7,
                "deletions": 3
              },
              {
                "path": "packages/plugin-goat/README.md",
                "additions": 39,
                "deletions": 12
              },
              {
                "path": "packages/plugin-goat/src/actions.ts",
                "additions": 14,
                "deletions": 30
              },
              {
                "path": "packages/plugin-goat/src/index.ts",
                "additions": 29,
                "deletions": 25
              },
              {
                "path": "packages/plugin-goat/src/provider.ts",
                "additions": 0,
                "deletions": 54
              },
              {
                "path": "packages/plugin-goat/src/wallet.ts",
                "additions": 42,
                "deletions": 0
              }
            ],
            "reviews": [
              {
                "author": "odilitime",
                "state": "COMMENTED",
                "body": ""
              },
              {
                "author": "0xaguspunk",
                "state": "COMMENTED",
                "body": ""
              },
              {
                "author": "odilitime",
                "state": "APPROVED",
                "body": ""
              }
            ],
            "comments": [
              {
                "author": "cygaar",
                "body": "we're currently in the process of refactoring how plugins are setup and initiated so we'll probably hold off on merging this for now"
              },
              {
                "author": "0xaguspunk",
                "body": "oh nice, any ETA for that @cygaar ? :)"
              }
            ]
          }
        ]
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "v1xingyue",
    "score": 0,
    "summary": "v1xingyue is actively contributing to the development of a basic SUI wallet provider plugin, as evidenced by their recent pull request for adding this feature. They are also working on continuous integration and delivery (CI/CD) processes related to GitHub images, with commits aimed at improving automation in release cycles. Additionally, v1xingyue has engaged with the community through an issue regarding provider ID features, demonstrating a focus on enhancing user experience and functionality within their project.",
    "avatar_url": "https://avatars.githubusercontent.com/u/974169?u=96c6a113a91978c041e5cf90965d7b66c5540af4&v=4",
    "activity": {
      "code": {
        "total_commits": 2,
        "total_prs": 2,
        "commits": [
          {
            "sha": "f99000e6b0b2f7ae9f50af6f83b3c19644656f3d",
            "message": "cicd when release",
            "created_at": "2024-12-07T04:59:32Z",
            "additions": 3,
            "deletions": 5,
            "changed_files": 1
          },
          {
            "sha": "c39b9a2d0e12957fd7094ae598bbeb28314c0bc9",
            "message": "github image cicd",
            "created_at": "2024-12-07T04:58:10Z",
            "additions": 63,
            "deletions": 0,
            "changed_files": 1
          }
        ],
        "pull_requests": [
          {
            "number": 908,
            "title": "Adding plugin-sui:  init basic sui wallet provider",
            "state": "CLOSED",
            "merged": false,
            "created_at": "2024-12-07T22:00:03Z",
            "updated_at": "2024-12-16T04:37:16Z",
            "body": "start add plugin-sui . \r\nAt first add the basic wallet provider. ",
            "files": [
              {
                "path": "packages/plugin-sui/.npmignore",
                "additions": 6,
                "deletions": 0
              },
              {
                "path": "packages/plugin-sui/eslint.config.mjs",
                "additions": 3,
                "deletions": 0
              },
              {
                "path": "packages/plugin-sui/package.json",
                "additions": 26,
                "deletions": 0
              },
              {
                "path": "packages/plugin-sui/src/constants.ts",
                "additions": 1,
                "deletions": 0
              },
              {
                "path": "packages/plugin-sui/src/enviroment.ts",
                "additions": 34,
                "deletions": 0
              },
              {
                "path": "packages/plugin-sui/src/index.ts",
                "additions": 14,
                "deletions": 0
              },
              {
                "path": "packages/plugin-sui/src/providers/wallet.ts",
                "additions": 251,
                "deletions": 0
              },
              {
                "path": "packages/plugin-sui/tsconfig.json",
                "additions": 10,
                "deletions": 0
              },
              {
                "path": "packages/plugin-sui/tsup.config.ts",
                "additions": 29,
                "deletions": 0
              }
            ],
            "reviews": [],
            "comments": []
          },
          {
            "number": 889,
            "title": "feat : github image cicd",
            "state": "MERGED",
            "merged": true,
            "created_at": "2024-12-07T05:00:07Z",
            "updated_at": "2024-12-13T22:18:12Z",
            "body": "when relase published make github docker image. ",
            "files": [
              {
                "path": ".github/workflows/image.yaml",
                "additions": 61,
                "deletions": 0
              },
              {
                "path": "Dockerfile",
                "additions": 1,
                "deletions": 1
              },
              {
                "path": "package.json",
                "additions": 1,
                "deletions": 1
              }
            ],
            "reviews": [
              {
                "author": "odilitime",
                "state": "APPROVED",
                "body": ""
              }
            ],
            "comments": [
              {
                "author": "monilpat",
                "body": "Looks good to me do you mind adding a test thanks! "
              },
              {
                "author": "v1xingyue",
                "body": "I'm not sure what does test mean. This only do build and publish image when released. I think it should be tested and prepared for publish "
              },
              {
                "author": "monilpat",
                "body": "> I'm not sure what does test mean. This only do build and publish image when released. I think it should be tested and prepared for publish\r\n\r\nI mean just adding a screenshot of successful run of the .yaml file. "
              },
              {
                "author": "v1xingyue",
                "body": "Ok that's fine I'll add that later "
              },
              {
                "author": "v1xingyue",
                "body": "This is one exmple running github cicd.\r\nhttps://github.com/v1xingyue/eliza/actions/runs/12220378514/job/34088113118\r\nI think this is enough for test.\r\n\r\nBut there is something wrong with `pnpm run build` in docker image. \r\nSo I just modify it with : \r\n\r\n`     \"build\": \"turbo run build\"  `"
              },
              {
                "author": "v1xingyue",
                "body": "Done. Seems package.json provide \r\npnpm build-docker \r\ncommand . \r\nI change it in Dockerfile . "
              }
            ]
          }
        ]
      },
      "issues": {
        "total_opened": 1,
        "opened": [
          {
            "number": 909,
            "title": "Provider Id Feature Request",
            "state": "OPEN",
            "created_at": "2024-12-07T23:14:40Z",
            "updated_at": "2024-12-07T23:14:40Z",
            "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\nI'm always frustrated when I have to call all providers each time instead of being able to identify them individually.\r\n\r\n**Describe the solution you'd like**\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\nI suggest adding an ID option to the Provider, similar to how actions are identified. This would allow for direct identification without the need to invoke all providers.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\nAn alternative would be using an external mapping or registry system to track and identify providers. However, this approach adds complexity and maintenance overhead.\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n\r\nAdding an ID to the Provider can streamline operations and improve efficiency when dealing with multiple providers in a system.\r\n\r\n",
            "labels": [
              {
                "name": "enhancement",
                "color": "a2eeef",
                "description": "New feature or request"
              }
            ],
            "comments": []
          }
        ]
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "btspoony",
    "score": 0,
    "summary": "Btspoony is actively merging branches, as seen by the recent merge from 'main' into the plugin-flow branch. They have also addressed a lock file issue to improve system stability and security. Overall, btspoony has made significant code changes with an increase of 2451 lines added and 475 removed in their commits over the past 90 days.",
    "avatar_url": "https://avatars.githubusercontent.com/u/707025?u=d8487801b6cc361f4a912518c54cc25cfb70d347&v=4",
    "activity": {
      "code": {
        "total_commits": 2,
        "total_prs": 0,
        "commits": [
          {
            "sha": "89f7a8a77e56c3ad7c5e3c45d2c843d97cc8c887",
            "message": "fix: lock file",
            "created_at": "2024-12-07T02:40:32Z",
            "additions": 111,
            "deletions": 0,
            "changed_files": 1
          },
          {
            "sha": "1989c8958681d72ed84e6a5e0d748f96e95bc5e0",
            "message": "Merge branch 'main' into tbh/plugin-flow",
            "created_at": "2024-12-07T02:38:07Z",
            "additions": 2340,
            "deletions": 475,
            "changed_files": 55
          }
        ],
        "pull_requests": []
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "L-jasmine",
    "score": 0,
    "summary": "L-jasmine is actively enhancing the project's configuration by incorporating `USE_GAIANET_EMBEDDING` into `.env.example`, introducing a default model for gaianet, and setting its baseUrl. Additionally, they have optimized the default dimensions of gaianet_embedding to 768.",
    "avatar_url": "https://avatars.githubusercontent.com/u/14789875?u=7ffd774ff152ea0d11288eeb45c0d09556681eb0&v=4",
    "activity": {
      "code": {
        "total_commits": 3,
        "total_prs": 0,
        "commits": [
          {
            "sha": "f0e331c06905d1508b2cc0abfce7e6eba6e21605",
            "message": "feat: add gaianet default model and baseUrl",
            "created_at": "2024-12-07T17:39:42Z",
            "additions": 25,
            "deletions": 6,
            "changed_files": 3
          },
          {
            "sha": "9fd0b5ddbbbfdfe13d4f9fb8350d624b89b62edb",
            "message": "fix: gaianet_embedding default dimensions to 768",
            "created_at": "2024-12-07T15:25:19Z",
            "additions": 1,
            "deletions": 1,
            "changed_files": 1
          },
          {
            "sha": "208fedd49051b302a2cd1db47cb81995b9a7bb2c",
            "message": "chore: add `USE_GAIANET_EMBEDDING` into `.env.example`",
            "created_at": "2024-12-07T15:24:35Z",
            "additions": 1,
            "deletions": 0,
            "changed_files": 1
          }
        ],
        "pull_requests": []
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "actions-user",
    "score": 0,
    "summary": "Actions-User is actively maintaining project documentation, as evidenced by a recent commit to update the changelog. With no pull requests or issues opened during this period, their contributions are currently limited to code changes aimed at improving the project's release notes and version tracking.",
    "avatar_url": null,
    "activity": {
      "code": {
        "total_commits": 1,
        "total_prs": 0,
        "commits": [
          {
            "sha": "24dccddb396337a284eda86cc23c60ed4f95472b",
            "message": "chore: update changelog",
            "created_at": "2024-12-07T00:35:47Z",
            "additions": 8,
            "deletions": 0,
            "changed_files": 1
          }
        ],
        "pull_requests": []
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "guzus",
    "score": 0,
    "summary": "Guzus is actively improving the readability of configuration files, specifically focusing on formatting changes to `.env.example`. In the past 90 days, they have contributed one merged pull request and commit related to this task, demonstrating a dedication to codebase maintenance and clarity.",
    "avatar_url": "https://avatars.githubusercontent.com/u/50664161?u=13fb44203ac4b9d6f3aa00f0fb75c329d486f57d&v=4",
    "activity": {
      "code": {
        "total_commits": 1,
        "total_prs": 1,
        "commits": [
          {
            "sha": "2fe083caa20496663bf35bfc2cbce149d947c3b2",
            "message": "chore: improve formatting of .env.example for better readability\n\n- Organized the `.env.example` file into clearly defined sections with headers.\r\n- Added comments to describe each configuration variable and its purpose.\r\n- Ensured consistent spacing and alignment across the file for readability.\r\n- Grouped related settings, such as API keys, model configurations, and platform-specific settings, under appropriate headers.\r\n- This update enhances maintainability and makes it easier for contributors to understand and update the file.\r\n\r\nNo functional changes were made; this commit is purely for structural and visual clarity.",
            "created_at": "2024-12-07T14:00:27Z",
            "additions": 147,
            "deletions": 109,
            "changed_files": 1
          }
        ],
        "pull_requests": [
          {
            "number": 897,
            "title": "chore: improve formatting of .env.example for better readability",
            "state": "MERGED",
            "merged": true,
            "created_at": "2024-12-07T14:05:16Z",
            "updated_at": "2024-12-14T22:39:12Z",
            "body": "<!-- Use this template by filling in information and copy and pasting relevant items out of the html comments. -->\r\n\r\n# Relates to:\r\n\r\n<!-- LINK TO ISSUE OR TICKET -->\r\n\r\n<!-- This risks section is to be filled out before final review and merge. -->\r\n\r\n# Risks\r\n\r\n<!--\r\nLow, medium, large. List what kind of risks, and what could be effected.\r\n-->\r\nLow, because no code has changed\r\n\r\n# Background\r\n\r\n## What does this PR do?\r\n- Ensured consistent spacing and alignment across the file for readability.\r\n- This update enhances maintainability and makes it easier for contributors to understand and update the file.\r\n\r\nNo functional changes were made; this commit is purely for structural and visual clarity.\r\n\r\n## What kind of change is this?\r\n\r\n<!--\r\nBug fixes (non-breaking change which fixes an issue)\r\nImprovements (misc. changes to existing features)\r\nFeatures (non-breaking change which adds functionality)\r\nUpdates (new versions of included code)\r\n-->\r\nImprovements\r\n\r\n<!-- This \"Why\" section is most relevant if there is no linked issue explaining why. If there is a related issue it might make sense to skip this why section. -->\r\n## Why are we doing this? Any context or related work?\r\nStandardizing formatting aligns with best practices for .env files, ensuring clarity and readability.\r\n\r\n# Documentation changes needed?\r\n\r\n<!--\r\nMy changes do not require a change to the project documentation.\r\nMy changes require a change to the project documentation.\r\nIf a docs change is needed: I have updated the documentation accordingly.\r\n-->\r\nMy changes do not require a change to the project documentation.\r\n\r\n<!-- Please show how you tested the PR. This will really help if the PR needs to be retested, and probably help the PR get merged quicker. -->\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\n\r\n## Detailed testing steps\r\n\r\nNone, automated tests are fine.\r\n\r\n<!--\r\n- As [anon/admin], go to [link]\r\n\u00a0 - [do action]\r\n\u00a0 - verify [result]\r\n-->\r\n\r\n<!-- If there is a UI change, please include before and after screenshots or videos. This will speed up PRs being merged. It is extra nice to annotate screenshots with arrows or boxes pointing out the differences. -->\r\n<!--\r\n## Screenshots\r\n### Before\r\n### After\r\n-->\r\n\r\n<!-- If there is anything about the deploy, please make a note. -->\r\n<!--\r\n# Deploy Notes\r\n-->\r\n\r\n<!-- \u00a0Copy and paste commandline output. -->\r\n<!--\r\n## Database changes\r\n-->\r\n\r\n<!-- \u00a0If there is something more than the automated steps, please specifiy deploy instructions. -->\r\n<!--\r\n## Deployment instructions\r\n-->\r\n\r\n<!-- If you are on Discord, please join https://discord.gg/ai16z and state your Discord username here for contribute role and join us in #development-feed -->\r\n## Discord username\r\nuncanny_guzus\r\n",
            "files": [
              {
                "path": ".env.example",
                "additions": 106,
                "deletions": 109
              }
            ],
            "reviews": [
              {
                "author": "monilpat",
                "state": "CHANGES_REQUESTED",
                "body": "Thanks for working on formatting this much needed - please make sure no comments are lost."
              },
              {
                "author": "monilpat",
                "state": "COMMENTED",
                "body": ""
              },
              {
                "author": "odilitime",
                "state": "COMMENTED",
                "body": ""
              },
              {
                "author": "guzus",
                "state": "COMMENTED",
                "body": ""
              },
              {
                "author": "odilitime",
                "state": "COMMENTED",
                "body": ""
              }
            ],
            "comments": [
              {
                "author": "guzus",
                "body": "Thank you for the review @monilpat ! I\u2019ve resolved the issue. Could you please take a look when you get a chance?"
              },
              {
                "author": "guzus",
                "body": "@monilpat I have intentionally minimized the changes in this Pull Request to reduce confusion for contributors, given the rapid pace of updates in the repository. The changes primarily focus on formatting and improving readability without altering the existing structure or comments. Thank you!"
              },
              {
                "author": "monilpat",
                "body": "Looks like there are merge conflicts :) "
              },
              {
                "author": "guzus",
                "body": "yeah, this repository is really growing fast... @monilpat can you pls check again?"
              }
            ]
          }
        ]
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "tharak123455",
    "score": 0,
    "summary": "Tharak123455 is actively working on enhancing a Twitter client, as evidenced by two pull requests submitted to the project within the last 90 days. Despite these contributions, none of the proposed changes have been merged into the main codebase yet. The developer's focus remains solely on this area without engagement in issues or additional commits during this period.",
    "avatar_url": "https://avatars.githubusercontent.com/u/83504457?v=4",
    "activity": {
      "code": {
        "total_commits": 0,
        "total_prs": 2,
        "commits": [],
        "pull_requests": [
          {
            "number": 896,
            "title": "Twitter client enhancements",
            "state": "CLOSED",
            "merged": false,
            "created_at": "2024-12-07T13:50:09Z",
            "updated_at": "2024-12-08T06:32:20Z",
            "body": "<!-- Use this template by filling in information and copy and pasting relevant items out of the html comments. -->\r\n\r\n# Relates to:\r\n\r\nIssue related to Twitter client enhancements and environment configuration\r\nRisks\r\n\r\n<!-- This risks section is to be filled out before final review and merge. -->\r\n\r\n# Risks\r\nLow - included new functionality of Twitter target users configuration and environment example file. No core functionality changes.\r\n# Background\r\n## What does this PR do?\r\nAdds dynamic Twitter target users configuration through environment variables(agent can now interact with configured user's tweets without mentioning agent)\r\nUpdates .env.example with Twitter-related configuration examples\r\nImproves error handling for wallet providers in Twitter client\r\nEnhances Twitter interaction handling\r\n\r\n## What kind of change is this?\r\nImprovements (misc. changes to existing features)\r\n\r\n<!--\r\nBug fixes (non-breaking change which fixes an issue)\r\nImprovements (misc. changes to existing features)\r\nFeatures (non-breaking change which adds functionality)\r\nUpdates (new versions of included code)\r\n-->\r\n\r\n<!-- This \"Why\" section is most relevant if there is no linked issue explaining why. If there is a related issue it might make sense to skip this why section. -->\r\n<!--\r\n## Why are we doing this? Any context or related work?\r\n-->\r\n\r\n# Documentation changes needed?\r\nMy changes require a change to the project documentation.\r\nUpdated .env.example with new Twitter configuration options\r\nDocumentation for Twitter target users configuration\r\n\r\n<!-- Please show how you tested the PR. This will really help if the PR needs to be retested, and probably help the PR get merged quicker. -->\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\nCheck the updated .env.example file for new Twitter configurations\r\nReview changes in packages/client-twitter/src/interactions.ts\r\n\r\n## Detailed testing steps\r\nCopy .env.example to .env\r\nConfigure TWITTER_TARGET_USERS with comma-separated usernames\r\nRun the Twitter client\r\nBot responds to configured target users\r\nError handling works for wallet provider issues\r\nTwitter interactions are properly processed\r\n\r\n<!-- If there is anything about the deploy, please make a note. -->\r\n\r\n# Deploy Notes\r\nNew environment variable TWITTER_TARGET_USERS needs to be configured if using custom target users\r\nNo database changes required\r\nNo special deployment steps needed\r\n\r\n## Discord username\r\ntharakesh5545\r\n\r\n\r\n",
            "files": [],
            "reviews": [
              {
                "author": "cygaar",
                "state": "CHANGES_REQUESTED",
                "body": ""
              }
            ],
            "comments": []
          },
          {
            "number": 894,
            "title": "Twitter client enhancements",
            "state": "CLOSED",
            "merged": false,
            "created_at": "2024-12-07T12:05:44Z",
            "updated_at": "2024-12-07T13:34:50Z",
            "body": "Relates to:\r\nIssue related to Twitter client enhancements and environment configuration\r\n\r\nRisks\r\nLow - Changes to Twitter target users configuration and environment example file. No core functionality changes.\r\nBackground\r\nWhat does this PR do?\r\nAdds dynamic Twitter target users(we can add userids to which agent should interact even if agent is not mentioned  ) configuration through environment variables\r\nUpdates .env.example with Twitter-related configuration examples\r\nImproves error handling for wallet providers in Twitter client\r\nEnhances Twitter interaction handling\r\n\r\nWhat kind of change is this?\r\nImprovements (misc. changes to existing features)\r\n\r\nDocumentation changes needed?\r\nMy changes require a change to the project documentation.\r\nUpdated .env.example with new Twitter configuration options\r\nDocumentation for Twitter target users configuration\r\nTesting\r\n\r\nWhere should a reviewer start?\r\nCheck the updated .env.example file for new Twitter configurations\r\nReview changes in packages/client-twitter/src/interactions.ts\r\nDetailed testing steps\r\nCopy .env.example to .env\r\nConfigure TWITTER_TARGET_USERS with comma-separated usernames\r\nRun the Twitter client\r\n\r\n4. Verify that:\r\nBot responds to configured target users\r\nError handling works for wallet provider issues\r\nTwitter interactions are properly processed\r\n\r\nDeploy Notes\r\nNew environment variable TWITTER_TARGET_USERS needs to be configured if using custom target users\r\nNo database changes required\r\nNo special deployment steps needed\r\n\r\nDiscord username\r\n[tharakesh5545]",
            "files": [
              {
                "path": ".env.example",
                "additions": 1,
                "deletions": 0
              },
              {
                "path": "packages/client-twitter/src/interactions.ts",
                "additions": 105,
                "deletions": 28
              }
            ],
            "reviews": [],
            "comments": []
          }
        ]
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "golryang",
    "score": 0,
    "summary": "golryang is focused on improving the consistency of language used for Community & Contact links within a project, as evidenced by their recent commit and merged pull request. This effort demonstrates an attention to detail and dedication to enhancing user experience through clear communication channels.",
    "avatar_url": "https://avatars.githubusercontent.com/u/41885614?u=e2ab916fbff8d9058272fb7acd9a35713f666791&v=4",
    "activity": {
      "code": {
        "total_commits": 1,
        "total_prs": 1,
        "commits": [
          {
            "sha": "27e8a7ee8af5ebbd2e0866fc39ee7da5da634c81",
            "message": "Consistent language for Community & Contact links",
            "created_at": "2024-12-07T14:28:57Z",
            "additions": 1,
            "deletions": 1,
            "changed_files": 1
          }
        ],
        "pull_requests": [
          {
            "number": 899,
            "title": "chore: Consistent language for Community & Contact link label",
            "state": "MERGED",
            "merged": true,
            "created_at": "2024-12-07T14:36:15Z",
            "updated_at": "2024-12-08T20:05:09Z",
            "body": "<!-- Use this template by filling in information and copy and pasting relevant items out of the html comments. -->\r\n\r\n# Relates to: \r\n\r\n<!-- LINK TO ISSUE OR TICKET -->\r\n\r\n<!-- This risks section is to be filled out before final review and merge. -->\r\n\r\n# Risks\r\nLow: This change only standardizes the link label and does not affect core functionality.\r\n\r\n<!--\r\nLow, medium, large. List what kind of risks, and what could be effected.\r\n-->\r\n\r\n# Background\r\n\r\n## What does this PR do?\r\nIt updates the label text for the Community and Contact links to ensure consistency.\r\n\r\n## What kind of change is this?\r\nImprovement\r\n\r\n<!--\r\nBug fixes (non-breaking change which fixes an issue)\r\nImprovements (misc. changes to existing features)\r\nFeatures (non-breaking change which adds functionality)\r\nUpdates (new versions of included code)\r\n-->\r\n\r\n<!-- This \"Why\" section is most relevant if there is no linked issue explaining why. If there is a related issue it might make sense to skip this why section. -->\r\n<!--\r\n## Why are we doing this? Any context or related work?\r\n-->\r\n\r\n# Documentation changes needed?\r\nNo documentation changes are needed.\r\n\r\n<!--\r\nMy changes do not require a change to the project documentation.\r\nMy changes require a change to the project documentation.\r\nIf a docs change is needed: I have updated the documentation accordingly.\r\n-->\r\n\r\n<!-- Please show how you tested the PR. This will really help if the PR needs to be retested, and probably help the PR get merged quicker. -->\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\nCheck the updated sections of the code that include the Community and Contact link label text.\r\n\r\n## Detailed testing steps\r\n1. Navigate to the screen containing the Community and Contact links.\r\n2. Verify that the link label text is consistent across the UI.\r\n\r\n<!--\r\nNone, automated tests are fine.\r\n-->\r\n\r\n<!--\r\n- As [anon/admin], go to [link]\r\n\u00a0 - [do action]\r\n\u00a0 - verify [result]\r\n-->\r\n\r\n<!-- If there is a UI change, please include before and after screenshots or videos. This will speed up PRs being merged. It is extra nice to annotate screenshots with arrows or boxes pointing out the differences. -->\r\n<!--\r\n## Screenshots\r\n### Before\r\n### After\r\n-->\r\n\r\n<!-- If there is anything about the deploy, please make a note. -->\r\n<!--\r\n# Deploy Notes\r\n-->\r\n\r\n<!-- \u00a0Copy and paste commandline output. -->\r\n<!--\r\n## Database changes\r\n-->\r\n\r\n<!-- \u00a0If there is something more than the automated steps, please specifiy deploy instructions. -->\r\n<!--\r\n## Deployment instructions\r\n-->\r\n\r\n<!-- If you are on Discord, please join https://discord.gg/ai16z and state your Discord username here for contribute role and join us in #development-feed -->\r\n<!--\r\n## Discord username\r\n\r\n-->\r\n",
            "files": [
              {
                "path": "README_KOR.md",
                "additions": 1,
                "deletions": 1
              }
            ],
            "reviews": [
              {
                "author": "cygaar",
                "state": "APPROVED",
                "body": ""
              },
              {
                "author": "monilpat",
                "state": "APPROVED",
                "body": ""
              },
              {
                "author": "monilpat",
                "state": "APPROVED",
                "body": ""
              },
              {
                "author": "jkbrooks",
                "state": "APPROVED",
                "body": ""
              }
            ],
            "comments": []
          }
        ]
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "samuveth",
    "score": 0,
    "summary": "Samuveth is currently focused on running tests for start and dev environments, as evidenced by the recent issue they've raised. Over the past 90 days, their activity has been centered around addressing a bug without any commits or code changes made to resolve it. There have also been no pull requests submitted during this period.",
    "avatar_url": "https://avatars.githubusercontent.com/u/51686767?u=ffa2b7744e836f30b37bf4d21edc3e5d9e00dde1&v=4",
    "activity": {
      "code": {
        "total_commits": 0,
        "total_prs": 0,
        "commits": [],
        "pull_requests": []
      },
      "issues": {
        "total_opened": 1,
        "opened": [
          {
            "number": 893,
            "title": "Running tests on start and dev?",
            "state": "CLOSED",
            "created_at": "2024-12-07T11:17:08Z",
            "updated_at": "2024-12-09T06:42:36Z",
            "body": "<img width=\"694\" alt=\"image\" src=\"https://github.com/user-attachments/assets/13863f5c-9bce-4cb8-92b8-06f25d6cf717\">\r\n\r\n\r\nSomehow it keeps running tests on `start` and `dev`. And after restarting a few times it starts slowing down my system a lot as each test requires 4gb of ram. Any idea why this is happening?",
            "labels": [
              {
                "name": "bug",
                "color": "d73a4a",
                "description": "Something isn't working"
              }
            ],
            "comments": []
          }
        ]
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "arose00",
    "score": 0,
    "summary": "Arose00 is actively contributing to the development of a new plugin for ZKsync Era, as evidenced by their recent pull request that has been merged into the project. Their involvement over the past 90 days primarily focuses on enhancing packages and agent code areas without any open issues or additional commits recorded during this period.",
    "avatar_url": "https://avatars.githubusercontent.com/u/152931880?v=4",
    "activity": {
      "code": {
        "total_commits": 0,
        "total_prs": 1,
        "commits": [],
        "pull_requests": [
          {
            "number": 906,
            "title": "Adding plugin for ZKsync Era",
            "state": "MERGED",
            "merged": true,
            "created_at": "2024-12-07T20:22:06Z",
            "updated_at": "2024-12-14T10:56:39Z",
            "body": "# Relates to:\r\n\r\nN/A\r\n\r\n# Risks\r\n\r\nLow. \r\n\r\nMain implementation risk is that the Plugin doesn't work correctly.\r\n\r\n# Background\r\n\r\n## What does this PR do?\r\n\r\n[ZKsync Era](https://zksync.io/) is one of the most established ZK rollups on Ethereum. This PR implements a plugin for agents to be able to interact with Era. \r\n\r\nIn this first version, only the `transfer` function is supported. Further work will extend this functionality. \r\n\r\nMany more L2s are being build w/ the ZK Stack (the open source framework used to build ZKsync Era), and this work can be extended/modified to support these as they come online.\r\n\r\n## What kind of change is this?\r\n\r\n\r\nFeatures (non-breaking change which adds functionality)\r\n\r\n\r\n## Why are we doing this? Any context or related work?\r\n\r\nWe're seeing a huge proliferation of AI agents being able to manage value on-chain. This is similar conceptually to these plugins (e.g. `plugin-solana` and others)\r\n\r\n# Documentation changes needed?\r\n\r\nThis plugin follows the standards set by other crypto integrations, including things like the `SEND_TOKENS` action. Changes to the overall project documentation don't seem to be required.\r\n\r\n<!-- Please show how you tested the PR. This will really help if the PR needs to be retested, and probably help the PR get merged quicker. -->\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\n\r\nMost of the changes are in `plugin-zksync-era`\r\n\r\n## Detailed testing steps\r\n\r\n1. In `.env` you should set the value for `ZKSYNC_ADDRESS` (this is the public address for the agent account) and `ZKSYNC_PRIVATE_KEY` (private key for the same account).\r\n2. To test the transfer function properly, this address needs tokens. Coinbase can be used to send ZK directly to an address on ZKsync Era, but I am also happy to provide tokens for reviewers (I'll send ZK tokens to reviewers that need it). \r\n3. Run the agent and prompt it with: \"send 0.5 ZK to <an address on ZKsync Era>\" - e.g. \"send 1 ZK to 0xee0c40F86544a8b0616BC827728f714a8B4cEeE7\"\r\n4. Assuming you had 1 ZK to send, the agent will confirm and respond with the tx hash, e.g. `Transfer completed successfully! \"tx: 0x45759cf3e76d26610154a094c87572fbd7f5ef909f62c4ea13f7defb0d87cf0b\"`\r\n5. The tx hash can be checked on the ZKsync block explorer at https://explorer.zksync.io, e.g. https://explorer.zksync.io/tx/0x45759cf3e76d26610154a094c87572fbd7f5ef909f62c4ea13f7defb0d87cf0b\r\n\r\n## Discord username\r\nanthonykrose\r\n",
            "files": [
              {
                "path": ".env.example",
                "additions": 4,
                "deletions": 0
              },
              {
                "path": "agent/package.json",
                "additions": 1,
                "deletions": 0
              },
              {
                "path": "agent/src/index.ts",
                "additions": 2,
                "deletions": 0
              },
              {
                "path": "packages/plugin-zksync-era/package.json",
                "additions": 20,
                "deletions": 0
              },
              {
                "path": "packages/plugin-zksync-era/src/actions/transfer.ts",
                "additions": 232,
                "deletions": 0
              },
              {
                "path": "packages/plugin-zksync-era/src/enviroment.ts",
                "additions": 36,
                "deletions": 0
              },
              {
                "path": "packages/plugin-zksync-era/src/index.ts",
                "additions": 13,
                "deletions": 0
              },
              {
                "path": "packages/plugin-zksync-era/tsconfig.json",
                "additions": 8,
                "deletions": 0
              },
              {
                "path": "packages/plugin-zksync-era/tsup.config.ts",
                "additions": 20,
                "deletions": 0
              }
            ],
            "reviews": [],
            "comments": [
              {
                "author": "arose00",
                "body": "@cygaar added ZKsync plugin w/ support so far just for a transfer function, following conventions from other blockchain plugins.\r\n\r\nWill extend to add other actions assuming general approach is consistent w/ what is expected."
              },
              {
                "author": "cygaar",
                "body": "@arose00 can you fix the merge conflict and adjust the pr title?"
              }
            ]
          }
        ]
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "MSghais",
    "score": 0,
    "summary": "Unable to generate summary for MSghais due to an error.",
    "avatar_url": "https://avatars.githubusercontent.com/u/59928086?u=07384d38f3c014a93581884d2bcaef4ee9772b73&v=4",
    "activity": {
      "code": {
        "total_commits": 0,
        "total_prs": 0,
        "commits": [],
        "pull_requests": []
      },
      "issues": {
        "total_opened": 1,
        "opened": [
          {
            "number": 905,
            "title": "Client Twitter Login issue: Error: {\"errors\":[{\"code\":399,\"message\":\"Incorrect. Please try again.\"}]}",
            "state": "CLOSED",
            "created_at": "2024-12-07T19:08:54Z",
            "updated_at": "2024-12-17T13:20:25Z",
            "body": "**Describe the bug**\r\n\r\nWhen I try to test the Twitter client, I get this message in the loading twitter client error.\r\n\r\nError: {\"errors\":[{\"code\":399,\"message\":\"Incorrect. Please try again.\"}]}\r\n\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\n**To Reproduce**\r\n\r\n<!-- Steps to reproduce the behavior. -->\r\n\r\n**Expected behavior**\r\n\r\n<!-- A clear and concise description of what you expected to happen. -->\r\n\r\n**Screenshots**\r\n\r\n<!-- If applicable, add screenshots to help explain your problem. -->\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n",
            "labels": [
              {
                "name": "bug",
                "color": "d73a4a",
                "description": "Something isn't working"
              }
            ],
            "comments": [
              {
                "author": "Lukapetro",
                "body": "Most likely, the data you entered in the environment variables is incorrect. Check them "
              },
              {
                "author": "nfwGytautas",
                "body": "Got the same it seems to be related to suspicious login checks from X"
              },
              {
                "author": "metatxn",
                "body": "> Got the same it seems to be related to suspicious login checks from X\r\n\r\n+1, even i'm getting same issue. I created a new account for the agent.\r\n\r\n@lalalune can you please share what's the fix for this issue?"
              },
              {
                "author": "aj47",
                "body": "\r\n\r\nfor those trying to set eliza up on a vps\r\nfrom the discord: \r\n```\r\nManaged to login to twitter finally by spoofing the browser for VPS\r\nFor anyone that is having trouble this is way easier than setting up graphic interface or VPN\r\n\r\nused Firefox settings > Network settings > manual proxy config \r\n\r\nSet SOCKS Host to 127.0.0.1 on port 8080\r\nssh -D 127.0.0.1:8080 user@<vps ip address>. \r\n#this using Mac/Windows you may need to generate keys\r\n\r\nThen use firefox browser to login and complete verification\r\n```\r\n\r\ni wasn't able to do this succesfully but if someone can take this knowledge and suggest another way would be greaytly appreciated"
              },
              {
                "author": "metatxn",
                "body": "@aj47 it didn't work :("
              },
              {
                "author": "0xfortes",
                "body": "Followed @aj47 procedure and it works! Solved!"
              },
              {
                "author": "KarimovMurodilla",
                "body": "Same problem..."
              }
            ]
          }
        ]
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "0x3N3jVhPUV",
    "score": 0,
    "summary": "0x3N3jVhPUV is currently addressing a Twitter premium subscription issue, where they are unable to post tweets exceeding the standard character limit despite having access to an extended MAX_TWEET_LENGTH of up to 2500 characters. Their recent activity has been focused on resolving this bug through one reported issue with no pull requests or code changes made in the last 90 days.",
    "avatar_url": "https://avatars.githubusercontent.com/u/46408093?v=4",
    "activity": {
      "code": {
        "total_commits": 0,
        "total_prs": 0,
        "commits": [],
        "pull_requests": []
      },
      "issues": {
        "total_opened": 1,
        "opened": [
          {
            "number": 883,
            "title": "I have a twitter premium subscription and MAX_TWEET_LENGTH  to 2500 but I can't to post a tweet with more than 280 characteres",
            "state": "OPEN",
            "created_at": "2024-12-07T02:51:08Z",
            "updated_at": "2024-12-12T04:07:42Z",
            "body": "**Describe the bug**\r\nI have a Premium twitter subscription, I'm using the latest coockies, in eliza/packages/client-twitter/src/post.ts, I changed MAX_TWEET_LENGTH  to 2500;  but my agent cannot post more than 280 characters on X. \r\nHere is what I'm getting when I'm trying to post with more thant 280 characters:\r\n\"Error sending tweet; Bad response: {\r\n  errors: [\r\n    {\r\n      message: 'Authorization: Tweet needs to be a bit shorter. (186)'\r\n....\"\r\n \r\n**To Reproduce**\r\n1- Get a premium twitter subscription\r\n2- Make sure you ar using the latest coockies\r\n3- Change MAX_TWEET_LENGTH  to 2500\r\n4- Run the agent\r\n\r\n**Expected behavior**\r\n\r\n Since I have a twitter premium subscription ,I should be able to post a tweet with more than 280 characteres.\r\n\r\n**Screenshots**\r\n![image](https://github.com/user-attachments/assets/fbfdf249-6bce-42da-9b59-1655190e2295)\r\n\r\n\r\nQuestion:\r\nWhat should I do in order to post more than 280 characters on X?\r\n\r\nRegards\r\n",
            "labels": [
              {
                "name": "bug",
                "color": "d73a4a",
                "description": "Something isn't working"
              }
            ],
            "comments": [
              {
                "author": "CodingTux",
                "body": "Wait for few hours if you purchased the premium recently. Also try with different length size first like 500, 1000, 1500 etc and check when it starts failing. Another thing you can do is check the generated response length."
              },
              {
                "author": "oxSaturn",
                "body": "Seems to be a bug fixed in agent-twitter-client https://github.com/ai16z/agent-twitter-client/pull/18"
              },
              {
                "author": "0x3N3jVhPUV",
                "body": "> Seems to be a bug fixed in agent-twitter-client [ai16z/agent-twitter-client#18](https://github.com/ai16z/agent-twitter-client/pull/18)\r\n\r\nIndded but when I tried to use the function sendNoteTweet(), I have the following error:\r\n ERRORS\r\n   Error sending tweet: \r\n   {} \r\n   \r\nAfter buildind, I checked  eliza/node_modules/agent-twitter-client/src/scraper.ts and the function  sendNoteTweet() is not in the file. "
              },
              {
                "author": "oxSaturn",
                "body": "> > Seems to be a bug fixed in agent-twitter-client [ai16z/agent-twitter-client#18](https://github.com/ai16z/agent-twitter-client/pull/18)\r\n> \r\n> Indded but when I tried to use the function sendNoteTweet(), I have the following error: ERRORS Error sending tweet: {}\r\n> \r\n> After buildind, I checked eliza/node_modules/agent-twitter-client/src/scraper.ts and the function sendNoteTweet() is not in the file.\r\n\r\nThe code was merged without a new release. cc @lalalune Can you please cut a release for `agent-twitter-client`?"
              }
            ]
          }
        ]
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "deepfates",
    "score": 0,
    "summary": "DeepFATES is currently addressing a bug related to the Ollama provider not using the correct endpoint, as evidenced by their recent activity on GitHub. With one issue reported but no pull requests or commits made within the last 90 days, they are focused on resolving this specific problem in their project's codebase.",
    "avatar_url": "https://avatars.githubusercontent.com/u/58602708?u=0a88f02b2d06c8f627124a61bf8261aa46cdfe1c&v=4",
    "activity": {
      "code": {
        "total_commits": 0,
        "total_prs": 0,
        "commits": [],
        "pull_requests": []
      },
      "issues": {
        "total_opened": 1,
        "opened": [
          {
            "number": 882,
            "title": "Ollama provider doesn't use correct endpoint",
            "state": "OPEN",
            "created_at": "2024-12-07T02:15:32Z",
            "updated_at": "2024-12-16T08:51:42Z",
            "body": "**Describe the bug**\r\n\r\nThe Ollama model provider sends a post to `localhost:11434/api/chat` instead of the correct endpoint, which should be either `localhost:11434/api/v1/chat/completions` (OpenAI compatible) or `localhost:11434/api/generation` (Ollama native API).\r\n\r\n**To Reproduce**\r\n\r\nSet OLLAMA_MODEL to a local model in `.env` and `\"modelProvider\": \"ollama\"` in the character file.\r\n\r\n**Expected behavior**\r\n\r\nGet a response instead of AI_APICallError",
            "labels": [
              {
                "name": "bug",
                "color": "d73a4a",
                "description": "Something isn't working"
              }
            ],
            "comments": [
              {
                "author": "djaramil",
                "body": "this is weird, i\u2019ve been using the ollama exclusively for a while now.  I know this part of the code and what you are suggesting is interesting about making it more compatible to the openai api. \r\n"
              },
              {
                "author": "deepfates",
                "body": "It works for you? What endpoint is it calling on the ollama server when it's successful?"
              }
            ]
          }
        ]
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "0xMxxx",
    "score": 0,
    "summary": "Over the past 90 days, 0xMxxx has focused primarily on addressing a specific issue related to an error encountered when running `pnpm start - Promise.withResolvers()` involving the `pdfjs-dist` library. Their work in this period has been concentrated on bug resolution without contributing any pull requests or commits to other areas of the project.",
    "avatar_url": "https://avatars.githubusercontent.com/u/49716006?u=c41333a0e8bfb6469f501287df94ae19a96fb460&v=4",
    "activity": {
      "code": {
        "total_commits": 0,
        "total_prs": 0,
        "commits": [],
        "pull_requests": []
      },
      "issues": {
        "total_opened": 1,
        "opened": [
          {
            "number": 902,
            "title": "Error pnpm start - Promise.withResolvers(): pdfjs-dist",
            "state": "CLOSED",
            "created_at": "2024-12-07T15:46:47Z",
            "updated_at": "2024-12-08T15:33:33Z",
            "body": "**Describe the bug**\r\n\r\nDoing all steps for the quick start, once pnpm start comes you get this error:\r\n\r\nTypeError: Cannot read properties of undefined (reading 'start')\r\n    at Object.start (file:///home/x/Desktop/x/eliza/packages/client-twitter/dist/index.js:563:35)\r\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\r\n    at async initializeClients (file:///home/x/Desktop/x/eliza/agent/src/index.ts:216:32)\r\n    at async startAgent (file:///home/x/Desktop/x/eliza/agent/src/index.ts:306:25)\r\n    at async startAgents (file:///home/x/Desktop/x/eliza/agent/src/index.ts:329:13)\r\n\r\n**To Reproduce**\r\n\r\nDoing all steps for the quick start, once pnpm start comes you get this error\r\n\r\n**Additional context**\r\n\r\nUsing Bedian 12 - Tested on Windows Server and MacOs, all same error.\r\nClean download/ git clone and pretty straight forward error/bug.\r\n\r\n\r\n------\r\nNEXT steps: to follow ->\r\nhttps://github.com/ai16z/eliza/issues/76\r\nhttps://github.com/wojtekmaj/react-pdf/issues/1811\r\n\r\nI'll come back to update.\r\n\r\n\r\n\r\n",
            "labels": [
              {
                "name": "bug",
                "color": "d73a4a",
                "description": "Something isn't working"
              }
            ],
            "comments": [
              {
                "author": "0xMxxx",
                "body": "tbh just redownloaded the project in a Debian 12, pnpm i - pnpm build and worked.\r\njust randomly."
              }
            ]
          }
        ]
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "arose0",
    "score": 0,
    "summary": "Arose0 is actively contributing to the zksync era by adding a transfer function, as evidenced by their recent commit activity. With 336 lines of code added and no issues or pull requests opened or merged within the last 90 days, arose0's focus remains on enhancing this specific feature.",
    "avatar_url": null,
    "activity": {
      "code": {
        "total_commits": 1,
        "total_prs": 0,
        "commits": [
          {
            "sha": "d2c8374f0655010d5f8e5120c67a3b49ab857f39",
            "message": "adding transfer function for zksync era",
            "created_at": "2024-12-07T19:52:53Z",
            "additions": 336,
            "deletions": 0,
            "changed_files": 9
          }
        ],
        "pull_requests": []
      },
      "issues": {
        "total_opened": 0,
        "opened": []
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "Travellereleven",
    "score": 0,
    "summary": "Travellereleven is currently addressing an issue related to posting tweets using Eliza integration with Twitter, specifically encountering difficulties with cookies or OAuth2 authentication methods. Over the past 90 days, their focus has been on resolving this single reported problem without any new pull requests, commits, or code changes made in other areas of work.",
    "avatar_url": "https://avatars.githubusercontent.com/u/538822?u=0a857e3e5648922a80254d2a5c16ebeee38b8e01&v=4",
    "activity": {
      "code": {
        "total_commits": 0,
        "total_prs": 0,
        "commits": [],
        "pull_requests": []
      },
      "issues": {
        "total_opened": 1,
        "opened": [
          {
            "number": 901,
            "title": "Issue: Unable to Post Tweets Using Eliza Integration with Twitter via Cookies or OAuth2",
            "state": "CLOSED",
            "created_at": "2024-12-07T15:39:33Z",
            "updated_at": "2024-12-08T17:50:47Z",
            "body": "Hey Guys! \r\n\r\nWe are attempting to enable the Eliza AI bot to post tweets using the agent-twitter-client setup as described in the Eliza documentation. We have the bot running smoothly via Telegram and the character are starting to behave exactly as wanted. Next step is Twitter/X posts. \r\n\r\nDespite following the documented process and adapting various approaches, we encountered multiple challenges, including issues with cookies-based authentication and OAuth2 flow.\r\n\r\nSteps Taken:\r\n\r\nCookies Authentication:\r\n\r\nExtracted cookies (auth_token, ct0, guest_id) directly from a valid, logged-in Twitter session.\r\nParsed cookies into the required format and supplied them to the scraper.\r\nEncountered Session is invalid. Login required. after setting the cookies.\r\nRetried using different extracted cookies after logging out and back into the account but received suspicious login alerts from Twitter.\r\n\r\nOAuth2 Authentication (User Context):\r\nConfigured the TWITTER_CLIENT_ID, TWITTER_CLIENT_SECRET, and TWITTER_REDIRECT_URL in .env file.\r\n\r\nGenerated the authorization URL and successfully obtained an authorization code after approving the app.\r\n\r\nExchanged the authorization code for an access token. This step initially failed due to redirect URI mismatch but was resolved after fixing .env and redirect configurations.\r\n\r\nSuccessfully retrieved an access token but encountered a 403 Forbidden error when attempting to post a tweet using the provided access token.\r\n\r\nOther Efforts:\r\nTested multiple approaches to ensure the server was running properly (ngrok tunnel, express server for callback handling).\r\n\r\nUsed the provided Eliza example retry mechanisms, cookies validation steps, and OAuth2 flows, but no approach successfully enabled the bot to interact with Twitter.\r\n\r\nTechnical Environment:\r\n\r\nEliza Package Version: 0.1.4-alpha.3\r\nNode.js Version: v23.0.0\r\nTwitter API Version: v2\r\nPlan: Free tier with 100 monthly interactions allowed.\r\nErrors Encountered:\r\n\r\nCookies Authentication Error: Session is invalid. Login required.\r\nOAuth2 Access Token Exchange Error: \"Value passed for the redirect uri did not match the uri of the authorization code.\"\r\nOAuth2 Post Tweet Error:\r\n{\r\n  \"title\": \"Forbidden\",\r\n  \"type\": \"about:blank\",\r\n  \"status\": 403,\r\n  \"detail\": \"Forbidden\"\r\n}\r\n\r\nWhat We\u2019ve Tried:\r\n\r\nFollowed the Eliza documentation for both cookies-based login and OAuth2 authentication.\r\nValidated cookies format, paths, and domains. Adjusted callback URLs to match the redirect URI.\r\nEnsured correct scopes (tweet.read, tweet.write, offline.access) were included in the authorization URL. Searched for solutions in related GitHub issues and documentation but could not resolve these issues.\r\n\r\nQuestions:\r\n\r\nCookies-based login: Is there an additional step needed to validate or reuse cookies without triggering suspicious login alerts?\r\n\r\nOAuth2 Post Tweet Forbidden: Are there any known limitations or configurations for the free tier that could block posting tweets, even after successfully obtaining an access token?\r\n\r\nDocumentation Alignment: Are there updated instructions or examples specific to the latest Twitter API v2 and free-tier limitations that might clarify the proper setup?\r\n\r\nAdditional Notes:\r\n\r\nThe primary goal is to enable the Eliza bot to post tweets under the speedcto account using either method (cookies or OAuth2).\r\n\r\nThe free-tier plan should suffice for our initial testing (17 tweets/day, 100 interactions/month).\r\nAny guidance or updates on how to resolve these issues would be highly appreciated!",
            "labels": [],
            "comments": []
          }
        ]
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "hugoroussel",
    "score": 0,
    "summary": "Hugorioussel is currently working on enhancing GitHub's support for Perplexity Sonar models, as evidenced by their recent activity involving the creation of one issue related to this topic. However, there have been no pull requests or commits made in connection with this work during the last 90 days.",
    "avatar_url": "https://avatars.githubusercontent.com/u/14925639?u=bdd55636aa33dd75ac52eb61a0387eaf46246fe5&v=4",
    "activity": {
      "code": {
        "total_commits": 0,
        "total_prs": 0,
        "commits": [],
        "pull_requests": []
      },
      "issues": {
        "total_opened": 1,
        "opened": [
          {
            "number": 900,
            "title": "Support for Perplexity Sonar models",
            "state": "OPEN",
            "created_at": "2024-12-07T15:03:17Z",
            "updated_at": "2024-12-07T15:13:34Z",
            "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nI want my agent to have access to the latest news etc!\r\n\r\n**Describe the solution you'd like**\r\n\r\nThere is already support for openrouter but only `nousresearch/hermes-3-llama-3.1-405b`. Adding `perplexity/llama-3.1-sonar-small-128k-chat` (sonar family of models)\r\n\r\n**Describe alternatives you've considered**\r\n\r\nAdding a custom action performing web search but worse latency\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n",
            "labels": [
              {
                "name": "enhancement",
                "color": "a2eeef",
                "description": "New feature or request"
              }
            ],
            "comments": []
          }
        ]
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  },
  {
    "contributor": "minichris",
    "score": 0,
    "summary": "minichris is currently addressing a critical issue related to the initialization failure of the ONNX Runtime API, as evidenced by their recent activity on GitHub. With one reported bug under investigation, they have not yet contributed any pull requests or code changes in this area over the past 90 days.",
    "avatar_url": "https://avatars.githubusercontent.com/u/7912522?u=18e3cca125a84db92cb62cb681be344114b9dbf0&v=4",
    "activity": {
      "code": {
        "total_commits": 0,
        "total_prs": 0,
        "commits": [],
        "pull_requests": []
      },
      "issues": {
        "total_opened": 1,
        "opened": [
          {
            "number": 881,
            "title": "Failed to initialize ONNX Runtime API",
            "state": "OPEN",
            "created_at": "2024-12-07T01:41:37Z",
            "updated_at": "2024-12-07T01:42:17Z",
            "body": "**Describe the bug**\r\n\r\nWhen launching with `pnpm --dir core start \"--character=characters/trump.character.json\"` I get \r\n```\r\n(node:16908) ExperimentalWarning: `--experimental-loader` may be removed in the future; instead use `register()`:\r\n--import 'data:text/javascript,import { register } from \"node:module\"; import { pathToFileURL } from \"node:url\"; register(\"ts-node/esm\", pathToFileURL(\"./\"));'\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n(node:16908) [DEP0180] DeprecationWarning: fs.Stats constructor is deprecated.\r\n(Use `node --trace-deprecation ...` to show where the warning was created)\r\nThe requested API version [20] is not available, only API versions [1, 19] are supported in this build. Current ORT Version is: 1.19.2\r\nnode:internal/modules/cjs/loader:1724\r\n  return process.dlopen(module, path.toNamespacedPath(filename));\r\n                 ^\r\n\r\nError: Failed to initialize ONNX Runtime API. It could happen when this nodejs binding was built with a higher version ONNX Runtime but now runs with a lower version ONNX Runtime DLL(or shared library).\r\n    at Object..node (node:internal/modules/cjs/loader:1724:18)\r\n    at Module.load (node:internal/modules/cjs/loader:1303:32)\r\n    at Function._load (node:internal/modules/cjs/loader:1117:12)\r\n    at TracingChannel.traceSync (node:diagnostics_channel:322:14)\r\n    at wrapModuleLoad (node:internal/modules/cjs/loader:218:24)\r\n    at Module.require (node:internal/modules/cjs/loader:1325:12)\r\n    at require (node:internal/modules/helpers:136:16)\r\n    at Object.<anonymous> (J:\\Eliza\\eliza\\core\\node_modules\\onnxruntime-node\\dist\\binding.js:9:1)\r\n    at Module._compile (node:internal/modules/cjs/loader:1546:14)\r\n    at Object..js (node:internal/modules/cjs/loader:1698:10)\r\n```\r\n\r\n\r\n**To Reproduce**\r\n\r\nInstall following the quickstart guide on Windows 10 Education Edition, using node 23.3.0\r\n\r\n**Expected behavior**\r\n\r\nI don't get this error.\r\n",
            "labels": [
              {
                "name": "bug",
                "color": "d73a4a",
                "description": "Something isn't working"
              }
            ],
            "comments": []
          }
        ]
      },
      "engagement": {
        "total_comments": 0,
        "total_reviews": 0,
        "comments": [],
        "reviews": []
      }
    }
  }
]