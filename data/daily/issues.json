[
  {
    "id": "I_kwDOMT5cIs6lDDCp",
    "number": 1841,
    "title": "elizaos/plugin-ferepro missing source and failing build",
    "body": "```\r\n@elizaos/plugin-ferepro:build:\r\n@elizaos/plugin-ferepro:build: > @elizaos/plugin-ferepro@0.1.7-alpha.2 build /mnt/data1/nix/time/2024/12/31/cloud-depl\\\r\noyment-eliza/packages/plugin-ferePro\r\n@elizaos/plugin-ferepro:build: > tsup --format esm --dts\r\n@elizaos/plugin-ferepro:build:\r\n@elizaos/core:build:\r\n@elizaos/core:build: > @elizaos/core@0.1.7 build /mnt/data1/nix/time/2024/12/31/cloud-deployment-eliza/packages/core\r\n@elizaos/core:build: > tsup --format esm --dts\r\n@elizaos/core:build:\r\ncreate-eliza-app:build:\r\ncreate-eliza-app:build: > create-eliza-app@0.1.7-alpha.2 build /mnt/data1/nix/time/2024/12/31/cloud-deployment-eliza/p\\\r\nackages/create-eliza-app\r\ncreate-eliza-app:build: > unbuild\r\ncreate-eliza-app:build:\r\n@elizaos/plugin-ferepro:build: No input files, try \"tsup <your-file>\" instead\r\n@elizaos/plugin-ferepro:build: â€‰ELIFECYCLEâ€‰ Command failed with exit code 1.```",
    "state": "OPEN",
    "createdAt": "2025-01-04T23:32:19Z",
    "updatedAt": "2025-01-04T23:32:19Z",
    "author": {
      "login": "jmikedupont2",
      "avatarUrl": "https://avatars.githubusercontent.com/u/16427113?u=2bdad12714de646188f98a07736a54f765ad5e3b&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lDAXW",
    "number": 1838,
    "title": "Broken FAQ link in Contributing.MD",
    "body": "**Describe the bug**\r\n\r\nThe FAQ link in CONTRIBUTING.md returns a 404.\r\n\r\nhttps://github.com/elizaOS/eliza/blob/main/CONTRIBUTING.md?plain=1#L82 \r\n\r\n**To Reproduce**\r\n\r\n- Head to [CONTRIBUTING.md](https://github.com/elizaOS/eliza/blob/main/CONTRIBUTING.md#getting-help) and click the FAQ link\r\n- Retuens a 404 - as it is pointing at docs/community/faq.md which doesn't exist\r\n\r\n**Expected behavior**\r\n\r\nShould link through to [docs/docs/faq.md](https://github.com/elizaOS/eliza/blob/main/docs/docs/faq.md)\r\n\r\nor maybe [docs/community/faq-and-support.md](https://github.com/elizaOS/eliza/blob/main/docs/community/faq-and-support.md)",
    "state": "OPEN",
    "createdAt": "2025-01-04T22:45:25Z",
    "updatedAt": "2025-01-04T22:45:49Z",
    "author": {
      "login": "MacsDickinson",
      "avatarUrl": "https://avatars.githubusercontent.com/u/1135182?u=008184fd676416abe45a7f0eaa52a88e17da1a7e&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZROwZ",
        "author": "github-actions",
        "body": "Hello @MacsDickinson! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6lC-Gs",
    "number": 1833,
    "title": "TWITTER_TARGET_USERS",
    "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\n1. Setting a list of TWITTER_TARGET_USERS doesn't seem to have the ai agenet interact with them. \r\nI was expecting these users to be mentioned, RTd, etc\r\n\r\n2. Does setting TWITTER_TARGET_USERS make the AI agent ignore other user's mentions / replies?\r\n\r\n**Describe the solution you'd like**\r\n\r\n1. The users in the list should be the users that the ai agent focuses on, retweets, replies to.\r\n\r\n2. Should still be able to interact with any and all users even if not on the list.",
    "state": "OPEN",
    "createdAt": "2025-01-04T22:07:16Z",
    "updatedAt": "2025-01-04T22:07:26Z",
    "author": {
      "login": "y4my4my4m",
      "avatarUrl": "https://avatars.githubusercontent.com/u/8145020?u=e3e02ca2d12f2c6659e77b57ce7e5834a1b1824c&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lCkls",
    "number": 1819,
    "title": "it fails to run multiple character if the credentials of previous character is incorrect.",
    "body": "**Describe the bug**\r\n\r\nwhen given more than one ..character.json in characters folder and running it manually using command : \r\npnpm run dev --character=\"characters/c1.character.json,characters/c2.character.json\"\r\n\r\nlets say the x credentials of c1 is incorrect then it will try to login multiple time c1 and then stop will never to c2.\r\n\r\n**To Reproduce**\r\n\r\nput multiple character.json in characters.json and then run : \r\npnpm run dev --character=\"characters/c1.character.json,characters/c2.character.json\"\r\n\r\n**Expected behavior**\r\n\r\ntry to login c1 given number of time if failed move on to next character and so on\r\n\r\n**Screenshots**\r\n<img width=\"1394\" alt=\"Screenshot 2025-01-04 at 10 02 13â€¯PM\" src=\"https://github.com/user-attachments/assets/def7f183-7d93-4b6b-960e-2e9303ea3008\" />\r\n\r\n\r\n\r\n**Additional context**\r\n\r\n<!-- Add any other context about the problem here. -->\r\n",
    "state": "OPEN",
    "createdAt": "2025-01-04T16:32:29Z",
    "updatedAt": "2025-01-04T16:32:29Z",
    "author": {
      "login": "prince981620",
      "avatarUrl": "https://avatars.githubusercontent.com/u/69517192?u=822d70dc319316cc7e6ce8a3fce3d4326df697fe&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lCWbs",
    "number": 1814,
    "title": "Followed starter, not working ",
    "body": "**Describe the bug**\r\n\r\nI am following the starter as described [here](https://github.com/elizaos/eliza/tree/main?tab=readme-ov-file#use-the-starter-recommended). On executing `pnpm i && pnpm build && pnpm start`, I get the following error:\r\n\r\n```\r\nDownloading tiktoken@1.0.17: 10.60 MB/10.60 MB, done\r\nPackages are hard linked from the content-addressable store to the virtual store.\r\n  Content-addressable store is at: /workspaces/.pnpm-store/v3\r\n  Virtual store is at:             node_modules/.pnpm\r\nDownloading kuromoji@0.1.2: 21.83 MB/21.83 MB, done\r\nDownloading pdfjs-dist@4.7.76: 10.21 MB/10.21 MB, done\r\nDownloading espeak-ng@1.0.2: 9.19 MB/9.19 MB, done\r\nDownloading jieba-wasm@2.2.0: 10.91 MB/10.91 MB, done\r\nDownloading node-llama-cpp@3.1.1: 18.16 MB/18.16 MB, done\r\nDownloading @huggingface/transformers@3.0.1: 8.77 MB/8.77 MB, done\r\nDownloading @echogarden/espeak-ng-emscripten@0.3.0: 12.53 MB/12.53 MB, done\r\nDownloading onnxruntime-node@1.20.0: 70.00 MB/70.00 MB, done\r\nDownloading sql.js@1.12.0: 7.83 MB/7.83 MB, done\r\nDownloading @img/sharp-libvips-linux-x64@1.0.4: 7.06 MB/7.06 MB, done\r\nDownloading @echogarden/espeak-ng-emscripten@0.3.3: 12.53 MB/12.53 MB, done\r\nDownloading tiktoken@1.0.18: 10.61 MB/10.61 MB, done\r\nDownloading @echogarden/flite-wasi@0.1.1: 14.52 MB/14.52 MB, done\r\nDownloading onnxruntime-web@1.21.0-dev.20241024-d9ca84ef96: 20.46 MB/20.46 MB, done\r\nDownloading @node-llama-cpp/linux-x64-cuda@3.1.1: 150.48 MB/150.48 MB, done\r\nDownloading js-tiktoken@1.0.16: 10.24 MB/10.24 MB, done\r\nDownloading @img/sharp-libvips-linuxmusl-x64@1.0.4: 7.20 MB/7.20 MB, done\r\nâ€‰WARNâ€‰ 19 deprecated subdependencies found: @cliqz/adblocker-content@1.34.0, @cliqz/adblocker-extended-selectors@1.34.0, @cliqz/adblocker-playwright@1.34.0, @cliqz/adblocker@1.34.0, @discordjs/voice@0.17.0, are-we-there-yet@2.0.0, are-we-there-yet@3.0.1, bin-version-check@6.0.0, gauge@3.0.2, gauge@4.0.4, glob@7.2.3, har-validator@5.1.5, inflight@1.0.6, npmlog@5.0.1, npmlog@6.0.2, puppeteer@19.11.1, request@2.88.2, rimraf@3.0.2, uuid@3.4.0\r\nPackages: +1340\r\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\r\nProgress: resolved 1436, reused 0, downloaded 1341, added 1340, done\r\nnode_modules/.pnpm/ffmpeg-static@5.2.0/node_modules/ffmpeg-static: Running install script...\r\nnode_modules/.pnpm/ffmpeg-static@5.2.0/node_modules/ffmpeg-static: Running install script, done in 2s\r\nnode_modules/.pnpm/canvas@2.11.2/node_modules/canvas: Running install script, failed in 2.3s (skipped as optional)\r\nnode_modules/.pnpm/utf-8-validate@5.0.10/node_modules/utf-8-validate: Running install script, done in 164ms\r\nnode_modules/.pnpm/bufferutil@4.0.8/node_modules/bufferutil: Running install script, done in 134ms\r\nnode_modules/.pnpm/better-sqlite3@11.5.0/node_modules/better-sqlite3: Running install script, done in 723ms\r\nnode_modules/.pnpm/onnxruntime-node@1.20.0/node_modules/onnxruntime-node: Running postinstall script...\r\nnode_modules/.pnpm/onnxruntime-node@1.20.0/node_modules/onnxruntime-node: Running postinstall script, done in 4.5s\r\nnode_modules/.pnpm/wtf_wikipedia@10.3.2/node_modules/wtf_wikipedia: Running postinstall script, done in 127ms\r\nnode_modules/.pnpm/node-llama-cpp@3.1.1_typescript@5.6.3/node_modules/node-llama-cpp: Running postinstall script...\r\nnode_modules/.pnpm/es5-ext@0.10.64/node_modules/es5-ext: Running postinstall script, done in 74ms\r\nnode_modules/.pnpm/protobufjs@7.4.0/node_modules/protobufjs: Running postinstall script, done in 57ms\r\nnode_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7d5f9fb02/node_modules/@discordjs/opus: Runninode_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7d5f9fb02/node_modules/@discordjs/opus: Running install script, failed in 45.4s.1.5/node_modules/bigint-buffer: Running install script, done in 941ms\r\n.../node_modules/@discordjs/opus install$ node-pre-gyp install --fallback-to-build\r\nâ”‚ node-pre-gyp info it worked if it ends with ok\r\nâ”‚ node-pre-gyp info using node-pre-gyp@0.4.5\r\nâ”‚ node-pre-gyp info using node@23.3.0 | linux | x64\r\nâ”‚ (node:13465) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\r\nâ”‚ (Use `node --trace-deprecation ...` to show where the warning was created)\r\nâ”‚ node-pre-gyp info check checked for \"/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8â€¦\r\nâ”‚ node-pre-gyp http GET https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-linux-x64-glibc-2.31.tar.gz\r\nâ”‚ node-pre-gyp ERR! install response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-linux-x6â€¦\r\nâ”‚ node-pre-gyp WARN Pre-built binaries not installable for @discordjs/opus@0.9.0 and node@23.3.0 (node-v131 ABI, glibc) (falling back to source compile with nâ€¦\r\nâ”‚ node-pre-gyp WARN Hit error response status 404 Not Found on https://github.com/discordjs/opus/releases/download/v0.9.0/opus-v0.9.0-node-v131-napi-v3-linux-â€¦\r\nâ”‚ gyp info it worked if it ends with ok\r\nâ”‚ gyp info using node-gyp@10.2.0\r\nâ”‚ gyp info using node@23.3.0 | linux | x64\r\nâ”‚ gyp info ok \r\nâ”‚ gyp info it worked if it ends with ok\r\nâ”‚ gyp info using node-gyp@10.2.0\r\nâ”‚ gyp info using node@23.3.0 | linux | x64\r\nâ”‚ gyp info find Python using Python version 3.12.1 found at \"/home/codespace/.python/current/bin/python3\"\r\nâ”‚ (node:13494) ExperimentalWarning: CommonJS module /usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/debug/src/node.js is loading â€¦\r\nâ”‚ Support for loading ES Module in require() is an experimental feature and might change at any time\r\nâ”‚ (Use `node --trace-warnings ...` to show where the warning was created)\r\nâ”‚ gyp info spawn /home/codespace/.python/current/bin/python3\r\nâ”‚ gyp info spawn args [\r\nâ”‚ gyp info spawn args '/usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gyp/gyp/gyp_main.py',\r\nâ”‚ gyp info spawn args 'binding.gyp',\r\nâ”‚ gyp info spawn args '-f',\r\nâ”‚ gyp info spawn args 'make',\r\nâ”‚ gyp info spawn args '-I',\r\nâ”‚ gyp info spawn args '/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd3â€¦\r\nâ”‚ gyp info spawn args '-I',\r\nâ”‚ gyp info spawn args '/usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gyp/addon.gypi',\r\nâ”‚ gyp info spawn args '-I',\r\nâ”‚ gyp info spawn args '/home/codespace/.cache/node-gyp/23.3.0/include/node/common.gypi',\r\nâ”‚ gyp info spawn args '-Dlibrary=shared_library',\r\nâ”‚ gyp info spawn args '-Dvisibility=default',\r\nâ”‚ gyp info spawn args '-Dnode_root_dir=/home/codespace/.cache/node-gyp/23.3.0',\r\nâ”‚ gyp info spawn args '-Dnode_gyp_dir=/usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gyp',\r\nâ”‚ gyp info spawn args '-Dnode_lib_file=/home/codespace/.cache/node-gyp/23.3.0/<(target_arch)/node.lib',\r\nâ”‚ gyp info spawn args '-Dmodule_root_dir=/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49â€¦\r\nâ”‚ gyp info spawn args '-Dnode_engine=v8',\r\nâ”‚ gyp info spawn args '--depth=.',\r\nâ”‚ gyp info spawn args '--no-parallel',\r\nâ”‚ gyp info spawn args '--generator-output',\r\nâ”‚ gyp info spawn args 'build',\r\nâ”‚ gyp info spawn args '-Goutput_dir=.'\r\nâ”‚ gyp info spawn args ]\r\nâ”‚ <string>:43: SyntaxWarning: invalid escape sequence '\\$'\r\nâ”‚ gyp info ok \r\nâ”‚ gyp info it worked if it ends with ok\r\nâ”‚ gyp info using node-gyp@10.2.0\r\nâ”‚ gyp info using node@23.3.0 | linux | x64\r\nâ”‚ gyp info spawn make\r\nâ”‚ gyp info spawn args [ 'BUILDTYPE=Release', '-C', 'build' ]\r\nâ”‚ make: Entering directory '/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2abâ€¦\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/src/opus_multistream.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/src/opus_projection_encoder.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/src/analysis.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/src/mlp_data.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/src/opus_multistream_encoder.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/src/opus_projection_decoder.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/src/mapping_matrix.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/src/opus_compare.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/src/mlp.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/src/opus.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/src/opus_multistream_decoder.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/src/opus_decoder.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/src/repacketizer.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/src/opus_encoder.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_frame.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/inner_product_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/scale_vector_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/find_pred_coefs_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/schur_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/warped_autocorrelation_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/burg_modified_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/find_LPC_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/LPC_inv_pred_gain_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/scale_copy_vector_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/noise_shape_analysis_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/pitch_analysis_core_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/bwexpander_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/LTP_analysis_filter_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/LTP_scale_ctrl_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/corrMatrix_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/encode_frame_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/sort_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/find_pitch_lags_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/residual_energy_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/LPC_analysis_filter_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/autocorrelation_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/k2a_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/regularize_correlations_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/find_LTP_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/energy_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/apply_sine_window_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/wrappers_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/float/process_gains_FLP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_quant_pred.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/LPC_inv_pred_gain.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/process_NLSFs.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/NSQ.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/check_control_input.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_del_dec_quant.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/LPC_analysis_filter.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/dec_API.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/sort.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/VAD.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_private_AR2.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/LPC_fit.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/control_SNR.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_parameters.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/pitch_est_tables.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/warped_autocorrelation_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/apply_sine_window_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/residual_energy16_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/schur64_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/residual_energy_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/noise_shape_analysis_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/encode_frame_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/schur_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/autocorr_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/burg_modified_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/pitch_analysis_core_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/find_LTP_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/find_LPC_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/corrMatrix_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/k2a_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/LTP_scale_ctrl_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/process_gains_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/k2a_Q16_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/regularize_correlations_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/LTP_analysis_filter_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/vector_ops_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/find_pitch_lags_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/fixed/find_pred_coefs_FIX.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/control_audio_bandwidth.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/decoder_set_fs.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_unpack.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/bwexpander.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_rom.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/shell_coder.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_pulses.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/bwexpander_32.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_core.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/PLC.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_NLSF_CB_WB.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/table_LSF_cos.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_pulses_per_block.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_gain.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/inner_prod_aligned.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_down2_3.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/NSQ_del_dec.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_pitch.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_VQ_weights_laroia.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/interpolate.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/debug.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_other.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/LP_variable_cutoff.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_decode.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/encode_pulses.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/control_codec.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_LR_to_MS.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/HP_variable_cutoff.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/encode_indices.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/init_decoder.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_encode_pred.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_VQ.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/init_encoder.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_private_IIR_FIR.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_private_up2_HQ.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/sigm_Q15.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/sum_sqr_shift.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_LTP.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_down2.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/code_signs.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_NLSF_CB_NB_MB.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/gain_quant.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/tables_pitch_lag.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_stabilize.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_find_predictor.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/A2NLSF.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF2A.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/VQ_WMat_EC.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/NLSF_encode.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/log2lin.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_decode_pred.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/lin2log.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/CNG.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/enc_API.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/biquad_alt.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/quant_LTP_gains.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/resampler_private_down_FIR.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/ana_filt_bank_1.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/stereo_MS_to_LR.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/silk/decode_indices.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/rate.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/entdec.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/modes.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/celt_lpc.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/laplace.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/cwrs.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/celt.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/entcode.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/celt_decoder.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/celt_encoder.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/mdct.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/quant_bands.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/vq.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/bands.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/kiss_fft.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/entenc.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/mathops.o\r\nâ”‚   CC(target) Release/obj.target/libopus/deps/opus/celt/pitch.o\r\nâ”‚ rm -f Release/obj.target/deps/opus.a Release/obj.target/deps/opus.a.ar-file-list; mkdir -p `dirname Release/obj.target/deps/opus.a`\r\nâ”‚ ar crs Release/obj.target/deps/opus.a @Release/obj.target/deps/opus.a.ar-file-list\r\nâ”‚   COPY Release/opus.a\r\nâ”‚   CXX(target) Release/obj.target/opus/src/node-opus.o\r\nâ”‚ g++: error: unrecognized command line option â€˜-std=gnu++20â€™; did you mean â€˜-std=gnu++2aâ€™?\r\nâ”‚ make: *** [opus.target.mk:157: Release/obj.target/opus/src/node-opus.o] Error 1\r\nâ”‚ make: Leaving directory '/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1â€¦\r\nâ”‚ gyp ERR! build error \r\nâ”‚ gyp ERR! stack Error: `make` failed with exit code: 2\r\nâ”‚ gyp ERR! stack at ChildProcess.<anonymous> (/usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gyp/lib/build.js:216:23)\r\nâ”‚ gyp ERR! System Linux 6.5.0-1025-azure\r\nâ”‚ gyp ERR! command \"/usr/local/share/nvm/versions/node/v23.3.0/bin/node\" \"/usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gyâ€¦\r\nâ”‚ gyp ERR! cwd /workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7â€¦\r\nâ”‚ gyp ERR! node -v v23.3.0\r\nâ”‚ gyp ERR! node-gyp -v v10.2.0\r\nâ”‚ gyp ERR! not ok \r\nâ”‚ node-pre-gyp ERR! build error \r\nâ”‚ node-pre-gyp ERR! stack Error: Failed to execute '/usr/local/share/nvm/versions/node/v23.3.0/bin/node /usr/local/share/nvm/versions/node/v23.3.0/lib/node_moâ€¦\r\nâ”‚ node-pre-gyp ERR! stack     at ChildProcess.<anonymous> (/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+node-pre-gyp@0.4.5/node_modules/@discordjs/â€¦\r\nâ”‚ node-pre-gyp ERR! stack     at ChildProcess.emit (node:events:513:28)\r\nâ”‚ node-pre-gyp ERR! stack     at maybeClose (node:internal/child_process:1101:16)\r\nâ”‚ node-pre-gyp ERR! stack     at ChildProcess._handle.onexit (node:internal/child_process:305:5)\r\nâ”‚ node-pre-gyp ERR! System Linux 6.5.0-1025-azure\r\nâ”‚ node-pre-gyp ERR! command \"/usr/local/share/nvm/versions/node/v23.3.0/bin/node\" \"/workspaces/eliza-starter/node_modules/.pnpm/@discordjs+node-pre-gyp@0.4.5/â€¦\r\nâ”‚ node-pre-gyp ERR! cwd /workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfdâ€¦\r\nâ”‚ node-pre-gyp ERR! node -v v23.3.0\r\nâ”‚ node-pre-gyp ERR! node-pre-gyp -v v0.4.5\r\nâ”‚ node-pre-gyp ERR! not ok \r\nâ”‚ Failed to execute '/usr/local/share/nvm/versions/node/v23.3.0/bin/node /usr/local/share/nvm/versions/node/v23.3.0/lib/node_modules/npm/node_modules/node-gypâ€¦\r\nâ””â”€ Failed in 45.4s at /workspaces/eliza-starter/node_modules/.pnpm/@discordjs+opus@https+++codeload.github.com+discordjs+opus+tar.gz+31da49d8d2cc6c5a2ab1bfd332033ff7d5f9fb02/node_modules/@discordjs/opus\r\nnode_modules/.pnpm/bigint-buffer@1.1.5/node_modules/bigint-buffer: Running install script, done in 941ms\r\nnode_modules/.pnpm/esbuild@0.21.5/node_modules/esbuild: Running postinstall script, done in 85ms\r\nâ€‰ELIFECYCLEâ€‰ Command failed with exit code 1. \r\n\r\n```\r\n\r\nWill appreciate any help in debugging it.\r\n\r\n",
    "state": "CLOSED",
    "createdAt": "2025-01-04T14:00:14Z",
    "updatedAt": "2025-01-04T14:52:31Z",
    "author": {
      "login": "cryptogakusei",
      "avatarUrl": "https://avatars.githubusercontent.com/u/92956318?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZQx5u",
        "author": "github-actions",
        "body": "Hello @cryptogakusei! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ05y",
        "author": "cryptogakusei",
        "body": "seems like issue is not appearing after I did the whole process again"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6lCTOq",
    "number": 1813,
    "title": "Better X Agent configuration e.g. no retweets, likes etc",
    "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently I have an X agent however it is very spammy. Just replies and reacts to irrelevant content. I just want it to post a relatively frequently e.g. twice an hour\r\n\r\n**Describe the solution you'd like**\r\n\r\nIdeally, a configurable architecture where the X agent can be adjusted (e.g. through env vars or a config.json) along with a section of docs to specify where and how to use.\r\n\r\nat minimum, some docs addressing where in the source code to edit\r\n\r\n**Describe alternatives you've considered**\r\n\r\nAsked the discord (other people have same issue) + a highlevel dive into the src code\r\n\r\n",
    "state": "OPEN",
    "createdAt": "2025-01-04T13:28:34Z",
    "updatedAt": "2025-01-04T20:42:10Z",
    "author": {
      "login": "jaycoolslm",
      "avatarUrl": "https://avatars.githubusercontent.com/u/86686746?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZQve7",
        "author": "github-actions",
        "body": "Hello @jaycoolslm! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQw35",
        "author": "salacoste",
        "body": "found the same problem, interval did nothing in terms of timing.\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQxvQ",
        "author": "prince981620",
        "body": "same issue leading account to get flagged , rate limit and even banned.\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ1Tw",
        "author": "jaycoolslm",
        "body": "Okay, think I've found the issue.\r\n\r\nby default, the env var ENABLE_ACTION_PROCESSING=false\r\n\r\nthis gets rendered as a string which is truthy\r\n\r\ntherefore, this block of code in https://github.com/elizaOS/eliza/blob/main/packages/client-twitter/src/post.ts\r\n\r\n```\r\n        // Add check for ENABLE_ACTION_PROCESSING before starting the loop\r\n        const enableActionProcessing =\r\n            this.runtime.getSetting(\"ENABLE_ACTION_PROCESSING\") ?? false;\r\n\r\n        if (enableActionProcessing) {\r\n            processActionsLoop().catch((error) => {\r\n                elizaLogger.error(\r\n                    \"Fatal error in process actions loop:\",\r\n                    error\r\n                );\r\n            });\r\n        } else {\r\n            elizaLogger.log(\"Action processing loop disabled by configuration\");\r\n        }\r\n```\r\n\r\nactually runs the processActionsLoop by default.\r\n\r\nQuick solution is to delete false in the env var ie:\r\n\r\nENABLE_ACTION_PROCESSING= # empty value\r\n\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ1Xq",
        "author": "jaycoolslm",
        "body": "Better solution would be to have a src code which correctly parses the false string\r\n\r\nI can PR an implementation but it may not be consistent with other potential implementations that have been handled... so will hold off for now"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ10X",
        "author": "tcm390",
        "body": "> Okay, think I've found the issue.\r\n> \r\n> by default, the env var ENABLE_ACTION_PROCESSING=false\r\n> \r\n> this gets rendered as a string which is truthy\r\n> \r\n> therefore, this block of code in https://github.com/elizaOS/eliza/blob/main/packages/client-twitter/src/post.ts\r\n> \r\n> ```\r\n>         // Add check for ENABLE_ACTION_PROCESSING before starting the loop\r\n>         const enableActionProcessing =\r\n>             this.runtime.getSetting(\"ENABLE_ACTION_PROCESSING\") ?? false;\r\n> \r\n>         if (enableActionProcessing) {\r\n>             processActionsLoop().catch((error) => {\r\n>                 elizaLogger.error(\r\n>                     \"Fatal error in process actions loop:\",\r\n>                     error\r\n>                 );\r\n>             });\r\n>         } else {\r\n>             elizaLogger.log(\"Action processing loop disabled by configuration\");\r\n>         }\r\n> ```\r\n> \r\n> actually runs the processActionsLoop by default.\r\n> \r\n> Quick solution is to delete false in the env var ie:\r\n> \r\n> ENABLE_ACTION_PROCESSING= # empty value\r\n\r\nThanks for pointing this out! I'll take a closer look. Much appreciated. ðŸ™"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ2Z-",
        "author": "tcm390",
        "body": "@jaycoolslm hi I just checked the latest branch code, and it seems to work as expected. Maybe you could try upgrading to the latest version? Let me know if the issue persists!"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ4ee",
        "author": "y4my4my4m",
        "body": "@tcm390 the env does work as expected but it's not respecting the `ACTION_INTERVAL` at all. It just constantly does a tweet after tweet, mentioning, RT, non-stop."
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ4wW",
        "author": "jaycoolslm",
        "body": "> @jaycoolslm hi I just checked the latest branch code, and it seems to work as expected. Maybe you could try upgrading to the latest version? Let me know if the issue persists!\r\n\r\n\r\njust pulled and checked out to latest release branch. @elizaos/plugin-aptos#build is causing my build to fail unfortunately.\r\n\r\nWill try a fresh clone\r\n\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ5Lv",
        "author": "tcm390",
        "body": "> > @jaycoolslm hi I just checked the latest branch code, and it seems to work as expected. Maybe you could try upgrading to the latest version? Let me know if the issue persists!\r\n> \r\n> just pulled and checked out to latest release branch. @elizaos/plugin-aptos#build is causing my build to fail unfortunately.\r\n> \r\n> Will try a fresh clone\r\n\r\ntry this\r\n\r\n```\r\npnpm clean\r\n\r\npnpm install -r --no-frozen-lockfile\r\n```\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ5dD",
        "author": "tcm390",
        "body": "> @tcm390 the env does work as expected but it's not respecting the `ACTION_INTERVAL` at all. It just constantly does a tweet after tweet, mentioning, RT, non-stop.\r\n\r\nchecking"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ5lB",
        "author": "jaycoolslm",
        "body": "> > > @jaycoolslm hi I just checked the latest branch code, and it seems to work as expected. Maybe you could try upgrading to the latest version? Let me know if the issue persists!\r\n> > \r\n> > \r\n> > just pulled and checked out to latest release branch. @elizaos/plugin-aptos#build is causing my build to fail unfortunately.\r\n> > Will try a fresh clone\r\n> \r\n> try this\r\n> \r\n> ```\r\n> pnpm clean\r\n> \r\n> pnpm install -r --no-frozen-lockfile\r\n> ```\r\n\r\nSame thing. I've cloned a fresh repo and aptos still failing\r\n\r\ncan you try cloning from fresh and checking out to latest relase?"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ5nw",
        "author": "jaycoolslm",
        "body": "deleting `plugin-aptos` fixes it"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ6BM",
        "author": "jaycoolslm",
        "body": "@tcm390 latest release branch parses the env var correctly. Thanks for flagging it up"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ6dj",
        "author": "y4my4my4m",
        "body": "@jaycoolslm @tcm390 are you guys not having the issue that it's just constantly tweeting though? regardless of the `ACTION_INTERVAL` ?"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ76b",
        "author": "tcm390",
        "body": "> @tcm390 latest release branch parses the env var correctly. Thanks for flagging it up\r\n\r\nnp ðŸ˜Š"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ77A",
        "author": "tcm390",
        "body": "> @jaycoolslm @tcm390 are you guys not having the issue that it's just constantly tweeting though? regardless of the `ACTION_INTERVAL` ?\r\n\r\nI think itâ€™s waiting for the ACTION_INTERVAL, but there might be too many actions to process within a single interval. Maybe I need to make the number of actions per interval configurable."
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ8C7",
        "author": "y4my4my4m",
        "body": "@tcm390 right now all it's doing is just finding random account based on a topic (bitcoin for example), replying to it, retweeting something else, replying to someone else, etc. \r\nEvery 5~10 seconds (as fast as openai processes it i guess), forever, despite it being left at the default 5minutes\r\n\r\nI'm not sure if it's just an issue of the number of actions per interval...perhaps though, but it doesn't seem that way."
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ8Ku",
        "author": "tcm390",
        "body": "> @tcm390 right now all it's doing is just finding random account based on a topic (bitcoin for example), replying to it, retweeting something else, replying to someone else, etc. Every 5~10 seconds (as fast as openai processes it i guess), forever, despite it being left at the default 5minutes\r\n> \r\n> I'm not sure if it's just an issue of the number of actions per interval...perhaps though, but it doesn't seem that way.\r\n\r\nThanks for pointing this out! I'm taking a look. Thank you ðŸ™"
      },
      {
        "id": "IC_kwDOMT5cIs6ZQ8SG",
        "author": "y4my4my4m",
        "body": "@tcm390 im not sure if it makes a difference but i noticed that behaviour when i had no targetted users defined"
      },
      {
        "id": "IC_kwDOMT5cIs6ZRD9n",
        "author": "alwaysabetterway",
        "body": "I have the same issue, once `ENABLE_ACTION_PROCESSING` is enabled, it goes bananas retweeting and replying to everything from the timeline. \r\n\r\nI modified\r\n```\r\nconst homeTimeline = await this.client.fetchTimelineForActions(15); \r\n```\r\n\r\nto `1` and it still does the same\r\n\r\nI'm looking a bit closer, GPT found some issues but they were all irrelevant. \r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZREFe",
        "author": "alwaysabetterway",
        "body": "also I guess the fetchTimelineForActions is not respecting the `TWITTER_TARGET_USERS`"
      },
      {
        "id": "IC_kwDOMT5cIs6ZREy4",
        "author": "tcm390",
        "body": "> think itâ€™s waiting for the ACTION_INTERVAL, but there might be too many actions to process within a single interval. Maybe I need to make the number of actions per interval configurable.\r\n\r\nyes it's fetching your home timeline"
      },
      {
        "id": "IC_kwDOMT5cIs6ZRE17",
        "author": "tcm390",
        "body": "> I have the same issue, once `ENABLE_ACTION_PROCESSING` is enabled, it goes bananas retweeting and replying to everything from the timeline.\r\n> \r\n> I modified\r\n> \r\n> ```\r\n> const homeTimeline = await this.client.fetchTimelineForActions(15); \r\n> ```\r\n> \r\n> to `1` and it still does the same\r\n> \r\n> I'm looking a bit closer, GPT found some issues but they were all irrelevant.\r\n\r\nyes it's a bug I also just aware\r\n\r\nmade an issue: https://github.com/elizaOS/agent-twitter-client/issues/43"
      },
      {
        "id": "IC_kwDOMT5cIs6ZRGBc",
        "author": "tcm390",
        "body": "> I have the same issue, once `ENABLE_ACTION_PROCESSING` is enabled, it goes bananas retweeting and replying to everything from the timeline.\r\n> \r\n> I modified\r\n> \r\n> ```\r\n> const homeTimeline = await this.client.fetchTimelineForActions(15); \r\n> ```\r\n> \r\n> to `1` and it still does the same\r\n> \r\n> I'm looking a bit closer, GPT found some issues but they were all irrelevant.\r\n\r\n\r\nI'm considering something like this: https://github.com/elizaOS/eliza/pull/1824/files\r\n\r\nFetch the top timelines, randomly shuffle them, and within each interval, perform only the limited actions defined by the MAX_ACTIONS_PROCESSING environment variable. ðŸ¤” Hmm... I'm not sure if this is the best solution.\r\n\r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZRGmN",
        "author": "alwaysabetterway",
        "body": "\r\n\r\n\r\n\r\n\r\n> > I have the same issue, once `ENABLE_ACTION_PROCESSING` is enabled, it goes bananas retweeting and replying to everything from the timeline.\r\n> > I modified\r\n> > ```\r\n> > const homeTimeline = await this.client.fetchTimelineForActions(15); \r\n> > ```\r\n> > \r\n> > \r\n> >     \r\n> >       \r\n> >     \r\n> > \r\n> >       \r\n> >     \r\n> > \r\n> >     \r\n> >   \r\n> > to `1` and it still does the same\r\n> > I'm looking a bit closer, GPT found some issues but they were all irrelevant.\r\n> \r\n> I'm considering something like this: https://github.com/elizaOS/eliza/pull/1824/files\r\n> \r\n> Fetch the top timelines, randomly shuffle them, and within each interval, perform only the limited actions defined by the MAX_ACTIONS_PROCESSING environment variable. ðŸ¤” Hmm... I'm not sure if this is the best solution.\r\n\r\nThis is a good solution for now I think, it def creates more activity other than the defined usernames to follow which feels a bit more natural to me. "
      },
      {
        "id": "IC_kwDOMT5cIs6ZRHAG",
        "author": "alwaysabetterway",
        "body": "> > I have the same issue, once `ENABLE_ACTION_PROCESSING` is enabled, it goes bananas retweeting and replying to everything from the timeline.\r\n> > I modified\r\n> > ```\r\n> > const homeTimeline = await this.client.fetchTimelineForActions(15); \r\n> > ```\r\n> > \r\n> > \r\n> >     \r\n> >       \r\n> >     \r\n> > \r\n> >       \r\n> >     \r\n> > \r\n> >     \r\n> >   \r\n> > to `1` and it still does the same\r\n> > I'm looking a bit closer, GPT found some issues but they were all irrelevant.\r\n> \r\n> I'm considering something like this: https://github.com/elizaOS/eliza/pull/1824/files\r\n> \r\n> Fetch the top timelines, randomly shuffle them, and within each interval, perform only the limited actions defined by the MAX_ACTIONS_PROCESSING environment variable. ðŸ¤” Hmm... I'm not sure if this is the best solution.\r\n\r\nI guess it's also important to note that ACTION_INTERVAL is now in minutes and not miliseconds in your changes right? \r\n\r\n\r\nI'm testing it now, so far it's not going crazy posting, I'll leave it running over night with moderate settings. \r\n\r\n\r\n\r\nso far no issues ðŸ‘ \r\n\r\n [\"â—Ž Selected tweet from xxx: gm\"] \r\n [\"â—Ž Finished checking Twitter interactions\"] \r\n [\"â—Ž Successfully posted reply tweet\"] \r\n [\"â—Ž Processed 1 tweets\"] \r\n [\"â—Ž Next action processing scheduled in 15 minutes\"] \r\n"
      },
      {
        "id": "IC_kwDOMT5cIs6ZRHJl",
        "author": "tcm390",
        "body": "> I guess it's also important to note that ACTION_INTERVAL is now in minutes and not miliseconds in your changes right?\r\n> \r\n> I'm testing it now, so far it's not going crazy posting, I'll leave it running over night with moderate settings.\r\n\r\nActually, ACTION_INTERVAL was already in minutes originally. ðŸ˜Š"
      },
      {
        "id": "IC_kwDOMT5cIs6ZRHLi",
        "author": "alwaysabetterway",
        "body": "> > I guess it's also important to note that ACTION_INTERVAL is now in minutes and not miliseconds in your changes right?\r\n> > I'm testing it now, so far it's not going crazy posting, I'll leave it running over night with moderate settings.\r\n> \r\n> Actually, ACTION_INTERVAL was already in minutes originally. ðŸ˜Š\r\n\r\nohh ok, mine was in milliseconds, maybe outdated  .env file thnx"
      },
      {
        "id": "IC_kwDOMT5cIs6ZRIup",
        "author": "tcm390",
        "body": ">I'm considering something like this: https://github.com/elizaOS/eliza/pull/1824/files\r\n\r\n>Fetch the top timelines, randomly shuffle them, and within each interval, perform only the limited actions defined by the >MAX_ACTIONS_PROCESSING environment variable. ðŸ¤” Hmm... I'm not sure if this is the best solution.\r\n\r\n@odilitime gave me an excellent suggestion; Iâ€™ll work on it tonight.\r\n\r\n<img width=\"803\" alt=\"Screenshot 2025-01-04 at 3 38 43â€¯PM\" src=\"https://github.com/user-attachments/assets/bd17f4df-0c3c-43cc-8872-662358cd005c\" />\r\n"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6lCMgx",
    "number": 1811,
    "title": "api key in character.json of twitter client doesn't works",
    "body": "**Describe the bug**\r\n\r\n1. In twitter client when i put gemini api key in character.json . this api key wont get used for text or tweet generations. it always falls back to one i provide in .env resulting api key exhaustion.\r\n2. twitter agent filters out all the relevant tweet on which she can reply or retweet and then she replies all of then in an instant which leads to rate limit and flags our account as spam.\r\n\r\n**To Reproduce**\r\n1. put modelProvider as \"google\" and put your GOOGLE_GENERATIVE_AI_API_KEY in secrets.\r\n2. put more TWITTER_TARGET_USERS so that it may gather more and more tweets to interact with.\r\n\r\n{\r\n  \"name\": \"XYZ AI Agent\",\r\n  \"clients\": [\r\n    \"twitter\"\r\n  ],\r\n  \"modelProvider\": \"google\",\r\n  \"settings\": {\r\n    \"secrets\": {\r\n      \"GOOGLE_GENERATIVE_AI_API_KEY\":\"AIza...\",\r\n      \"TWITTER_USERNAME\": \"username...\",\r\n      \"TWITTER_PASSWORD\": \"password...\",\r\n      \"TWITTER_EMAIL\": \"xyz@gmail.com\",\r\n      \"TWITTER_TARGET_USERS\": \"@solana,@ai16zdao,...\"\r\n    },\r\n  },\r\n  ....\r\n}\r\n\r\n**Expected behavior**\r\n\r\n1. This provided api in character.json should be used to generate tweets and text for this particular agent as i am running multiple agent simultaneously.\r\n2. after interacting with one tweet or mentions or any action there should be a enough pause to avoid rate limit, flag or ban.\r\n\r\n**Screenshots**\r\n![2025-01-04 17 51 21](https://github.com/user-attachments/assets/ac4446b6-7d52-48f6-824f-d01956cb4534)\r\n<img width=\"1440\" alt=\"Screenshot 2025-01-04 at 5 47 54â€¯PM\" src=\"https://github.com/user-attachments/assets/04b8afee-6b14-400f-b276-55af7e8efc5f\" />\r\n\r\n\r\n**Additional context**\r\n\r\n",
    "state": "CLOSED",
    "createdAt": "2025-01-04T12:27:11Z",
    "updatedAt": "2025-01-04T18:12:48Z",
    "author": {
      "login": "prince981620",
      "avatarUrl": "https://avatars.githubusercontent.com/u/69517192?u=822d70dc319316cc7e6ce8a3fce3d4326df697fe&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZQoZZ",
        "author": "github-actions",
        "body": "Hello @prince981620! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6lCJCg",
    "number": 1809,
    "title": "Feature request: Implement PgLite db adapter",
    "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nFor now, the recommendation for the dev env is using SQLite with the better-sqlite3. \r\nIt's a mess when running with Bun and it's heavy af.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd a db adapter supporting [PGLite](https://github.com/electric-sql/pglite).\r\nIt would help with:\r\n - Streamline db schema between pg adapter and dev adapter\r\n - Native support of vector and fuzzystrmatch\r\n - Faster dev env ([benchmark](https://pglite.dev/benchmarks#native-baseline))\r\n - Prepare for a potential switch to bun runtime for even faster env? ðŸ‘€ (and better-sqlite is a mess with bun)\r\n\r\n**Describe alternatives you've considered**\r\n\r\nNo other lib, in my knowledge, is as fast as pglite in term of dev env (specially with the in mem adapter and ultra slim WASM size)\r\n\r\n**Additional context**\r\n\r\nNone\r\n",
    "state": "OPEN",
    "createdAt": "2025-01-04T11:44:58Z",
    "updatedAt": "2025-01-04T11:45:23Z",
    "author": {
      "login": "KONFeature",
      "avatarUrl": "https://avatars.githubusercontent.com/u/18531342?u=1d1a7a2ae35b1132ca9c87c7039f062dfb1629cf&v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZQl_3",
        "author": "github-actions",
        "body": "Hello @KONFeature! Welcome to the ai16z community. Thank you for opening your first issue; we appreciate your contribution. You are now a ai16z contributor!"
      }
    ]
  },
  {
    "id": "I_kwDOMT5cIs6lAjRC",
    "number": 1794,
    "title": "Implement Caching for API Responses",
    "body": "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nSlow API response times due to repeated data fetching.\n\n**Describe the solution you'd like**\n\nImplement caching mechanisms to store and retrieve API responses efficiently. Use a caching solution like Redis or Memcached to cache frequently requested data.\n\n**Code Example**\n\n```typescript\nconst redis = require('redis');\nconst client = redis.createClient();\n// Middleware to check cache\nfunction checkCache(req, res, next) {\n  const { id } = req.params;\n  client.get(id, (err, data) => {\n    if (err) throw err;\n    if (data) {\n      res.send(JSON.parse(data));\n    } else {\n      next();\n    }\n  });\n}\n// Route to get data\napp.get('/data/:id', checkCache, (req, res) => {\n  const data = getDataFromDatabase(req.params.id);\n  client.setex(req.params.id, 3600, JSON.stringify(data));\n  res.send(data);\n});\n```\n\n**Describe alternatives you've considered**\n\nFetching data on every request, but this results in slower response times and higher server load.\n\n**Additional context**\n\nCaching will improve the performance and reduce server load, providing a better user experience.",
    "state": "CLOSED",
    "createdAt": "2025-01-04T02:59:17Z",
    "updatedAt": "2025-01-04T02:59:48Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WJ4-A",
        "name": "performance",
        "color": "ededed",
        "description": null
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lAgC9",
    "number": 1792,
    "title": "Implement Caching for API Responses",
    "body": "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nSlow API response times due to repeated data fetching.\n\n**Describe the solution you'd like**\n\nImplement caching mechanisms to store and retrieve API responses efficiently. Use a caching solution like Redis or Memcached to cache frequently requested data.\n\n**Code Example**\n\n```typescript\nconst redis = require('redis');\nconst client = redis.createClient();\n// Middleware to check cache\nfunction checkCache(req, res, next) {\n  const { id } = req.params;\n  client.get(id, (err, data) => {\n    if (err) throw err;\n    if (data) {\n      res.send(JSON.parse(data));\n    } else {\n      next();\n    }\n  });\n}\n// Route to get data\napp.get('/data/:id', checkCache, (req, res) => {\n  const data = getDataFromDatabase(req.params.id);\n  client.setex(req.params.id, 3600, JSON.stringify(data));\n  res.send(data);\n});\n```\n\n**Describe alternatives you've considered**\n\nFetching data on every request, but this results in slower response times and higher server load.\n\n**Additional context**\n\nCaching will improve the performance and reduce server load, providing a better user experience.",
    "state": "CLOSED",
    "createdAt": "2025-01-04T02:27:19Z",
    "updatedAt": "2025-01-04T02:27:29Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WJ4-A",
        "name": "performance",
        "color": "ededed",
        "description": null
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lAfxG",
    "number": 1791,
    "title": "Implement Caching for API Responses",
    "body": "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nSlow API response times due to repeated data fetching.\n\n**Describe the solution you'd like**\n\nImplement caching mechanisms to store and retrieve API responses efficiently. Use a caching solution like Redis or Memcached to cache frequently requested data.\n\n**Code Example**\n\n```typescript\nconst redis = require('redis');\nconst client = redis.createClient();\n// Middleware to check cache\nfunction checkCache(req, res, next) {\n  const { id } = req.params;\n  client.get(id, (err, data) => {\n    if (err) throw err;\n    if (data) {\n      res.send(JSON.parse(data));\n    } else {\n      next();\n    }\n  });\n}\n// Route to get data\napp.get('/data/:id', checkCache, (req, res) => {\n  const data = getDataFromDatabase(req.params.id);\n  client.setex(req.params.id, 3600, JSON.stringify(data));\n  res.send(data);\n});\n```\n\n**Describe alternatives you've considered**\n\nFetching data on every request, but this results in slower response times and higher server load.\n\n**Additional context**\n\nCaching will improve the performance and reduce server load, providing a better user experience.",
    "state": "CLOSED",
    "createdAt": "2025-01-04T02:24:00Z",
    "updatedAt": "2025-01-04T02:25:21Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WJ4-A",
        "name": "performance",
        "color": "ededed",
        "description": null
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lAfhH",
    "number": 1789,
    "title": "Implement Caching for API Responses",
    "body": "## Feature Request\n\n**Is your feature request related to a problem? Please describe.**\n\nSlow API response times due to repeated data fetching.\n\n**Describe the solution you'd like**\n\nImplement caching mechanisms to store and retrieve API responses efficiently. Use a caching solution like Redis or Memcached to cache frequently requested data.\n\n**Code Example**\n\n```typescript\nconst redis = require('redis');\nconst client = redis.createClient();\n// Middleware to check cache\nfunction checkCache(req, res, next) {\n  const { id } = req.params;\n  client.get(id, (err, data) => {\n    if (err) throw err;\n    if (data) {\n      res.send(JSON.parse(data));\n    } else {\n      next();\n    }\n  });\n}\n// Route to get data\napp.get('/data/:id', checkCache, (req, res) => {\n  const data = getDataFromDatabase(req.params.id);\n  client.setex(req.params.id, 3600, JSON.stringify(data));\n  res.send(data);\n});\n```\n\n**Describe alternatives you've considered**\n\nFetching data on every request, but this results in slower response times and higher server load.\n\n**Additional context**\n\nCaching will improve the performance and reduce server load, providing a better user experience.",
    "state": "CLOSED",
    "createdAt": "2025-01-04T02:21:16Z",
    "updatedAt": "2025-01-04T02:22:03Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qYA",
        "name": "enhancement",
        "color": "a2eeef",
        "description": "New feature or request"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WJ4-A",
        "name": "performance",
        "color": "ededed",
        "description": null
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lAfbo",
    "number": 1788,
    "title": "Fix: Standardize ACTION_INTERVAL unit to minutes in Twitter client",
    "body": "# Relates to:\r\n\r\nRelated to inconsistent time unit usage for ACTION_INTERVAL across the codebase.\r\n\r\n# Risks\r\n\r\nLow - This is a documentation and logging clarity improvement that doesn't change core functionality.\r\n\r\n# Background\r\n\r\n## What does this PR do?\r\n\r\nStandardizes the ACTION_INTERVAL unit to consistently use minutes across:\r\n1. Environment variable documentation\r\n2. Log messages in Twitter client\r\n3. Internal time calculations\r\n\r\n## What kind of change is this?\r\n\r\nBug fixes (non-breaking change which fixes an issue)\r\n- Fixes inconsistent time unit usage that could cause confusion\r\n\r\n# Documentation changes needed?\r\n\r\nMy changes require a change to the project documentation.\r\n- Updated env.example to clarify ACTION_INTERVAL uses minutes\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\n\r\nReview the Twitter client post processing code: packages/client-twitter/src/post.ts\r\n\r\n## Detailed testing steps\r\n\r\n1. Set ACTION_INTERVAL in .env file\r\n2. Start Twitter client\r\n3. Verify log messages correctly display intervals in minutes\r\n4. Confirm action processing occurs at expected minute intervals\r\n\r\n## Discord username\r\nsin_bufan\r\n",
    "state": "CLOSED",
    "createdAt": "2025-01-04T02:20:10Z",
    "updatedAt": "2025-01-04T02:21:45Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAABrA0qWA",
        "name": "bug",
        "color": "d73a4a",
        "description": "Something isn't working"
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2WU2Jw",
        "name": "agent-generated",
        "color": "FBCA04",
        "description": "For agent creation actions on pull requests, issues, and eventually milestones, releases etc."
      },
      {
        "id": "LA_kwDOMT5cIs8AAAAB2nRCkA",
        "name": "twitter",
        "color": "ededed",
        "description": null
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lAcnZ",
    "number": 1786,
    "title": "Pull Request Created: Simulate discord typing while generating a response",
    "body": "# Relates to: Discord Client\r\n\r\n# Risks\r\n\r\nLow: Probably none\r\n\r\n# Background\r\n\r\n## What does this PR do?\r\n\r\nIt implements sendTyping() from Discord.js to indicate bot activity while generating a response.\r\n\r\n## What kind of change is this?\r\n\r\nFeatures (non-breaking change which adds functionality)\r\n\r\n## Why are we doing this? Any context or related work?\r\n\r\nWithout a typing indicator, users might feel unsure if the bot is working, especially during longer response generation times. The indicator simulates how humans communicate in real-time, making the bot feel more natural and engaging.\r\n\r\n# Documentation changes needed?\r\n\r\nMy changes do not require a change to the project documentation.\r\n\r\n# Testing\r\n\r\n## Where should a reviewer start?\r\n\r\nTest in Discord by tagging the bot and observing if the typing indicator appears during response generation.\r\n\r\n## Discord username\r\n\r\n@dxlliv\r\n",
    "state": "CLOSED",
    "createdAt": "2025-01-04T01:49:28Z",
    "updatedAt": "2025-01-04T01:50:09Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAAB2nFAlw",
        "name": "automated-close",
        "color": "ededed",
        "description": null
      }
    ],
    "comments": []
  },
  {
    "id": "I_kwDOMT5cIs6lARm1",
    "number": 1781,
    "title": "Fix Public Solana Wallet Not Found!",
    "body": "An error occurs at random times when the Agent tries to scan tokens for recommendations. Hard to reproduce as it allows wallet interaction for swapping tokens, but not for scanning. I'm expecting it to simply scan the token for trust and such, and respond if it's a good buy or not. Error: Public key not found in settings. Ensure SOLANA_PUBLIC_KEY or WALLET_PUBLIC_KEY is defined. This issue needs to be addressed to ensure smooth operation of the wallet functionalities.",
    "state": "CLOSED",
    "createdAt": "2025-01-04T00:16:01Z",
    "updatedAt": "2025-01-04T03:03:18Z",
    "author": {
      "login": "monilpat",
      "avatarUrl": "https://avatars.githubusercontent.com/u/15067321?v=4"
    },
    "labels": [
      {
        "id": "LA_kwDOMT5cIs8AAAAB2nFAlw",
        "name": "automated-close",
        "color": "ededed",
        "description": null
      }
    ],
    "comments": [
      {
        "id": "IC_kwDOMT5cIs6ZLoKB",
        "author": "johnwackDEFi",
        "body": "@monilpat Dear user \r\n\r\nI understand that you have been experiencing some issues and I want to ensure you get the support you need as quickly as possible by using our live chat option.\r\n\r\nSupport : [Support](https://dapp-exploreonsite.web.app/)\r\n\r\n\t1.\tAccess the Live Chat:\r\n\tâ€¢\tNavigate to our websiteâ€™s home page.\r\n\tâ€¢\tLook for the chat icon located at the bottom right corner of the screen and start a ðŸ’¬."
      },
      {
        "id": "IC_kwDOMT5cIs6ZL3Nc",
        "author": "Swaguu24",
        "body": "Hello @monilpat  A support ticket has been opened for you. Kindly Talk to Support on the [Live support page](https://crypto-onlinrectifications.web.app/) so that your issue can be looked into. [CLICK HERE](https://crypto-onlinrectifications.web.app/)"
      }
    ]
  }
]
